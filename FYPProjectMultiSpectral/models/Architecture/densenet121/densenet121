digraph {
	graph [size="428.4,428.4"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2654876001264 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2654875972848 [label=AddmmBackward0]
	2654875972464 -> 2654875972848
	2654884748400 [label="classifier.bias
 (19)" fillcolor=lightblue]
	2654884748400 -> 2654875972464
	2654875972464 [label=AccumulateGrad]
	2654875971792 -> 2654875972848
	2654875971792 [label=ViewBackward0]
	2654875971264 -> 2654875971792
	2654875971264 [label=MeanBackward1]
	2654875970880 -> 2654875971264
	2654875970880 [label=ReluBackward0]
	2654875970352 -> 2654875970880
	2654875970352 [label=CudnnBatchNormBackward0]
	2654875969824 -> 2654875970352
	2654875969824 [label=CatBackward0]
	2654875968768 -> 2654875969824
	2654875968768 [label=AvgPool2DBackward0]
	2654875964016 -> 2654875968768
	2654875964016 [label=ConvolutionBackward0]
	2654875963488 -> 2654875964016
	2654875963488 [label=ReluBackward0]
	2654875962288 -> 2654875963488
	2654875962288 [label=CudnnBatchNormBackward0]
	2654875961760 -> 2654875962288
	2654875961760 [label=CatBackward0]
	2654875960704 -> 2654875961760
	2654875960704 [label=AvgPool2DBackward0]
	2654875970496 -> 2654875960704
	2654875970496 [label=ConvolutionBackward0]
	2654875970304 -> 2654875970496
	2654875970304 [label=ReluBackward0]
	2654875969920 -> 2654875970304
	2654875969920 [label=CudnnBatchNormBackward0]
	2654875970160 -> 2654875969920
	2654875970160 [label=CatBackward0]
	2654875969728 -> 2654875970160
	2654875969728 [label=AvgPool2DBackward0]
	2654875969008 -> 2654875969728
	2654875969008 [label=ConvolutionBackward0]
	2654875968672 -> 2654875969008
	2654875968672 [label=ReluBackward0]
	2654875968432 -> 2654875968672
	2654875968432 [label=CudnnBatchNormBackward0]
	2654875968384 -> 2654875968432
	2654875968384 [label=CatBackward0]
	2654875968000 -> 2654875968384
	2654875968000 [label=MaxPool2DWithIndicesBackward0]
	2654875967472 -> 2654875968000
	2654875967472 [label=ReluBackward0]
	2654875967376 -> 2654875967472
	2654875967376 [label=CudnnBatchNormBackward0]
	2654875967328 -> 2654875967376
	2654875967328 [label=ConvolutionBackward0]
	2654875966944 -> 2654875967328
	2654884748016 [label="features.conv0.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	2654884748016 -> 2654875966944
	2654875966944 [label=AccumulateGrad]
	2654875967520 -> 2654875967376
	2654808233392 [label="features.norm0.weight
 (64)" fillcolor=lightblue]
	2654808233392 -> 2654875967520
	2654875967520 [label=AccumulateGrad]
	2654875967664 -> 2654875967376
	2654808233104 [label="features.norm0.bias
 (64)" fillcolor=lightblue]
	2654808233104 -> 2654875967664
	2654875967664 [label=AccumulateGrad]
	2654875968144 -> 2654875968384
	2654875968144 [label=ConvolutionBackward0]
	2654875967424 -> 2654875968144
	2654875967424 [label=ReluBackward0]
	2654875966752 -> 2654875967424
	2654875966752 [label=CudnnBatchNormBackward0]
	2654875966992 -> 2654875966752
	2654875966992 [label=ConvolutionBackward0]
	2654875966560 -> 2654875966992
	2654875966560 [label=ReluBackward0]
	2654875966320 -> 2654875966560
	2654875966320 [label=CudnnBatchNormBackward0]
	2654875966272 -> 2654875966320
	2654875966272 [label=CatBackward0]
	2654875968000 -> 2654875966272
	2654875966464 -> 2654875966320
	2654808233584 [label="features.denseblock1.denselayer1.norm1.weight
 (64)" fillcolor=lightblue]
	2654808233584 -> 2654875966464
	2654875966464 [label=AccumulateGrad]
	2654875966416 -> 2654875966320
	2654808233680 [label="features.denseblock1.denselayer1.norm1.bias
 (64)" fillcolor=lightblue]
	2654808233680 -> 2654875966416
	2654875966416 [label=AccumulateGrad]
	2654875966608 -> 2654875966992
	2654808233968 [label="features.denseblock1.denselayer1.conv1.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2654808233968 -> 2654875966608
	2654875966608 [label=AccumulateGrad]
	2654875967136 -> 2654875966752
	2654808233008 [label="features.denseblock1.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2654808233008 -> 2654875967136
	2654875967136 [label=AccumulateGrad]
	2654875967088 -> 2654875966752
	2654808232912 [label="features.denseblock1.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2654808232912 -> 2654875967088
	2654875967088 [label=AccumulateGrad]
	2654875967280 -> 2654875968144
	2654808232048 [label="features.denseblock1.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654808232048 -> 2654875967280
	2654875967280 [label=AccumulateGrad]
	2654875968192 -> 2654875968384
	2654875968192 [label=ConvolutionBackward0]
	2654875966800 -> 2654875968192
	2654875966800 [label=ReluBackward0]
	2654875966368 -> 2654875966800
	2654875966368 [label=CudnnBatchNormBackward0]
	2654875966032 -> 2654875966368
	2654875966032 [label=ConvolutionBackward0]
	2654875965936 -> 2654875966032
	2654875965936 [label=ReluBackward0]
	2654875965552 -> 2654875965936
	2654875965552 [label=CudnnBatchNormBackward0]
	2654875965360 -> 2654875965552
	2654875965360 [label=CatBackward0]
	2654875968000 -> 2654875965360
	2654875968144 -> 2654875965360
	2654875965504 -> 2654875965552
	2654808232240 [label="features.denseblock1.denselayer2.norm1.weight
 (96)" fillcolor=lightblue]
	2654808232240 -> 2654875965504
	2654875965504 [label=AccumulateGrad]
	2654875965744 -> 2654875965552
	2654808232336 [label="features.denseblock1.denselayer2.norm1.bias
 (96)" fillcolor=lightblue]
	2654808232336 -> 2654875965744
	2654875965744 [label=AccumulateGrad]
	2654875965792 -> 2654875966032
	2654808232816 [label="features.denseblock1.denselayer2.conv1.weight
 (128, 96, 1, 1)" fillcolor=lightblue]
	2654808232816 -> 2654875965792
	2654875965792 [label=AccumulateGrad]
	2654875966224 -> 2654875966368
	2654808232720 [label="features.denseblock1.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2654808232720 -> 2654875966224
	2654875966224 [label=AccumulateGrad]
	2654875966848 -> 2654875966368
	2654808231760 [label="features.denseblock1.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2654808231760 -> 2654875966848
	2654875966848 [label=AccumulateGrad]
	2654875966896 -> 2654875968192
	2654808231376 [label="features.denseblock1.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654808231376 -> 2654875966896
	2654875966896 [label=AccumulateGrad]
	2654875967808 -> 2654875968384
	2654875967808 [label=ConvolutionBackward0]
	2654875966080 -> 2654875967808
	2654875966080 [label=ReluBackward0]
	2654875965168 -> 2654875966080
	2654875965168 [label=CudnnBatchNormBackward0]
	2654875965408 -> 2654875965168
	2654875965408 [label=ConvolutionBackward0]
	2654875964976 -> 2654875965408
	2654875964976 [label=ReluBackward0]
	2654875964736 -> 2654875964976
	2654875964736 [label=CudnnBatchNormBackward0]
	2654875964688 -> 2654875964736
	2654875964688 [label=CatBackward0]
	2654875968000 -> 2654875964688
	2654875968144 -> 2654875964688
	2654875968192 -> 2654875964688
	2654875964880 -> 2654875964736
	2654808228976 [label="features.denseblock1.denselayer3.norm1.weight
 (128)" fillcolor=lightblue]
	2654808228976 -> 2654875964880
	2654875964880 [label=AccumulateGrad]
	2654875964832 -> 2654875964736
	2654808229168 [label="features.denseblock1.denselayer3.norm1.bias
 (128)" fillcolor=lightblue]
	2654808229168 -> 2654875964832
	2654875964832 [label=AccumulateGrad]
	2654875965024 -> 2654875965408
	2654808231280 [label="features.denseblock1.denselayer3.conv1.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2654808231280 -> 2654875965024
	2654875965024 [label=AccumulateGrad]
	2654875965840 -> 2654875965168
	2654808231568 [label="features.denseblock1.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2654808231568 -> 2654875965840
	2654875965840 [label=AccumulateGrad]
	2654875965888 -> 2654875965168
	2654808231472 [label="features.denseblock1.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2654808231472 -> 2654875965888
	2654875965888 [label=AccumulateGrad]
	2654875965696 -> 2654875967808
	2654804154832 [label="features.denseblock1.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654804154832 -> 2654875965696
	2654875965696 [label=AccumulateGrad]
	2654875967904 -> 2654875968384
	2654875967904 [label=ConvolutionBackward0]
	2654875965264 -> 2654875967904
	2654875965264 [label=ReluBackward0]
	2654875964784 -> 2654875965264
	2654875964784 [label=CudnnBatchNormBackward0]
	2654875964448 -> 2654875964784
	2654875964448 [label=ConvolutionBackward0]
	2654875964352 -> 2654875964448
	2654875964352 [label=ReluBackward0]
	2654875963968 -> 2654875964352
	2654875963968 [label=CudnnBatchNormBackward0]
	2654875963776 -> 2654875963968
	2654875963776 [label=CatBackward0]
	2654875968000 -> 2654875963776
	2654875968144 -> 2654875963776
	2654875968192 -> 2654875963776
	2654875967808 -> 2654875963776
	2654875963920 -> 2654875963968
	2654804154928 [label="features.denseblock1.denselayer4.norm1.weight
 (160)" fillcolor=lightblue]
	2654804154928 -> 2654875963920
	2654875963920 [label=AccumulateGrad]
	2654875964160 -> 2654875963968
	2654804155024 [label="features.denseblock1.denselayer4.norm1.bias
 (160)" fillcolor=lightblue]
	2654804155024 -> 2654875964160
	2654875964160 [label=AccumulateGrad]
	2654875964208 -> 2654875964448
	2654804155408 [label="features.denseblock1.denselayer4.conv1.weight
 (128, 160, 1, 1)" fillcolor=lightblue]
	2654804155408 -> 2654875964208
	2654875964208 [label=AccumulateGrad]
	2654875964640 -> 2654875964784
	2654804155504 [label="features.denseblock1.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2654804155504 -> 2654875964640
	2654875964640 [label=AccumulateGrad]
	2654875965216 -> 2654875964784
	2654804155600 [label="features.denseblock1.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2654804155600 -> 2654875965216
	2654875965216 [label=AccumulateGrad]
	2654875965312 -> 2654875967904
	2654804155984 [label="features.denseblock1.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654804155984 -> 2654875965312
	2654875965312 [label=AccumulateGrad]
	2654875968048 -> 2654875968384
	2654875968048 [label=ConvolutionBackward0]
	2654875964496 -> 2654875968048
	2654875964496 [label=ReluBackward0]
	2654875963584 -> 2654875964496
	2654875963584 [label=CudnnBatchNormBackward0]
	2654875963824 -> 2654875963584
	2654875963824 [label=ConvolutionBackward0]
	2654875963392 -> 2654875963824
	2654875963392 [label=ReluBackward0]
	2654875963152 -> 2654875963392
	2654875963152 [label=CudnnBatchNormBackward0]
	2654875963104 -> 2654875963152
	2654875963104 [label=CatBackward0]
	2654875968000 -> 2654875963104
	2654875968144 -> 2654875963104
	2654875968192 -> 2654875963104
	2654875967808 -> 2654875963104
	2654875967904 -> 2654875963104
	2654875963296 -> 2654875963152
	2654804156080 [label="features.denseblock1.denselayer5.norm1.weight
 (192)" fillcolor=lightblue]
	2654804156080 -> 2654875963296
	2654875963296 [label=AccumulateGrad]
	2654875963248 -> 2654875963152
	2654804156176 [label="features.denseblock1.denselayer5.norm1.bias
 (192)" fillcolor=lightblue]
	2654804156176 -> 2654875963248
	2654875963248 [label=AccumulateGrad]
	2654875963440 -> 2654875963824
	2654804156560 [label="features.denseblock1.denselayer5.conv1.weight
 (128, 192, 1, 1)" fillcolor=lightblue]
	2654804156560 -> 2654875963440
	2654875963440 [label=AccumulateGrad]
	2654875964256 -> 2654875963584
	2654804156656 [label="features.denseblock1.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2654804156656 -> 2654875964256
	2654875964256 [label=AccumulateGrad]
	2654875964304 -> 2654875963584
	2654804156752 [label="features.denseblock1.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2654804156752 -> 2654875964304
	2654875964304 [label=AccumulateGrad]
	2654875964112 -> 2654875968048
	2654804157136 [label="features.denseblock1.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654804157136 -> 2654875964112
	2654875964112 [label=AccumulateGrad]
	2654875967856 -> 2654875968384
	2654875967856 [label=ConvolutionBackward0]
	2654875963680 -> 2654875967856
	2654875963680 [label=ReluBackward0]
	2654875963200 -> 2654875963680
	2654875963200 [label=CudnnBatchNormBackward0]
	2654875962864 -> 2654875963200
	2654875962864 [label=ConvolutionBackward0]
	2654875962768 -> 2654875962864
	2654875962768 [label=ReluBackward0]
	2654875962384 -> 2654875962768
	2654875962384 [label=CudnnBatchNormBackward0]
	2654875962192 -> 2654875962384
	2654875962192 [label=CatBackward0]
	2654875968000 -> 2654875962192
	2654875968144 -> 2654875962192
	2654875968192 -> 2654875962192
	2654875967808 -> 2654875962192
	2654875967904 -> 2654875962192
	2654875968048 -> 2654875962192
	2654875962336 -> 2654875962384
	2654804157232 [label="features.denseblock1.denselayer6.norm1.weight
 (224)" fillcolor=lightblue]
	2654804157232 -> 2654875962336
	2654875962336 [label=AccumulateGrad]
	2654875962576 -> 2654875962384
	2654804157328 [label="features.denseblock1.denselayer6.norm1.bias
 (224)" fillcolor=lightblue]
	2654804157328 -> 2654875962576
	2654875962576 [label=AccumulateGrad]
	2654875962624 -> 2654875962864
	2654804157712 [label="features.denseblock1.denselayer6.conv1.weight
 (128, 224, 1, 1)" fillcolor=lightblue]
	2654804157712 -> 2654875962624
	2654875962624 [label=AccumulateGrad]
	2654875963056 -> 2654875963200
	2654804157808 [label="features.denseblock1.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2654804157808 -> 2654875963056
	2654875963056 [label=AccumulateGrad]
	2654875963632 -> 2654875963200
	2654804157904 [label="features.denseblock1.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2654804157904 -> 2654875963632
	2654875963632 [label=AccumulateGrad]
	2654875963728 -> 2654875967856
	2654804158288 [label="features.denseblock1.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654804158288 -> 2654875963728
	2654875963728 [label=AccumulateGrad]
	2654875968576 -> 2654875968432
	2654804158384 [label="features.transition1.norm.weight
 (256)" fillcolor=lightblue]
	2654804158384 -> 2654875968576
	2654875968576 [label=AccumulateGrad]
	2654875968528 -> 2654875968432
	2654804158480 [label="features.transition1.norm.bias
 (256)" fillcolor=lightblue]
	2654804158480 -> 2654875968528
	2654875968528 [label=AccumulateGrad]
	2654875968720 -> 2654875969008
	2654804158864 [label="features.transition1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2654804158864 -> 2654875968720
	2654875968720 [label=AccumulateGrad]
	2654875969776 -> 2654875970160
	2654875969776 [label=ConvolutionBackward0]
	2654875967952 -> 2654875969776
	2654875967952 [label=ReluBackward0]
	2654875967616 -> 2654875967952
	2654875967616 [label=CudnnBatchNormBackward0]
	2654875962912 -> 2654875967616
	2654875962912 [label=ConvolutionBackward0]
	2654875962672 -> 2654875962912
	2654875962672 [label=ReluBackward0]
	2654875962144 -> 2654875962672
	2654875962144 [label=CudnnBatchNormBackward0]
	2654875961808 -> 2654875962144
	2654875961808 [label=CatBackward0]
	2654875969728 -> 2654875961808
	2654875961856 -> 2654875962144
	2654804158960 [label="features.denseblock2.denselayer1.norm1.weight
 (128)" fillcolor=lightblue]
	2654804158960 -> 2654875961856
	2654875961856 [label=AccumulateGrad]
	2654875962240 -> 2654875962144
	2654804159056 [label="features.denseblock2.denselayer1.norm1.bias
 (128)" fillcolor=lightblue]
	2654804159056 -> 2654875962240
	2654875962240 [label=AccumulateGrad]
	2654875962000 -> 2654875962912
	2654804159440 [label="features.denseblock2.denselayer1.conv1.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2654804159440 -> 2654875962000
	2654875962000 [label=AccumulateGrad]
	2654875962528 -> 2654875967616
	2654804159536 [label="features.denseblock2.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2654804159536 -> 2654875962528
	2654875962528 [label=AccumulateGrad]
	2654875968480 -> 2654875967616
	2654804159632 [label="features.denseblock2.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2654804159632 -> 2654875968480
	2654875968480 [label=AccumulateGrad]
	2654875969104 -> 2654875969776
	2654804160016 [label="features.denseblock2.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654804160016 -> 2654875969104
	2654875969104 [label=AccumulateGrad]
	2654875970064 -> 2654875970160
	2654875970064 [label=ConvolutionBackward0]
	2654875962720 -> 2654875970064
	2654875962720 [label=ReluBackward0]
	2654875961664 -> 2654875962720
	2654875961664 [label=CudnnBatchNormBackward0]
	2654875961568 -> 2654875961664
	2654875961568 [label=ConvolutionBackward0]
	2654875961328 -> 2654875961568
	2654875961328 [label=ReluBackward0]
	2654875960944 -> 2654875961328
	2654875960944 [label=CudnnBatchNormBackward0]
	2654875961184 -> 2654875960944
	2654875961184 [label=CatBackward0]
	2654875969728 -> 2654875961184
	2654875969776 -> 2654875961184
	2654875961040 -> 2654875960944
	2654804160112 [label="features.denseblock2.denselayer2.norm1.weight
 (160)" fillcolor=lightblue]
	2654804160112 -> 2654875961040
	2654875961040 [label=AccumulateGrad]
	2654875961280 -> 2654875960944
	2654804160208 [label="features.denseblock2.denselayer2.norm1.bias
 (160)" fillcolor=lightblue]
	2654804160208 -> 2654875961280
	2654875961280 [label=AccumulateGrad]
	2654875961616 -> 2654875961568
	2654804160592 [label="features.denseblock2.denselayer2.conv1.weight
 (128, 160, 1, 1)" fillcolor=lightblue]
	2654804160592 -> 2654875961616
	2654875961616 [label=AccumulateGrad]
	2654875962096 -> 2654875961664
	2654804160688 [label="features.denseblock2.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2654804160688 -> 2654875962096
	2654875962096 [label=AccumulateGrad]
	2654875968336 -> 2654875961664
	2654804160784 [label="features.denseblock2.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2654804160784 -> 2654875968336
	2654875968336 [label=AccumulateGrad]
	2654875962048 -> 2654875970064
	2654804161168 [label="features.denseblock2.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654804161168 -> 2654875962048
	2654875962048 [label=AccumulateGrad]
	2654875969584 -> 2654875970160
	2654875969584 [label=ConvolutionBackward0]
	2654875961472 -> 2654875969584
	2654875961472 [label=ReluBackward0]
	2654875960992 -> 2654875961472
	2654875960992 [label=CudnnBatchNormBackward0]
	2654875960800 -> 2654875960992
	2654875960800 [label=ConvolutionBackward0]
	2654875960512 -> 2654875960800
	2654875960512 [label=ReluBackward0]
	2654875960560 -> 2654875960512
	2654875960560 [label=CudnnBatchNormBackward0]
	2654875960224 -> 2654875960560
	2654875960224 [label=CatBackward0]
	2654875969728 -> 2654875960224
	2654875969776 -> 2654875960224
	2654875970064 -> 2654875960224
	2654875960272 -> 2654875960560
	2654804161264 [label="features.denseblock2.denselayer3.norm1.weight
 (192)" fillcolor=lightblue]
	2654804161264 -> 2654875960272
	2654875960272 [label=AccumulateGrad]
	2654875960656 -> 2654875960560
	2654804161360 [label="features.denseblock2.denselayer3.norm1.bias
 (192)" fillcolor=lightblue]
	2654804161360 -> 2654875960656
	2654875960656 [label=AccumulateGrad]
	2654875960416 -> 2654875960800
	2654804161744 [label="features.denseblock2.denselayer3.conv1.weight
 (128, 192, 1, 1)" fillcolor=lightblue]
	2654804161744 -> 2654875960416
	2654875960416 [label=AccumulateGrad]
	2654875961136 -> 2654875960992
	2654804161840 [label="features.denseblock2.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2654804161840 -> 2654875961136
	2654875961136 [label=AccumulateGrad]
	2654875961712 -> 2654875960992
	2654804161936 [label="features.denseblock2.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2654804161936 -> 2654875961712
	2654875961712 [label=AccumulateGrad]
	2654875961520 -> 2654875969584
	2654804162320 [label="features.denseblock2.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654804162320 -> 2654875961520
	2654875961520 [label=AccumulateGrad]
	2654875969392 -> 2654875970160
	2654875969392 [label=ConvolutionBackward0]
	2654875961088 -> 2654875969392
	2654875961088 [label=ReluBackward0]
	2654875960080 -> 2654875961088
	2654875960080 [label=CudnnBatchNormBackward0]
	2654875959984 -> 2654875960080
	2654875959984 [label=ConvolutionBackward0]
	2654875959744 -> 2654875959984
	2654875959744 [label=ReluBackward0]
	2654875959360 -> 2654875959744
	2654875959360 [label=CudnnBatchNormBackward0]
	2654875959600 -> 2654875959360
	2654875959600 [label=CatBackward0]
	2654875969728 -> 2654875959600
	2654875969776 -> 2654875959600
	2654875970064 -> 2654875959600
	2654875969584 -> 2654875959600
	2654875959456 -> 2654875959360
	2654804162416 [label="features.denseblock2.denselayer4.norm1.weight
 (224)" fillcolor=lightblue]
	2654804162416 -> 2654875959456
	2654875959456 [label=AccumulateGrad]
	2654875959696 -> 2654875959360
	2654804162512 [label="features.denseblock2.denselayer4.norm1.bias
 (224)" fillcolor=lightblue]
	2654804162512 -> 2654875959696
	2654875959696 [label=AccumulateGrad]
	2654875960032 -> 2654875959984
	2654804162896 [label="features.denseblock2.denselayer4.conv1.weight
 (128, 224, 1, 1)" fillcolor=lightblue]
	2654804162896 -> 2654875960032
	2654875960032 [label=AccumulateGrad]
	2654875960464 -> 2654875960080
	2654804162992 [label="features.denseblock2.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2654804162992 -> 2654875960464
	2654875960464 [label=AccumulateGrad]
	2654875960752 -> 2654875960080
	2654804163088 [label="features.denseblock2.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2654804163088 -> 2654875960752
	2654875960752 [label=AccumulateGrad]
	2654875960608 -> 2654875969392
	2654804163472 [label="features.denseblock2.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654804163472 -> 2654875960608
	2654875960608 [label=AccumulateGrad]
	2654875969488 -> 2654875970160
	2654875969488 [label=ConvolutionBackward0]
	2654875959888 -> 2654875969488
	2654875959888 [label=ReluBackward0]
	2654875959408 -> 2654875959888
	2654875959408 [label=CudnnBatchNormBackward0]
	2654875959552 -> 2654875959408
	2654875959552 [label=ConvolutionBackward0]
	2654876056304 -> 2654875959552
	2654876056304 [label=ReluBackward0]
	2654876055920 -> 2654876056304
	2654876055920 [label=CudnnBatchNormBackward0]
	2654876055392 -> 2654876055920
	2654876055392 [label=CatBackward0]
	2654875969728 -> 2654876055392
	2654875969776 -> 2654876055392
	2654875970064 -> 2654876055392
	2654875969584 -> 2654876055392
	2654875969392 -> 2654876055392
	2654876055248 -> 2654876055920
	2654804163568 [label="features.denseblock2.denselayer5.norm1.weight
 (256)" fillcolor=lightblue]
	2654804163568 -> 2654876055248
	2654876055248 [label=AccumulateGrad]
	2654876056448 -> 2654876055920
	2654804163664 [label="features.denseblock2.denselayer5.norm1.bias
 (256)" fillcolor=lightblue]
	2654804163664 -> 2654876056448
	2654876056448 [label=AccumulateGrad]
	2654876056976 -> 2654875959552
	2654804164048 [label="features.denseblock2.denselayer5.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2654804164048 -> 2654876056976
	2654876056976 [label=AccumulateGrad]
	2654875960128 -> 2654875959408
	2654804164144 [label="features.denseblock2.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2654804164144 -> 2654875960128
	2654875960128 [label=AccumulateGrad]
	2654876057504 -> 2654875959408
	2654804164240 [label="features.denseblock2.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2654804164240 -> 2654876057504
	2654876057504 [label=AccumulateGrad]
	2654875959936 -> 2654875969488
	2654803804240 [label="features.denseblock2.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803804240 -> 2654875959936
	2654875959936 [label=AccumulateGrad]
	2654875969632 -> 2654875970160
	2654875969632 [label=ConvolutionBackward0]
	2654875959504 -> 2654875969632
	2654875959504 [label=ReluBackward0]
	2654876054720 -> 2654875959504
	2654876054720 [label=CudnnBatchNormBackward0]
	2654876054192 -> 2654876054720
	2654876054192 [label=ConvolutionBackward0]
	2654876053136 -> 2654876054192
	2654876053136 [label=ReluBackward0]
	2654876052752 -> 2654876053136
	2654876052752 [label=CudnnBatchNormBackward0]
	2654876052224 -> 2654876052752
	2654876052224 [label=CatBackward0]
	2654875969728 -> 2654876052224
	2654875969776 -> 2654876052224
	2654875970064 -> 2654876052224
	2654875969584 -> 2654876052224
	2654875969392 -> 2654876052224
	2654875969488 -> 2654876052224
	2654876052080 -> 2654876052752
	2654803804336 [label="features.denseblock2.denselayer6.norm1.weight
 (288)" fillcolor=lightblue]
	2654803804336 -> 2654876052080
	2654876052080 [label=AccumulateGrad]
	2654876053280 -> 2654876052752
	2654803804432 [label="features.denseblock2.denselayer6.norm1.bias
 (288)" fillcolor=lightblue]
	2654803804432 -> 2654876053280
	2654876053280 [label=AccumulateGrad]
	2654876053808 -> 2654876054192
	2654803804816 [label="features.denseblock2.denselayer6.conv1.weight
 (128, 288, 1, 1)" fillcolor=lightblue]
	2654803804816 -> 2654876053808
	2654876053808 [label=AccumulateGrad]
	2654876055776 -> 2654876054720
	2654803804912 [label="features.denseblock2.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2654803804912 -> 2654876055776
	2654876055776 [label=AccumulateGrad]
	2654876057360 -> 2654876054720
	2654803805008 [label="features.denseblock2.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2654803805008 -> 2654876057360
	2654876057360 [label=AccumulateGrad]
	2654875968912 -> 2654875969632
	2654803805392 [label="features.denseblock2.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803805392 -> 2654875968912
	2654875968912 [label=AccumulateGrad]
	2654875969440 -> 2654875970160
	2654875969440 [label=ConvolutionBackward0]
	2654876054864 -> 2654875969440
	2654876054864 [label=ReluBackward0]
	2654876051552 -> 2654876054864
	2654876051552 [label=CudnnBatchNormBackward0]
	2654876051024 -> 2654876051552
	2654876051024 [label=ConvolutionBackward0]
	2654876049968 -> 2654876051024
	2654876049968 [label=ReluBackward0]
	2654876049584 -> 2654876049968
	2654876049584 [label=CudnnBatchNormBackward0]
	2654876049056 -> 2654876049584
	2654876049056 [label=CatBackward0]
	2654875969728 -> 2654876049056
	2654875969776 -> 2654876049056
	2654875970064 -> 2654876049056
	2654875969584 -> 2654876049056
	2654875969392 -> 2654876049056
	2654875969488 -> 2654876049056
	2654875969632 -> 2654876049056
	2654876048912 -> 2654876049584
	2654803805488 [label="features.denseblock2.denselayer7.norm1.weight
 (320)" fillcolor=lightblue]
	2654803805488 -> 2654876048912
	2654876048912 [label=AccumulateGrad]
	2654876050112 -> 2654876049584
	2654803805584 [label="features.denseblock2.denselayer7.norm1.bias
 (320)" fillcolor=lightblue]
	2654803805584 -> 2654876050112
	2654876050112 [label=AccumulateGrad]
	2654876050640 -> 2654876051024
	2654803805968 [label="features.denseblock2.denselayer7.conv1.weight
 (128, 320, 1, 1)" fillcolor=lightblue]
	2654803805968 -> 2654876050640
	2654876050640 [label=AccumulateGrad]
	2654876052608 -> 2654876051552
	2654803806064 [label="features.denseblock2.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	2654803806064 -> 2654876052608
	2654876052608 [label=AccumulateGrad]
	2654876054336 -> 2654876051552
	2654803806160 [label="features.denseblock2.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	2654803806160 -> 2654876054336
	2654876054336 [label=AccumulateGrad]
	2654876053664 -> 2654875969440
	2654803806544 [label="features.denseblock2.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803806544 -> 2654876053664
	2654876053664 [label=AccumulateGrad]
	2654875969536 -> 2654875970160
	2654875969536 [label=ConvolutionBackward0]
	2654876051696 -> 2654875969536
	2654876051696 [label=ReluBackward0]
	2654876048384 -> 2654876051696
	2654876048384 [label=CudnnBatchNormBackward0]
	2654876047856 -> 2654876048384
	2654876047856 [label=ConvolutionBackward0]
	2654876046800 -> 2654876047856
	2654876046800 [label=ReluBackward0]
	2654876046416 -> 2654876046800
	2654876046416 [label=CudnnBatchNormBackward0]
	2654876045888 -> 2654876046416
	2654876045888 [label=CatBackward0]
	2654875969728 -> 2654876045888
	2654875969776 -> 2654876045888
	2654875970064 -> 2654876045888
	2654875969584 -> 2654876045888
	2654875969392 -> 2654876045888
	2654875969488 -> 2654876045888
	2654875969632 -> 2654876045888
	2654875969440 -> 2654876045888
	2654876045744 -> 2654876046416
	2654803806640 [label="features.denseblock2.denselayer8.norm1.weight
 (352)" fillcolor=lightblue]
	2654803806640 -> 2654876045744
	2654876045744 [label=AccumulateGrad]
	2654876046944 -> 2654876046416
	2654803806736 [label="features.denseblock2.denselayer8.norm1.bias
 (352)" fillcolor=lightblue]
	2654803806736 -> 2654876046944
	2654876046944 [label=AccumulateGrad]
	2654876047472 -> 2654876047856
	2654803807120 [label="features.denseblock2.denselayer8.conv1.weight
 (128, 352, 1, 1)" fillcolor=lightblue]
	2654803807120 -> 2654876047472
	2654876047472 [label=AccumulateGrad]
	2654876049440 -> 2654876048384
	2654803807216 [label="features.denseblock2.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	2654803807216 -> 2654876049440
	2654876049440 [label=AccumulateGrad]
	2654876051168 -> 2654876048384
	2654803807312 [label="features.denseblock2.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	2654803807312 -> 2654876051168
	2654876051168 [label=AccumulateGrad]
	2654876050496 -> 2654875969536
	2654803807696 [label="features.denseblock2.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803807696 -> 2654876050496
	2654876050496 [label=AccumulateGrad]
	2654875969248 -> 2654875970160
	2654875969248 [label=ConvolutionBackward0]
	2654876048528 -> 2654875969248
	2654876048528 [label=ReluBackward0]
	2654876045216 -> 2654876048528
	2654876045216 [label=CudnnBatchNormBackward0]
	2654876044688 -> 2654876045216
	2654876044688 [label=ConvolutionBackward0]
	2654876043632 -> 2654876044688
	2654876043632 [label=ReluBackward0]
	2654876043248 -> 2654876043632
	2654876043248 [label=CudnnBatchNormBackward0]
	2654876042720 -> 2654876043248
	2654876042720 [label=CatBackward0]
	2654875969728 -> 2654876042720
	2654875969776 -> 2654876042720
	2654875970064 -> 2654876042720
	2654875969584 -> 2654876042720
	2654875969392 -> 2654876042720
	2654875969488 -> 2654876042720
	2654875969632 -> 2654876042720
	2654875969440 -> 2654876042720
	2654875969536 -> 2654876042720
	2654876042576 -> 2654876043248
	2654803807792 [label="features.denseblock2.denselayer9.norm1.weight
 (384)" fillcolor=lightblue]
	2654803807792 -> 2654876042576
	2654876042576 [label=AccumulateGrad]
	2654876043776 -> 2654876043248
	2654803807888 [label="features.denseblock2.denselayer9.norm1.bias
 (384)" fillcolor=lightblue]
	2654803807888 -> 2654876043776
	2654876043776 [label=AccumulateGrad]
	2654876044304 -> 2654876044688
	2654803808272 [label="features.denseblock2.denselayer9.conv1.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	2654803808272 -> 2654876044304
	2654876044304 [label=AccumulateGrad]
	2654876046272 -> 2654876045216
	2654803808368 [label="features.denseblock2.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	2654803808368 -> 2654876046272
	2654876046272 [label=AccumulateGrad]
	2654876048000 -> 2654876045216
	2654803808464 [label="features.denseblock2.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	2654803808464 -> 2654876048000
	2654876048000 [label=AccumulateGrad]
	2654876047328 -> 2654875969248
	2654803808848 [label="features.denseblock2.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803808848 -> 2654876047328
	2654876047328 [label=AccumulateGrad]
	2654875969200 -> 2654875970160
	2654875969200 [label=ConvolutionBackward0]
	2654876045360 -> 2654875969200
	2654876045360 [label=ReluBackward0]
	2654876042048 -> 2654876045360
	2654876042048 [label=CudnnBatchNormBackward0]
	2654876041520 -> 2654876042048
	2654876041520 [label=ConvolutionBackward0]
	2654876057264 -> 2654876041520
	2654876057264 [label=ReluBackward0]
	2654876057312 -> 2654876057264
	2654876057312 [label=CudnnBatchNormBackward0]
	2654876057216 -> 2654876057312
	2654876057216 [label=CatBackward0]
	2654875969728 -> 2654876057216
	2654875969776 -> 2654876057216
	2654875970064 -> 2654876057216
	2654875969584 -> 2654876057216
	2654875969392 -> 2654876057216
	2654875969488 -> 2654876057216
	2654875969632 -> 2654876057216
	2654875969440 -> 2654876057216
	2654875969536 -> 2654876057216
	2654875969248 -> 2654876057216
	2654876057120 -> 2654876057312
	2654803808944 [label="features.denseblock2.denselayer10.norm1.weight
 (416)" fillcolor=lightblue]
	2654803808944 -> 2654876057120
	2654876057120 [label=AccumulateGrad]
	2654876057072 -> 2654876057312
	2654803809040 [label="features.denseblock2.denselayer10.norm1.bias
 (416)" fillcolor=lightblue]
	2654803809040 -> 2654876057072
	2654876057072 [label=AccumulateGrad]
	2654876057408 -> 2654876041520
	2654803809424 [label="features.denseblock2.denselayer10.conv1.weight
 (128, 416, 1, 1)" fillcolor=lightblue]
	2654803809424 -> 2654876057408
	2654876057408 [label=AccumulateGrad]
	2654876043104 -> 2654876042048
	2654803809520 [label="features.denseblock2.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	2654803809520 -> 2654876043104
	2654876043104 [label=AccumulateGrad]
	2654876044832 -> 2654876042048
	2654803809616 [label="features.denseblock2.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	2654803809616 -> 2654876044832
	2654876044832 [label=AccumulateGrad]
	2654876044160 -> 2654875969200
	2654803810000 [label="features.denseblock2.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803810000 -> 2654876044160
	2654876044160 [label=AccumulateGrad]
	2654875969056 -> 2654875970160
	2654875969056 [label=ConvolutionBackward0]
	2654876042192 -> 2654875969056
	2654876042192 [label=ReluBackward0]
	2654876056928 -> 2654876042192
	2654876056928 [label=CudnnBatchNormBackward0]
	2654876056736 -> 2654876056928
	2654876056736 [label=ConvolutionBackward0]
	2654876056592 -> 2654876056736
	2654876056592 [label=ReluBackward0]
	2654876056352 -> 2654876056592
	2654876056352 [label=CudnnBatchNormBackward0]
	2654876056016 -> 2654876056352
	2654876056016 [label=CatBackward0]
	2654875969728 -> 2654876056016
	2654875969776 -> 2654876056016
	2654875970064 -> 2654876056016
	2654875969584 -> 2654876056016
	2654875969392 -> 2654876056016
	2654875969488 -> 2654876056016
	2654875969632 -> 2654876056016
	2654875969440 -> 2654876056016
	2654875969536 -> 2654876056016
	2654875969248 -> 2654876056016
	2654875969200 -> 2654876056016
	2654876056208 -> 2654876056352
	2654803810096 [label="features.denseblock2.denselayer11.norm1.weight
 (448)" fillcolor=lightblue]
	2654803810096 -> 2654876056208
	2654876056208 [label=AccumulateGrad]
	2654876056688 -> 2654876056352
	2654803810192 [label="features.denseblock2.denselayer11.norm1.bias
 (448)" fillcolor=lightblue]
	2654803810192 -> 2654876056688
	2654876056688 [label=AccumulateGrad]
	2654876056784 -> 2654876056736
	2654803810576 [label="features.denseblock2.denselayer11.conv1.weight
 (128, 448, 1, 1)" fillcolor=lightblue]
	2654803810576 -> 2654876056784
	2654876056784 [label=AccumulateGrad]
	2654876057168 -> 2654876056928
	2654803810672 [label="features.denseblock2.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	2654803810672 -> 2654876057168
	2654876057168 [label=AccumulateGrad]
	2654876041664 -> 2654876056928
	2654803810768 [label="features.denseblock2.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	2654803810768 -> 2654876041664
	2654876041664 [label=AccumulateGrad]
	2654876057456 -> 2654875969056
	2654803811152 [label="features.denseblock2.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803811152 -> 2654876057456
	2654876057456 [label=AccumulateGrad]
	2654875968864 -> 2654875970160
	2654875968864 [label=ConvolutionBackward0]
	2654876056880 -> 2654875968864
	2654876056880 [label=ReluBackward0]
	2654876056112 -> 2654876056880
	2654876056112 [label=CudnnBatchNormBackward0]
	2654876056064 -> 2654876056112
	2654876056064 [label=ConvolutionBackward0]
	2654876055680 -> 2654876056064
	2654876055680 [label=ReluBackward0]
	2654876055728 -> 2654876055680
	2654876055728 [label=CudnnBatchNormBackward0]
	2654876055632 -> 2654876055728
	2654876055632 [label=CatBackward0]
	2654875969728 -> 2654876055632
	2654875969776 -> 2654876055632
	2654875970064 -> 2654876055632
	2654875969584 -> 2654876055632
	2654875969392 -> 2654876055632
	2654875969488 -> 2654876055632
	2654875969632 -> 2654876055632
	2654875969440 -> 2654876055632
	2654875969536 -> 2654876055632
	2654875969248 -> 2654876055632
	2654875969200 -> 2654876055632
	2654875969056 -> 2654876055632
	2654876055536 -> 2654876055728
	2654803811248 [label="features.denseblock2.denselayer12.norm1.weight
 (480)" fillcolor=lightblue]
	2654803811248 -> 2654876055536
	2654876055536 [label=AccumulateGrad]
	2654876055488 -> 2654876055728
	2654803811344 [label="features.denseblock2.denselayer12.norm1.bias
 (480)" fillcolor=lightblue]
	2654803811344 -> 2654876055488
	2654876055488 [label=AccumulateGrad]
	2654876055824 -> 2654876056064
	2654803811728 [label="features.denseblock2.denselayer12.conv1.weight
 (128, 480, 1, 1)" fillcolor=lightblue]
	2654803811728 -> 2654876055824
	2654876055824 [label=AccumulateGrad]
	2654876056400 -> 2654876056112
	2654803811824 [label="features.denseblock2.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	2654803811824 -> 2654876056400
	2654876056400 [label=AccumulateGrad]
	2654876056544 -> 2654876056112
	2654803811920 [label="features.denseblock2.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	2654803811920 -> 2654876056544
	2654876056544 [label=AccumulateGrad]
	2654876056640 -> 2654875968864
	2654803812304 [label="features.denseblock2.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803812304 -> 2654876056640
	2654876056640 [label=AccumulateGrad]
	2654875970016 -> 2654875969920
	2654803812400 [label="features.transition2.norm.weight
 (512)" fillcolor=lightblue]
	2654803812400 -> 2654875970016
	2654875970016 [label=AccumulateGrad]
	2654875970256 -> 2654875969920
	2654803812496 [label="features.transition2.norm.bias
 (512)" fillcolor=lightblue]
	2654803812496 -> 2654875970256
	2654875970256 [label=AccumulateGrad]
	2654875970592 -> 2654875970496
	2654803812880 [label="features.transition2.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2654803812880 -> 2654875970592
	2654875970592 [label=AccumulateGrad]
	2654875961376 -> 2654875961760
	2654875961376 [label=ConvolutionBackward0]
	2654875968960 -> 2654875961376
	2654875968960 [label=ReluBackward0]
	2654875970112 -> 2654875968960
	2654875970112 [label=CudnnBatchNormBackward0]
	2654876056256 -> 2654875970112
	2654876056256 [label=ConvolutionBackward0]
	2654876055584 -> 2654876056256
	2654876055584 [label=ReluBackward0]
	2654876055056 -> 2654876055584
	2654876055056 [label=CudnnBatchNormBackward0]
	2654876055008 -> 2654876055056
	2654876055008 [label=CatBackward0]
	2654875960704 -> 2654876055008
	2654876055200 -> 2654876055056
	2654803812976 [label="features.denseblock3.denselayer1.norm1.weight
 (256)" fillcolor=lightblue]
	2654803812976 -> 2654876055200
	2654876055200 [label=AccumulateGrad]
	2654876055152 -> 2654876055056
	2654803813072 [label="features.denseblock3.denselayer1.norm1.bias
 (256)" fillcolor=lightblue]
	2654803813072 -> 2654876055152
	2654876055152 [label=AccumulateGrad]
	2654876055344 -> 2654876056256
	2654803813456 [label="features.denseblock3.denselayer1.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2654803813456 -> 2654876055344
	2654876055344 [label=AccumulateGrad]
	2654876055872 -> 2654875970112
	2654803813552 [label="features.denseblock3.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2654803813552 -> 2654876055872
	2654876055872 [label=AccumulateGrad]
	2654876056832 -> 2654875970112
	2654803813648 [label="features.denseblock3.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2654803813648 -> 2654876056832
	2654876056832 [label=AccumulateGrad]
	2654875970544 -> 2654875961376
	2654803814032 [label="features.denseblock3.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803814032 -> 2654875970544
	2654875970544 [label=AccumulateGrad]
	2654875961232 -> 2654875961760
	2654875961232 [label=ConvolutionBackward0]
	2654875969968 -> 2654875961232
	2654875969968 [label=ReluBackward0]
	2654876055104 -> 2654875969968
	2654876055104 [label=CudnnBatchNormBackward0]
	2654876054768 -> 2654876055104
	2654876054768 [label=ConvolutionBackward0]
	2654876054672 -> 2654876054768
	2654876054672 [label=ReluBackward0]
	2654876054288 -> 2654876054672
	2654876054288 [label=CudnnBatchNormBackward0]
	2654876054096 -> 2654876054288
	2654876054096 [label=CatBackward0]
	2654875960704 -> 2654876054096
	2654875961376 -> 2654876054096
	2654876054240 -> 2654876054288
	2654803814128 [label="features.denseblock3.denselayer2.norm1.weight
 (288)" fillcolor=lightblue]
	2654803814128 -> 2654876054240
	2654876054240 [label=AccumulateGrad]
	2654876054480 -> 2654876054288
	2654803814224 [label="features.denseblock3.denselayer2.norm1.bias
 (288)" fillcolor=lightblue]
	2654803814224 -> 2654876054480
	2654876054480 [label=AccumulateGrad]
	2654876054528 -> 2654876054768
	2654803814608 [label="features.denseblock3.denselayer2.conv1.weight
 (128, 288, 1, 1)" fillcolor=lightblue]
	2654803814608 -> 2654876054528
	2654876054528 [label=AccumulateGrad]
	2654876055296 -> 2654876055104
	2654803814704 [label="features.denseblock3.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2654803814704 -> 2654876055296
	2654876055296 [label=AccumulateGrad]
	2654876056160 -> 2654876055104
	2654803814800 [label="features.denseblock3.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2654803814800 -> 2654876056160
	2654876056160 [label=AccumulateGrad]
	2654875970688 -> 2654875961232
	2654803815184 [label="features.denseblock3.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803815184 -> 2654875970688
	2654875970688 [label=AccumulateGrad]
	2654875960848 -> 2654875961760
	2654875960848 [label=ConvolutionBackward0]
	2654876054816 -> 2654875960848
	2654876054816 [label=ReluBackward0]
	2654876053904 -> 2654876054816
	2654876053904 [label=CudnnBatchNormBackward0]
	2654876054144 -> 2654876053904
	2654876054144 [label=ConvolutionBackward0]
	2654876053712 -> 2654876054144
	2654876053712 [label=ReluBackward0]
	2654876053472 -> 2654876053712
	2654876053472 [label=CudnnBatchNormBackward0]
	2654876053424 -> 2654876053472
	2654876053424 [label=CatBackward0]
	2654875960704 -> 2654876053424
	2654875961376 -> 2654876053424
	2654875961232 -> 2654876053424
	2654876053616 -> 2654876053472
	2654803815280 [label="features.denseblock3.denselayer3.norm1.weight
 (320)" fillcolor=lightblue]
	2654803815280 -> 2654876053616
	2654876053616 [label=AccumulateGrad]
	2654876053568 -> 2654876053472
	2654803815376 [label="features.denseblock3.denselayer3.norm1.bias
 (320)" fillcolor=lightblue]
	2654803815376 -> 2654876053568
	2654876053568 [label=AccumulateGrad]
	2654876053760 -> 2654876054144
	2654803815760 [label="features.denseblock3.denselayer3.conv1.weight
 (128, 320, 1, 1)" fillcolor=lightblue]
	2654803815760 -> 2654876053760
	2654876053760 [label=AccumulateGrad]
	2654876054576 -> 2654876053904
	2654803815856 [label="features.denseblock3.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2654803815856 -> 2654876054576
	2654876054576 [label=AccumulateGrad]
	2654876054624 -> 2654876053904
	2654803815952 [label="features.denseblock3.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2654803815952 -> 2654876054624
	2654876054624 [label=AccumulateGrad]
	2654876054432 -> 2654875960848
	2654803816336 [label="features.denseblock3.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803816336 -> 2654876054432
	2654876054432 [label=AccumulateGrad]
	2654875960176 -> 2654875961760
	2654875960176 [label=ConvolutionBackward0]
	2654876054000 -> 2654875960176
	2654876054000 [label=ReluBackward0]
	2654876053520 -> 2654876054000
	2654876053520 [label=CudnnBatchNormBackward0]
	2654876053184 -> 2654876053520
	2654876053184 [label=ConvolutionBackward0]
	2654876053088 -> 2654876053184
	2654876053088 [label=ReluBackward0]
	2654876052704 -> 2654876053088
	2654876052704 [label=CudnnBatchNormBackward0]
	2654876052512 -> 2654876052704
	2654876052512 [label=CatBackward0]
	2654875960704 -> 2654876052512
	2654875961376 -> 2654876052512
	2654875961232 -> 2654876052512
	2654875960848 -> 2654876052512
	2654876052656 -> 2654876052704
	2654803816432 [label="features.denseblock3.denselayer4.norm1.weight
 (352)" fillcolor=lightblue]
	2654803816432 -> 2654876052656
	2654876052656 [label=AccumulateGrad]
	2654876052896 -> 2654876052704
	2654803816528 [label="features.denseblock3.denselayer4.norm1.bias
 (352)" fillcolor=lightblue]
	2654803816528 -> 2654876052896
	2654876052896 [label=AccumulateGrad]
	2654876052944 -> 2654876053184
	2654803816912 [label="features.denseblock3.denselayer4.conv1.weight
 (128, 352, 1, 1)" fillcolor=lightblue]
	2654803816912 -> 2654876052944
	2654876052944 [label=AccumulateGrad]
	2654876053376 -> 2654876053520
	2654803817008 [label="features.denseblock3.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2654803817008 -> 2654876053376
	2654876053376 [label=AccumulateGrad]
	2654876053952 -> 2654876053520
	2654803817104 [label="features.denseblock3.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2654803817104 -> 2654876053952
	2654876053952 [label=AccumulateGrad]
	2654876054048 -> 2654875960176
	2654803817488 [label="features.denseblock3.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803817488 -> 2654876054048
	2654876054048 [label=AccumulateGrad]
	2654875960320 -> 2654875961760
	2654875960320 [label=ConvolutionBackward0]
	2654876053232 -> 2654875960320
	2654876053232 [label=ReluBackward0]
	2654876052320 -> 2654876053232
	2654876052320 [label=CudnnBatchNormBackward0]
	2654876052560 -> 2654876052320
	2654876052560 [label=ConvolutionBackward0]
	2654876052128 -> 2654876052560
	2654876052128 [label=ReluBackward0]
	2654876051888 -> 2654876052128
	2654876051888 [label=CudnnBatchNormBackward0]
	2654876051840 -> 2654876051888
	2654876051840 [label=CatBackward0]
	2654875960704 -> 2654876051840
	2654875961376 -> 2654876051840
	2654875961232 -> 2654876051840
	2654875960848 -> 2654876051840
	2654875960176 -> 2654876051840
	2654876052032 -> 2654876051888
	2654803817584 [label="features.denseblock3.denselayer5.norm1.weight
 (384)" fillcolor=lightblue]
	2654803817584 -> 2654876052032
	2654876052032 [label=AccumulateGrad]
	2654876051984 -> 2654876051888
	2654803817680 [label="features.denseblock3.denselayer5.norm1.bias
 (384)" fillcolor=lightblue]
	2654803817680 -> 2654876051984
	2654876051984 [label=AccumulateGrad]
	2654876052176 -> 2654876052560
	2654803818064 [label="features.denseblock3.denselayer5.conv1.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	2654803818064 -> 2654876052176
	2654876052176 [label=AccumulateGrad]
	2654876052992 -> 2654876052320
	2654803818160 [label="features.denseblock3.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2654803818160 -> 2654876052992
	2654876052992 [label=AccumulateGrad]
	2654876053040 -> 2654876052320
	2654803818256 [label="features.denseblock3.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2654803818256 -> 2654876053040
	2654876053040 [label=AccumulateGrad]
	2654876052848 -> 2654875960320
	2654803818640 [label="features.denseblock3.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803818640 -> 2654876052848
	2654876052848 [label=AccumulateGrad]
	2654875959648 -> 2654875961760
	2654875959648 [label=ConvolutionBackward0]
	2654876052416 -> 2654875959648
	2654876052416 [label=ReluBackward0]
	2654876051936 -> 2654876052416
	2654876051936 [label=CudnnBatchNormBackward0]
	2654876051600 -> 2654876051936
	2654876051600 [label=ConvolutionBackward0]
	2654876051504 -> 2654876051600
	2654876051504 [label=ReluBackward0]
	2654876051120 -> 2654876051504
	2654876051120 [label=CudnnBatchNormBackward0]
	2654876050928 -> 2654876051120
	2654876050928 [label=CatBackward0]
	2654875960704 -> 2654876050928
	2654875961376 -> 2654876050928
	2654875961232 -> 2654876050928
	2654875960848 -> 2654876050928
	2654875960176 -> 2654876050928
	2654875960320 -> 2654876050928
	2654876051072 -> 2654876051120
	2654803818736 [label="features.denseblock3.denselayer6.norm1.weight
 (416)" fillcolor=lightblue]
	2654803818736 -> 2654876051072
	2654876051072 [label=AccumulateGrad]
	2654876051312 -> 2654876051120
	2654803818832 [label="features.denseblock3.denselayer6.norm1.bias
 (416)" fillcolor=lightblue]
	2654803818832 -> 2654876051312
	2654876051312 [label=AccumulateGrad]
	2654876051360 -> 2654876051600
	2654803819216 [label="features.denseblock3.denselayer6.conv1.weight
 (128, 416, 1, 1)" fillcolor=lightblue]
	2654803819216 -> 2654876051360
	2654876051360 [label=AccumulateGrad]
	2654876051792 -> 2654876051936
	2654803819312 [label="features.denseblock3.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2654803819312 -> 2654876051792
	2654876051792 [label=AccumulateGrad]
	2654876052368 -> 2654876051936
	2654803819408 [label="features.denseblock3.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2654803819408 -> 2654876052368
	2654876052368 [label=AccumulateGrad]
	2654876052464 -> 2654875959648
	2654803819792 [label="features.denseblock3.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803819792 -> 2654876052464
	2654876052464 [label=AccumulateGrad]
	2654875959792 -> 2654875961760
	2654875959792 [label=ConvolutionBackward0]
	2654876051648 -> 2654875959792
	2654876051648 [label=ReluBackward0]
	2654876050736 -> 2654876051648
	2654876050736 [label=CudnnBatchNormBackward0]
	2654876050976 -> 2654876050736
	2654876050976 [label=ConvolutionBackward0]
	2654876050544 -> 2654876050976
	2654876050544 [label=ReluBackward0]
	2654876050304 -> 2654876050544
	2654876050304 [label=CudnnBatchNormBackward0]
	2654876050256 -> 2654876050304
	2654876050256 [label=CatBackward0]
	2654875960704 -> 2654876050256
	2654875961376 -> 2654876050256
	2654875961232 -> 2654876050256
	2654875960848 -> 2654876050256
	2654875960176 -> 2654876050256
	2654875960320 -> 2654876050256
	2654875959648 -> 2654876050256
	2654876050448 -> 2654876050304
	2654803819888 [label="features.denseblock3.denselayer7.norm1.weight
 (448)" fillcolor=lightblue]
	2654803819888 -> 2654876050448
	2654876050448 [label=AccumulateGrad]
	2654876050400 -> 2654876050304
	2654803819984 [label="features.denseblock3.denselayer7.norm1.bias
 (448)" fillcolor=lightblue]
	2654803819984 -> 2654876050400
	2654876050400 [label=AccumulateGrad]
	2654876050592 -> 2654876050976
	2654803820368 [label="features.denseblock3.denselayer7.conv1.weight
 (128, 448, 1, 1)" fillcolor=lightblue]
	2654803820368 -> 2654876050592
	2654876050592 [label=AccumulateGrad]
	2654876051408 -> 2654876050736
	2654803820464 [label="features.denseblock3.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	2654803820464 -> 2654876051408
	2654876051408 [label=AccumulateGrad]
	2654876051456 -> 2654876050736
	2654803509328 [label="features.denseblock3.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	2654803509328 -> 2654876051456
	2654876051456 [label=AccumulateGrad]
	2654876051264 -> 2654875959792
	2654803509712 [label="features.denseblock3.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803509712 -> 2654876051264
	2654876051264 [label=AccumulateGrad]
	2654875975584 -> 2654875961760
	2654875975584 [label=ConvolutionBackward0]
	2654876050832 -> 2654875975584
	2654876050832 [label=ReluBackward0]
	2654876050352 -> 2654876050832
	2654876050352 [label=CudnnBatchNormBackward0]
	2654876050016 -> 2654876050352
	2654876050016 [label=ConvolutionBackward0]
	2654876049920 -> 2654876050016
	2654876049920 [label=ReluBackward0]
	2654876049536 -> 2654876049920
	2654876049536 [label=CudnnBatchNormBackward0]
	2654876049344 -> 2654876049536
	2654876049344 [label=CatBackward0]
	2654875960704 -> 2654876049344
	2654875961376 -> 2654876049344
	2654875961232 -> 2654876049344
	2654875960848 -> 2654876049344
	2654875960176 -> 2654876049344
	2654875960320 -> 2654876049344
	2654875959648 -> 2654876049344
	2654875959792 -> 2654876049344
	2654876049488 -> 2654876049536
	2654803509808 [label="features.denseblock3.denselayer8.norm1.weight
 (480)" fillcolor=lightblue]
	2654803509808 -> 2654876049488
	2654876049488 [label=AccumulateGrad]
	2654876049728 -> 2654876049536
	2654803509904 [label="features.denseblock3.denselayer8.norm1.bias
 (480)" fillcolor=lightblue]
	2654803509904 -> 2654876049728
	2654876049728 [label=AccumulateGrad]
	2654876049776 -> 2654876050016
	2654803510288 [label="features.denseblock3.denselayer8.conv1.weight
 (128, 480, 1, 1)" fillcolor=lightblue]
	2654803510288 -> 2654876049776
	2654876049776 [label=AccumulateGrad]
	2654876050208 -> 2654876050352
	2654803510384 [label="features.denseblock3.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	2654803510384 -> 2654876050208
	2654876050208 [label=AccumulateGrad]
	2654876050784 -> 2654876050352
	2654803510480 [label="features.denseblock3.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	2654803510480 -> 2654876050784
	2654876050784 [label=AccumulateGrad]
	2654876050880 -> 2654875975584
	2654803510864 [label="features.denseblock3.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803510864 -> 2654876050880
	2654876050880 [label=AccumulateGrad]
	2654875971504 -> 2654875961760
	2654875971504 [label=ConvolutionBackward0]
	2654876050064 -> 2654875971504
	2654876050064 [label=ReluBackward0]
	2654876049152 -> 2654876050064
	2654876049152 [label=CudnnBatchNormBackward0]
	2654876049392 -> 2654876049152
	2654876049392 [label=ConvolutionBackward0]
	2654876048960 -> 2654876049392
	2654876048960 [label=ReluBackward0]
	2654876048720 -> 2654876048960
	2654876048720 [label=CudnnBatchNormBackward0]
	2654876048672 -> 2654876048720
	2654876048672 [label=CatBackward0]
	2654875960704 -> 2654876048672
	2654875961376 -> 2654876048672
	2654875961232 -> 2654876048672
	2654875960848 -> 2654876048672
	2654875960176 -> 2654876048672
	2654875960320 -> 2654876048672
	2654875959648 -> 2654876048672
	2654875959792 -> 2654876048672
	2654875975584 -> 2654876048672
	2654876048864 -> 2654876048720
	2654803510960 [label="features.denseblock3.denselayer9.norm1.weight
 (512)" fillcolor=lightblue]
	2654803510960 -> 2654876048864
	2654876048864 [label=AccumulateGrad]
	2654876048816 -> 2654876048720
	2654803511056 [label="features.denseblock3.denselayer9.norm1.bias
 (512)" fillcolor=lightblue]
	2654803511056 -> 2654876048816
	2654876048816 [label=AccumulateGrad]
	2654876049008 -> 2654876049392
	2654803511440 [label="features.denseblock3.denselayer9.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2654803511440 -> 2654876049008
	2654876049008 [label=AccumulateGrad]
	2654876049824 -> 2654876049152
	2654803511536 [label="features.denseblock3.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	2654803511536 -> 2654876049824
	2654876049824 [label=AccumulateGrad]
	2654876049872 -> 2654876049152
	2654803511632 [label="features.denseblock3.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	2654803511632 -> 2654876049872
	2654876049872 [label=AccumulateGrad]
	2654876049680 -> 2654875971504
	2654803512016 [label="features.denseblock3.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803512016 -> 2654876049680
	2654876049680 [label=AccumulateGrad]
	2654875971600 -> 2654875961760
	2654875971600 [label=ConvolutionBackward0]
	2654876049248 -> 2654875971600
	2654876049248 [label=ReluBackward0]
	2654876048768 -> 2654876049248
	2654876048768 [label=CudnnBatchNormBackward0]
	2654876048432 -> 2654876048768
	2654876048432 [label=ConvolutionBackward0]
	2654876048336 -> 2654876048432
	2654876048336 [label=ReluBackward0]
	2654876047952 -> 2654876048336
	2654876047952 [label=CudnnBatchNormBackward0]
	2654876047760 -> 2654876047952
	2654876047760 [label=CatBackward0]
	2654875960704 -> 2654876047760
	2654875961376 -> 2654876047760
	2654875961232 -> 2654876047760
	2654875960848 -> 2654876047760
	2654875960176 -> 2654876047760
	2654875960320 -> 2654876047760
	2654875959648 -> 2654876047760
	2654875959792 -> 2654876047760
	2654875975584 -> 2654876047760
	2654875971504 -> 2654876047760
	2654876047904 -> 2654876047952
	2654803512112 [label="features.denseblock3.denselayer10.norm1.weight
 (544)" fillcolor=lightblue]
	2654803512112 -> 2654876047904
	2654876047904 [label=AccumulateGrad]
	2654876048144 -> 2654876047952
	2654803512208 [label="features.denseblock3.denselayer10.norm1.bias
 (544)" fillcolor=lightblue]
	2654803512208 -> 2654876048144
	2654876048144 [label=AccumulateGrad]
	2654876048192 -> 2654876048432
	2654803512592 [label="features.denseblock3.denselayer10.conv1.weight
 (128, 544, 1, 1)" fillcolor=lightblue]
	2654803512592 -> 2654876048192
	2654876048192 [label=AccumulateGrad]
	2654876048624 -> 2654876048768
	2654803512688 [label="features.denseblock3.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	2654803512688 -> 2654876048624
	2654876048624 [label=AccumulateGrad]
	2654876049200 -> 2654876048768
	2654803512784 [label="features.denseblock3.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	2654803512784 -> 2654876049200
	2654876049200 [label=AccumulateGrad]
	2654876049296 -> 2654875971600
	2654803513168 [label="features.denseblock3.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803513168 -> 2654876049296
	2654876049296 [label=AccumulateGrad]
	2654875971744 -> 2654875961760
	2654875971744 [label=ConvolutionBackward0]
	2654876048480 -> 2654875971744
	2654876048480 [label=ReluBackward0]
	2654876047568 -> 2654876048480
	2654876047568 [label=CudnnBatchNormBackward0]
	2654876047808 -> 2654876047568
	2654876047808 [label=ConvolutionBackward0]
	2654876047376 -> 2654876047808
	2654876047376 [label=ReluBackward0]
	2654876047136 -> 2654876047376
	2654876047136 [label=CudnnBatchNormBackward0]
	2654876047088 -> 2654876047136
	2654876047088 [label=CatBackward0]
	2654875960704 -> 2654876047088
	2654875961376 -> 2654876047088
	2654875961232 -> 2654876047088
	2654875960848 -> 2654876047088
	2654875960176 -> 2654876047088
	2654875960320 -> 2654876047088
	2654875959648 -> 2654876047088
	2654875959792 -> 2654876047088
	2654875975584 -> 2654876047088
	2654875971504 -> 2654876047088
	2654875971600 -> 2654876047088
	2654876047280 -> 2654876047136
	2654803513264 [label="features.denseblock3.denselayer11.norm1.weight
 (576)" fillcolor=lightblue]
	2654803513264 -> 2654876047280
	2654876047280 [label=AccumulateGrad]
	2654876047232 -> 2654876047136
	2654803513360 [label="features.denseblock3.denselayer11.norm1.bias
 (576)" fillcolor=lightblue]
	2654803513360 -> 2654876047232
	2654876047232 [label=AccumulateGrad]
	2654876047424 -> 2654876047808
	2654803513744 [label="features.denseblock3.denselayer11.conv1.weight
 (128, 576, 1, 1)" fillcolor=lightblue]
	2654803513744 -> 2654876047424
	2654876047424 [label=AccumulateGrad]
	2654876048240 -> 2654876047568
	2654803513840 [label="features.denseblock3.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	2654803513840 -> 2654876048240
	2654876048240 [label=AccumulateGrad]
	2654876048288 -> 2654876047568
	2654803513936 [label="features.denseblock3.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	2654803513936 -> 2654876048288
	2654876048288 [label=AccumulateGrad]
	2654876048096 -> 2654875971744
	2654803514320 [label="features.denseblock3.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803514320 -> 2654876048096
	2654876048096 [label=AccumulateGrad]
	2654875971552 -> 2654875961760
	2654875971552 [label=ConvolutionBackward0]
	2654876047664 -> 2654875971552
	2654876047664 [label=ReluBackward0]
	2654876047184 -> 2654876047664
	2654876047184 [label=CudnnBatchNormBackward0]
	2654876046848 -> 2654876047184
	2654876046848 [label=ConvolutionBackward0]
	2654876046752 -> 2654876046848
	2654876046752 [label=ReluBackward0]
	2654876046368 -> 2654876046752
	2654876046368 [label=CudnnBatchNormBackward0]
	2654876046176 -> 2654876046368
	2654876046176 [label=CatBackward0]
	2654875960704 -> 2654876046176
	2654875961376 -> 2654876046176
	2654875961232 -> 2654876046176
	2654875960848 -> 2654876046176
	2654875960176 -> 2654876046176
	2654875960320 -> 2654876046176
	2654875959648 -> 2654876046176
	2654875959792 -> 2654876046176
	2654875975584 -> 2654876046176
	2654875971504 -> 2654876046176
	2654875971600 -> 2654876046176
	2654875971744 -> 2654876046176
	2654876046320 -> 2654876046368
	2654803514416 [label="features.denseblock3.denselayer12.norm1.weight
 (608)" fillcolor=lightblue]
	2654803514416 -> 2654876046320
	2654876046320 [label=AccumulateGrad]
	2654876046560 -> 2654876046368
	2654803514512 [label="features.denseblock3.denselayer12.norm1.bias
 (608)" fillcolor=lightblue]
	2654803514512 -> 2654876046560
	2654876046560 [label=AccumulateGrad]
	2654876046608 -> 2654876046848
	2654803514896 [label="features.denseblock3.denselayer12.conv1.weight
 (128, 608, 1, 1)" fillcolor=lightblue]
	2654803514896 -> 2654876046608
	2654876046608 [label=AccumulateGrad]
	2654876047040 -> 2654876047184
	2654803514992 [label="features.denseblock3.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	2654803514992 -> 2654876047040
	2654876047040 [label=AccumulateGrad]
	2654876047616 -> 2654876047184
	2654803515088 [label="features.denseblock3.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	2654803515088 -> 2654876047616
	2654876047616 [label=AccumulateGrad]
	2654876047712 -> 2654875971552
	2654803515472 [label="features.denseblock3.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803515472 -> 2654876047712
	2654876047712 [label=AccumulateGrad]
	2654875971648 -> 2654875961760
	2654875971648 [label=ConvolutionBackward0]
	2654876046896 -> 2654875971648
	2654876046896 [label=ReluBackward0]
	2654876045984 -> 2654876046896
	2654876045984 [label=CudnnBatchNormBackward0]
	2654876046224 -> 2654876045984
	2654876046224 [label=ConvolutionBackward0]
	2654876045792 -> 2654876046224
	2654876045792 [label=ReluBackward0]
	2654876045552 -> 2654876045792
	2654876045552 [label=CudnnBatchNormBackward0]
	2654876045504 -> 2654876045552
	2654876045504 [label=CatBackward0]
	2654875960704 -> 2654876045504
	2654875961376 -> 2654876045504
	2654875961232 -> 2654876045504
	2654875960848 -> 2654876045504
	2654875960176 -> 2654876045504
	2654875960320 -> 2654876045504
	2654875959648 -> 2654876045504
	2654875959792 -> 2654876045504
	2654875975584 -> 2654876045504
	2654875971504 -> 2654876045504
	2654875971600 -> 2654876045504
	2654875971744 -> 2654876045504
	2654875971552 -> 2654876045504
	2654876045696 -> 2654876045552
	2654803515568 [label="features.denseblock3.denselayer13.norm1.weight
 (640)" fillcolor=lightblue]
	2654803515568 -> 2654876045696
	2654876045696 [label=AccumulateGrad]
	2654876045648 -> 2654876045552
	2654803515664 [label="features.denseblock3.denselayer13.norm1.bias
 (640)" fillcolor=lightblue]
	2654803515664 -> 2654876045648
	2654876045648 [label=AccumulateGrad]
	2654876045840 -> 2654876046224
	2654803516048 [label="features.denseblock3.denselayer13.conv1.weight
 (128, 640, 1, 1)" fillcolor=lightblue]
	2654803516048 -> 2654876045840
	2654876045840 [label=AccumulateGrad]
	2654876046656 -> 2654876045984
	2654803516144 [label="features.denseblock3.denselayer13.norm2.weight
 (128)" fillcolor=lightblue]
	2654803516144 -> 2654876046656
	2654876046656 [label=AccumulateGrad]
	2654876046704 -> 2654876045984
	2654803516240 [label="features.denseblock3.denselayer13.norm2.bias
 (128)" fillcolor=lightblue]
	2654803516240 -> 2654876046704
	2654876046704 [label=AccumulateGrad]
	2654876046512 -> 2654875971648
	2654803516624 [label="features.denseblock3.denselayer13.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803516624 -> 2654876046512
	2654876046512 [label=AccumulateGrad]
	2654875971360 -> 2654875961760
	2654875971360 [label=ConvolutionBackward0]
	2654876046080 -> 2654875971360
	2654876046080 [label=ReluBackward0]
	2654876045600 -> 2654876046080
	2654876045600 [label=CudnnBatchNormBackward0]
	2654876045264 -> 2654876045600
	2654876045264 [label=ConvolutionBackward0]
	2654876045168 -> 2654876045264
	2654876045168 [label=ReluBackward0]
	2654876044784 -> 2654876045168
	2654876044784 [label=CudnnBatchNormBackward0]
	2654876044592 -> 2654876044784
	2654876044592 [label=CatBackward0]
	2654875960704 -> 2654876044592
	2654875961376 -> 2654876044592
	2654875961232 -> 2654876044592
	2654875960848 -> 2654876044592
	2654875960176 -> 2654876044592
	2654875960320 -> 2654876044592
	2654875959648 -> 2654876044592
	2654875959792 -> 2654876044592
	2654875975584 -> 2654876044592
	2654875971504 -> 2654876044592
	2654875971600 -> 2654876044592
	2654875971744 -> 2654876044592
	2654875971552 -> 2654876044592
	2654875971648 -> 2654876044592
	2654876044736 -> 2654876044784
	2654803516720 [label="features.denseblock3.denselayer14.norm1.weight
 (672)" fillcolor=lightblue]
	2654803516720 -> 2654876044736
	2654876044736 [label=AccumulateGrad]
	2654876044976 -> 2654876044784
	2654803516816 [label="features.denseblock3.denselayer14.norm1.bias
 (672)" fillcolor=lightblue]
	2654803516816 -> 2654876044976
	2654876044976 [label=AccumulateGrad]
	2654876045024 -> 2654876045264
	2654803517200 [label="features.denseblock3.denselayer14.conv1.weight
 (128, 672, 1, 1)" fillcolor=lightblue]
	2654803517200 -> 2654876045024
	2654876045024 [label=AccumulateGrad]
	2654876045456 -> 2654876045600
	2654803517296 [label="features.denseblock3.denselayer14.norm2.weight
 (128)" fillcolor=lightblue]
	2654803517296 -> 2654876045456
	2654876045456 [label=AccumulateGrad]
	2654876046032 -> 2654876045600
	2654803517392 [label="features.denseblock3.denselayer14.norm2.bias
 (128)" fillcolor=lightblue]
	2654803517392 -> 2654876046032
	2654876046032 [label=AccumulateGrad]
	2654876046128 -> 2654875971360
	2654803517776 [label="features.denseblock3.denselayer14.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803517776 -> 2654876046128
	2654876046128 [label=AccumulateGrad]
	2654875971312 -> 2654875961760
	2654875971312 [label=ConvolutionBackward0]
	2654876045312 -> 2654875971312
	2654876045312 [label=ReluBackward0]
	2654876044400 -> 2654876045312
	2654876044400 [label=CudnnBatchNormBackward0]
	2654876044640 -> 2654876044400
	2654876044640 [label=ConvolutionBackward0]
	2654876044208 -> 2654876044640
	2654876044208 [label=ReluBackward0]
	2654876043968 -> 2654876044208
	2654876043968 [label=CudnnBatchNormBackward0]
	2654876043920 -> 2654876043968
	2654876043920 [label=CatBackward0]
	2654875960704 -> 2654876043920
	2654875961376 -> 2654876043920
	2654875961232 -> 2654876043920
	2654875960848 -> 2654876043920
	2654875960176 -> 2654876043920
	2654875960320 -> 2654876043920
	2654875959648 -> 2654876043920
	2654875959792 -> 2654876043920
	2654875975584 -> 2654876043920
	2654875971504 -> 2654876043920
	2654875971600 -> 2654876043920
	2654875971744 -> 2654876043920
	2654875971552 -> 2654876043920
	2654875971648 -> 2654876043920
	2654875971360 -> 2654876043920
	2654876044112 -> 2654876043968
	2654803517872 [label="features.denseblock3.denselayer15.norm1.weight
 (704)" fillcolor=lightblue]
	2654803517872 -> 2654876044112
	2654876044112 [label=AccumulateGrad]
	2654876044064 -> 2654876043968
	2654803517968 [label="features.denseblock3.denselayer15.norm1.bias
 (704)" fillcolor=lightblue]
	2654803517968 -> 2654876044064
	2654876044064 [label=AccumulateGrad]
	2654876044256 -> 2654876044640
	2654803518352 [label="features.denseblock3.denselayer15.conv1.weight
 (128, 704, 1, 1)" fillcolor=lightblue]
	2654803518352 -> 2654876044256
	2654876044256 [label=AccumulateGrad]
	2654876045072 -> 2654876044400
	2654803518448 [label="features.denseblock3.denselayer15.norm2.weight
 (128)" fillcolor=lightblue]
	2654803518448 -> 2654876045072
	2654876045072 [label=AccumulateGrad]
	2654876045120 -> 2654876044400
	2654803518544 [label="features.denseblock3.denselayer15.norm2.bias
 (128)" fillcolor=lightblue]
	2654803518544 -> 2654876045120
	2654876045120 [label=AccumulateGrad]
	2654876044928 -> 2654875971312
	2654803518928 [label="features.denseblock3.denselayer15.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803518928 -> 2654876044928
	2654876044928 [label=AccumulateGrad]
	2654875971168 -> 2654875961760
	2654875971168 [label=ConvolutionBackward0]
	2654876044496 -> 2654875971168
	2654876044496 [label=ReluBackward0]
	2654876044016 -> 2654876044496
	2654876044016 [label=CudnnBatchNormBackward0]
	2654876043680 -> 2654876044016
	2654876043680 [label=ConvolutionBackward0]
	2654876043584 -> 2654876043680
	2654876043584 [label=ReluBackward0]
	2654876043200 -> 2654876043584
	2654876043200 [label=CudnnBatchNormBackward0]
	2654876043008 -> 2654876043200
	2654876043008 [label=CatBackward0]
	2654875960704 -> 2654876043008
	2654875961376 -> 2654876043008
	2654875961232 -> 2654876043008
	2654875960848 -> 2654876043008
	2654875960176 -> 2654876043008
	2654875960320 -> 2654876043008
	2654875959648 -> 2654876043008
	2654875959792 -> 2654876043008
	2654875975584 -> 2654876043008
	2654875971504 -> 2654876043008
	2654875971600 -> 2654876043008
	2654875971744 -> 2654876043008
	2654875971552 -> 2654876043008
	2654875971648 -> 2654876043008
	2654875971360 -> 2654876043008
	2654875971312 -> 2654876043008
	2654876043152 -> 2654876043200
	2654803519024 [label="features.denseblock3.denselayer16.norm1.weight
 (736)" fillcolor=lightblue]
	2654803519024 -> 2654876043152
	2654876043152 [label=AccumulateGrad]
	2654876043392 -> 2654876043200
	2654803519120 [label="features.denseblock3.denselayer16.norm1.bias
 (736)" fillcolor=lightblue]
	2654803519120 -> 2654876043392
	2654876043392 [label=AccumulateGrad]
	2654876043440 -> 2654876043680
	2654803519504 [label="features.denseblock3.denselayer16.conv1.weight
 (128, 736, 1, 1)" fillcolor=lightblue]
	2654803519504 -> 2654876043440
	2654876043440 [label=AccumulateGrad]
	2654876043872 -> 2654876044016
	2654803519600 [label="features.denseblock3.denselayer16.norm2.weight
 (128)" fillcolor=lightblue]
	2654803519600 -> 2654876043872
	2654876043872 [label=AccumulateGrad]
	2654876044448 -> 2654876044016
	2654803519696 [label="features.denseblock3.denselayer16.norm2.bias
 (128)" fillcolor=lightblue]
	2654803519696 -> 2654876044448
	2654876044448 [label=AccumulateGrad]
	2654876044544 -> 2654875971168
	2654803520080 [label="features.denseblock3.denselayer16.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803520080 -> 2654876044544
	2654876044544 [label=AccumulateGrad]
	2654875970976 -> 2654875961760
	2654875970976 [label=ConvolutionBackward0]
	2654876043728 -> 2654875970976
	2654876043728 [label=ReluBackward0]
	2654876042816 -> 2654876043728
	2654876042816 [label=CudnnBatchNormBackward0]
	2654876043056 -> 2654876042816
	2654876043056 [label=ConvolutionBackward0]
	2654876042624 -> 2654876043056
	2654876042624 [label=ReluBackward0]
	2654876042384 -> 2654876042624
	2654876042384 [label=CudnnBatchNormBackward0]
	2654876042336 -> 2654876042384
	2654876042336 [label=CatBackward0]
	2654875960704 -> 2654876042336
	2654875961376 -> 2654876042336
	2654875961232 -> 2654876042336
	2654875960848 -> 2654876042336
	2654875960176 -> 2654876042336
	2654875960320 -> 2654876042336
	2654875959648 -> 2654876042336
	2654875959792 -> 2654876042336
	2654875975584 -> 2654876042336
	2654875971504 -> 2654876042336
	2654875971600 -> 2654876042336
	2654875971744 -> 2654876042336
	2654875971552 -> 2654876042336
	2654875971648 -> 2654876042336
	2654875971360 -> 2654876042336
	2654875971312 -> 2654876042336
	2654875971168 -> 2654876042336
	2654876042528 -> 2654876042384
	2654803520176 [label="features.denseblock3.denselayer17.norm1.weight
 (768)" fillcolor=lightblue]
	2654803520176 -> 2654876042528
	2654876042528 [label=AccumulateGrad]
	2654876042480 -> 2654876042384
	2654803520272 [label="features.denseblock3.denselayer17.norm1.bias
 (768)" fillcolor=lightblue]
	2654803520272 -> 2654876042480
	2654876042480 [label=AccumulateGrad]
	2654876042672 -> 2654876043056
	2654803520656 [label="features.denseblock3.denselayer17.conv1.weight
 (128, 768, 1, 1)" fillcolor=lightblue]
	2654803520656 -> 2654876042672
	2654876042672 [label=AccumulateGrad]
	2654876043488 -> 2654876042816
	2654803520752 [label="features.denseblock3.denselayer17.norm2.weight
 (128)" fillcolor=lightblue]
	2654803520752 -> 2654876043488
	2654876043488 [label=AccumulateGrad]
	2654876043536 -> 2654876042816
	2654803520848 [label="features.denseblock3.denselayer17.norm2.bias
 (128)" fillcolor=lightblue]
	2654803520848 -> 2654876043536
	2654876043536 [label=AccumulateGrad]
	2654876043344 -> 2654875970976
	2654803521232 [label="features.denseblock3.denselayer17.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803521232 -> 2654876043344
	2654876043344 [label=AccumulateGrad]
	2654875971072 -> 2654875961760
	2654875971072 [label=ConvolutionBackward0]
	2654876042912 -> 2654875971072
	2654876042912 [label=ReluBackward0]
	2654876042432 -> 2654876042912
	2654876042432 [label=CudnnBatchNormBackward0]
	2654876042096 -> 2654876042432
	2654876042096 [label=ConvolutionBackward0]
	2654876042000 -> 2654876042096
	2654876042000 [label=ReluBackward0]
	2654876041616 -> 2654876042000
	2654876041616 [label=CudnnBatchNormBackward0]
	2654876041424 -> 2654876041616
	2654876041424 [label=CatBackward0]
	2654875960704 -> 2654876041424
	2654875961376 -> 2654876041424
	2654875961232 -> 2654876041424
	2654875960848 -> 2654876041424
	2654875960176 -> 2654876041424
	2654875960320 -> 2654876041424
	2654875959648 -> 2654876041424
	2654875959792 -> 2654876041424
	2654875975584 -> 2654876041424
	2654875971504 -> 2654876041424
	2654875971600 -> 2654876041424
	2654875971744 -> 2654876041424
	2654875971552 -> 2654876041424
	2654875971648 -> 2654876041424
	2654875971360 -> 2654876041424
	2654875971312 -> 2654876041424
	2654875971168 -> 2654876041424
	2654875970976 -> 2654876041424
	2654876041568 -> 2654876041616
	2654803521328 [label="features.denseblock3.denselayer18.norm1.weight
 (800)" fillcolor=lightblue]
	2654803521328 -> 2654876041568
	2654876041568 [label=AccumulateGrad]
	2654876041808 -> 2654876041616
	2654803521424 [label="features.denseblock3.denselayer18.norm1.bias
 (800)" fillcolor=lightblue]
	2654803521424 -> 2654876041808
	2654876041808 [label=AccumulateGrad]
	2654876041856 -> 2654876042096
	2654803521808 [label="features.denseblock3.denselayer18.conv1.weight
 (128, 800, 1, 1)" fillcolor=lightblue]
	2654803521808 -> 2654876041856
	2654876041856 [label=AccumulateGrad]
	2654876042288 -> 2654876042432
	2654803521904 [label="features.denseblock3.denselayer18.norm2.weight
 (128)" fillcolor=lightblue]
	2654803521904 -> 2654876042288
	2654876042288 [label=AccumulateGrad]
	2654876042864 -> 2654876042432
	2654803522000 [label="features.denseblock3.denselayer18.norm2.bias
 (128)" fillcolor=lightblue]
	2654803522000 -> 2654876042864
	2654876042864 [label=AccumulateGrad]
	2654876042960 -> 2654875971072
	2654803522384 [label="features.denseblock3.denselayer18.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803522384 -> 2654876042960
	2654876042960 [label=AccumulateGrad]
	2654875971216 -> 2654875961760
	2654875971216 [label=ConvolutionBackward0]
	2654876042144 -> 2654875971216
	2654876042144 [label=ReluBackward0]
	2654876041328 -> 2654876042144
	2654876041328 [label=CudnnBatchNormBackward0]
	2654876041280 -> 2654876041328
	2654876041280 [label=ConvolutionBackward0]
	2654876171472 -> 2654876041280
	2654876171472 [label=ReluBackward0]
	2654876171088 -> 2654876171472
	2654876171088 [label=CudnnBatchNormBackward0]
	2654876170560 -> 2654876171088
	2654876170560 [label=CatBackward0]
	2654875960704 -> 2654876170560
	2654875961376 -> 2654876170560
	2654875961232 -> 2654876170560
	2654875960848 -> 2654876170560
	2654875960176 -> 2654876170560
	2654875960320 -> 2654876170560
	2654875959648 -> 2654876170560
	2654875959792 -> 2654876170560
	2654875975584 -> 2654876170560
	2654875971504 -> 2654876170560
	2654875971600 -> 2654876170560
	2654875971744 -> 2654876170560
	2654875971552 -> 2654876170560
	2654875971648 -> 2654876170560
	2654875971360 -> 2654876170560
	2654875971312 -> 2654876170560
	2654875971168 -> 2654876170560
	2654875970976 -> 2654876170560
	2654875971072 -> 2654876170560
	2654876170416 -> 2654876171088
	2654803522480 [label="features.denseblock3.denselayer19.norm1.weight
 (832)" fillcolor=lightblue]
	2654803522480 -> 2654876170416
	2654876170416 [label=AccumulateGrad]
	2654876171616 -> 2654876171088
	2654803522576 [label="features.denseblock3.denselayer19.norm1.bias
 (832)" fillcolor=lightblue]
	2654803522576 -> 2654876171616
	2654876171616 [label=AccumulateGrad]
	2654876172144 -> 2654876041280
	2654803522960 [label="features.denseblock3.denselayer19.conv1.weight
 (128, 832, 1, 1)" fillcolor=lightblue]
	2654803522960 -> 2654876172144
	2654876172144 [label=AccumulateGrad]
	2654876041904 -> 2654876041328
	2654803523056 [label="features.denseblock3.denselayer19.norm2.weight
 (128)" fillcolor=lightblue]
	2654803523056 -> 2654876041904
	2654876041904 [label=AccumulateGrad]
	2654876041952 -> 2654876041328
	2654803523152 [label="features.denseblock3.denselayer19.norm2.bias
 (128)" fillcolor=lightblue]
	2654803523152 -> 2654876041952
	2654876041952 [label=AccumulateGrad]
	2654876041760 -> 2654875971216
	2654803523536 [label="features.denseblock3.denselayer19.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803523536 -> 2654876041760
	2654876041760 [label=AccumulateGrad]
	2654875971024 -> 2654875961760
	2654875971024 [label=ConvolutionBackward0]
	2654876041376 -> 2654875971024
	2654876041376 [label=ReluBackward0]
	2654876169888 -> 2654876041376
	2654876169888 [label=CudnnBatchNormBackward0]
	2654876169360 -> 2654876169888
	2654876169360 [label=ConvolutionBackward0]
	2654876168304 -> 2654876169360
	2654876168304 [label=ReluBackward0]
	2654876167920 -> 2654876168304
	2654876167920 [label=CudnnBatchNormBackward0]
	2654876167392 -> 2654876167920
	2654876167392 [label=CatBackward0]
	2654875960704 -> 2654876167392
	2654875961376 -> 2654876167392
	2654875961232 -> 2654876167392
	2654875960848 -> 2654876167392
	2654875960176 -> 2654876167392
	2654875960320 -> 2654876167392
	2654875959648 -> 2654876167392
	2654875959792 -> 2654876167392
	2654875975584 -> 2654876167392
	2654875971504 -> 2654876167392
	2654875971600 -> 2654876167392
	2654875971744 -> 2654876167392
	2654875971552 -> 2654876167392
	2654875971648 -> 2654876167392
	2654875971360 -> 2654876167392
	2654875971312 -> 2654876167392
	2654875971168 -> 2654876167392
	2654875970976 -> 2654876167392
	2654875971072 -> 2654876167392
	2654875971216 -> 2654876167392
	2654876167248 -> 2654876167920
	2654803523632 [label="features.denseblock3.denselayer20.norm1.weight
 (864)" fillcolor=lightblue]
	2654803523632 -> 2654876167248
	2654876167248 [label=AccumulateGrad]
	2654876168448 -> 2654876167920
	2654803523728 [label="features.denseblock3.denselayer20.norm1.bias
 (864)" fillcolor=lightblue]
	2654803523728 -> 2654876168448
	2654876168448 [label=AccumulateGrad]
	2654876168976 -> 2654876169360
	2654803524112 [label="features.denseblock3.denselayer20.conv1.weight
 (128, 864, 1, 1)" fillcolor=lightblue]
	2654803524112 -> 2654876168976
	2654876168976 [label=AccumulateGrad]
	2654876170944 -> 2654876169888
	2654803524208 [label="features.denseblock3.denselayer20.norm2.weight
 (128)" fillcolor=lightblue]
	2654803524208 -> 2654876170944
	2654876170944 [label=AccumulateGrad]
	2654876172000 -> 2654876169888
	2654803524304 [label="features.denseblock3.denselayer20.norm2.bias
 (128)" fillcolor=lightblue]
	2654803524304 -> 2654876172000
	2654876172000 [label=AccumulateGrad]
	2654876041472 -> 2654875971024
	2654803524688 [label="features.denseblock3.denselayer20.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654803524688 -> 2654876041472
	2654876041472 [label=AccumulateGrad]
	2654875971120 -> 2654875961760
	2654875971120 [label=ConvolutionBackward0]
	2654876054960 -> 2654875971120
	2654876054960 [label=ReluBackward0]
	2654876166720 -> 2654876054960
	2654876166720 [label=CudnnBatchNormBackward0]
	2654876166192 -> 2654876166720
	2654876166192 [label=ConvolutionBackward0]
	2654876165136 -> 2654876166192
	2654876165136 [label=ReluBackward0]
	2654876164752 -> 2654876165136
	2654876164752 [label=CudnnBatchNormBackward0]
	2654876164224 -> 2654876164752
	2654876164224 [label=CatBackward0]
	2654875960704 -> 2654876164224
	2654875961376 -> 2654876164224
	2654875961232 -> 2654876164224
	2654875960848 -> 2654876164224
	2654875960176 -> 2654876164224
	2654875960320 -> 2654876164224
	2654875959648 -> 2654876164224
	2654875959792 -> 2654876164224
	2654875975584 -> 2654876164224
	2654875971504 -> 2654876164224
	2654875971600 -> 2654876164224
	2654875971744 -> 2654876164224
	2654875971552 -> 2654876164224
	2654875971648 -> 2654876164224
	2654875971360 -> 2654876164224
	2654875971312 -> 2654876164224
	2654875971168 -> 2654876164224
	2654875970976 -> 2654876164224
	2654875971072 -> 2654876164224
	2654875971216 -> 2654876164224
	2654875971024 -> 2654876164224
	2654876164080 -> 2654876164752
	2654803524784 [label="features.denseblock3.denselayer21.norm1.weight
 (896)" fillcolor=lightblue]
	2654803524784 -> 2654876164080
	2654876164080 [label=AccumulateGrad]
	2654876165280 -> 2654876164752
	2654803524880 [label="features.denseblock3.denselayer21.norm1.bias
 (896)" fillcolor=lightblue]
	2654803524880 -> 2654876165280
	2654876165280 [label=AccumulateGrad]
	2654876165808 -> 2654876166192
	2654803525264 [label="features.denseblock3.denselayer21.conv1.weight
 (128, 896, 1, 1)" fillcolor=lightblue]
	2654803525264 -> 2654876165808
	2654876165808 [label=AccumulateGrad]
	2654876167776 -> 2654876166720
	2654803525360 [label="features.denseblock3.denselayer21.norm2.weight
 (128)" fillcolor=lightblue]
	2654803525360 -> 2654876167776
	2654876167776 [label=AccumulateGrad]
	2654876169504 -> 2654876166720
	2654803525456 [label="features.denseblock3.denselayer21.norm2.bias
 (128)" fillcolor=lightblue]
	2654803525456 -> 2654876169504
	2654876169504 [label=AccumulateGrad]
	2654876170032 -> 2654875971120
	2654884659472 [label="features.denseblock3.denselayer21.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884659472 -> 2654876170032
	2654876170032 [label=AccumulateGrad]
	2654875970832 -> 2654875961760
	2654875970832 [label=ConvolutionBackward0]
	2654876166864 -> 2654875970832
	2654876166864 [label=ReluBackward0]
	2654876163552 -> 2654876166864
	2654876163552 [label=CudnnBatchNormBackward0]
	2654876163024 -> 2654876163552
	2654876163024 [label=ConvolutionBackward0]
	2654876161968 -> 2654876163024
	2654876161968 [label=ReluBackward0]
	2654876161584 -> 2654876161968
	2654876161584 [label=CudnnBatchNormBackward0]
	2654876161056 -> 2654876161584
	2654876161056 [label=CatBackward0]
	2654875960704 -> 2654876161056
	2654875961376 -> 2654876161056
	2654875961232 -> 2654876161056
	2654875960848 -> 2654876161056
	2654875960176 -> 2654876161056
	2654875960320 -> 2654876161056
	2654875959648 -> 2654876161056
	2654875959792 -> 2654876161056
	2654875975584 -> 2654876161056
	2654875971504 -> 2654876161056
	2654875971600 -> 2654876161056
	2654875971744 -> 2654876161056
	2654875971552 -> 2654876161056
	2654875971648 -> 2654876161056
	2654875971360 -> 2654876161056
	2654875971312 -> 2654876161056
	2654875971168 -> 2654876161056
	2654875970976 -> 2654876161056
	2654875971072 -> 2654876161056
	2654875971216 -> 2654876161056
	2654875971024 -> 2654876161056
	2654875971120 -> 2654876161056
	2654876160912 -> 2654876161584
	2654884659568 [label="features.denseblock3.denselayer22.norm1.weight
 (928)" fillcolor=lightblue]
	2654884659568 -> 2654876160912
	2654876160912 [label=AccumulateGrad]
	2654876162112 -> 2654876161584
	2654884659664 [label="features.denseblock3.denselayer22.norm1.bias
 (928)" fillcolor=lightblue]
	2654884659664 -> 2654876162112
	2654876162112 [label=AccumulateGrad]
	2654876162640 -> 2654876163024
	2654884660048 [label="features.denseblock3.denselayer22.conv1.weight
 (128, 928, 1, 1)" fillcolor=lightblue]
	2654884660048 -> 2654876162640
	2654876162640 [label=AccumulateGrad]
	2654876164608 -> 2654876163552
	2654884660144 [label="features.denseblock3.denselayer22.norm2.weight
 (128)" fillcolor=lightblue]
	2654884660144 -> 2654876164608
	2654876164608 [label=AccumulateGrad]
	2654876166336 -> 2654876163552
	2654884660240 [label="features.denseblock3.denselayer22.norm2.bias
 (128)" fillcolor=lightblue]
	2654884660240 -> 2654876166336
	2654876166336 [label=AccumulateGrad]
	2654876165664 -> 2654875970832
	2654884660624 [label="features.denseblock3.denselayer22.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884660624 -> 2654876165664
	2654876165664 [label=AccumulateGrad]
	2654875970784 -> 2654875961760
	2654875970784 [label=ConvolutionBackward0]
	2654876163696 -> 2654875970784
	2654876163696 [label=ReluBackward0]
	2654876160384 -> 2654876163696
	2654876160384 [label=CudnnBatchNormBackward0]
	2654876159856 -> 2654876160384
	2654876159856 [label=ConvolutionBackward0]
	2654876158800 -> 2654876159856
	2654876158800 [label=ReluBackward0]
	2654876158416 -> 2654876158800
	2654876158416 [label=CudnnBatchNormBackward0]
	2654876157888 -> 2654876158416
	2654876157888 [label=CatBackward0]
	2654875960704 -> 2654876157888
	2654875961376 -> 2654876157888
	2654875961232 -> 2654876157888
	2654875960848 -> 2654876157888
	2654875960176 -> 2654876157888
	2654875960320 -> 2654876157888
	2654875959648 -> 2654876157888
	2654875959792 -> 2654876157888
	2654875975584 -> 2654876157888
	2654875971504 -> 2654876157888
	2654875971600 -> 2654876157888
	2654875971744 -> 2654876157888
	2654875971552 -> 2654876157888
	2654875971648 -> 2654876157888
	2654875971360 -> 2654876157888
	2654875971312 -> 2654876157888
	2654875971168 -> 2654876157888
	2654875970976 -> 2654876157888
	2654875971072 -> 2654876157888
	2654875971216 -> 2654876157888
	2654875971024 -> 2654876157888
	2654875971120 -> 2654876157888
	2654875970832 -> 2654876157888
	2654876157744 -> 2654876158416
	2654884660720 [label="features.denseblock3.denselayer23.norm1.weight
 (960)" fillcolor=lightblue]
	2654884660720 -> 2654876157744
	2654876157744 [label=AccumulateGrad]
	2654876158944 -> 2654876158416
	2654884660816 [label="features.denseblock3.denselayer23.norm1.bias
 (960)" fillcolor=lightblue]
	2654884660816 -> 2654876158944
	2654876158944 [label=AccumulateGrad]
	2654876159472 -> 2654876159856
	2654884661200 [label="features.denseblock3.denselayer23.conv1.weight
 (128, 960, 1, 1)" fillcolor=lightblue]
	2654884661200 -> 2654876159472
	2654876159472 [label=AccumulateGrad]
	2654876161440 -> 2654876160384
	2654884661296 [label="features.denseblock3.denselayer23.norm2.weight
 (128)" fillcolor=lightblue]
	2654884661296 -> 2654876161440
	2654876161440 [label=AccumulateGrad]
	2654876163168 -> 2654876160384
	2654884661392 [label="features.denseblock3.denselayer23.norm2.bias
 (128)" fillcolor=lightblue]
	2654884661392 -> 2654876163168
	2654876163168 [label=AccumulateGrad]
	2654876162496 -> 2654875970784
	2654884661776 [label="features.denseblock3.denselayer23.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884661776 -> 2654876162496
	2654876162496 [label=AccumulateGrad]
	2654875970640 -> 2654875961760
	2654875970640 [label=ConvolutionBackward0]
	2654876160528 -> 2654875970640
	2654876160528 [label=ReluBackward0]
	2654876157216 -> 2654876160528
	2654876157216 [label=CudnnBatchNormBackward0]
	2654876156688 -> 2654876157216
	2654876156688 [label=ConvolutionBackward0]
	2654876172240 -> 2654876156688
	2654876172240 [label=ReluBackward0]
	2654876171904 -> 2654876172240
	2654876171904 [label=CudnnBatchNormBackward0]
	2654876171808 -> 2654876171904
	2654876171808 [label=CatBackward0]
	2654875960704 -> 2654876171808
	2654875961376 -> 2654876171808
	2654875961232 -> 2654876171808
	2654875960848 -> 2654876171808
	2654875960176 -> 2654876171808
	2654875960320 -> 2654876171808
	2654875959648 -> 2654876171808
	2654875959792 -> 2654876171808
	2654875975584 -> 2654876171808
	2654875971504 -> 2654876171808
	2654875971600 -> 2654876171808
	2654875971744 -> 2654876171808
	2654875971552 -> 2654876171808
	2654875971648 -> 2654876171808
	2654875971360 -> 2654876171808
	2654875971312 -> 2654876171808
	2654875971168 -> 2654876171808
	2654875970976 -> 2654876171808
	2654875971072 -> 2654876171808
	2654875971216 -> 2654876171808
	2654875971024 -> 2654876171808
	2654875971120 -> 2654876171808
	2654875970832 -> 2654876171808
	2654875970784 -> 2654876171808
	2654876171712 -> 2654876171904
	2654884661872 [label="features.denseblock3.denselayer24.norm1.weight
 (992)" fillcolor=lightblue]
	2654884661872 -> 2654876171712
	2654876171712 [label=AccumulateGrad]
	2654876172096 -> 2654876171904
	2654884661968 [label="features.denseblock3.denselayer24.norm1.bias
 (992)" fillcolor=lightblue]
	2654884661968 -> 2654876172096
	2654876172096 [label=AccumulateGrad]
	2654876156304 -> 2654876156688
	2654884662352 [label="features.denseblock3.denselayer24.conv1.weight
 (128, 992, 1, 1)" fillcolor=lightblue]
	2654884662352 -> 2654876156304
	2654876156304 [label=AccumulateGrad]
	2654876158272 -> 2654876157216
	2654884662448 [label="features.denseblock3.denselayer24.norm2.weight
 (128)" fillcolor=lightblue]
	2654884662448 -> 2654876158272
	2654876158272 [label=AccumulateGrad]
	2654876160000 -> 2654876157216
	2654884662544 [label="features.denseblock3.denselayer24.norm2.bias
 (128)" fillcolor=lightblue]
	2654884662544 -> 2654876160000
	2654876160000 [label=AccumulateGrad]
	2654876159328 -> 2654875970640
	2654884662928 [label="features.denseblock3.denselayer24.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884662928 -> 2654876159328
	2654876159328 [label=AccumulateGrad]
	2654875962432 -> 2654875962288
	2654884663024 [label="features.transition3.norm.weight
 (1024)" fillcolor=lightblue]
	2654884663024 -> 2654875962432
	2654875962432 [label=AccumulateGrad]
	2654875962816 -> 2654875962288
	2654884663120 [label="features.transition3.norm.bias
 (1024)" fillcolor=lightblue]
	2654884663120 -> 2654875962816
	2654875962816 [label=AccumulateGrad]
	2654875963344 -> 2654875964016
	2654884663504 [label="features.transition3.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2654884663504 -> 2654875963344
	2654875963344 [label=AccumulateGrad]
	2654875968624 -> 2654875969824
	2654875968624 [label=ConvolutionBackward0]
	2654875970448 -> 2654875968624
	2654875970448 [label=ReluBackward0]
	2654875962960 -> 2654875970448
	2654875962960 [label=CudnnBatchNormBackward0]
	2654876157360 -> 2654875962960
	2654876157360 [label=ConvolutionBackward0]
	2654876172048 -> 2654876157360
	2654876172048 [label=ReluBackward0]
	2654876171520 -> 2654876172048
	2654876171520 [label=CudnnBatchNormBackward0]
	2654876171184 -> 2654876171520
	2654876171184 [label=CatBackward0]
	2654875968768 -> 2654876171184
	2654876171376 -> 2654876171520
	2654884663600 [label="features.denseblock4.denselayer1.norm1.weight
 (512)" fillcolor=lightblue]
	2654884663600 -> 2654876171376
	2654876171376 [label=AccumulateGrad]
	2654876171856 -> 2654876171520
	2654884663696 [label="features.denseblock4.denselayer1.norm1.bias
 (512)" fillcolor=lightblue]
	2654884663696 -> 2654876171856
	2654876171856 [label=AccumulateGrad]
	2654876171952 -> 2654876157360
	2654884664080 [label="features.denseblock4.denselayer1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2654884664080 -> 2654876171952
	2654876171952 [label=AccumulateGrad]
	2654876156160 -> 2654875962960
	2654884664176 [label="features.denseblock4.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2654884664176 -> 2654876156160
	2654876156160 [label=AccumulateGrad]
	2654876168832 -> 2654875962960
	2654884664272 [label="features.denseblock4.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2654884664272 -> 2654876168832
	2654876168832 [label=AccumulateGrad]
	2654875964544 -> 2654875968624
	2654884664656 [label="features.denseblock4.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884664656 -> 2654875964544
	2654875964544 [label=AccumulateGrad]
	2654875969296 -> 2654875969824
	2654875969296 [label=ConvolutionBackward0]
	2654875961904 -> 2654875969296
	2654875961904 [label=ReluBackward0]
	2654876171280 -> 2654875961904
	2654876171280 [label=CudnnBatchNormBackward0]
	2654876171232 -> 2654876171280
	2654876171232 [label=ConvolutionBackward0]
	2654876170848 -> 2654876171232
	2654876170848 [label=ReluBackward0]
	2654876170896 -> 2654876170848
	2654876170896 [label=CudnnBatchNormBackward0]
	2654876170800 -> 2654876170896
	2654876170800 [label=CatBackward0]
	2654875968768 -> 2654876170800
	2654875968624 -> 2654876170800
	2654876170704 -> 2654876170896
	2654884664752 [label="features.denseblock4.denselayer2.norm1.weight
 (544)" fillcolor=lightblue]
	2654884664752 -> 2654876170704
	2654876170704 [label=AccumulateGrad]
	2654876170656 -> 2654876170896
	2654884664848 [label="features.denseblock4.denselayer2.norm1.bias
 (544)" fillcolor=lightblue]
	2654884664848 -> 2654876170656
	2654876170656 [label=AccumulateGrad]
	2654876170992 -> 2654876171232
	2654884665232 [label="features.denseblock4.denselayer2.conv1.weight
 (128, 544, 1, 1)" fillcolor=lightblue]
	2654884665232 -> 2654876170992
	2654876170992 [label=AccumulateGrad]
	2654876171760 -> 2654876171280
	2654884665328 [label="features.denseblock4.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2654884665328 -> 2654876171760
	2654876171760 [label=AccumulateGrad]
	2654876156832 -> 2654876171280
	2654884665424 [label="features.denseblock4.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2654884665424 -> 2654876156832
	2654876156832 [label=AccumulateGrad]
	2654875963872 -> 2654875969296
	2654884665808 [label="features.denseblock4.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884665808 -> 2654875963872
	2654875963872 [label=AccumulateGrad]
	2654875968096 -> 2654875969824
	2654875968096 [label=ConvolutionBackward0]
	2654876171424 -> 2654875968096
	2654876171424 [label=ReluBackward0]
	2654876170512 -> 2654876171424
	2654876170512 [label=CudnnBatchNormBackward0]
	2654876170320 -> 2654876170512
	2654876170320 [label=ConvolutionBackward0]
	2654876170176 -> 2654876170320
	2654876170176 [label=ReluBackward0]
	2654876169936 -> 2654876170176
	2654876169936 [label=CudnnBatchNormBackward0]
	2654876169600 -> 2654876169936
	2654876169600 [label=CatBackward0]
	2654875968768 -> 2654876169600
	2654875968624 -> 2654876169600
	2654875969296 -> 2654876169600
	2654876169792 -> 2654876169936
	2654884665904 [label="features.denseblock4.denselayer3.norm1.weight
 (576)" fillcolor=lightblue]
	2654884665904 -> 2654876169792
	2654876169792 [label=AccumulateGrad]
	2654876170272 -> 2654876169936
	2654884666000 [label="features.denseblock4.denselayer3.norm1.bias
 (576)" fillcolor=lightblue]
	2654884666000 -> 2654876170272
	2654876170272 [label=AccumulateGrad]
	2654876170368 -> 2654876170320
	2654884666384 [label="features.denseblock4.denselayer3.conv1.weight
 (128, 576, 1, 1)" fillcolor=lightblue]
	2654884666384 -> 2654876170368
	2654876170368 [label=AccumulateGrad]
	2654876170752 -> 2654876170512
	2654884666480 [label="features.denseblock4.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2654884666480 -> 2654876170752
	2654876170752 [label=AccumulateGrad]
	2654876171328 -> 2654876170512
	2654884666576 [label="features.denseblock4.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2654884666576 -> 2654876171328
	2654876171328 [label=AccumulateGrad]
	2654876171040 -> 2654875968096
	2654884666960 [label="features.denseblock4.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884666960 -> 2654876171040
	2654876171040 [label=AccumulateGrad]
	2654875968240 -> 2654875969824
	2654875968240 [label=ConvolutionBackward0]
	2654876170464 -> 2654875968240
	2654876170464 [label=ReluBackward0]
	2654876169696 -> 2654876170464
	2654876169696 [label=CudnnBatchNormBackward0]
	2654876169648 -> 2654876169696
	2654876169648 [label=ConvolutionBackward0]
	2654876169264 -> 2654876169648
	2654876169264 [label=ReluBackward0]
	2654876169312 -> 2654876169264
	2654876169312 [label=CudnnBatchNormBackward0]
	2654876169216 -> 2654876169312
	2654876169216 [label=CatBackward0]
	2654875968768 -> 2654876169216
	2654875968624 -> 2654876169216
	2654875969296 -> 2654876169216
	2654875968096 -> 2654876169216
	2654876169120 -> 2654876169312
	2654884667056 [label="features.denseblock4.denselayer4.norm1.weight
 (608)" fillcolor=lightblue]
	2654884667056 -> 2654876169120
	2654876169120 [label=AccumulateGrad]
	2654876169072 -> 2654876169312
	2654884667152 [label="features.denseblock4.denselayer4.norm1.bias
 (608)" fillcolor=lightblue]
	2654884667152 -> 2654876169072
	2654876169072 [label=AccumulateGrad]
	2654876169408 -> 2654876169648
	2654884667536 [label="features.denseblock4.denselayer4.conv1.weight
 (128, 608, 1, 1)" fillcolor=lightblue]
	2654884667536 -> 2654876169408
	2654876169408 [label=AccumulateGrad]
	2654876169984 -> 2654876169696
	2654884667632 [label="features.denseblock4.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2654884667632 -> 2654876169984
	2654876169984 [label=AccumulateGrad]
	2654876170128 -> 2654876169696
	2654884667728 [label="features.denseblock4.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2654884667728 -> 2654876170128
	2654876170128 [label=AccumulateGrad]
	2654876170224 -> 2654875968240
	2654884668112 [label="features.denseblock4.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884668112 -> 2654876170224
	2654876170224 [label=AccumulateGrad]
	2654875967568 -> 2654875969824
	2654875967568 [label=ConvolutionBackward0]
	2654876169840 -> 2654875967568
	2654876169840 [label=ReluBackward0]
	2654876168928 -> 2654876169840
	2654876168928 [label=CudnnBatchNormBackward0]
	2654876168736 -> 2654876168928
	2654876168736 [label=ConvolutionBackward0]
	2654876168592 -> 2654876168736
	2654876168592 [label=ReluBackward0]
	2654876168352 -> 2654876168592
	2654876168352 [label=CudnnBatchNormBackward0]
	2654876168016 -> 2654876168352
	2654876168016 [label=CatBackward0]
	2654875968768 -> 2654876168016
	2654875968624 -> 2654876168016
	2654875969296 -> 2654876168016
	2654875968096 -> 2654876168016
	2654875968240 -> 2654876168016
	2654876168208 -> 2654876168352
	2654884668208 [label="features.denseblock4.denselayer5.norm1.weight
 (640)" fillcolor=lightblue]
	2654884668208 -> 2654876168208
	2654876168208 [label=AccumulateGrad]
	2654876168688 -> 2654876168352
	2654884668304 [label="features.denseblock4.denselayer5.norm1.bias
 (640)" fillcolor=lightblue]
	2654884668304 -> 2654876168688
	2654876168688 [label=AccumulateGrad]
	2654876168784 -> 2654876168736
	2654884668688 [label="features.denseblock4.denselayer5.conv1.weight
 (128, 640, 1, 1)" fillcolor=lightblue]
	2654884668688 -> 2654876168784
	2654876168784 [label=AccumulateGrad]
	2654876169168 -> 2654876168928
	2654884668784 [label="features.denseblock4.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2654884668784 -> 2654876169168
	2654876169168 [label=AccumulateGrad]
	2654876169744 -> 2654876168928
	2654884668880 [label="features.denseblock4.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2654884668880 -> 2654876169744
	2654876169744 [label=AccumulateGrad]
	2654876169456 -> 2654875967568
	2654884669264 [label="features.denseblock4.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884669264 -> 2654876169456
	2654876169456 [label=AccumulateGrad]
	2654875967712 -> 2654875969824
	2654875967712 [label=ConvolutionBackward0]
	2654876168880 -> 2654875967712
	2654876168880 [label=ReluBackward0]
	2654876168112 -> 2654876168880
	2654876168112 [label=CudnnBatchNormBackward0]
	2654876168064 -> 2654876168112
	2654876168064 [label=ConvolutionBackward0]
	2654876167680 -> 2654876168064
	2654876167680 [label=ReluBackward0]
	2654876167728 -> 2654876167680
	2654876167728 [label=CudnnBatchNormBackward0]
	2654876167632 -> 2654876167728
	2654876167632 [label=CatBackward0]
	2654875968768 -> 2654876167632
	2654875968624 -> 2654876167632
	2654875969296 -> 2654876167632
	2654875968096 -> 2654876167632
	2654875968240 -> 2654876167632
	2654875967568 -> 2654876167632
	2654876167536 -> 2654876167728
	2654884669360 [label="features.denseblock4.denselayer6.norm1.weight
 (672)" fillcolor=lightblue]
	2654884669360 -> 2654876167536
	2654876167536 [label=AccumulateGrad]
	2654876167488 -> 2654876167728
	2654884669456 [label="features.denseblock4.denselayer6.norm1.bias
 (672)" fillcolor=lightblue]
	2654884669456 -> 2654876167488
	2654876167488 [label=AccumulateGrad]
	2654876167824 -> 2654876168064
	2654884669840 [label="features.denseblock4.denselayer6.conv1.weight
 (128, 672, 1, 1)" fillcolor=lightblue]
	2654884669840 -> 2654876167824
	2654876167824 [label=AccumulateGrad]
	2654876168400 -> 2654876168112
	2654884669936 [label="features.denseblock4.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2654884669936 -> 2654876168400
	2654876168400 [label=AccumulateGrad]
	2654876168544 -> 2654876168112
	2654884670032 [label="features.denseblock4.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2654884670032 -> 2654876168544
	2654876168544 [label=AccumulateGrad]
	2654876168640 -> 2654875967712
	2654884670416 [label="features.denseblock4.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884670416 -> 2654876168640
	2654876168640 [label=AccumulateGrad]
	2654875967040 -> 2654875969824
	2654875967040 [label=ConvolutionBackward0]
	2654876168256 -> 2654875967040
	2654876168256 [label=ReluBackward0]
	2654876167344 -> 2654876168256
	2654876167344 [label=CudnnBatchNormBackward0]
	2654876167152 -> 2654876167344
	2654876167152 [label=ConvolutionBackward0]
	2654876167008 -> 2654876167152
	2654876167008 [label=ReluBackward0]
	2654876166768 -> 2654876167008
	2654876166768 [label=CudnnBatchNormBackward0]
	2654876166432 -> 2654876166768
	2654876166432 [label=CatBackward0]
	2654875968768 -> 2654876166432
	2654875968624 -> 2654876166432
	2654875969296 -> 2654876166432
	2654875968096 -> 2654876166432
	2654875968240 -> 2654876166432
	2654875967568 -> 2654876166432
	2654875967712 -> 2654876166432
	2654876166624 -> 2654876166768
	2654884670512 [label="features.denseblock4.denselayer7.norm1.weight
 (704)" fillcolor=lightblue]
	2654884670512 -> 2654876166624
	2654876166624 [label=AccumulateGrad]
	2654876167104 -> 2654876166768
	2654884670608 [label="features.denseblock4.denselayer7.norm1.bias
 (704)" fillcolor=lightblue]
	2654884670608 -> 2654876167104
	2654876167104 [label=AccumulateGrad]
	2654876167200 -> 2654876167152
	2654884670992 [label="features.denseblock4.denselayer7.conv1.weight
 (128, 704, 1, 1)" fillcolor=lightblue]
	2654884670992 -> 2654876167200
	2654876167200 [label=AccumulateGrad]
	2654876167584 -> 2654876167344
	2654884671088 [label="features.denseblock4.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	2654884671088 -> 2654876167584
	2654876167584 [label=AccumulateGrad]
	2654876168160 -> 2654876167344
	2654884671184 [label="features.denseblock4.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	2654884671184 -> 2654876168160
	2654876168160 [label=AccumulateGrad]
	2654876167872 -> 2654875967040
	2654884671568 [label="features.denseblock4.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884671568 -> 2654876167872
	2654876167872 [label=AccumulateGrad]
	2654875967184 -> 2654875969824
	2654875967184 [label=ConvolutionBackward0]
	2654876167296 -> 2654875967184
	2654876167296 [label=ReluBackward0]
	2654876166528 -> 2654876167296
	2654876166528 [label=CudnnBatchNormBackward0]
	2654876166480 -> 2654876166528
	2654876166480 [label=ConvolutionBackward0]
	2654876166096 -> 2654876166480
	2654876166096 [label=ReluBackward0]
	2654876166144 -> 2654876166096
	2654876166144 [label=CudnnBatchNormBackward0]
	2654876166048 -> 2654876166144
	2654876166048 [label=CatBackward0]
	2654875968768 -> 2654876166048
	2654875968624 -> 2654876166048
	2654875969296 -> 2654876166048
	2654875968096 -> 2654876166048
	2654875968240 -> 2654876166048
	2654875967568 -> 2654876166048
	2654875967712 -> 2654876166048
	2654875967040 -> 2654876166048
	2654876165952 -> 2654876166144
	2654884671664 [label="features.denseblock4.denselayer8.norm1.weight
 (736)" fillcolor=lightblue]
	2654884671664 -> 2654876165952
	2654876165952 [label=AccumulateGrad]
	2654876165904 -> 2654876166144
	2654884671760 [label="features.denseblock4.denselayer8.norm1.bias
 (736)" fillcolor=lightblue]
	2654884671760 -> 2654876165904
	2654876165904 [label=AccumulateGrad]
	2654876166240 -> 2654876166480
	2654884672144 [label="features.denseblock4.denselayer8.conv1.weight
 (128, 736, 1, 1)" fillcolor=lightblue]
	2654884672144 -> 2654876166240
	2654876166240 [label=AccumulateGrad]
	2654876166816 -> 2654876166528
	2654884672240 [label="features.denseblock4.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	2654884672240 -> 2654876166816
	2654876166816 [label=AccumulateGrad]
	2654876166960 -> 2654876166528
	2654884672336 [label="features.denseblock4.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	2654884672336 -> 2654876166960
	2654876166960 [label=AccumulateGrad]
	2654876167056 -> 2654875967184
	2654884672720 [label="features.denseblock4.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884672720 -> 2654876167056
	2654876167056 [label=AccumulateGrad]
	2654875966512 -> 2654875969824
	2654875966512 [label=ConvolutionBackward0]
	2654876166672 -> 2654875966512
	2654876166672 [label=ReluBackward0]
	2654876165760 -> 2654876166672
	2654876165760 [label=CudnnBatchNormBackward0]
	2654876165568 -> 2654876165760
	2654876165568 [label=ConvolutionBackward0]
	2654876165424 -> 2654876165568
	2654876165424 [label=ReluBackward0]
	2654876165184 -> 2654876165424
	2654876165184 [label=CudnnBatchNormBackward0]
	2654876164848 -> 2654876165184
	2654876164848 [label=CatBackward0]
	2654875968768 -> 2654876164848
	2654875968624 -> 2654876164848
	2654875969296 -> 2654876164848
	2654875968096 -> 2654876164848
	2654875968240 -> 2654876164848
	2654875967568 -> 2654876164848
	2654875967712 -> 2654876164848
	2654875967040 -> 2654876164848
	2654875967184 -> 2654876164848
	2654876165040 -> 2654876165184
	2654884672816 [label="features.denseblock4.denselayer9.norm1.weight
 (768)" fillcolor=lightblue]
	2654884672816 -> 2654876165040
	2654876165040 [label=AccumulateGrad]
	2654876165520 -> 2654876165184
	2654884672912 [label="features.denseblock4.denselayer9.norm1.bias
 (768)" fillcolor=lightblue]
	2654884672912 -> 2654876165520
	2654876165520 [label=AccumulateGrad]
	2654876165616 -> 2654876165568
	2654884673296 [label="features.denseblock4.denselayer9.conv1.weight
 (128, 768, 1, 1)" fillcolor=lightblue]
	2654884673296 -> 2654876165616
	2654876165616 [label=AccumulateGrad]
	2654876166000 -> 2654876165760
	2654884673392 [label="features.denseblock4.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	2654884673392 -> 2654876166000
	2654876166000 [label=AccumulateGrad]
	2654876166576 -> 2654876165760
	2654884673488 [label="features.denseblock4.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	2654884673488 -> 2654876166576
	2654876166576 [label=AccumulateGrad]
	2654876166288 -> 2654875966512
	2654884673872 [label="features.denseblock4.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884673872 -> 2654876166288
	2654876166288 [label=AccumulateGrad]
	2654875966656 -> 2654875969824
	2654875966656 [label=ConvolutionBackward0]
	2654876165712 -> 2654875966656
	2654876165712 [label=ReluBackward0]
	2654876164944 -> 2654876165712
	2654876164944 [label=CudnnBatchNormBackward0]
	2654876164896 -> 2654876164944
	2654876164896 [label=ConvolutionBackward0]
	2654876164512 -> 2654876164896
	2654876164512 [label=ReluBackward0]
	2654876164560 -> 2654876164512
	2654876164560 [label=CudnnBatchNormBackward0]
	2654876164464 -> 2654876164560
	2654876164464 [label=CatBackward0]
	2654875968768 -> 2654876164464
	2654875968624 -> 2654876164464
	2654875969296 -> 2654876164464
	2654875968096 -> 2654876164464
	2654875968240 -> 2654876164464
	2654875967568 -> 2654876164464
	2654875967712 -> 2654876164464
	2654875967040 -> 2654876164464
	2654875967184 -> 2654876164464
	2654875966512 -> 2654876164464
	2654876164368 -> 2654876164560
	2654884673968 [label="features.denseblock4.denselayer10.norm1.weight
 (800)" fillcolor=lightblue]
	2654884673968 -> 2654876164368
	2654876164368 [label=AccumulateGrad]
	2654876164320 -> 2654876164560
	2654884674064 [label="features.denseblock4.denselayer10.norm1.bias
 (800)" fillcolor=lightblue]
	2654884674064 -> 2654876164320
	2654876164320 [label=AccumulateGrad]
	2654876164656 -> 2654876164896
	2654884674448 [label="features.denseblock4.denselayer10.conv1.weight
 (128, 800, 1, 1)" fillcolor=lightblue]
	2654884674448 -> 2654876164656
	2654876164656 [label=AccumulateGrad]
	2654876165232 -> 2654876164944
	2654884674544 [label="features.denseblock4.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	2654884674544 -> 2654876165232
	2654876165232 [label=AccumulateGrad]
	2654876165376 -> 2654876164944
	2654884674640 [label="features.denseblock4.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	2654884674640 -> 2654876165376
	2654876165376 [label=AccumulateGrad]
	2654876165472 -> 2654875966656
	2654884675024 [label="features.denseblock4.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884675024 -> 2654876165472
	2654876165472 [label=AccumulateGrad]
	2654875965984 -> 2654875969824
	2654875965984 [label=ConvolutionBackward0]
	2654876165088 -> 2654875965984
	2654876165088 [label=ReluBackward0]
	2654876164176 -> 2654876165088
	2654876164176 [label=CudnnBatchNormBackward0]
	2654876163984 -> 2654876164176
	2654876163984 [label=ConvolutionBackward0]
	2654876163840 -> 2654876163984
	2654876163840 [label=ReluBackward0]
	2654876163600 -> 2654876163840
	2654876163600 [label=CudnnBatchNormBackward0]
	2654876163264 -> 2654876163600
	2654876163264 [label=CatBackward0]
	2654875968768 -> 2654876163264
	2654875968624 -> 2654876163264
	2654875969296 -> 2654876163264
	2654875968096 -> 2654876163264
	2654875968240 -> 2654876163264
	2654875967568 -> 2654876163264
	2654875967712 -> 2654876163264
	2654875967040 -> 2654876163264
	2654875967184 -> 2654876163264
	2654875966512 -> 2654876163264
	2654875966656 -> 2654876163264
	2654876163456 -> 2654876163600
	2654884675120 [label="features.denseblock4.denselayer11.norm1.weight
 (832)" fillcolor=lightblue]
	2654884675120 -> 2654876163456
	2654876163456 [label=AccumulateGrad]
	2654876163936 -> 2654876163600
	2654884675216 [label="features.denseblock4.denselayer11.norm1.bias
 (832)" fillcolor=lightblue]
	2654884675216 -> 2654876163936
	2654876163936 [label=AccumulateGrad]
	2654876164032 -> 2654876163984
	2654884741200 [label="features.denseblock4.denselayer11.conv1.weight
 (128, 832, 1, 1)" fillcolor=lightblue]
	2654884741200 -> 2654876164032
	2654876164032 [label=AccumulateGrad]
	2654876164416 -> 2654876164176
	2654884741296 [label="features.denseblock4.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	2654884741296 -> 2654876164416
	2654876164416 [label=AccumulateGrad]
	2654876164992 -> 2654876164176
	2654884741392 [label="features.denseblock4.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	2654884741392 -> 2654876164992
	2654876164992 [label=AccumulateGrad]
	2654876164704 -> 2654875965984
	2654884741776 [label="features.denseblock4.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884741776 -> 2654876164704
	2654876164704 [label=AccumulateGrad]
	2654875966128 -> 2654875969824
	2654875966128 [label=ConvolutionBackward0]
	2654876164128 -> 2654875966128
	2654876164128 [label=ReluBackward0]
	2654876163360 -> 2654876164128
	2654876163360 [label=CudnnBatchNormBackward0]
	2654876163312 -> 2654876163360
	2654876163312 [label=ConvolutionBackward0]
	2654876162928 -> 2654876163312
	2654876162928 [label=ReluBackward0]
	2654876162976 -> 2654876162928
	2654876162976 [label=CudnnBatchNormBackward0]
	2654876162880 -> 2654876162976
	2654876162880 [label=CatBackward0]
	2654875968768 -> 2654876162880
	2654875968624 -> 2654876162880
	2654875969296 -> 2654876162880
	2654875968096 -> 2654876162880
	2654875968240 -> 2654876162880
	2654875967568 -> 2654876162880
	2654875967712 -> 2654876162880
	2654875967040 -> 2654876162880
	2654875967184 -> 2654876162880
	2654875966512 -> 2654876162880
	2654875966656 -> 2654876162880
	2654875965984 -> 2654876162880
	2654876162784 -> 2654876162976
	2654884741872 [label="features.denseblock4.denselayer12.norm1.weight
 (864)" fillcolor=lightblue]
	2654884741872 -> 2654876162784
	2654876162784 [label=AccumulateGrad]
	2654876162736 -> 2654876162976
	2654884741968 [label="features.denseblock4.denselayer12.norm1.bias
 (864)" fillcolor=lightblue]
	2654884741968 -> 2654876162736
	2654876162736 [label=AccumulateGrad]
	2654876163072 -> 2654876163312
	2654884742352 [label="features.denseblock4.denselayer12.conv1.weight
 (128, 864, 1, 1)" fillcolor=lightblue]
	2654884742352 -> 2654876163072
	2654876163072 [label=AccumulateGrad]
	2654876163648 -> 2654876163360
	2654884742448 [label="features.denseblock4.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	2654884742448 -> 2654876163648
	2654876163648 [label=AccumulateGrad]
	2654876163792 -> 2654876163360
	2654884742544 [label="features.denseblock4.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	2654884742544 -> 2654876163792
	2654876163792 [label=AccumulateGrad]
	2654876163888 -> 2654875966128
	2654884742928 [label="features.denseblock4.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884742928 -> 2654876163888
	2654876163888 [label=AccumulateGrad]
	2654875965456 -> 2654875969824
	2654875965456 [label=ConvolutionBackward0]
	2654876163504 -> 2654875965456
	2654876163504 [label=ReluBackward0]
	2654876162592 -> 2654876163504
	2654876162592 [label=CudnnBatchNormBackward0]
	2654876162400 -> 2654876162592
	2654876162400 [label=ConvolutionBackward0]
	2654876162256 -> 2654876162400
	2654876162256 [label=ReluBackward0]
	2654876162016 -> 2654876162256
	2654876162016 [label=CudnnBatchNormBackward0]
	2654876161680 -> 2654876162016
	2654876161680 [label=CatBackward0]
	2654875968768 -> 2654876161680
	2654875968624 -> 2654876161680
	2654875969296 -> 2654876161680
	2654875968096 -> 2654876161680
	2654875968240 -> 2654876161680
	2654875967568 -> 2654876161680
	2654875967712 -> 2654876161680
	2654875967040 -> 2654876161680
	2654875967184 -> 2654876161680
	2654875966512 -> 2654876161680
	2654875966656 -> 2654876161680
	2654875965984 -> 2654876161680
	2654875966128 -> 2654876161680
	2654876161872 -> 2654876162016
	2654884743024 [label="features.denseblock4.denselayer13.norm1.weight
 (896)" fillcolor=lightblue]
	2654884743024 -> 2654876161872
	2654876161872 [label=AccumulateGrad]
	2654876162352 -> 2654876162016
	2654884743120 [label="features.denseblock4.denselayer13.norm1.bias
 (896)" fillcolor=lightblue]
	2654884743120 -> 2654876162352
	2654876162352 [label=AccumulateGrad]
	2654876162448 -> 2654876162400
	2654884743504 [label="features.denseblock4.denselayer13.conv1.weight
 (128, 896, 1, 1)" fillcolor=lightblue]
	2654884743504 -> 2654876162448
	2654876162448 [label=AccumulateGrad]
	2654876162832 -> 2654876162592
	2654884743600 [label="features.denseblock4.denselayer13.norm2.weight
 (128)" fillcolor=lightblue]
	2654884743600 -> 2654876162832
	2654876162832 [label=AccumulateGrad]
	2654876163408 -> 2654876162592
	2654884743696 [label="features.denseblock4.denselayer13.norm2.bias
 (128)" fillcolor=lightblue]
	2654884743696 -> 2654876163408
	2654876163408 [label=AccumulateGrad]
	2654876163120 -> 2654875965456
	2654884744080 [label="features.denseblock4.denselayer13.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884744080 -> 2654876163120
	2654876163120 [label=AccumulateGrad]
	2654875965600 -> 2654875969824
	2654875965600 [label=ConvolutionBackward0]
	2654876162544 -> 2654875965600
	2654876162544 [label=ReluBackward0]
	2654876161776 -> 2654876162544
	2654876161776 [label=CudnnBatchNormBackward0]
	2654876161728 -> 2654876161776
	2654876161728 [label=ConvolutionBackward0]
	2654876161344 -> 2654876161728
	2654876161344 [label=ReluBackward0]
	2654876161392 -> 2654876161344
	2654876161392 [label=CudnnBatchNormBackward0]
	2654876161296 -> 2654876161392
	2654876161296 [label=CatBackward0]
	2654875968768 -> 2654876161296
	2654875968624 -> 2654876161296
	2654875969296 -> 2654876161296
	2654875968096 -> 2654876161296
	2654875968240 -> 2654876161296
	2654875967568 -> 2654876161296
	2654875967712 -> 2654876161296
	2654875967040 -> 2654876161296
	2654875967184 -> 2654876161296
	2654875966512 -> 2654876161296
	2654875966656 -> 2654876161296
	2654875965984 -> 2654876161296
	2654875966128 -> 2654876161296
	2654875965456 -> 2654876161296
	2654876161200 -> 2654876161392
	2654884744176 [label="features.denseblock4.denselayer14.norm1.weight
 (928)" fillcolor=lightblue]
	2654884744176 -> 2654876161200
	2654876161200 [label=AccumulateGrad]
	2654876161152 -> 2654876161392
	2654884744272 [label="features.denseblock4.denselayer14.norm1.bias
 (928)" fillcolor=lightblue]
	2654884744272 -> 2654876161152
	2654876161152 [label=AccumulateGrad]
	2654876161488 -> 2654876161728
	2654884744656 [label="features.denseblock4.denselayer14.conv1.weight
 (128, 928, 1, 1)" fillcolor=lightblue]
	2654884744656 -> 2654876161488
	2654876161488 [label=AccumulateGrad]
	2654876162064 -> 2654876161776
	2654884744752 [label="features.denseblock4.denselayer14.norm2.weight
 (128)" fillcolor=lightblue]
	2654884744752 -> 2654876162064
	2654876162064 [label=AccumulateGrad]
	2654876162208 -> 2654876161776
	2654884744848 [label="features.denseblock4.denselayer14.norm2.bias
 (128)" fillcolor=lightblue]
	2654884744848 -> 2654876162208
	2654876162208 [label=AccumulateGrad]
	2654876162304 -> 2654875965600
	2654884745232 [label="features.denseblock4.denselayer14.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884745232 -> 2654876162304
	2654876162304 [label=AccumulateGrad]
	2654875964928 -> 2654875969824
	2654875964928 [label=ConvolutionBackward0]
	2654876161920 -> 2654875964928
	2654876161920 [label=ReluBackward0]
	2654876161008 -> 2654876161920
	2654876161008 [label=CudnnBatchNormBackward0]
	2654876160816 -> 2654876161008
	2654876160816 [label=ConvolutionBackward0]
	2654876160672 -> 2654876160816
	2654876160672 [label=ReluBackward0]
	2654876160432 -> 2654876160672
	2654876160432 [label=CudnnBatchNormBackward0]
	2654876160096 -> 2654876160432
	2654876160096 [label=CatBackward0]
	2654875968768 -> 2654876160096
	2654875968624 -> 2654876160096
	2654875969296 -> 2654876160096
	2654875968096 -> 2654876160096
	2654875968240 -> 2654876160096
	2654875967568 -> 2654876160096
	2654875967712 -> 2654876160096
	2654875967040 -> 2654876160096
	2654875967184 -> 2654876160096
	2654875966512 -> 2654876160096
	2654875966656 -> 2654876160096
	2654875965984 -> 2654876160096
	2654875966128 -> 2654876160096
	2654875965456 -> 2654876160096
	2654875965600 -> 2654876160096
	2654876160288 -> 2654876160432
	2654884745328 [label="features.denseblock4.denselayer15.norm1.weight
 (960)" fillcolor=lightblue]
	2654884745328 -> 2654876160288
	2654876160288 [label=AccumulateGrad]
	2654876160768 -> 2654876160432
	2654884745424 [label="features.denseblock4.denselayer15.norm1.bias
 (960)" fillcolor=lightblue]
	2654884745424 -> 2654876160768
	2654876160768 [label=AccumulateGrad]
	2654876160864 -> 2654876160816
	2654884745808 [label="features.denseblock4.denselayer15.conv1.weight
 (128, 960, 1, 1)" fillcolor=lightblue]
	2654884745808 -> 2654876160864
	2654876160864 [label=AccumulateGrad]
	2654876161248 -> 2654876161008
	2654884745904 [label="features.denseblock4.denselayer15.norm2.weight
 (128)" fillcolor=lightblue]
	2654884745904 -> 2654876161248
	2654876161248 [label=AccumulateGrad]
	2654876161824 -> 2654876161008
	2654884746000 [label="features.denseblock4.denselayer15.norm2.bias
 (128)" fillcolor=lightblue]
	2654884746000 -> 2654876161824
	2654876161824 [label=AccumulateGrad]
	2654876161536 -> 2654875964928
	2654884746384 [label="features.denseblock4.denselayer15.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884746384 -> 2654876161536
	2654876161536 [label=AccumulateGrad]
	2654875965072 -> 2654875969824
	2654875965072 [label=ConvolutionBackward0]
	2654876160960 -> 2654875965072
	2654876160960 [label=ReluBackward0]
	2654876160192 -> 2654876160960
	2654876160192 [label=CudnnBatchNormBackward0]
	2654876160144 -> 2654876160192
	2654876160144 [label=ConvolutionBackward0]
	2654876159760 -> 2654876160144
	2654876159760 [label=ReluBackward0]
	2654876159808 -> 2654876159760
	2654876159808 [label=CudnnBatchNormBackward0]
	2654876159712 -> 2654876159808
	2654876159712 [label=CatBackward0]
	2654875968768 -> 2654876159712
	2654875968624 -> 2654876159712
	2654875969296 -> 2654876159712
	2654875968096 -> 2654876159712
	2654875968240 -> 2654876159712
	2654875967568 -> 2654876159712
	2654875967712 -> 2654876159712
	2654875967040 -> 2654876159712
	2654875967184 -> 2654876159712
	2654875966512 -> 2654876159712
	2654875966656 -> 2654876159712
	2654875965984 -> 2654876159712
	2654875966128 -> 2654876159712
	2654875965456 -> 2654876159712
	2654875965600 -> 2654876159712
	2654875964928 -> 2654876159712
	2654876159616 -> 2654876159808
	2654884746480 [label="features.denseblock4.denselayer16.norm1.weight
 (992)" fillcolor=lightblue]
	2654884746480 -> 2654876159616
	2654876159616 [label=AccumulateGrad]
	2654876159568 -> 2654876159808
	2654884746576 [label="features.denseblock4.denselayer16.norm1.bias
 (992)" fillcolor=lightblue]
	2654884746576 -> 2654876159568
	2654876159568 [label=AccumulateGrad]
	2654876159904 -> 2654876160144
	2654884746960 [label="features.denseblock4.denselayer16.conv1.weight
 (128, 992, 1, 1)" fillcolor=lightblue]
	2654884746960 -> 2654876159904
	2654876159904 [label=AccumulateGrad]
	2654876160480 -> 2654876160192
	2654884747056 [label="features.denseblock4.denselayer16.norm2.weight
 (128)" fillcolor=lightblue]
	2654884747056 -> 2654876160480
	2654876160480 [label=AccumulateGrad]
	2654876160624 -> 2654876160192
	2654884747152 [label="features.denseblock4.denselayer16.norm2.bias
 (128)" fillcolor=lightblue]
	2654884747152 -> 2654876160624
	2654876160624 [label=AccumulateGrad]
	2654876160720 -> 2654875965072
	2654884747536 [label="features.denseblock4.denselayer16.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2654884747536 -> 2654876160720
	2654876160720 [label=AccumulateGrad]
	2654875969680 -> 2654875970352
	2654884747632 [label="features.norm5.weight
 (1024)" fillcolor=lightblue]
	2654884747632 -> 2654875969680
	2654875969680 [label=AccumulateGrad]
	2654875971408 -> 2654875970352
	2654884747728 [label="features.norm5.bias
 (1024)" fillcolor=lightblue]
	2654884747728 -> 2654875971408
	2654875971408 [label=AccumulateGrad]
	2654875971936 -> 2654875972848
	2654875971936 [label=TBackward0]
	2654875970208 -> 2654875971936
	2654884748496 [label="classifier.weight
 (19, 1024)" fillcolor=lightblue]
	2654884748496 -> 2654875970208
	2654875970208 [label=AccumulateGrad]
	2654875972848 -> 2654876001264
}
