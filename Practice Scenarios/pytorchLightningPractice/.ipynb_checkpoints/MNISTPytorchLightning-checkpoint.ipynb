{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningMNISTClassifier(pl.LightningModule):\n",
    "    def __init__(self, lr_rate):\n",
    "        super(LightningMNISTClassifier, self).__init__()\n",
    "\n",
    "        self.layer_1 = torch.nn.Linear(28 * 28, 128)\n",
    "        self.layer_2 = torch.nn.Linear(128, 256)\n",
    "        self.layer_3 = torch.nn.Linear(256, 10)\n",
    "        self.lr_rate = lr_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, width, height = x.size()  \n",
    "\n",
    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        # layer 1 (b, 1*28*28) -> (b, 128)\n",
    "        x = self.layer_1(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # layer 2 (b, 128) -> (b, 256)\n",
    "        x = self.layer_2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # layer 3 (b, 256) -> (b, 10)\n",
    "        x = self.layer_3(x)\n",
    "\n",
    "        # probability distribution\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "\n",
    "        # x = torch.sigmoid(x)\n",
    "        return x\n",
    "        \n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.nll_loss(logits, labels)\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "\n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    def test_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "\n",
    "        return {'test_loss': loss}\n",
    "    \n",
    "    def on_validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        logs = {'val_loss': avg_loss}\n",
    "\n",
    "        return {'avg_val_loss': avg_loss, 'log': logs}\n",
    "    \n",
    "    def on_test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        logs = {'test_loss': avg_loss}\n",
    "\n",
    "        return {'avg_test_loss': avg_loss, 'log': logs}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr_rate)\n",
    "        lr_scheduler = {'scheduler': torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1),\n",
    "                        'monitor': 'val_loss'}\n",
    "        \n",
    "        return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Callbacks\n",
    "class MyPrintingCallback(pl.Callback):\n",
    "\n",
    "    def on_init_start(self, trainer):\n",
    "        print('Starting to init trainer!')\n",
    "\n",
    "    def on_init_end(self, trainer):\n",
    "        print('trainer is init now')\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print('do something when training ends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data():\n",
    "  # transforms for images\n",
    "  transform=transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    \n",
    "  # prepare transforms standard to MNIST\n",
    "  mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
    "  mnist_train = [mnist_train[i] for i in range(2200)]\n",
    "  \n",
    "  mnist_train, mnist_val = random_split(mnist_train, [2000, 200])\n",
    "\n",
    "  mnist_test = MNIST(os.getcwd(), train=False, download=True, transform=transform)\n",
    "  mnist_test = [mnist_test[i] for i in range(3000,4000)]\n",
    "\n",
    "  return mnist_train, mnist_val, mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to C:\\Users\\isaac\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [01:57<00:00, 84483.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\isaac\\MNIST\\raw\\train-images-idx3-ubyte.gz to C:\\Users\\isaac\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to C:\\Users\\isaac\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 223748.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\isaac\\MNIST\\raw\\train-labels-idx1-ubyte.gz to C:\\Users\\isaac\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to C:\\Users\\isaac\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2227017.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\isaac\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to C:\\Users\\isaac\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to C:\\Users\\isaac\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4538001.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\isaac\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to C:\\Users\\isaac\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, val, test = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = DataLoader(train, batch_size=64), DataLoader(val, batch_size=64), DataLoader(test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# saves checkpoints to 'model_path' whenever 'val_loss' has a new min\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39mmodel_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist_\u001b[39m\u001b[38;5;132;01m{epoch}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{val_loss:.2f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m                                       monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, save_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     11\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, profiler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m[lr_logger], \n\u001b[0;32m     12\u001b[0m                      early_stop_callback\u001b[38;5;241m=\u001b[39mearly_stopping, checkpoint_callback\u001b[38;5;241m=\u001b[39mcheckpoint_callback,\n\u001b[0;32m     13\u001b[0m                      default_root_dir\u001b[38;5;241m=\u001b[39mmodel_path) \u001b[38;5;66;03m#gpus=1\u001b[39;00m\n\u001b[0;32m     15\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, train_dataloader\u001b[38;5;241m=\u001b[39mtrain_loader, val_dataloaders\u001b[38;5;241m=\u001b[39mval_loader)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_path' is not defined"
     ]
    }
   ],
   "source": [
    "model = LightningMNISTClassifier(lr_rate=1e-3)\n",
    "\n",
    "# Learning Rate Logger\n",
    "lr_logger = LearningRateMonitor()\n",
    "# Set Early Stopping\n",
    "early_stopping = EarlyStopping('val_loss', mode='min', patience=5)\n",
    "# saves checkpoints to 'model_path' whenever 'val_loss' has a new min\n",
    "checkpoint_callback = ModelCheckpoint(filepath=model_path+'mnist_{epoch}-{val_loss:.2f}',\n",
    "                                      monitor='val_loss', mode='min', save_top_k=3)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=30, profiler=True, callbacks=[lr_logger], \n",
    "                     early_stop_callback=early_stopping, checkpoint_callback=checkpoint_callback,\n",
    "                     default_root_dir=model_path) #gpus=1\n",
    "\n",
    "trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
