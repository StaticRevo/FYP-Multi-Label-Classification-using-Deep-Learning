digraph {
	graph [size="297.3,297.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1618212354576 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1618212303776 [label=AddmmBackward0]
	1618212303392 -> 1618212303776
	1618214499920 [label="fc.bias
 (19)" fillcolor=lightblue]
	1618214499920 -> 1618212303392
	1618212303392 [label=AccumulateGrad]
	1618212302720 -> 1618212303776
	1618212302720 [label=ViewBackward0]
	1618212302192 -> 1618212302720
	1618212302192 [label=MeanBackward1]
	1618212301808 -> 1618212302192
	1618212301808 [label=ReluBackward0]
	1618212301280 -> 1618212301808
	1618212301280 [label=AddBackward0]
	1618212300752 -> 1618212301280
	1618212300752 [label=CudnnBatchNormBackward0]
	1618212299552 -> 1618212300752
	1618212299552 [label=ConvolutionBackward0]
	1618212298496 -> 1618212299552
	1618212298496 [label=ReluBackward0]
	1618212298112 -> 1618212298496
	1618212298112 [label=CudnnBatchNormBackward0]
	1618212297584 -> 1618212298112
	1618212297584 [label=ConvolutionBackward0]
	1618212296528 -> 1618212297584
	1618212296528 [label=ReluBackward0]
	1618212295328 -> 1618212296528
	1618212295328 [label=CudnnBatchNormBackward0]
	1618212294800 -> 1618212295328
	1618212294800 [label=ConvolutionBackward0]
	1618212300608 -> 1618212294800
	1618212300608 [label=ReluBackward0]
	1618212293216 -> 1618212300608
	1618212293216 [label=AddBackward0]
	1618212292688 -> 1618212293216
	1618212292688 [label=CudnnBatchNormBackward0]
	1618212292304 -> 1618212292688
	1618212292304 [label=ConvolutionBackward0]
	1618212291248 -> 1618212292304
	1618212291248 [label=ReluBackward0]
	1618212306656 -> 1618212291248
	1618212306656 [label=CudnnBatchNormBackward0]
	1618212306896 -> 1618212306656
	1618212306896 [label=ConvolutionBackward0]
	1618212306464 -> 1618212306896
	1618212306464 [label=ReluBackward0]
	1618212306224 -> 1618212306464
	1618212306224 [label=CudnnBatchNormBackward0]
	1618212306176 -> 1618212306224
	1618212306176 [label=ConvolutionBackward0]
	1618212293360 -> 1618212306176
	1618212293360 [label=ReluBackward0]
	1618212305696 -> 1618212293360
	1618212305696 [label=AddBackward0]
	1618212305648 -> 1618212305696
	1618212305648 [label=CudnnBatchNormBackward0]
	1618212305408 -> 1618212305648
	1618212305408 [label=ConvolutionBackward0]
	1618212305312 -> 1618212305408
	1618212305312 [label=ReluBackward0]
	1618212304928 -> 1618212305312
	1618212304928 [label=CudnnBatchNormBackward0]
	1618212304736 -> 1618212304928
	1618212304736 [label=ConvolutionBackward0]
	1618212304592 -> 1618212304736
	1618212304592 [label=ReluBackward0]
	1618212304352 -> 1618212304592
	1618212304352 [label=CudnnBatchNormBackward0]
	1618212304016 -> 1618212304352
	1618212304016 [label=ConvolutionBackward0]
	1618212304160 -> 1618212304016
	1618212304160 [label=ReluBackward0]
	1618212303680 -> 1618212304160
	1618212303680 [label=AddBackward0]
	1618212303584 -> 1618212303680
	1618212303584 [label=CudnnBatchNormBackward0]
	1618212303632 -> 1618212303584
	1618212303632 [label=ConvolutionBackward0]
	1618212302960 -> 1618212303632
	1618212302960 [label=ReluBackward0]
	1618212303008 -> 1618212302960
	1618212303008 [label=CudnnBatchNormBackward0]
	1618212302816 -> 1618212303008
	1618212302816 [label=ConvolutionBackward0]
	1618212302528 -> 1618212302816
	1618212302528 [label=ReluBackward0]
	1618212302576 -> 1618212302528
	1618212302576 [label=CudnnBatchNormBackward0]
	1618212302240 -> 1618212302576
	1618212302240 [label=ConvolutionBackward0]
	1618212303488 -> 1618212302240
	1618212303488 [label=ReluBackward0]
	1618212302048 -> 1618212303488
	1618212302048 [label=AddBackward0]
	1618212301712 -> 1618212302048
	1618212301712 [label=CudnnBatchNormBackward0]
	1618212301472 -> 1618212301712
	1618212301472 [label=ConvolutionBackward0]
	1618212301232 -> 1618212301472
	1618212301232 [label=ReluBackward0]
	1618212300848 -> 1618212301232
	1618212300848 [label=CudnnBatchNormBackward0]
	1618212301088 -> 1618212300848
	1618212301088 [label=ConvolutionBackward0]
	1618212300656 -> 1618212301088
	1618212300656 [label=ReluBackward0]
	1618212300416 -> 1618212300656
	1618212300416 [label=CudnnBatchNormBackward0]
	1618212300368 -> 1618212300416
	1618212300368 [label=ConvolutionBackward0]
	1618212301760 -> 1618212300368
	1618212301760 [label=ReluBackward0]
	1618212299888 -> 1618212301760
	1618212299888 [label=AddBackward0]
	1618212299840 -> 1618212299888
	1618212299840 [label=CudnnBatchNormBackward0]
	1618212299600 -> 1618212299840
	1618212299600 [label=ConvolutionBackward0]
	1618212299504 -> 1618212299600
	1618212299504 [label=ReluBackward0]
	1618212299120 -> 1618212299504
	1618212299120 [label=CudnnBatchNormBackward0]
	1618212298928 -> 1618212299120
	1618212298928 [label=ConvolutionBackward0]
	1618212298784 -> 1618212298928
	1618212298784 [label=ReluBackward0]
	1618212298544 -> 1618212298784
	1618212298544 [label=CudnnBatchNormBackward0]
	1618212298208 -> 1618212298544
	1618212298208 [label=ConvolutionBackward0]
	1618212300032 -> 1618212298208
	1618212300032 [label=ReluBackward0]
	1618212298016 -> 1618212300032
	1618212298016 [label=AddBackward0]
	1618212297680 -> 1618212298016
	1618212297680 [label=CudnnBatchNormBackward0]
	1618212297728 -> 1618212297680
	1618212297728 [label=ConvolutionBackward0]
	1618212297344 -> 1618212297728
	1618212297344 [label=ReluBackward0]
	1618212297392 -> 1618212297344
	1618212297392 [label=CudnnBatchNormBackward0]
	1618212297296 -> 1618212297392
	1618212297296 [label=ConvolutionBackward0]
	1618212296624 -> 1618212297296
	1618212296624 [label=ReluBackward0]
	1618212296672 -> 1618212296624
	1618212296672 [label=CudnnBatchNormBackward0]
	1618212296480 -> 1618212296672
	1618212296480 [label=ConvolutionBackward0]
	1618212297872 -> 1618212296480
	1618212297872 [label=ReluBackward0]
	1618212296144 -> 1618212297872
	1618212296144 [label=AddBackward0]
	1618212295952 -> 1618212296144
	1618212295952 [label=CudnnBatchNormBackward0]
	1618212295568 -> 1618212295952
	1618212295568 [label=ConvolutionBackward0]
	1618212295712 -> 1618212295568
	1618212295712 [label=ReluBackward0]
	1618212295232 -> 1618212295712
	1618212295232 [label=CudnnBatchNormBackward0]
	1618212295136 -> 1618212295232
	1618212295136 [label=ConvolutionBackward0]
	1618212294896 -> 1618212295136
	1618212294896 [label=ReluBackward0]
	1618212294512 -> 1618212294896
	1618212294512 [label=CudnnBatchNormBackward0]
	1618212294752 -> 1618212294512
	1618212294752 [label=ConvolutionBackward0]
	1618212296240 -> 1618212294752
	1618212296240 [label=ReluBackward0]
	1618212293984 -> 1618212296240
	1618212293984 [label=AddBackward0]
	1618212294224 -> 1618212293984
	1618212294224 [label=CudnnBatchNormBackward0]
	1618212293840 -> 1618212294224
	1618212293840 [label=ConvolutionBackward0]
	1618212293552 -> 1618212293840
	1618212293552 [label=ReluBackward0]
	1618212293600 -> 1618212293552
	1618212293600 [label=CudnnBatchNormBackward0]
	1618212293264 -> 1618212293600
	1618212293264 [label=ConvolutionBackward0]
	1618212293168 -> 1618212293264
	1618212293168 [label=ReluBackward0]
	1618212292784 -> 1618212293168
	1618212292784 [label=CudnnBatchNormBackward0]
	1618212292592 -> 1618212292784
	1618212292592 [label=ConvolutionBackward0]
	1618212294080 -> 1618212292592
	1618212294080 [label=ReluBackward0]
	1618212292256 -> 1618212294080
	1618212292256 [label=AddBackward0]
	1618212292064 -> 1618212292256
	1618212292064 [label=CudnnBatchNormBackward0]
	1618212292112 -> 1618212292064
	1618212292112 [label=ConvolutionBackward0]
	1618212291680 -> 1618212292112
	1618212291680 [label=ReluBackward0]
	1618212291440 -> 1618212291680
	1618212291440 [label=CudnnBatchNormBackward0]
	1618212291392 -> 1618212291440
	1618212291392 [label=ConvolutionBackward0]
	1618212291008 -> 1618212291392
	1618212291008 [label=ReluBackward0]
	1618212291056 -> 1618212291008
	1618212291056 [label=CudnnBatchNormBackward0]
	1618212290960 -> 1618212291056
	1618212290960 [label=ConvolutionBackward0]
	1618212292208 -> 1618212290960
	1618212292208 [label=ReluBackward0]
	1618212404144 -> 1618212292208
	1618212404144 [label=AddBackward0]
	1618212403616 -> 1618212404144
	1618212403616 [label=CudnnBatchNormBackward0]
	1618212403232 -> 1618212403616
	1618212403232 [label=ConvolutionBackward0]
	1618212402176 -> 1618212403232
	1618212402176 [label=ReluBackward0]
	1618212400976 -> 1618212402176
	1618212400976 [label=CudnnBatchNormBackward0]
	1618212400448 -> 1618212400976
	1618212400448 [label=ConvolutionBackward0]
	1618212399392 -> 1618212400448
	1618212399392 [label=ReluBackward0]
	1618212399008 -> 1618212399392
	1618212399008 [label=CudnnBatchNormBackward0]
	1618212398480 -> 1618212399008
	1618212398480 [label=ConvolutionBackward0]
	1618212404288 -> 1618212398480
	1618212404288 [label=ReluBackward0]
	1618212396896 -> 1618212404288
	1618212396896 [label=AddBackward0]
	1618212396368 -> 1618212396896
	1618212396368 [label=CudnnBatchNormBackward0]
	1618212395168 -> 1618212396368
	1618212395168 [label=ConvolutionBackward0]
	1618212394112 -> 1618212395168
	1618212394112 [label=ReluBackward0]
	1618212393728 -> 1618212394112
	1618212393728 [label=CudnnBatchNormBackward0]
	1618212393200 -> 1618212393728
	1618212393200 [label=ConvolutionBackward0]
	1618212392144 -> 1618212393200
	1618212392144 [label=ReluBackward0]
	1618212390944 -> 1618212392144
	1618212390944 [label=CudnnBatchNormBackward0]
	1618212390416 -> 1618212390944
	1618212390416 [label=ConvolutionBackward0]
	1618212396224 -> 1618212390416
	1618212396224 [label=ReluBackward0]
	1618212388976 -> 1618212396224
	1618212388976 [label=AddBackward0]
	1618212404912 -> 1618212388976
	1618212404912 [label=CudnnBatchNormBackward0]
	1618212404960 -> 1618212404912
	1618212404960 [label=ConvolutionBackward0]
	1618212404576 -> 1618212404960
	1618212404576 [label=ReluBackward0]
	1618212404624 -> 1618212404576
	1618212404624 [label=CudnnBatchNormBackward0]
	1618212404528 -> 1618212404624
	1618212404528 [label=ConvolutionBackward0]
	1618212403856 -> 1618212404528
	1618212403856 [label=ReluBackward0]
	1618212403904 -> 1618212403856
	1618212403904 [label=CudnnBatchNormBackward0]
	1618212403712 -> 1618212403904
	1618212403712 [label=ConvolutionBackward0]
	1618212405104 -> 1618212403712
	1618212405104 [label=ReluBackward0]
	1618212403376 -> 1618212405104
	1618212403376 [label=AddBackward0]
	1618212403184 -> 1618212403376
	1618212403184 [label=CudnnBatchNormBackward0]
	1618212402800 -> 1618212403184
	1618212402800 [label=ConvolutionBackward0]
	1618212402944 -> 1618212402800
	1618212402944 [label=ReluBackward0]
	1618212402464 -> 1618212402944
	1618212402464 [label=CudnnBatchNormBackward0]
	1618212402368 -> 1618212402464
	1618212402368 [label=ConvolutionBackward0]
	1618212402128 -> 1618212402368
	1618212402128 [label=ReluBackward0]
	1618212401744 -> 1618212402128
	1618212401744 [label=CudnnBatchNormBackward0]
	1618212401984 -> 1618212401744
	1618212401984 [label=ConvolutionBackward0]
	1618212403472 -> 1618212401984
	1618212403472 [label=ReluBackward0]
	1618212401216 -> 1618212403472
	1618212401216 [label=AddBackward0]
	1618212401456 -> 1618212401216
	1618212401456 [label=CudnnBatchNormBackward0]
	1618212401072 -> 1618212401456
	1618212401072 [label=ConvolutionBackward0]
	1618212400784 -> 1618212401072
	1618212400784 [label=ReluBackward0]
	1618212400832 -> 1618212400784
	1618212400832 [label=CudnnBatchNormBackward0]
	1618212400496 -> 1618212400832
	1618212400496 [label=ConvolutionBackward0]
	1618212400400 -> 1618212400496
	1618212400400 [label=ReluBackward0]
	1618212400016 -> 1618212400400
	1618212400016 [label=CudnnBatchNormBackward0]
	1618212399824 -> 1618212400016
	1618212399824 [label=ConvolutionBackward0]
	1618212401312 -> 1618212399824
	1618212401312 [label=ReluBackward0]
	1618212399488 -> 1618212401312
	1618212399488 [label=AddBackward0]
	1618212399296 -> 1618212399488
	1618212399296 [label=CudnnBatchNormBackward0]
	1618212399344 -> 1618212399296
	1618212399344 [label=ConvolutionBackward0]
	1618212398912 -> 1618212399344
	1618212398912 [label=ReluBackward0]
	1618212398672 -> 1618212398912
	1618212398672 [label=CudnnBatchNormBackward0]
	1618212398624 -> 1618212398672
	1618212398624 [label=ConvolutionBackward0]
	1618212398240 -> 1618212398624
	1618212398240 [label=ReluBackward0]
	1618212398288 -> 1618212398240
	1618212398288 [label=CudnnBatchNormBackward0]
	1618212398192 -> 1618212398288
	1618212398192 [label=ConvolutionBackward0]
	1618212399440 -> 1618212398192
	1618212399440 [label=ReluBackward0]
	1618212397760 -> 1618212399440
	1618212397760 [label=AddBackward0]
	1618212397664 -> 1618212397760
	1618212397664 [label=CudnnBatchNormBackward0]
	1618212397184 -> 1618212397664
	1618212397184 [label=ConvolutionBackward0]
	1618212397040 -> 1618212397184
	1618212397040 [label=ReluBackward0]
	1618212396800 -> 1618212397040
	1618212396800 [label=CudnnBatchNormBackward0]
	1618212396464 -> 1618212396800
	1618212396464 [label=ConvolutionBackward0]
	1618212396608 -> 1618212396464
	1618212396608 [label=ReluBackward0]
	1618212396128 -> 1618212396608
	1618212396128 [label=CudnnBatchNormBackward0]
	1618212396032 -> 1618212396128
	1618212396032 [label=ConvolutionBackward0]
	1618212397568 -> 1618212396032
	1618212397568 [label=ReluBackward0]
	1618212395600 -> 1618212397568
	1618212395600 [label=AddBackward0]
	1618212395504 -> 1618212395600
	1618212395504 [label=CudnnBatchNormBackward0]
	1618212395552 -> 1618212395504
	1618212395552 [label=ConvolutionBackward0]
	1618212394880 -> 1618212395552
	1618212394880 [label=ReluBackward0]
	1618212394928 -> 1618212394880
	1618212394928 [label=CudnnBatchNormBackward0]
	1618212394736 -> 1618212394928
	1618212394736 [label=ConvolutionBackward0]
	1618212394448 -> 1618212394736
	1618212394448 [label=ReluBackward0]
	1618212394496 -> 1618212394448
	1618212394496 [label=CudnnBatchNormBackward0]
	1618212394160 -> 1618212394496
	1618212394160 [label=ConvolutionBackward0]
	1618212395408 -> 1618212394160
	1618212395408 [label=ReluBackward0]
	1618212393968 -> 1618212395408
	1618212393968 [label=AddBackward0]
	1618212393632 -> 1618212393968
	1618212393632 [label=CudnnBatchNormBackward0]
	1618212393392 -> 1618212393632
	1618212393392 [label=ConvolutionBackward0]
	1618212393152 -> 1618212393392
	1618212393152 [label=ReluBackward0]
	1618212392768 -> 1618212393152
	1618212392768 [label=CudnnBatchNormBackward0]
	1618212393008 -> 1618212392768
	1618212393008 [label=ConvolutionBackward0]
	1618212392576 -> 1618212393008
	1618212392576 [label=ReluBackward0]
	1618212392336 -> 1618212392576
	1618212392336 [label=CudnnBatchNormBackward0]
	1618212392288 -> 1618212392336
	1618212392288 [label=ConvolutionBackward0]
	1618212393680 -> 1618212392288
	1618212393680 [label=ReluBackward0]
	1618212391808 -> 1618212393680
	1618212391808 [label=AddBackward0]
	1618212391760 -> 1618212391808
	1618212391760 [label=CudnnBatchNormBackward0]
	1618212391520 -> 1618212391760
	1618212391520 [label=ConvolutionBackward0]
	1618212391424 -> 1618212391520
	1618212391424 [label=ReluBackward0]
	1618212391040 -> 1618212391424
	1618212391040 [label=CudnnBatchNormBackward0]
	1618212390848 -> 1618212391040
	1618212390848 [label=ConvolutionBackward0]
	1618212390704 -> 1618212390848
	1618212390704 [label=ReluBackward0]
	1618212390464 -> 1618212390704
	1618212390464 [label=CudnnBatchNormBackward0]
	1618212390128 -> 1618212390464
	1618212390128 [label=ConvolutionBackward0]
	1618212391952 -> 1618212390128
	1618212391952 [label=ReluBackward0]
	1618212389936 -> 1618212391952
	1618212389936 [label=AddBackward0]
	1618212389600 -> 1618212389936
	1618212389600 [label=CudnnBatchNormBackward0]
	1618212389648 -> 1618212389600
	1618212389648 [label=ConvolutionBackward0]
	1618212389264 -> 1618212389648
	1618212389264 [label=ReluBackward0]
	1618212389312 -> 1618212389264
	1618212389312 [label=CudnnBatchNormBackward0]
	1618212389216 -> 1618212389312
	1618212389216 [label=ConvolutionBackward0]
	1618212503072 -> 1618212389216
	1618212503072 [label=ReluBackward0]
	1618212501872 -> 1618212503072
	1618212501872 [label=CudnnBatchNormBackward0]
	1618212501344 -> 1618212501872
	1618212501344 [label=ConvolutionBackward0]
	1618212389792 -> 1618212501344
	1618212389792 [label=ReluBackward0]
	1618212499760 -> 1618212389792
	1618212499760 [label=AddBackward0]
	1618212499232 -> 1618212499760
	1618212499232 [label=CudnnBatchNormBackward0]
	1618212498848 -> 1618212499232
	1618212498848 [label=ConvolutionBackward0]
	1618212497792 -> 1618212498848
	1618212497792 [label=ReluBackward0]
	1618212496592 -> 1618212497792
	1618212496592 [label=CudnnBatchNormBackward0]
	1618212496064 -> 1618212496592
	1618212496064 [label=ConvolutionBackward0]
	1618212495008 -> 1618212496064
	1618212495008 [label=ReluBackward0]
	1618212494624 -> 1618212495008
	1618212494624 [label=CudnnBatchNormBackward0]
	1618212494096 -> 1618212494624
	1618212494096 [label=ConvolutionBackward0]
	1618212499904 -> 1618212494096
	1618212499904 [label=ReluBackward0]
	1618212492512 -> 1618212499904
	1618212492512 [label=AddBackward0]
	1618212491984 -> 1618212492512
	1618212491984 [label=CudnnBatchNormBackward0]
	1618212490784 -> 1618212491984
	1618212490784 [label=ConvolutionBackward0]
	1618212489728 -> 1618212490784
	1618212489728 [label=ReluBackward0]
	1618212489344 -> 1618212489728
	1618212489344 [label=CudnnBatchNormBackward0]
	1618212488816 -> 1618212489344
	1618212488816 [label=ConvolutionBackward0]
	1618212487760 -> 1618212488816
	1618212487760 [label=ReluBackward0]
	1618212503360 -> 1618212487760
	1618212503360 [label=CudnnBatchNormBackward0]
	1618212503264 -> 1618212503360
	1618212503264 [label=ConvolutionBackward0]
	1618212491840 -> 1618212503264
	1618212491840 [label=ReluBackward0]
	1618212502832 -> 1618212491840
	1618212502832 [label=AddBackward0]
	1618212502736 -> 1618212502832
	1618212502736 [label=CudnnBatchNormBackward0]
	1618212502784 -> 1618212502736
	1618212502784 [label=ConvolutionBackward0]
	1618212502112 -> 1618212502784
	1618212502112 [label=ReluBackward0]
	1618212502160 -> 1618212502112
	1618212502160 [label=CudnnBatchNormBackward0]
	1618212501968 -> 1618212502160
	1618212501968 [label=ConvolutionBackward0]
	1618212501680 -> 1618212501968
	1618212501680 [label=ReluBackward0]
	1618212501728 -> 1618212501680
	1618212501728 [label=CudnnBatchNormBackward0]
	1618212501392 -> 1618212501728
	1618212501392 [label=ConvolutionBackward0]
	1618212502640 -> 1618212501392
	1618212502640 [label=ReluBackward0]
	1618212501200 -> 1618212502640
	1618212501200 [label=AddBackward0]
	1618212500864 -> 1618212501200
	1618212500864 [label=CudnnBatchNormBackward0]
	1618212500624 -> 1618212500864
	1618212500624 [label=ConvolutionBackward0]
	1618212500384 -> 1618212500624
	1618212500384 [label=ReluBackward0]
	1618212500000 -> 1618212500384
	1618212500000 [label=CudnnBatchNormBackward0]
	1618212500240 -> 1618212500000
	1618212500240 [label=ConvolutionBackward0]
	1618212499808 -> 1618212500240
	1618212499808 [label=ReluBackward0]
	1618212499568 -> 1618212499808
	1618212499568 [label=CudnnBatchNormBackward0]
	1618212499520 -> 1618212499568
	1618212499520 [label=ConvolutionBackward0]
	1618212500912 -> 1618212499520
	1618212500912 [label=ReluBackward0]
	1618212499040 -> 1618212500912
	1618212499040 [label=AddBackward0]
	1618212498992 -> 1618212499040
	1618212498992 [label=CudnnBatchNormBackward0]
	1618212498752 -> 1618212498992
	1618212498752 [label=ConvolutionBackward0]
	1618212498656 -> 1618212498752
	1618212498656 [label=ReluBackward0]
	1618212498272 -> 1618212498656
	1618212498272 [label=CudnnBatchNormBackward0]
	1618212498080 -> 1618212498272
	1618212498080 [label=ConvolutionBackward0]
	1618212497936 -> 1618212498080
	1618212497936 [label=ReluBackward0]
	1618212497696 -> 1618212497936
	1618212497696 [label=CudnnBatchNormBackward0]
	1618212497360 -> 1618212497696
	1618212497360 [label=ConvolutionBackward0]
	1618212497504 -> 1618212497360
	1618212497504 [label=ReluBackward0]
	1618212497024 -> 1618212497504
	1618212497024 [label=AddBackward0]
	1618212496928 -> 1618212497024
	1618212496928 [label=CudnnBatchNormBackward0]
	1618212496976 -> 1618212496928
	1618212496976 [label=ConvolutionBackward0]
	1618212496304 -> 1618212496976
	1618212496304 [label=ReluBackward0]
	1618212496352 -> 1618212496304
	1618212496352 [label=CudnnBatchNormBackward0]
	1618212496160 -> 1618212496352
	1618212496160 [label=ConvolutionBackward0]
	1618212495872 -> 1618212496160
	1618212495872 [label=ReluBackward0]
	1618212495920 -> 1618212495872
	1618212495920 [label=CudnnBatchNormBackward0]
	1618212495584 -> 1618212495920
	1618212495584 [label=ConvolutionBackward0]
	1618212496832 -> 1618212495584
	1618212496832 [label=ReluBackward0]
	1618212495392 -> 1618212496832
	1618212495392 [label=AddBackward0]
	1618212495056 -> 1618212495392
	1618212495056 [label=CudnnBatchNormBackward0]
	1618212494816 -> 1618212495056
	1618212494816 [label=ConvolutionBackward0]
	1618212494576 -> 1618212494816
	1618212494576 [label=ReluBackward0]
	1618212494192 -> 1618212494576
	1618212494192 [label=CudnnBatchNormBackward0]
	1618212494432 -> 1618212494192
	1618212494432 [label=ConvolutionBackward0]
	1618212494000 -> 1618212494432
	1618212494000 [label=ReluBackward0]
	1618212493760 -> 1618212494000
	1618212493760 [label=CudnnBatchNormBackward0]
	1618212493712 -> 1618212493760
	1618212493712 [label=ConvolutionBackward0]
	1618212495104 -> 1618212493712
	1618212495104 [label=ReluBackward0]
	1618212493232 -> 1618212495104
	1618212493232 [label=AddBackward0]
	1618212493184 -> 1618212493232
	1618212493184 [label=CudnnBatchNormBackward0]
	1618212492944 -> 1618212493184
	1618212492944 [label=ConvolutionBackward0]
	1618212492848 -> 1618212492944
	1618212492848 [label=ReluBackward0]
	1618212492464 -> 1618212492848
	1618212492464 [label=CudnnBatchNormBackward0]
	1618212492272 -> 1618212492464
	1618212492272 [label=ConvolutionBackward0]
	1618212492128 -> 1618212492272
	1618212492128 [label=ReluBackward0]
	1618212491888 -> 1618212492128
	1618212491888 [label=CudnnBatchNormBackward0]
	1618212491552 -> 1618212491888
	1618212491552 [label=ConvolutionBackward0]
	1618212493376 -> 1618212491552
	1618212493376 [label=ReluBackward0]
	1618212491360 -> 1618212493376
	1618212491360 [label=AddBackward0]
	1618212491024 -> 1618212491360
	1618212491024 [label=CudnnBatchNormBackward0]
	1618212491072 -> 1618212491024
	1618212491072 [label=ConvolutionBackward0]
	1618212490688 -> 1618212491072
	1618212490688 [label=ReluBackward0]
	1618212490736 -> 1618212490688
	1618212490736 [label=CudnnBatchNormBackward0]
	1618212490640 -> 1618212490736
	1618212490640 [label=ConvolutionBackward0]
	1618212489968 -> 1618212490640
	1618212489968 [label=ReluBackward0]
	1618212490016 -> 1618212489968
	1618212490016 [label=CudnnBatchNormBackward0]
	1618212489824 -> 1618212490016
	1618212489824 [label=ConvolutionBackward0]
	1618212489536 -> 1618212489824
	1618212489536 [label=ReluBackward0]
	1618212489584 -> 1618212489536
	1618212489584 [label=AddBackward0]
	1618212489248 -> 1618212489584
	1618212489248 [label=CudnnBatchNormBackward0]
	1618212489008 -> 1618212489248
	1618212489008 [label=ConvolutionBackward0]
	1618212488768 -> 1618212489008
	1618212488768 [label=ReluBackward0]
	1618212488384 -> 1618212488768
	1618212488384 [label=CudnnBatchNormBackward0]
	1618212488624 -> 1618212488384
	1618212488624 [label=ConvolutionBackward0]
	1618212488192 -> 1618212488624
	1618212488192 [label=ReluBackward0]
	1618212487952 -> 1618212488192
	1618212487952 [label=CudnnBatchNormBackward0]
	1618212487904 -> 1618212487952
	1618212487904 [label=ConvolutionBackward0]
	1618212489296 -> 1618212487904
	1618212489296 [label=ReluBackward0]
	1618212487424 -> 1618212489296
	1618212487424 [label=AddBackward0]
	1618212487376 -> 1618212487424
	1618212487376 [label=CudnnBatchNormBackward0]
	1618212487472 -> 1618212487376
	1618212487472 [label=ConvolutionBackward0]
	1618212534592 -> 1618212487472
	1618212534592 [label=ReluBackward0]
	1618212534208 -> 1618212534592
	1618212534208 [label=CudnnBatchNormBackward0]
	1618212533680 -> 1618212534208
	1618212533680 [label=ConvolutionBackward0]
	1618212532624 -> 1618212533680
	1618212532624 [label=ReluBackward0]
	1618212531424 -> 1618212532624
	1618212531424 [label=CudnnBatchNormBackward0]
	1618212530896 -> 1618212531424
	1618212530896 [label=ConvolutionBackward0]
	1618212487568 -> 1618212530896
	1618212487568 [label=ReluBackward0]
	1618212529312 -> 1618212487568
	1618212529312 [label=AddBackward0]
	1618212528784 -> 1618212529312
	1618212528784 [label=CudnnBatchNormBackward0]
	1618212528400 -> 1618212528784
	1618212528400 [label=ConvolutionBackward0]
	1618212527344 -> 1618212528400
	1618212527344 [label=ReluBackward0]
	1618212526144 -> 1618212527344
	1618212526144 [label=CudnnBatchNormBackward0]
	1618212525616 -> 1618212526144
	1618212525616 [label=ConvolutionBackward0]
	1618212524560 -> 1618212525616
	1618212524560 [label=ReluBackward0]
	1618212524176 -> 1618212524560
	1618212524176 [label=CudnnBatchNormBackward0]
	1618212523648 -> 1618212524176
	1618212523648 [label=ConvolutionBackward0]
	1618212522592 -> 1618212523648
	1618212522592 [label=MaxPool2DWithIndicesBackward0]
	1618212521488 -> 1618212522592
	1618212521488 [label=ReluBackward0]
	1618212521008 -> 1618212521488
	1618212521008 [label=CudnnBatchNormBackward0]
	1618212520528 -> 1618212521008
	1618212520528 [label=ConvolutionBackward0]
	1618212536272 -> 1618212520528
	1618214499728 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	1618214499728 -> 1618212536272
	1618212536272 [label=AccumulateGrad]
	1618212521152 -> 1618212521008
	1618218341712 [label="bn1.weight
 (64)" fillcolor=lightblue]
	1618218341712 -> 1618212521152
	1618212521152 [label=AccumulateGrad]
	1618212521968 -> 1618212521008
	1618218341424 [label="bn1.bias
 (64)" fillcolor=lightblue]
	1618218341424 -> 1618212521968
	1618212521968 [label=AccumulateGrad]
	1618212522448 -> 1618212523648
	1618218341328 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	1618218341328 -> 1618212522448
	1618212522448 [label=AccumulateGrad]
	1618212523504 -> 1618212524176
	1618218341232 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1618218341232 -> 1618212523504
	1618212523504 [label=AccumulateGrad]
	1618212524704 -> 1618212524176
	1618218340464 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1618218340464 -> 1618212524704
	1618212524704 [label=AccumulateGrad]
	1618212525232 -> 1618212525616
	1618218340560 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1618218340560 -> 1618212525232
	1618212525232 [label=AccumulateGrad]
	1618212526288 -> 1618212526144
	1618218340656 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1618218340656 -> 1618212526288
	1618212526288 [label=AccumulateGrad]
	1618212526672 -> 1618212526144
	1618218340752 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1618218340752 -> 1618212526672
	1618212526672 [label=AccumulateGrad]
	1618212527200 -> 1618212528400
	1618218341040 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1618218341040 -> 1618212527200
	1618212527200 [label=AccumulateGrad]
	1618212528256 -> 1618212528784
	1618218340080 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	1618218340080 -> 1618212528256
	1618212528256 [label=AccumulateGrad]
	1618212528928 -> 1618212528784
	1618218339984 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	1618218339984 -> 1618212528928
	1618212528928 [label=AccumulateGrad]
	1618212529456 -> 1618212529312
	1618212529456 [label=CudnnBatchNormBackward0]
	1618212525088 -> 1618212529456
	1618212525088 [label=ConvolutionBackward0]
	1618212522592 -> 1618212525088
	1618212522976 -> 1618212525088
	1618218341904 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1618218341904 -> 1618212522976
	1618212522976 [label=AccumulateGrad]
	1618212527872 -> 1618212529456
	1618218342000 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1618218342000 -> 1618212527872
	1618212527872 [label=AccumulateGrad]
	1618212527728 -> 1618212529456
	1618218342096 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1618218342096 -> 1618212527728
	1618212527728 [label=AccumulateGrad]
	1618212529840 -> 1618212530896
	1618218337296 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1618218337296 -> 1618212529840
	1618212529840 [label=AccumulateGrad]
	1618212531568 -> 1618212531424
	1618218337488 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1618218337488 -> 1618212531568
	1618212531568 [label=AccumulateGrad]
	1618212531952 -> 1618212531424
	1618218339120 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1618218339120 -> 1618212531952
	1618212531952 [label=AccumulateGrad]
	1618212532480 -> 1618212533680
	1618218339888 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1618218339888 -> 1618212532480
	1618212532480 [label=AccumulateGrad]
	1618212533536 -> 1618212534208
	1618218339792 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1618218339792 -> 1618212533536
	1618212533536 [label=AccumulateGrad]
	1618212534736 -> 1618212534208
	1618215327824 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1618215327824 -> 1618212534736
	1618212534736 [label=AccumulateGrad]
	1618212535264 -> 1618212487472
	1618215328208 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1618215328208 -> 1618212535264
	1618212535264 [label=AccumulateGrad]
	1618212535648 -> 1618212487376
	1618215328304 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	1618215328304 -> 1618212535648
	1618212535648 [label=AccumulateGrad]
	1618212536176 -> 1618212487376
	1618215328400 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	1618215328400 -> 1618212536176
	1618212536176 [label=AccumulateGrad]
	1618212487568 -> 1618212487424
	1618212487520 -> 1618212487904
	1618215328784 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1618215328784 -> 1618212487520
	1618212487520 [label=AccumulateGrad]
	1618212488096 -> 1618212487952
	1618215328880 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	1618215328880 -> 1618212488096
	1618212488096 [label=AccumulateGrad]
	1618212488048 -> 1618212487952
	1618215328976 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	1618215328976 -> 1618212488048
	1618212488048 [label=AccumulateGrad]
	1618212488240 -> 1618212488624
	1618215329360 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1618215329360 -> 1618212488240
	1618212488240 [label=AccumulateGrad]
	1618212488480 -> 1618212488384
	1618215329456 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	1618215329456 -> 1618212488480
	1618212488480 [label=AccumulateGrad]
	1618212488720 -> 1618212488384
	1618215329552 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	1618215329552 -> 1618212488720
	1618212488720 [label=AccumulateGrad]
	1618212489056 -> 1618212489008
	1618215329936 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1618215329936 -> 1618212489056
	1618212489056 [label=AccumulateGrad]
	1618212488912 -> 1618212489248
	1618215330032 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	1618215330032 -> 1618212488912
	1618212488912 [label=AccumulateGrad]
	1618212489104 -> 1618212489248
	1618215330128 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	1618215330128 -> 1618212489104
	1618212489104 [label=AccumulateGrad]
	1618212489296 -> 1618212489584
	1618212489440 -> 1618212489824
	1618215331088 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	1618215331088 -> 1618212489440
	1618212489440 [label=AccumulateGrad]
	1618212490112 -> 1618212490016
	1618215331184 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1618215331184 -> 1618212490112
	1618212490112 [label=AccumulateGrad]
	1618212490064 -> 1618212490016
	1618215331280 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1618215331280 -> 1618212490064
	1618212490064 [label=AccumulateGrad]
	1618212490160 -> 1618212490640
	1618215331664 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1618215331664 -> 1618212490160
	1618212490160 [label=AccumulateGrad]
	1618212490544 -> 1618212490736
	1618215331760 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1618215331760 -> 1618212490544
	1618212490544 [label=AccumulateGrad]
	1618212490496 -> 1618212490736
	1618215331856 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1618215331856 -> 1618212490496
	1618212490496 [label=AccumulateGrad]
	1618212490832 -> 1618212491072
	1618215332240 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1618215332240 -> 1618212490832
	1618212490832 [label=AccumulateGrad]
	1618212491264 -> 1618212491024
	1618215332336 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	1618215332336 -> 1618212491264
	1618212491264 [label=AccumulateGrad]
	1618212491120 -> 1618212491024
	1618215332432 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	1618215332432 -> 1618212491120
	1618212491120 [label=AccumulateGrad]
	1618212491216 -> 1618212491360
	1618212491216 [label=CudnnBatchNormBackward0]
	1618212490304 -> 1618212491216
	1618212490304 [label=ConvolutionBackward0]
	1618212489536 -> 1618212490304
	1618212489776 -> 1618212490304
	1618215330512 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1618215330512 -> 1618212489776
	1618212489776 [label=AccumulateGrad]
	1618212490880 -> 1618212491216
	1618215330608 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1618215330608 -> 1618212490880
	1618212490880 [label=AccumulateGrad]
	1618212491168 -> 1618212491216
	1618215330704 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1618215330704 -> 1618212491168
	1618212491168 [label=AccumulateGrad]
	1618212491696 -> 1618212491552
	1618215332816 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1618215332816 -> 1618212491696
	1618212491696 [label=AccumulateGrad]
	1618212491744 -> 1618212491888
	1618215332912 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1618215332912 -> 1618212491744
	1618212491744 [label=AccumulateGrad]
	1618212492224 -> 1618212491888
	1618215333008 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1618215333008 -> 1618212492224
	1618212492224 [label=AccumulateGrad]
	1618212492320 -> 1618212492272
	1618215333392 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1618215333392 -> 1618212492320
	1618212492320 [label=AccumulateGrad]
	1618212492416 -> 1618212492464
	1618215333488 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1618215333488 -> 1618212492416
	1618212492416 [label=AccumulateGrad]
	1618212492656 -> 1618212492464
	1618215333584 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1618215333584 -> 1618212492656
	1618212492656 [label=AccumulateGrad]
	1618212492704 -> 1618212492944
	1618215333968 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1618215333968 -> 1618212492704
	1618212492704 [label=AccumulateGrad]
	1618212492992 -> 1618212493184
	1618215334064 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	1618215334064 -> 1618212492992
	1618212492992 [label=AccumulateGrad]
	1618212493280 -> 1618212493184
	1618215334160 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	1618215334160 -> 1618212493280
	1618212493280 [label=AccumulateGrad]
	1618212493376 -> 1618212493232
	1618212493328 -> 1618212493712
	1618215334544 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1618215334544 -> 1618212493328
	1618212493328 [label=AccumulateGrad]
	1618212493904 -> 1618212493760
	1618215334640 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	1618215334640 -> 1618212493904
	1618212493904 [label=AccumulateGrad]
	1618212493856 -> 1618212493760
	1618215334736 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	1618215334736 -> 1618212493856
	1618212493856 [label=AccumulateGrad]
	1618212494048 -> 1618212494432
	1618215335120 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1618215335120 -> 1618212494048
	1618212494048 [label=AccumulateGrad]
	1618212494288 -> 1618212494192
	1618215335216 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	1618215335216 -> 1618212494288
	1618212494288 [label=AccumulateGrad]
	1618212494528 -> 1618212494192
	1618215335312 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	1618215335312 -> 1618212494528
	1618212494528 [label=AccumulateGrad]
	1618212494864 -> 1618212494816
	1618215335696 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1618215335696 -> 1618212494864
	1618212494864 [label=AccumulateGrad]
	1618212494720 -> 1618212495056
	1618215335792 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	1618215335792 -> 1618212494720
	1618212494720 [label=AccumulateGrad]
	1618212494912 -> 1618212495056
	1618215335888 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	1618215335888 -> 1618212494912
	1618212494912 [label=AccumulateGrad]
	1618212495104 -> 1618212495392
	1618212495488 -> 1618212495584
	1618215336272 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1618215336272 -> 1618212495488
	1618212495488 [label=AccumulateGrad]
	1618212495632 -> 1618212495920
	1618215336368 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	1618215336368 -> 1618212495632
	1618212495632 [label=AccumulateGrad]
	1618212496016 -> 1618212495920
	1618215336464 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	1618215336464 -> 1618212496016
	1618212496016 [label=AccumulateGrad]
	1618212495776 -> 1618212496160
	1618215336848 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1618215336848 -> 1618212495776
	1618212495776 [label=AccumulateGrad]
	1618212496448 -> 1618212496352
	1618215336944 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	1618215336944 -> 1618212496448
	1618212496448 [label=AccumulateGrad]
	1618212496400 -> 1618212496352
	1618215337040 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	1618215337040 -> 1618212496400
	1618212496400 [label=AccumulateGrad]
	1618212496496 -> 1618212496976
	1618215337424 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1618215337424 -> 1618212496496
	1618212496496 [label=AccumulateGrad]
	1618212496880 -> 1618212496928
	1618215337520 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	1618215337520 -> 1618212496880
	1618212496880 [label=AccumulateGrad]
	1618212497072 -> 1618212496928
	1618215337616 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	1618215337616 -> 1618212497072
	1618212497072 [label=AccumulateGrad]
	1618212496832 -> 1618212497024
	1618212497408 -> 1618212497360
	1618215027344 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	1618215027344 -> 1618212497408
	1618212497408 [label=AccumulateGrad]
	1618212497552 -> 1618212497696
	1618215027440 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1618215027440 -> 1618212497552
	1618212497552 [label=AccumulateGrad]
	1618212498032 -> 1618212497696
	1618215027536 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1618215027536 -> 1618212498032
	1618212498032 [label=AccumulateGrad]
	1618212498128 -> 1618212498080
	1618215027920 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618215027920 -> 1618212498128
	1618212498128 [label=AccumulateGrad]
	1618212498224 -> 1618212498272
	1618215028016 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1618215028016 -> 1618212498224
	1618212498224 [label=AccumulateGrad]
	1618212498464 -> 1618212498272
	1618215028112 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1618215028112 -> 1618212498464
	1618212498464 [label=AccumulateGrad]
	1618212498512 -> 1618212498752
	1618215028496 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618215028496 -> 1618212498512
	1618212498512 [label=AccumulateGrad]
	1618212498800 -> 1618212498992
	1618215028592 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	1618215028592 -> 1618212498800
	1618212498800 [label=AccumulateGrad]
	1618212499088 -> 1618212498992
	1618215028688 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	1618215028688 -> 1618212499088
	1618212499088 [label=AccumulateGrad]
	1618212499184 -> 1618212499040
	1618212499184 [label=CudnnBatchNormBackward0]
	1618212497984 -> 1618212499184
	1618212497984 [label=ConvolutionBackward0]
	1618212497504 -> 1618212497984
	1618212497456 -> 1618212497984
	1618215026768 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	1618215026768 -> 1618212497456
	1618212497456 [label=AccumulateGrad]
	1618212498416 -> 1618212499184
	1618215026864 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	1618215026864 -> 1618212498416
	1618212498416 [label=AccumulateGrad]
	1618212498608 -> 1618212499184
	1618215026960 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	1618215026960 -> 1618212498608
	1618212498608 [label=AccumulateGrad]
	1618212499136 -> 1618212499520
	1618215029072 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618215029072 -> 1618212499136
	1618212499136 [label=AccumulateGrad]
	1618212499712 -> 1618212499568
	1618215029168 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1618215029168 -> 1618212499712
	1618212499712 [label=AccumulateGrad]
	1618212499664 -> 1618212499568
	1618215029264 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1618215029264 -> 1618212499664
	1618212499664 [label=AccumulateGrad]
	1618212499856 -> 1618212500240
	1618215029648 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618215029648 -> 1618212499856
	1618212499856 [label=AccumulateGrad]
	1618212500096 -> 1618212500000
	1618215029744 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1618215029744 -> 1618212500096
	1618212500096 [label=AccumulateGrad]
	1618212500336 -> 1618212500000
	1618215029840 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1618215029840 -> 1618212500336
	1618212500336 [label=AccumulateGrad]
	1618212500672 -> 1618212500624
	1618215030224 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618215030224 -> 1618212500672
	1618212500672 [label=AccumulateGrad]
	1618212500528 -> 1618212500864
	1618215030320 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	1618215030320 -> 1618212500528
	1618212500528 [label=AccumulateGrad]
	1618212500720 -> 1618212500864
	1618215030416 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	1618215030416 -> 1618212500720
	1618212500720 [label=AccumulateGrad]
	1618212500912 -> 1618212501200
	1618212501296 -> 1618212501392
	1618215030800 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618215030800 -> 1618212501296
	1618212501296 [label=AccumulateGrad]
	1618212501440 -> 1618212501728
	1618215030896 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	1618215030896 -> 1618212501440
	1618212501440 [label=AccumulateGrad]
	1618212501824 -> 1618212501728
	1618215030992 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	1618215030992 -> 1618212501824
	1618212501824 [label=AccumulateGrad]
	1618212501584 -> 1618212501968
	1618215031376 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618215031376 -> 1618212501584
	1618212501584 [label=AccumulateGrad]
	1618212502256 -> 1618212502160
	1618215031472 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	1618215031472 -> 1618212502256
	1618212502256 [label=AccumulateGrad]
	1618212502208 -> 1618212502160
	1618215031568 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	1618215031568 -> 1618212502208
	1618212502208 [label=AccumulateGrad]
	1618212502304 -> 1618212502784
	1618215031952 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618215031952 -> 1618212502304
	1618212502304 [label=AccumulateGrad]
	1618212502688 -> 1618212502736
	1618215032048 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	1618215032048 -> 1618212502688
	1618212502688 [label=AccumulateGrad]
	1618212502880 -> 1618212502736
	1618215032144 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	1618215032144 -> 1618212502880
	1618212502880 [label=AccumulateGrad]
	1618212502640 -> 1618212502832
	1618212503024 -> 1618212503264
	1618215032528 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618215032528 -> 1618212503024
	1618212503024 [label=AccumulateGrad]
	1618212503168 -> 1618212503360
	1618215032624 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	1618215032624 -> 1618212503168
	1618212503168 [label=AccumulateGrad]
	1618212487232 -> 1618212503360
	1618215032720 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	1618215032720 -> 1618212487232
	1618212487232 [label=AccumulateGrad]
	1618212487616 -> 1618212488816
	1618215033104 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618215033104 -> 1618212487616
	1618212487616 [label=AccumulateGrad]
	1618212488672 -> 1618212489344
	1618215033200 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	1618215033200 -> 1618212488672
	1618212488672 [label=AccumulateGrad]
	1618212489872 -> 1618212489344
	1618215033296 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	1618215033296 -> 1618212489872
	1618212489872 [label=AccumulateGrad]
	1618212490400 -> 1618212490784
	1618215033680 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618215033680 -> 1618212490400
	1618212490400 [label=AccumulateGrad]
	1618212491456 -> 1618212491984
	1618215033776 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	1618215033776 -> 1618212491456
	1618212491456 [label=AccumulateGrad]
	1618212491312 -> 1618212491984
	1618215033872 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	1618215033872 -> 1618212491312
	1618212491312 [label=AccumulateGrad]
	1618212491840 -> 1618212492512
	1618212493040 -> 1618212494096
	1618215034256 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618215034256 -> 1618212493040
	1618212493040 [label=AccumulateGrad]
	1618212493952 -> 1618212494624
	1618215034352 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	1618215034352 -> 1618212493952
	1618212493952 [label=AccumulateGrad]
	1618212495152 -> 1618212494624
	1618215034448 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	1618215034448 -> 1618212495152
	1618212495152 [label=AccumulateGrad]
	1618212495680 -> 1618212496064
	1618215034832 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618215034832 -> 1618212495680
	1618212495680 [label=AccumulateGrad]
	1618212496736 -> 1618212496592
	1618215034928 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	1618215034928 -> 1618212496736
	1618212496736 [label=AccumulateGrad]
	1618212497120 -> 1618212496592
	1618215035024 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	1618215035024 -> 1618212497120
	1618212497120 [label=AccumulateGrad]
	1618212497648 -> 1618212498848
	1618215035408 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618215035408 -> 1618212497648
	1618212497648 [label=AccumulateGrad]
	1618212498704 -> 1618212499232
	1618215035504 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	1618215035504 -> 1618212498704
	1618212498704 [label=AccumulateGrad]
	1618212499376 -> 1618212499232
	1618215035600 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	1618215035600 -> 1618212499376
	1618212499376 [label=AccumulateGrad]
	1618212499904 -> 1618212499760
	1618212500288 -> 1618212501344
	1618215035984 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618215035984 -> 1618212500288
	1618212500288 [label=AccumulateGrad]
	1618212502016 -> 1618212501872
	1618215036080 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	1618215036080 -> 1618212502016
	1618212502016 [label=AccumulateGrad]
	1618212502400 -> 1618212501872
	1618215036176 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	1618215036176 -> 1618212502400
	1618212502400 [label=AccumulateGrad]
	1618212502928 -> 1618212389216
	1618215036560 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618215036560 -> 1618212502928
	1618212502928 [label=AccumulateGrad]
	1618212389120 -> 1618212389312
	1618215036656 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	1618215036656 -> 1618212389120
	1618212389120 [label=AccumulateGrad]
	1618212389072 -> 1618212389312
	1618215036752 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	1618215036752 -> 1618212389072
	1618212389072 [label=AccumulateGrad]
	1618212389408 -> 1618212389648
	1618215037136 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618215037136 -> 1618212389408
	1618212389408 [label=AccumulateGrad]
	1618212389840 -> 1618212389600
	1618215037232 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	1618215037232 -> 1618212389840
	1618212389840 [label=AccumulateGrad]
	1618212389696 -> 1618212389600
	1618215037328 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	1618215037328 -> 1618212389696
	1618212389696 [label=AccumulateGrad]
	1618212389792 -> 1618212389936
	1618212390272 -> 1618212390128
	1618215037712 [label="layer3.6.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618215037712 -> 1618212390272
	1618212390272 [label=AccumulateGrad]
	1618212390320 -> 1618212390464
	1618215037808 [label="layer3.6.bn1.weight
 (256)" fillcolor=lightblue]
	1618215037808 -> 1618212390320
	1618212390320 [label=AccumulateGrad]
	1618212390800 -> 1618212390464
	1618215037904 [label="layer3.6.bn1.bias
 (256)" fillcolor=lightblue]
	1618215037904 -> 1618212390800
	1618212390800 [label=AccumulateGrad]
	1618212390896 -> 1618212390848
	1618215038288 [label="layer3.6.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618215038288 -> 1618212390896
	1618212390896 [label=AccumulateGrad]
	1618212390992 -> 1618212391040
	1618215038384 [label="layer3.6.bn2.weight
 (256)" fillcolor=lightblue]
	1618215038384 -> 1618212390992
	1618212390992 [label=AccumulateGrad]
	1618212391232 -> 1618212391040
	1618215038480 [label="layer3.6.bn2.bias
 (256)" fillcolor=lightblue]
	1618215038480 -> 1618212391232
	1618212391232 [label=AccumulateGrad]
	1618212391280 -> 1618212391520
	1618215038864 [label="layer3.6.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618215038864 -> 1618212391280
	1618212391280 [label=AccumulateGrad]
	1618212391568 -> 1618212391760
	1618215038960 [label="layer3.6.bn3.weight
 (1024)" fillcolor=lightblue]
	1618215038960 -> 1618212391568
	1618212391568 [label=AccumulateGrad]
	1618212391856 -> 1618212391760
	1618215039056 [label="layer3.6.bn3.bias
 (1024)" fillcolor=lightblue]
	1618215039056 -> 1618212391856
	1618212391856 [label=AccumulateGrad]
	1618212391952 -> 1618212391808
	1618212391904 -> 1618212392288
	1618215039440 [label="layer3.7.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618215039440 -> 1618212391904
	1618212391904 [label=AccumulateGrad]
	1618212392480 -> 1618212392336
	1618215039536 [label="layer3.7.bn1.weight
 (256)" fillcolor=lightblue]
	1618215039536 -> 1618212392480
	1618212392480 [label=AccumulateGrad]
	1618212392432 -> 1618212392336
	1618215039632 [label="layer3.7.bn1.bias
 (256)" fillcolor=lightblue]
	1618215039632 -> 1618212392432
	1618212392432 [label=AccumulateGrad]
	1618212392624 -> 1618212393008
	1618215040016 [label="layer3.7.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618215040016 -> 1618212392624
	1618212392624 [label=AccumulateGrad]
	1618212392864 -> 1618212392768
	1618215040112 [label="layer3.7.bn2.weight
 (256)" fillcolor=lightblue]
	1618215040112 -> 1618212392864
	1618212392864 [label=AccumulateGrad]
	1618212393104 -> 1618212392768
	1618215040208 [label="layer3.7.bn2.bias
 (256)" fillcolor=lightblue]
	1618215040208 -> 1618212393104
	1618212393104 [label=AccumulateGrad]
	1618212393440 -> 1618212393392
	1618215040592 [label="layer3.7.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618215040592 -> 1618212393440
	1618212393440 [label=AccumulateGrad]
	1618212393296 -> 1618212393632
	1618215040688 [label="layer3.7.bn3.weight
 (1024)" fillcolor=lightblue]
	1618215040688 -> 1618212393296
	1618212393296 [label=AccumulateGrad]
	1618212393488 -> 1618212393632
	1618215040784 [label="layer3.7.bn3.bias
 (1024)" fillcolor=lightblue]
	1618215040784 -> 1618212393488
	1618212393488 [label=AccumulateGrad]
	1618212393680 -> 1618212393968
	1618212394064 -> 1618212394160
	1618215041168 [label="layer3.8.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618215041168 -> 1618212394064
	1618212394064 [label=AccumulateGrad]
	1618212394208 -> 1618212394496
	1618215041264 [label="layer3.8.bn1.weight
 (256)" fillcolor=lightblue]
	1618215041264 -> 1618212394208
	1618212394208 [label=AccumulateGrad]
	1618212394592 -> 1618212394496
	1618215041360 [label="layer3.8.bn1.bias
 (256)" fillcolor=lightblue]
	1618215041360 -> 1618212394592
	1618212394592 [label=AccumulateGrad]
	1618212394352 -> 1618212394736
	1618215041744 [label="layer3.8.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618215041744 -> 1618212394352
	1618212394352 [label=AccumulateGrad]
	1618212395024 -> 1618212394928
	1618215041840 [label="layer3.8.bn2.weight
 (256)" fillcolor=lightblue]
	1618215041840 -> 1618212395024
	1618212395024 [label=AccumulateGrad]
	1618212394976 -> 1618212394928
	1618215041936 [label="layer3.8.bn2.bias
 (256)" fillcolor=lightblue]
	1618215041936 -> 1618212394976
	1618212394976 [label=AccumulateGrad]
	1618212395072 -> 1618212395552
	1618215042320 [label="layer3.8.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618215042320 -> 1618212395072
	1618212395072 [label=AccumulateGrad]
	1618212395456 -> 1618212395504
	1618215042416 [label="layer3.8.bn3.weight
 (1024)" fillcolor=lightblue]
	1618215042416 -> 1618212395456
	1618212395456 [label=AccumulateGrad]
	1618212395648 -> 1618212395504
	1618215042512 [label="layer3.8.bn3.bias
 (1024)" fillcolor=lightblue]
	1618215042512 -> 1618212395648
	1618212395648 [label=AccumulateGrad]
	1618212395408 -> 1618212395600
	1618212395792 -> 1618212396032
	1618215042896 [label="layer3.9.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618215042896 -> 1618212395792
	1618212395792 [label=AccumulateGrad]
	1618212395936 -> 1618212396128
	1618215042992 [label="layer3.9.bn1.weight
 (256)" fillcolor=lightblue]
	1618215042992 -> 1618212395936
	1618212395936 [label=AccumulateGrad]
	1618212396320 -> 1618212396128
	1618214797392 [label="layer3.9.bn1.bias
 (256)" fillcolor=lightblue]
	1618214797392 -> 1618212396320
	1618212396320 [label=AccumulateGrad]
	1618212396512 -> 1618212396464
	1618214797776 [label="layer3.9.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214797776 -> 1618212396512
	1618212396512 [label=AccumulateGrad]
	1618212396656 -> 1618212396800
	1618214797872 [label="layer3.9.bn2.weight
 (256)" fillcolor=lightblue]
	1618214797872 -> 1618212396656
	1618212396656 [label=AccumulateGrad]
	1618212397136 -> 1618212396800
	1618214797968 [label="layer3.9.bn2.bias
 (256)" fillcolor=lightblue]
	1618214797968 -> 1618212397136
	1618212397136 [label=AccumulateGrad]
	1618212397232 -> 1618212397184
	1618214798352 [label="layer3.9.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214798352 -> 1618212397232
	1618212397232 [label=AccumulateGrad]
	1618212397328 -> 1618212397664
	1618214798448 [label="layer3.9.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214798448 -> 1618212397328
	1618212397328 [label=AccumulateGrad]
	1618212397376 -> 1618212397664
	1618214798544 [label="layer3.9.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214798544 -> 1618212397376
	1618212397376 [label=AccumulateGrad]
	1618212397568 -> 1618212397760
	1618212397520 -> 1618212398192
	1618214798928 [label="layer3.10.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214798928 -> 1618212397520
	1618212397520 [label=AccumulateGrad]
	1618212398096 -> 1618212398288
	1618214799024 [label="layer3.10.bn1.weight
 (256)" fillcolor=lightblue]
	1618214799024 -> 1618212398096
	1618212398096 [label=AccumulateGrad]
	1618212398048 -> 1618212398288
	1618214799120 [label="layer3.10.bn1.bias
 (256)" fillcolor=lightblue]
	1618214799120 -> 1618212398048
	1618212398048 [label=AccumulateGrad]
	1618212398384 -> 1618212398624
	1618214799504 [label="layer3.10.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214799504 -> 1618212398384
	1618212398384 [label=AccumulateGrad]
	1618212398816 -> 1618212398672
	1618214799600 [label="layer3.10.bn2.weight
 (256)" fillcolor=lightblue]
	1618214799600 -> 1618212398816
	1618212398816 [label=AccumulateGrad]
	1618212398768 -> 1618212398672
	1618214799696 [label="layer3.10.bn2.bias
 (256)" fillcolor=lightblue]
	1618214799696 -> 1618212398768
	1618212398768 [label=AccumulateGrad]
	1618212398960 -> 1618212399344
	1618214800080 [label="layer3.10.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214800080 -> 1618212398960
	1618212398960 [label=AccumulateGrad]
	1618212399200 -> 1618212399296
	1618214800176 [label="layer3.10.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214800176 -> 1618212399200
	1618212399200 [label=AccumulateGrad]
	1618212399104 -> 1618212399296
	1618214800272 [label="layer3.10.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214800272 -> 1618212399104
	1618212399104 [label=AccumulateGrad]
	1618212399440 -> 1618212399488
	1618212399680 -> 1618212399824
	1618214800656 [label="layer3.11.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214800656 -> 1618212399680
	1618212399680 [label=AccumulateGrad]
	1618212399968 -> 1618212400016
	1618214800752 [label="layer3.11.bn1.weight
 (256)" fillcolor=lightblue]
	1618214800752 -> 1618212399968
	1618212399968 [label=AccumulateGrad]
	1618212400208 -> 1618212400016
	1618214800848 [label="layer3.11.bn1.bias
 (256)" fillcolor=lightblue]
	1618214800848 -> 1618212400208
	1618212400208 [label=AccumulateGrad]
	1618212400256 -> 1618212400496
	1618214801232 [label="layer3.11.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214801232 -> 1618212400256
	1618212400256 [label=AccumulateGrad]
	1618212400544 -> 1618212400832
	1618214801328 [label="layer3.11.bn2.weight
 (256)" fillcolor=lightblue]
	1618214801328 -> 1618212400544
	1618212400544 [label=AccumulateGrad]
	1618212400928 -> 1618212400832
	1618214801424 [label="layer3.11.bn2.bias
 (256)" fillcolor=lightblue]
	1618214801424 -> 1618212400928
	1618212400928 [label=AccumulateGrad]
	1618212400688 -> 1618212401072
	1618214801808 [label="layer3.11.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214801808 -> 1618212400688
	1618212400688 [label=AccumulateGrad]
	1618212401360 -> 1618212401456
	1618214801904 [label="layer3.11.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214801904 -> 1618212401360
	1618212401360 [label=AccumulateGrad]
	1618212401264 -> 1618212401456
	1618214802000 [label="layer3.11.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214802000 -> 1618212401264
	1618212401264 [label=AccumulateGrad]
	1618212401312 -> 1618212401216
	1618212401552 -> 1618212401984
	1618214802384 [label="layer3.12.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214802384 -> 1618212401552
	1618212401552 [label=AccumulateGrad]
	1618212401840 -> 1618212401744
	1618214802480 [label="layer3.12.bn1.weight
 (256)" fillcolor=lightblue]
	1618214802480 -> 1618212401840
	1618212401840 [label=AccumulateGrad]
	1618212402080 -> 1618212401744
	1618214802576 [label="layer3.12.bn1.bias
 (256)" fillcolor=lightblue]
	1618214802576 -> 1618212402080
	1618212402080 [label=AccumulateGrad]
	1618212402416 -> 1618212402368
	1618214802960 [label="layer3.12.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214802960 -> 1618212402416
	1618212402416 [label=AccumulateGrad]
	1618212402272 -> 1618212402464
	1618214803056 [label="layer3.12.bn2.weight
 (256)" fillcolor=lightblue]
	1618214803056 -> 1618212402272
	1618212402272 [label=AccumulateGrad]
	1618212402656 -> 1618212402464
	1618214803152 [label="layer3.12.bn2.bias
 (256)" fillcolor=lightblue]
	1618214803152 -> 1618212402656
	1618212402656 [label=AccumulateGrad]
	1618212402848 -> 1618212402800
	1618214803536 [label="layer3.12.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214803536 -> 1618212402848
	1618212402848 [label=AccumulateGrad]
	1618212402992 -> 1618212403184
	1618214803632 [label="layer3.12.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214803632 -> 1618212402992
	1618212402992 [label=AccumulateGrad]
	1618212403136 -> 1618212403184
	1618214803728 [label="layer3.12.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214803728 -> 1618212403136
	1618212403136 [label=AccumulateGrad]
	1618212403472 -> 1618212403376
	1618212403424 -> 1618212403712
	1618214804112 [label="layer3.13.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214804112 -> 1618212403424
	1618212403424 [label=AccumulateGrad]
	1618212404000 -> 1618212403904
	1618214804208 [label="layer3.13.bn1.weight
 (256)" fillcolor=lightblue]
	1618214804208 -> 1618212404000
	1618212404000 [label=AccumulateGrad]
	1618212403952 -> 1618212403904
	1618214804304 [label="layer3.13.bn1.bias
 (256)" fillcolor=lightblue]
	1618214804304 -> 1618212403952
	1618212403952 [label=AccumulateGrad]
	1618212404048 -> 1618212404528
	1618214804688 [label="layer3.13.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214804688 -> 1618212404048
	1618212404048 [label=AccumulateGrad]
	1618212404432 -> 1618212404624
	1618214804784 [label="layer3.13.bn2.weight
 (256)" fillcolor=lightblue]
	1618214804784 -> 1618212404432
	1618212404432 [label=AccumulateGrad]
	1618212404384 -> 1618212404624
	1618214804880 [label="layer3.13.bn2.bias
 (256)" fillcolor=lightblue]
	1618214804880 -> 1618212404384
	1618212404384 [label=AccumulateGrad]
	1618212404720 -> 1618212404960
	1618214805264 [label="layer3.13.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214805264 -> 1618212404720
	1618212404720 [label=AccumulateGrad]
	1618212405152 -> 1618212404912
	1618214805360 [label="layer3.13.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214805360 -> 1618212405152
	1618212405152 [label=AccumulateGrad]
	1618212405008 -> 1618212404912
	1618214805456 [label="layer3.13.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214805456 -> 1618212405008
	1618212405008 [label=AccumulateGrad]
	1618212405104 -> 1618212388976
	1618212389360 -> 1618212390416
	1618214805840 [label="layer3.14.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214805840 -> 1618212389360
	1618212389360 [label=AccumulateGrad]
	1618212391088 -> 1618212390944
	1618214805936 [label="layer3.14.bn1.weight
 (256)" fillcolor=lightblue]
	1618214805936 -> 1618212391088
	1618212391088 [label=AccumulateGrad]
	1618212391472 -> 1618212390944
	1618214806032 [label="layer3.14.bn1.bias
 (256)" fillcolor=lightblue]
	1618214806032 -> 1618212391472
	1618212391472 [label=AccumulateGrad]
	1618212392000 -> 1618212393200
	1618214806416 [label="layer3.14.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214806416 -> 1618212392000
	1618212392000 [label=AccumulateGrad]
	1618212393056 -> 1618212393728
	1618214806512 [label="layer3.14.bn2.weight
 (256)" fillcolor=lightblue]
	1618214806512 -> 1618212393056
	1618212393056 [label=AccumulateGrad]
	1618212394256 -> 1618212393728
	1618214806608 [label="layer3.14.bn2.bias
 (256)" fillcolor=lightblue]
	1618214806608 -> 1618212394256
	1618212394256 [label=AccumulateGrad]
	1618212394784 -> 1618212395168
	1618214806992 [label="layer3.14.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214806992 -> 1618212394784
	1618212394784 [label=AccumulateGrad]
	1618212395840 -> 1618212396368
	1618214807088 [label="layer3.14.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214807088 -> 1618212395840
	1618212395840 [label=AccumulateGrad]
	1618212395696 -> 1618212396368
	1618214807184 [label="layer3.14.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214807184 -> 1618212395696
	1618212395696 [label=AccumulateGrad]
	1618212396224 -> 1618212396896
	1618212397424 -> 1618212398480
	1618214807568 [label="layer3.15.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214807568 -> 1618212397424
	1618212397424 [label=AccumulateGrad]
	1618212398336 -> 1618212399008
	1618214807664 [label="layer3.15.bn1.weight
 (256)" fillcolor=lightblue]
	1618214807664 -> 1618212398336
	1618212398336 [label=AccumulateGrad]
	1618212399536 -> 1618212399008
	1618214807760 [label="layer3.15.bn1.bias
 (256)" fillcolor=lightblue]
	1618214807760 -> 1618212399536
	1618212399536 [label=AccumulateGrad]
	1618212400064 -> 1618212400448
	1618214808144 [label="layer3.15.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214808144 -> 1618212400064
	1618212400064 [label=AccumulateGrad]
	1618212401120 -> 1618212400976
	1618214808240 [label="layer3.15.bn2.weight
 (256)" fillcolor=lightblue]
	1618214808240 -> 1618212401120
	1618212401120 [label=AccumulateGrad]
	1618212401504 -> 1618212400976
	1618214808336 [label="layer3.15.bn2.bias
 (256)" fillcolor=lightblue]
	1618214808336 -> 1618212401504
	1618212401504 [label=AccumulateGrad]
	1618212402032 -> 1618212403232
	1618214808720 [label="layer3.15.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214808720 -> 1618212402032
	1618212402032 [label=AccumulateGrad]
	1618212403088 -> 1618212403616
	1618214808816 [label="layer3.15.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214808816 -> 1618212403088
	1618212403088 [label=AccumulateGrad]
	1618212403760 -> 1618212403616
	1618214808912 [label="layer3.15.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214808912 -> 1618212403760
	1618212403760 [label=AccumulateGrad]
	1618212404288 -> 1618212404144
	1618212290624 -> 1618212290960
	1618214809296 [label="layer3.16.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214809296 -> 1618212290624
	1618212290624 [label=AccumulateGrad]
	1618212290864 -> 1618212291056
	1618214809392 [label="layer3.16.bn1.weight
 (256)" fillcolor=lightblue]
	1618214809392 -> 1618212290864
	1618212290864 [label=AccumulateGrad]
	1618212290816 -> 1618212291056
	1618214809488 [label="layer3.16.bn1.bias
 (256)" fillcolor=lightblue]
	1618214809488 -> 1618212290816
	1618212290816 [label=AccumulateGrad]
	1618212291152 -> 1618212291392
	1618214809872 [label="layer3.16.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214809872 -> 1618212291152
	1618212291152 [label=AccumulateGrad]
	1618212291584 -> 1618212291440
	1618214809968 [label="layer3.16.bn2.weight
 (256)" fillcolor=lightblue]
	1618214809968 -> 1618212291584
	1618212291584 [label=AccumulateGrad]
	1618212291536 -> 1618212291440
	1618214810064 [label="layer3.16.bn2.bias
 (256)" fillcolor=lightblue]
	1618214810064 -> 1618212291536
	1618212291536 [label=AccumulateGrad]
	1618212291728 -> 1618212292112
	1618214810448 [label="layer3.16.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214810448 -> 1618212291728
	1618212291728 [label=AccumulateGrad]
	1618212291968 -> 1618212292064
	1618214810544 [label="layer3.16.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214810544 -> 1618212291968
	1618212291968 [label=AccumulateGrad]
	1618212291872 -> 1618212292064
	1618214810640 [label="layer3.16.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214810640 -> 1618212291872
	1618212291872 [label=AccumulateGrad]
	1618212292208 -> 1618212292256
	1618212292448 -> 1618212292592
	1618214811024 [label="layer3.17.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214811024 -> 1618212292448
	1618212292448 [label=AccumulateGrad]
	1618212292736 -> 1618212292784
	1618214811120 [label="layer3.17.bn1.weight
 (256)" fillcolor=lightblue]
	1618214811120 -> 1618212292736
	1618212292736 [label=AccumulateGrad]
	1618212292976 -> 1618212292784
	1618214811216 [label="layer3.17.bn1.bias
 (256)" fillcolor=lightblue]
	1618214811216 -> 1618212292976
	1618212292976 [label=AccumulateGrad]
	1618212293024 -> 1618212293264
	1618214811600 [label="layer3.17.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214811600 -> 1618212293024
	1618212293024 [label=AccumulateGrad]
	1618212293312 -> 1618212293600
	1618214811696 [label="layer3.17.bn2.weight
 (256)" fillcolor=lightblue]
	1618214811696 -> 1618212293312
	1618212293312 [label=AccumulateGrad]
	1618212293696 -> 1618212293600
	1618214811792 [label="layer3.17.bn2.bias
 (256)" fillcolor=lightblue]
	1618214811792 -> 1618212293696
	1618212293696 [label=AccumulateGrad]
	1618212293456 -> 1618212293840
	1618214812176 [label="layer3.17.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214812176 -> 1618212293456
	1618212293456 [label=AccumulateGrad]
	1618212294128 -> 1618212294224
	1618214812272 [label="layer3.17.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214812272 -> 1618212294128
	1618212294128 [label=AccumulateGrad]
	1618212294032 -> 1618212294224
	1618214812368 [label="layer3.17.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214812368 -> 1618212294032
	1618212294032 [label=AccumulateGrad]
	1618212294080 -> 1618212293984
	1618212294320 -> 1618212294752
	1618214812752 [label="layer3.18.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214812752 -> 1618212294320
	1618212294320 [label=AccumulateGrad]
	1618212294608 -> 1618212294512
	1618214812848 [label="layer3.18.bn1.weight
 (256)" fillcolor=lightblue]
	1618214812848 -> 1618212294608
	1618212294608 [label=AccumulateGrad]
	1618212294848 -> 1618212294512
	1618214812944 [label="layer3.18.bn1.bias
 (256)" fillcolor=lightblue]
	1618214812944 -> 1618212294848
	1618212294848 [label=AccumulateGrad]
	1618212295184 -> 1618212295136
	1618214813328 [label="layer3.18.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214813328 -> 1618212295184
	1618212295184 [label=AccumulateGrad]
	1618212295040 -> 1618212295232
	1618214813424 [label="layer3.18.bn2.weight
 (256)" fillcolor=lightblue]
	1618214813424 -> 1618212295040
	1618212295040 [label=AccumulateGrad]
	1618212295424 -> 1618212295232
	1618214813520 [label="layer3.18.bn2.bias
 (256)" fillcolor=lightblue]
	1618214813520 -> 1618212295424
	1618212295424 [label=AccumulateGrad]
	1618212295616 -> 1618212295568
	1618214486288 [label="layer3.18.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214486288 -> 1618212295616
	1618212295616 [label=AccumulateGrad]
	1618212295760 -> 1618212295952
	1618214486384 [label="layer3.18.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214486384 -> 1618212295760
	1618212295760 [label=AccumulateGrad]
	1618212295904 -> 1618212295952
	1618214486480 [label="layer3.18.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214486480 -> 1618212295904
	1618212295904 [label=AccumulateGrad]
	1618212296240 -> 1618212296144
	1618212296192 -> 1618212296480
	1618214486864 [label="layer3.19.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214486864 -> 1618212296192
	1618212296192 [label=AccumulateGrad]
	1618212296768 -> 1618212296672
	1618214486960 [label="layer3.19.bn1.weight
 (256)" fillcolor=lightblue]
	1618214486960 -> 1618212296768
	1618212296768 [label=AccumulateGrad]
	1618212296720 -> 1618212296672
	1618214487056 [label="layer3.19.bn1.bias
 (256)" fillcolor=lightblue]
	1618214487056 -> 1618212296720
	1618212296720 [label=AccumulateGrad]
	1618212296816 -> 1618212297296
	1618214487440 [label="layer3.19.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214487440 -> 1618212296816
	1618212296816 [label=AccumulateGrad]
	1618212297200 -> 1618212297392
	1618214487536 [label="layer3.19.bn2.weight
 (256)" fillcolor=lightblue]
	1618214487536 -> 1618212297200
	1618212297200 [label=AccumulateGrad]
	1618212297152 -> 1618212297392
	1618214487632 [label="layer3.19.bn2.bias
 (256)" fillcolor=lightblue]
	1618214487632 -> 1618212297152
	1618212297152 [label=AccumulateGrad]
	1618212297488 -> 1618212297728
	1618214488016 [label="layer3.19.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214488016 -> 1618212297488
	1618212297488 [label=AccumulateGrad]
	1618212297920 -> 1618212297680
	1618214488112 [label="layer3.19.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214488112 -> 1618212297920
	1618212297920 [label=AccumulateGrad]
	1618212297776 -> 1618212297680
	1618214488208 [label="layer3.19.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214488208 -> 1618212297776
	1618212297776 [label=AccumulateGrad]
	1618212297872 -> 1618212298016
	1618212298352 -> 1618212298208
	1618214488592 [label="layer3.20.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214488592 -> 1618212298352
	1618212298352 [label=AccumulateGrad]
	1618212298400 -> 1618212298544
	1618214488688 [label="layer3.20.bn1.weight
 (256)" fillcolor=lightblue]
	1618214488688 -> 1618212298400
	1618212298400 [label=AccumulateGrad]
	1618212298880 -> 1618212298544
	1618214488784 [label="layer3.20.bn1.bias
 (256)" fillcolor=lightblue]
	1618214488784 -> 1618212298880
	1618212298880 [label=AccumulateGrad]
	1618212298976 -> 1618212298928
	1618214489168 [label="layer3.20.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214489168 -> 1618212298976
	1618212298976 [label=AccumulateGrad]
	1618212299072 -> 1618212299120
	1618214489264 [label="layer3.20.bn2.weight
 (256)" fillcolor=lightblue]
	1618214489264 -> 1618212299072
	1618212299072 [label=AccumulateGrad]
	1618212299312 -> 1618212299120
	1618214489360 [label="layer3.20.bn2.bias
 (256)" fillcolor=lightblue]
	1618214489360 -> 1618212299312
	1618212299312 [label=AccumulateGrad]
	1618212299360 -> 1618212299600
	1618214489744 [label="layer3.20.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214489744 -> 1618212299360
	1618212299360 [label=AccumulateGrad]
	1618212299648 -> 1618212299840
	1618214489840 [label="layer3.20.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214489840 -> 1618212299648
	1618212299648 [label=AccumulateGrad]
	1618212299936 -> 1618212299840
	1618214489936 [label="layer3.20.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214489936 -> 1618212299936
	1618212299936 [label=AccumulateGrad]
	1618212300032 -> 1618212299888
	1618212299984 -> 1618212300368
	1618214490320 [label="layer3.21.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214490320 -> 1618212299984
	1618212299984 [label=AccumulateGrad]
	1618212300560 -> 1618212300416
	1618214490416 [label="layer3.21.bn1.weight
 (256)" fillcolor=lightblue]
	1618214490416 -> 1618212300560
	1618212300560 [label=AccumulateGrad]
	1618212300512 -> 1618212300416
	1618214490512 [label="layer3.21.bn1.bias
 (256)" fillcolor=lightblue]
	1618214490512 -> 1618212300512
	1618212300512 [label=AccumulateGrad]
	1618212300704 -> 1618212301088
	1618214490896 [label="layer3.21.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214490896 -> 1618212300704
	1618212300704 [label=AccumulateGrad]
	1618212300944 -> 1618212300848
	1618214490992 [label="layer3.21.bn2.weight
 (256)" fillcolor=lightblue]
	1618214490992 -> 1618212300944
	1618212300944 [label=AccumulateGrad]
	1618212301184 -> 1618212300848
	1618214491088 [label="layer3.21.bn2.bias
 (256)" fillcolor=lightblue]
	1618214491088 -> 1618212301184
	1618212301184 [label=AccumulateGrad]
	1618212301520 -> 1618212301472
	1618214491472 [label="layer3.21.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214491472 -> 1618212301520
	1618212301520 [label=AccumulateGrad]
	1618212301376 -> 1618212301712
	1618214491568 [label="layer3.21.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214491568 -> 1618212301376
	1618212301376 [label=AccumulateGrad]
	1618212301568 -> 1618212301712
	1618214491664 [label="layer3.21.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214491664 -> 1618212301568
	1618212301568 [label=AccumulateGrad]
	1618212301760 -> 1618212302048
	1618212302144 -> 1618212302240
	1618214492048 [label="layer3.22.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1618214492048 -> 1618212302144
	1618212302144 [label=AccumulateGrad]
	1618212302288 -> 1618212302576
	1618214492144 [label="layer3.22.bn1.weight
 (256)" fillcolor=lightblue]
	1618214492144 -> 1618212302288
	1618212302288 [label=AccumulateGrad]
	1618212302672 -> 1618212302576
	1618214492240 [label="layer3.22.bn1.bias
 (256)" fillcolor=lightblue]
	1618214492240 -> 1618212302672
	1618212302672 [label=AccumulateGrad]
	1618212302432 -> 1618212302816
	1618214492624 [label="layer3.22.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1618214492624 -> 1618212302432
	1618212302432 [label=AccumulateGrad]
	1618212303104 -> 1618212303008
	1618214492720 [label="layer3.22.bn2.weight
 (256)" fillcolor=lightblue]
	1618214492720 -> 1618212303104
	1618212303104 [label=AccumulateGrad]
	1618212303056 -> 1618212303008
	1618214492816 [label="layer3.22.bn2.bias
 (256)" fillcolor=lightblue]
	1618214492816 -> 1618212303056
	1618212303056 [label=AccumulateGrad]
	1618212303152 -> 1618212303632
	1618214493200 [label="layer3.22.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1618214493200 -> 1618212303152
	1618212303152 [label=AccumulateGrad]
	1618212303536 -> 1618212303584
	1618214493296 [label="layer3.22.bn3.weight
 (1024)" fillcolor=lightblue]
	1618214493296 -> 1618212303536
	1618212303536 [label=AccumulateGrad]
	1618212303728 -> 1618212303584
	1618214493392 [label="layer3.22.bn3.bias
 (1024)" fillcolor=lightblue]
	1618214493392 -> 1618212303728
	1618212303728 [label=AccumulateGrad]
	1618212303488 -> 1618212303680
	1618212304064 -> 1618212304016
	1618214494352 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	1618214494352 -> 1618212304064
	1618212304064 [label=AccumulateGrad]
	1618212304208 -> 1618212304352
	1618214494448 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1618214494448 -> 1618212304208
	1618212304208 [label=AccumulateGrad]
	1618212304688 -> 1618212304352
	1618214494544 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1618214494544 -> 1618212304688
	1618212304688 [label=AccumulateGrad]
	1618212304784 -> 1618212304736
	1618214494928 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1618214494928 -> 1618212304784
	1618212304784 [label=AccumulateGrad]
	1618212304880 -> 1618212304928
	1618214495024 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1618214495024 -> 1618212304880
	1618212304880 [label=AccumulateGrad]
	1618212305120 -> 1618212304928
	1618214495120 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1618214495120 -> 1618212305120
	1618212305120 [label=AccumulateGrad]
	1618212305168 -> 1618212305408
	1618214495504 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1618214495504 -> 1618212305168
	1618212305168 [label=AccumulateGrad]
	1618212305456 -> 1618212305648
	1618214495600 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	1618214495600 -> 1618212305456
	1618212305456 [label=AccumulateGrad]
	1618212305744 -> 1618212305648
	1618214495696 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	1618214495696 -> 1618212305744
	1618212305744 [label=AccumulateGrad]
	1618212305840 -> 1618212305696
	1618212305840 [label=CudnnBatchNormBackward0]
	1618212304640 -> 1618212305840
	1618212304640 [label=ConvolutionBackward0]
	1618212304160 -> 1618212304640
	1618212304112 -> 1618212304640
	1618214493776 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	1618214493776 -> 1618212304112
	1618212304112 [label=AccumulateGrad]
	1618212305072 -> 1618212305840
	1618214493872 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	1618214493872 -> 1618212305072
	1618212305072 [label=AccumulateGrad]
	1618212305264 -> 1618212305840
	1618214493968 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	1618214493968 -> 1618212305264
	1618212305264 [label=AccumulateGrad]
	1618212305792 -> 1618212306176
	1618214496080 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1618214496080 -> 1618212305792
	1618212305792 [label=AccumulateGrad]
	1618212306368 -> 1618212306224
	1618214496176 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1618214496176 -> 1618212306368
	1618212306368 [label=AccumulateGrad]
	1618212306320 -> 1618212306224
	1618214496272 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1618214496272 -> 1618212306320
	1618212306320 [label=AccumulateGrad]
	1618212306512 -> 1618212306896
	1618214496656 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1618214496656 -> 1618212306512
	1618212306512 [label=AccumulateGrad]
	1618212306752 -> 1618212306656
	1618214496752 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1618214496752 -> 1618212306752
	1618212306752 [label=AccumulateGrad]
	1618212290720 -> 1618212306656
	1618214496848 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1618214496848 -> 1618212290720
	1618212290720 [label=AccumulateGrad]
	1618212291104 -> 1618212292304
	1618214497232 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1618214497232 -> 1618212291104
	1618212291104 [label=AccumulateGrad]
	1618212292160 -> 1618212292688
	1618214497328 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	1618214497328 -> 1618212292160
	1618212292160 [label=AccumulateGrad]
	1618212292832 -> 1618212292688
	1618214497424 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	1618214497424 -> 1618212292832
	1618212292832 [label=AccumulateGrad]
	1618212293360 -> 1618212293216
	1618212293744 -> 1618212294800
	1618214497808 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1618214497808 -> 1618212293744
	1618212293744 [label=AccumulateGrad]
	1618212295472 -> 1618212295328
	1618214497904 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	1618214497904 -> 1618212295472
	1618212295472 [label=AccumulateGrad]
	1618212295856 -> 1618212295328
	1618214498000 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	1618214498000 -> 1618212295856
	1618212295856 [label=AccumulateGrad]
	1618212296384 -> 1618212297584
	1618214498384 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1618214498384 -> 1618212296384
	1618212296384 [label=AccumulateGrad]
	1618212297440 -> 1618212298112
	1618214498480 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	1618214498480 -> 1618212297440
	1618212297440 [label=AccumulateGrad]
	1618212298640 -> 1618212298112
	1618214498576 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	1618214498576 -> 1618212298640
	1618212298640 [label=AccumulateGrad]
	1618212299168 -> 1618212299552
	1618214498960 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1618214498960 -> 1618212299168
	1618212299168 [label=AccumulateGrad]
	1618212300224 -> 1618212300752
	1618214499056 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	1618214499056 -> 1618212300224
	1618212300224 [label=AccumulateGrad]
	1618212300080 -> 1618212300752
	1618214499152 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	1618214499152 -> 1618212300080
	1618212300080 [label=AccumulateGrad]
	1618212300608 -> 1618212301280
	1618212302864 -> 1618212303776
	1618212302864 [label=TBackward0]
	1618212301136 -> 1618212302864
	1618214499824 [label="fc.weight
 (19, 2048)" fillcolor=lightblue]
	1618214499824 -> 1618212301136
	1618212301136 [label=AccumulateGrad]
	1618212303776 -> 1618212354576
}
