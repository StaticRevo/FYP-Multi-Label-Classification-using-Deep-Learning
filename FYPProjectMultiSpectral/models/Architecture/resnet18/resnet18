digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2098161328560 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2098257541920 [label=AddmmBackward0]
	2098257541968 -> 2098257541920
	2098160923952 [label="fc.bias
 (19)" fillcolor=lightblue]
	2098160923952 -> 2098257541968
	2098257541968 [label=AccumulateGrad]
	2098257532032 -> 2098257541920
	2098257532032 [label=ViewBackward0]
	2098257540048 -> 2098257532032
	2098257540048 [label=MeanBackward1]
	2098257537648 -> 2098257540048
	2098257537648 [label=ReluBackward0]
	2098257528192 -> 2098257537648
	2098257528192 [label=AddBackward0]
	2098257536352 -> 2098257528192
	2098257536352 [label=CudnnBatchNormBackward0]
	2098257539232 -> 2098257536352
	2098257539232 [label=ConvolutionBackward0]
	2098257537600 -> 2098257539232
	2098257537600 [label=ReluBackward0]
	2098257535056 -> 2098257537600
	2098257535056 [label=CudnnBatchNormBackward0]
	2098257531504 -> 2098257535056
	2098257531504 [label=ConvolutionBackward0]
	2098257541728 -> 2098257531504
	2098257541728 [label=ReluBackward0]
	2098257528384 -> 2098257541728
	2098257528384 [label=AddBackward0]
	2098257532656 -> 2098257528384
	2098257532656 [label=CudnnBatchNormBackward0]
	2098257534912 -> 2098257532656
	2098257534912 [label=ConvolutionBackward0]
	2098257539952 -> 2098257534912
	2098257539952 [label=ReluBackward0]
	2098257536784 -> 2098257539952
	2098257536784 [label=CudnnBatchNormBackward0]
	2098257527280 -> 2098257536784
	2098257527280 [label=ConvolutionBackward0]
	2098257536448 -> 2098257527280
	2098257536448 [label=ReluBackward0]
	2098257539664 -> 2098257536448
	2098257539664 [label=AddBackward0]
	2098257526848 -> 2098257539664
	2098257526848 [label=CudnnBatchNormBackward0]
	2098257533568 -> 2098257526848
	2098257533568 [label=ConvolutionBackward0]
	2098257538416 -> 2098257533568
	2098257538416 [label=ReluBackward0]
	2098257540864 -> 2098257538416
	2098257540864 [label=CudnnBatchNormBackward0]
	2098257540240 -> 2098257540864
	2098257540240 [label=ConvolutionBackward0]
	2098257530304 -> 2098257540240
	2098257530304 [label=ReluBackward0]
	2098257540432 -> 2098257530304
	2098257540432 [label=AddBackward0]
	2098257536880 -> 2098257540432
	2098257536880 [label=CudnnBatchNormBackward0]
	2098257538176 -> 2098257536880
	2098257538176 [label=ConvolutionBackward0]
	2098257535152 -> 2098257538176
	2098257535152 [label=ReluBackward0]
	2098257527376 -> 2098257535152
	2098257527376 [label=CudnnBatchNormBackward0]
	2098257535632 -> 2098257527376
	2098257535632 [label=ConvolutionBackward0]
	2098257542640 -> 2098257535632
	2098257542640 [label=ReluBackward0]
	2098257528960 -> 2098257542640
	2098257528960 [label=AddBackward0]
	2098257537936 -> 2098257528960
	2098257537936 [label=CudnnBatchNormBackward0]
	2098257534000 -> 2098257537936
	2098257534000 [label=ConvolutionBackward0]
	2098257542256 -> 2098257534000
	2098257542256 [label=ReluBackward0]
	2098257531744 -> 2098257542256
	2098257531744 [label=CudnnBatchNormBackward0]
	2098257528048 -> 2098257531744
	2098257528048 [label=ConvolutionBackward0]
	2098257529680 -> 2098257528048
	2098257529680 [label=ReluBackward0]
	2098257540384 -> 2098257529680
	2098257540384 [label=AddBackward0]
	2098257530544 -> 2098257540384
	2098257530544 [label=CudnnBatchNormBackward0]
	2098257542448 -> 2098257530544
	2098257542448 [label=ConvolutionBackward0]
	2098257539088 -> 2098257542448
	2098257539088 [label=ReluBackward0]
	2098257534768 -> 2098257539088
	2098257534768 [label=CudnnBatchNormBackward0]
	2098257533472 -> 2098257534768
	2098257533472 [label=ConvolutionBackward0]
	2098257536928 -> 2098257533472
	2098257536928 [label=ReluBackward0]
	2098257536544 -> 2098257536928
	2098257536544 [label=AddBackward0]
	2098257529824 -> 2098257536544
	2098257529824 [label=CudnnBatchNormBackward0]
	2098257539616 -> 2098257529824
	2098257539616 [label=ConvolutionBackward0]
	2098257527904 -> 2098257539616
	2098257527904 [label=ReluBackward0]
	2098257528720 -> 2098257527904
	2098257528720 [label=CudnnBatchNormBackward0]
	2098257540000 -> 2098257528720
	2098257540000 [label=ConvolutionBackward0]
	2098257533280 -> 2098257540000
	2098257533280 [label=ReluBackward0]
	2098257537168 -> 2098257533280
	2098257537168 [label=AddBackward0]
	2098257538368 -> 2098257537168
	2098257538368 [label=CudnnBatchNormBackward0]
	2098217481600 -> 2098257538368
	2098217481600 [label=ConvolutionBackward0]
	2098217483280 -> 2098217481600
	2098217483280 [label=ReluBackward0]
	2098217483568 -> 2098217483280
	2098217483568 [label=CudnnBatchNormBackward0]
	2098217484240 -> 2098217483568
	2098217484240 [label=ConvolutionBackward0]
	2098217479536 -> 2098217484240
	2098217479536 [label=MaxPool2DWithIndicesBackward0]
	2098217481648 -> 2098217479536
	2098217481648 [label=ReluBackward0]
	2098217479104 -> 2098217481648
	2098217479104 [label=CudnnBatchNormBackward0]
	2098217481984 -> 2098217479104
	2098217481984 [label=ConvolutionBackward0]
	2098217484000 -> 2098217481984
	2098160923760 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	2098160923760 -> 2098217484000
	2098217484000 [label=AccumulateGrad]
	2098217481696 -> 2098217479104
	2098218731088 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2098218731088 -> 2098217481696
	2098217481696 [label=AccumulateGrad]
	2098217481840 -> 2098217479104
	2098218730800 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2098218730800 -> 2098217481840
	2098217481840 [label=AccumulateGrad]
	2098217480976 -> 2098217484240
	2098218731280 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2098218731280 -> 2098217480976
	2098217480976 [label=AccumulateGrad]
	2098217483520 -> 2098217483568
	2098218731376 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2098218731376 -> 2098217483520
	2098217483520 [label=AccumulateGrad]
	2098217483904 -> 2098217483568
	2098218731472 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2098218731472 -> 2098217483904
	2098217483904 [label=AccumulateGrad]
	2098217482896 -> 2098217481600
	2098218730704 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2098218730704 -> 2098217482896
	2098217482896 [label=AccumulateGrad]
	2098217480208 -> 2098257538368
	2098218730608 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2098218730608 -> 2098217480208
	2098217480208 [label=AccumulateGrad]
	2098217481264 -> 2098257538368
	2098218729840 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2098218729840 -> 2098217481264
	2098217481264 [label=AccumulateGrad]
	2098217479536 -> 2098257537168
	2098257536064 -> 2098257540000
	2098218729936 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2098218729936 -> 2098257536064
	2098257536064 [label=AccumulateGrad]
	2098257535488 -> 2098257528720
	2098218730032 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2098218730032 -> 2098257535488
	2098257535488 [label=AccumulateGrad]
	2098257535680 -> 2098257528720
	2098218730128 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2098218730128 -> 2098257535680
	2098257535680 [label=AccumulateGrad]
	2098257539280 -> 2098257539616
	2098218730416 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2098218730416 -> 2098257539280
	2098257539280 [label=AccumulateGrad]
	2098257542544 -> 2098257529824
	2098222153648 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2098222153648 -> 2098257542544
	2098257542544 [label=AccumulateGrad]
	2098257531936 -> 2098257529824
	2098222153552 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2098222153552 -> 2098257531936
	2098257531936 [label=AccumulateGrad]
	2098257533280 -> 2098257536544
	2098257537744 -> 2098257533472
	2098222153456 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2098222153456 -> 2098257537744
	2098257537744 [label=AccumulateGrad]
	2098257542016 -> 2098257534768
	2098222153360 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2098222153360 -> 2098257542016
	2098257542016 [label=AccumulateGrad]
	2098257531888 -> 2098257534768
	2098160915696 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2098160915696 -> 2098257531888
	2098257531888 [label=AccumulateGrad]
	2098257533184 -> 2098257542448
	2098160916080 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2098160916080 -> 2098257533184
	2098257533184 [label=AccumulateGrad]
	2098257541488 -> 2098257530544
	2098160916176 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2098160916176 -> 2098257541488
	2098257541488 [label=AccumulateGrad]
	2098257538848 -> 2098257530544
	2098160916272 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2098160916272 -> 2098257538848
	2098257538848 [label=AccumulateGrad]
	2098257530496 -> 2098257540384
	2098257530496 [label=CudnnBatchNormBackward0]
	2098257537216 -> 2098257530496
	2098257537216 [label=ConvolutionBackward0]
	2098257536928 -> 2098257537216
	2098257543024 -> 2098257537216
	2098222150864 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2098222150864 -> 2098257543024
	2098257543024 [label=AccumulateGrad]
	2098257530448 -> 2098257530496
	2098222151056 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2098222151056 -> 2098257530448
	2098257530448 [label=AccumulateGrad]
	2098257541584 -> 2098257530496
	2098222152688 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2098222152688 -> 2098257541584
	2098257541584 [label=AccumulateGrad]
	2098257530784 -> 2098257528048
	2098160916656 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2098160916656 -> 2098257530784
	2098257530784 [label=AccumulateGrad]
	2098257527040 -> 2098257531744
	2098160916752 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2098160916752 -> 2098257527040
	2098257527040 [label=AccumulateGrad]
	2098257529872 -> 2098257531744
	2098160916848 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2098160916848 -> 2098257529872
	2098257529872 [label=AccumulateGrad]
	2098257535440 -> 2098257534000
	2098160917232 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2098160917232 -> 2098257535440
	2098257535440 [label=AccumulateGrad]
	2098257541248 -> 2098257537936
	2098160917328 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2098160917328 -> 2098257541248
	2098257541248 [label=AccumulateGrad]
	2098257533856 -> 2098257537936
	2098160917424 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2098160917424 -> 2098257533856
	2098257533856 [label=AccumulateGrad]
	2098257529680 -> 2098257528960
	2098257532752 -> 2098257535632
	2098160918384 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2098160918384 -> 2098257532752
	2098257532752 [label=AccumulateGrad]
	2098257538800 -> 2098257527376
	2098160918480 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2098160918480 -> 2098257538800
	2098257538800 [label=AccumulateGrad]
	2098257532320 -> 2098257527376
	2098160918576 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2098160918576 -> 2098257532320
	2098257532320 [label=AccumulateGrad]
	2098257527952 -> 2098257538176
	2098160918960 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2098160918960 -> 2098257527952
	2098257527952 [label=AccumulateGrad]
	2098257534144 -> 2098257536880
	2098160919056 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2098160919056 -> 2098257534144
	2098257534144 [label=AccumulateGrad]
	2098257541776 -> 2098257536880
	2098160919152 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2098160919152 -> 2098257541776
	2098257541776 [label=AccumulateGrad]
	2098257527424 -> 2098257540432
	2098257527424 [label=CudnnBatchNormBackward0]
	2098257542400 -> 2098257527424
	2098257542400 [label=ConvolutionBackward0]
	2098257542640 -> 2098257542400
	2098257541200 -> 2098257542400
	2098160917808 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2098160917808 -> 2098257541200
	2098257541200 [label=AccumulateGrad]
	2098257532464 -> 2098257527424
	2098160917904 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2098160917904 -> 2098257532464
	2098257532464 [label=AccumulateGrad]
	2098257528864 -> 2098257527424
	2098160918000 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2098160918000 -> 2098257528864
	2098257528864 [label=AccumulateGrad]
	2098257533664 -> 2098257540240
	2098160919536 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2098160919536 -> 2098257533664
	2098257533664 [label=AccumulateGrad]
	2098257538512 -> 2098257540864
	2098160919632 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2098160919632 -> 2098257538512
	2098257538512 [label=AccumulateGrad]
	2098257532992 -> 2098257540864
	2098160919728 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2098160919728 -> 2098257532992
	2098257532992 [label=AccumulateGrad]
	2098257531024 -> 2098257533568
	2098160920112 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2098160920112 -> 2098257531024
	2098257531024 [label=AccumulateGrad]
	2098257533952 -> 2098257526848
	2098160920208 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2098160920208 -> 2098257533952
	2098257533952 [label=AccumulateGrad]
	2098257534240 -> 2098257526848
	2098160920304 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2098160920304 -> 2098257534240
	2098257534240 [label=AccumulateGrad]
	2098257530304 -> 2098257539664
	2098257528480 -> 2098257527280
	2098160921264 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2098160921264 -> 2098257528480
	2098257528480 [label=AccumulateGrad]
	2098257533040 -> 2098257536784
	2098160921360 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2098160921360 -> 2098257533040
	2098257533040 [label=AccumulateGrad]
	2098257535248 -> 2098257536784
	2098160921456 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2098160921456 -> 2098257535248
	2098257535248 [label=AccumulateGrad]
	2098257530352 -> 2098257534912
	2098160921840 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2098160921840 -> 2098257530352
	2098257530352 [label=AccumulateGrad]
	2098257539328 -> 2098257532656
	2098160921936 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2098160921936 -> 2098257539328
	2098257539328 [label=AccumulateGrad]
	2098257538080 -> 2098257532656
	2098160922032 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2098160922032 -> 2098257538080
	2098257538080 [label=AccumulateGrad]
	2098257542304 -> 2098257528384
	2098257542304 [label=CudnnBatchNormBackward0]
	2098257537264 -> 2098257542304
	2098257537264 [label=ConvolutionBackward0]
	2098257536448 -> 2098257537264
	2098257541152 -> 2098257537264
	2098160920688 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2098160920688 -> 2098257541152
	2098257541152 [label=AccumulateGrad]
	2098257527616 -> 2098257542304
	2098160920784 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2098160920784 -> 2098257527616
	2098257527616 [label=AccumulateGrad]
	2098257540576 -> 2098257542304
	2098160920880 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2098160920880 -> 2098257540576
	2098257540576 [label=AccumulateGrad]
	2098257532512 -> 2098257531504
	2098160922416 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2098160922416 -> 2098257532512
	2098257532512 [label=AccumulateGrad]
	2098257539472 -> 2098257535056
	2098160922512 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2098160922512 -> 2098257539472
	2098257539472 [label=AccumulateGrad]
	2098257537120 -> 2098257535056
	2098160922608 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2098160922608 -> 2098257537120
	2098257537120 [label=AccumulateGrad]
	2098257538896 -> 2098257539232
	2098160922992 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2098160922992 -> 2098257538896
	2098257538896 [label=AccumulateGrad]
	2098257536256 -> 2098257536352
	2098160923088 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2098160923088 -> 2098257536256
	2098257536256 [label=AccumulateGrad]
	2098257528096 -> 2098257536352
	2098160923184 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2098160923184 -> 2098257528096
	2098257528096 [label=AccumulateGrad]
	2098257541728 -> 2098257528192
	2098257534480 -> 2098257541920
	2098257534480 [label=TBackward0]
	2098257541104 -> 2098257534480
	2098160923856 [label="fc.weight
 (19, 512)" fillcolor=lightblue]
	2098160923856 -> 2098257541104
	2098257541104 [label=AccumulateGrad]
	2098257541920 -> 2098161328560
}
