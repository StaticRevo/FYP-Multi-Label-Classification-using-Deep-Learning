digraph {
	graph [size="151.95,151.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2298823063216 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2298739259040 [label=AddmmBackward0]
	2298739257936 -> 2298739259040
	2298815936848 [label="fc.bias
 (19)" fillcolor=lightblue]
	2298815936848 -> 2298739257936
	2298739257936 [label=AccumulateGrad]
	2298739258080 -> 2298739259040
	2298739258080 [label=ViewBackward0]
	2298739257600 -> 2298739258080
	2298739257600 [label=MeanBackward1]
	2298739256496 -> 2298739257600
	2298739256496 [label=ReluBackward0]
	2298739256016 -> 2298739256496
	2298739256016 [label=AddBackward0]
	2298739255536 -> 2298739256016
	2298739255536 [label=CudnnBatchNormBackward0]
	2298739255200 -> 2298739255536
	2298739255200 [label=ConvolutionBackward0]
	2298739254240 -> 2298739255200
	2298739254240 [label=ReluBackward0]
	2298739253136 -> 2298739254240
	2298739253136 [label=CudnnBatchNormBackward0]
	2298739250352 -> 2298739253136
	2298739250352 [label=ConvolutionBackward0]
	2298739245216 -> 2298739250352
	2298739245216 [label=ReluBackward0]
	2298739261344 -> 2298739245216
	2298739261344 [label=CudnnBatchNormBackward0]
	2298739261008 -> 2298739261344
	2298739261008 [label=ConvolutionBackward0]
	2298739256160 -> 2298739261008
	2298739256160 [label=ReluBackward0]
	2298739260864 -> 2298739256160
	2298739260864 [label=AddBackward0]
	2298739260528 -> 2298739260864
	2298739260528 [label=CudnnBatchNormBackward0]
	2298739260576 -> 2298739260528
	2298739260576 [label=ConvolutionBackward0]
	2298739260240 -> 2298739260576
	2298739260240 [label=ReluBackward0]
	2298739260288 -> 2298739260240
	2298739260288 [label=CudnnBatchNormBackward0]
	2298739260192 -> 2298739260288
	2298739260192 [label=ConvolutionBackward0]
	2298739259568 -> 2298739260192
	2298739259568 [label=ReluBackward0]
	2298739259616 -> 2298739259568
	2298739259616 [label=CudnnBatchNormBackward0]
	2298739259472 -> 2298739259616
	2298739259472 [label=ConvolutionBackward0]
	2298739260720 -> 2298739259472
	2298739260720 [label=ReluBackward0]
	2298739259136 -> 2298739260720
	2298739259136 [label=AddBackward0]
	2298739258992 -> 2298739259136
	2298739258992 [label=CudnnBatchNormBackward0]
	2298739258608 -> 2298739258992
	2298739258608 [label=ConvolutionBackward0]
	2298739258752 -> 2298739258608
	2298739258752 [label=ReluBackward0]
	2298739258320 -> 2298739258752
	2298739258320 [label=CudnnBatchNormBackward0]
	2298739258224 -> 2298739258320
	2298739258224 [label=ConvolutionBackward0]
	2298739258032 -> 2298739258224
	2298739258032 [label=ReluBackward0]
	2298739257648 -> 2298739258032
	2298739257648 [label=CudnnBatchNormBackward0]
	2298739257888 -> 2298739257648
	2298739257888 [label=ConvolutionBackward0]
	2298739257504 -> 2298739257888
	2298739257504 [label=ReluBackward0]
	2298739257264 -> 2298739257504
	2298739257264 [label=AddBackward0]
	2298739257216 -> 2298739257264
	2298739257216 [label=CudnnBatchNormBackward0]
	2298739257024 -> 2298739257216
	2298739257024 [label=ConvolutionBackward0]
	2298739256928 -> 2298739257024
	2298739256928 [label=ReluBackward0]
	2298739256592 -> 2298739256928
	2298739256592 [label=CudnnBatchNormBackward0]
	2298739256400 -> 2298739256592
	2298739256400 [label=ConvolutionBackward0]
	2298739256256 -> 2298739256400
	2298739256256 [label=ReluBackward0]
	2298739256064 -> 2298739256256
	2298739256064 [label=CudnnBatchNormBackward0]
	2298739255728 -> 2298739256064
	2298739255728 [label=ConvolutionBackward0]
	2298739257408 -> 2298739255728
	2298739257408 [label=ReluBackward0]
	2298739255584 -> 2298739257408
	2298739255584 [label=AddBackward0]
	2298739255248 -> 2298739255584
	2298739255248 [label=CudnnBatchNormBackward0]
	2298739255296 -> 2298739255248
	2298739255296 [label=ConvolutionBackward0]
	2298739254960 -> 2298739255296
	2298739254960 [label=ReluBackward0]
	2298739255008 -> 2298739254960
	2298739255008 [label=CudnnBatchNormBackward0]
	2298739254912 -> 2298739255008
	2298739254912 [label=ConvolutionBackward0]
	2298739254288 -> 2298739254912
	2298739254288 [label=ReluBackward0]
	2298739254336 -> 2298739254288
	2298739254336 [label=CudnnBatchNormBackward0]
	2298739254192 -> 2298739254336
	2298739254192 [label=ConvolutionBackward0]
	2298739255440 -> 2298739254192
	2298739255440 [label=ReluBackward0]
	2298739253856 -> 2298739255440
	2298739253856 [label=AddBackward0]
	2298739253712 -> 2298739253856
	2298739253712 [label=CudnnBatchNormBackward0]
	2298739253328 -> 2298739253712
	2298739253328 [label=ConvolutionBackward0]
	2298739253472 -> 2298739253328
	2298739253472 [label=ReluBackward0]
	2298739253040 -> 2298739253472
	2298739253040 [label=CudnnBatchNormBackward0]
	2298739252944 -> 2298739253040
	2298739252944 [label=ConvolutionBackward0]
	2298739247472 -> 2298739252944
	2298739247472 [label=ReluBackward0]
	2298739252320 -> 2298739247472
	2298739252320 [label=CudnnBatchNormBackward0]
	2298739246512 -> 2298739252320
	2298739246512 [label=ConvolutionBackward0]
	2298739253952 -> 2298739246512
	2298739253952 [label=ReluBackward0]
	2298739248960 -> 2298739253952
	2298739248960 [label=AddBackward0]
	2298739247568 -> 2298739248960
	2298739247568 [label=CudnnBatchNormBackward0]
	2298739248192 -> 2298739247568
	2298739248192 [label=ConvolutionBackward0]
	2298739249296 -> 2298739248192
	2298739249296 [label=ReluBackward0]
	2298739251888 -> 2298739249296
	2298739251888 [label=CudnnBatchNormBackward0]
	2298739246848 -> 2298739251888
	2298739246848 [label=ConvolutionBackward0]
	2298739250832 -> 2298739246848
	2298739250832 [label=ReluBackward0]
	2298739252128 -> 2298739250832
	2298739252128 [label=CudnnBatchNormBackward0]
	2298739250928 -> 2298739252128
	2298739250928 [label=ConvolutionBackward0]
	2298739251840 -> 2298739250928
	2298739251840 [label=ReluBackward0]
	2298739251024 -> 2298739251840
	2298739251024 [label=AddBackward0]
	2298739251456 -> 2298739251024
	2298739251456 [label=CudnnBatchNormBackward0]
	2298739250064 -> 2298739251456
	2298739250064 [label=ConvolutionBackward0]
	2298739250160 -> 2298739250064
	2298739250160 [label=ReluBackward0]
	2298739252656 -> 2298739250160
	2298739252656 [label=CudnnBatchNormBackward0]
	2298739252608 -> 2298739252656
	2298739252608 [label=ConvolutionBackward0]
	2298739247280 -> 2298739252608
	2298739247280 [label=ReluBackward0]
	2298739246176 -> 2298739247280
	2298739246176 [label=CudnnBatchNormBackward0]
	2298739245744 -> 2298739246176
	2298739245744 [label=ConvolutionBackward0]
	2298739246416 -> 2298739245744
	2298739246416 [label=ReluBackward0]
	2298739251312 -> 2298739246416
	2298739251312 [label=AddBackward0]
	2298739249872 -> 2298739251312
	2298739249872 [label=CudnnBatchNormBackward0]
	2298739252848 -> 2298739249872
	2298739252848 [label=ConvolutionBackward0]
	2298739245600 -> 2298739252848
	2298739245600 [label=ReluBackward0]
	2298739252032 -> 2298739245600
	2298739252032 [label=CudnnBatchNormBackward0]
	2298739248480 -> 2298739252032
	2298739248480 [label=ConvolutionBackward0]
	2298739248096 -> 2298739248480
	2298739248096 [label=ReluBackward0]
	2298739252704 -> 2298739248096
	2298739252704 [label=CudnnBatchNormBackward0]
	2298739249968 -> 2298739252704
	2298739249968 [label=ConvolutionBackward0]
	2298739246368 -> 2298739249968
	2298739246368 [label=ReluBackward0]
	2298739374736 -> 2298739246368
	2298739374736 [label=AddBackward0]
	2298739371136 -> 2298739374736
	2298739371136 [label=CudnnBatchNormBackward0]
	2298739373392 -> 2298739371136
	2298739373392 [label=ConvolutionBackward0]
	2298739362160 -> 2298739373392
	2298739362160 [label=ReluBackward0]
	2298739360672 -> 2298739362160
	2298739360672 [label=CudnnBatchNormBackward0]
	2298739373152 -> 2298739360672
	2298739373152 [label=ConvolutionBackward0]
	2298739365952 -> 2298739373152
	2298739365952 [label=ReluBackward0]
	2298479769056 -> 2298739365952
	2298479769056 [label=CudnnBatchNormBackward0]
	2298739375504 -> 2298479769056
	2298739375504 [label=ConvolutionBackward0]
	2298739375600 -> 2298739375504
	2298739375600 [label=ReluBackward0]
	2298823530656 -> 2298739375600
	2298823530656 [label=AddBackward0]
	2298823530176 -> 2298823530656
	2298823530176 [label=CudnnBatchNormBackward0]
	2298823529072 -> 2298823530176
	2298823529072 [label=ConvolutionBackward0]
	2298823528112 -> 2298823529072
	2298823528112 [label=ReluBackward0]
	2298823527776 -> 2298823528112
	2298823527776 [label=CudnnBatchNormBackward0]
	2298823527296 -> 2298823527776
	2298823527296 [label=ConvolutionBackward0]
	2298823526336 -> 2298823527296
	2298823526336 [label=ReluBackward0]
	2298823525232 -> 2298823526336
	2298823525232 [label=CudnnBatchNormBackward0]
	2298823524752 -> 2298823525232
	2298823524752 [label=ConvolutionBackward0]
	2298823530032 -> 2298823524752
	2298823530032 [label=ReluBackward0]
	2298823531664 -> 2298823530032
	2298823531664 [label=AddBackward0]
	2298823531904 -> 2298823531664
	2298823531904 [label=CudnnBatchNormBackward0]
	2298823531568 -> 2298823531904
	2298823531568 [label=ConvolutionBackward0]
	2298823531280 -> 2298823531568
	2298823531280 [label=ReluBackward0]
	2298823531328 -> 2298823531280
	2298823531328 [label=CudnnBatchNormBackward0]
	2298823531040 -> 2298823531328
	2298823531040 [label=ConvolutionBackward0]
	2298823530944 -> 2298823531040
	2298823530944 [label=ReluBackward0]
	2298823530608 -> 2298823530944
	2298823530608 [label=CudnnBatchNormBackward0]
	2298823530416 -> 2298823530608
	2298823530416 [label=ConvolutionBackward0]
	2298823531760 -> 2298823530416
	2298823531760 [label=ReluBackward0]
	2298823530128 -> 2298823531760
	2298823530128 [label=AddBackward0]
	2298823529936 -> 2298823530128
	2298823529936 [label=CudnnBatchNormBackward0]
	2298823529984 -> 2298823529936
	2298823529984 [label=ConvolutionBackward0]
	2298823529600 -> 2298823529984
	2298823529600 [label=ReluBackward0]
	2298823529360 -> 2298823529600
	2298823529360 [label=CudnnBatchNormBackward0]
	2298823529312 -> 2298823529360
	2298823529312 [label=ConvolutionBackward0]
	2298823528976 -> 2298823529312
	2298823528976 [label=ReluBackward0]
	2298823529024 -> 2298823528976
	2298823529024 [label=CudnnBatchNormBackward0]
	2298823528928 -> 2298823529024
	2298823528928 [label=ConvolutionBackward0]
	2298823528304 -> 2298823528928
	2298823528304 [label=ReluBackward0]
	2298823528352 -> 2298823528304
	2298823528352 [label=AddBackward0]
	2298823528208 -> 2298823528352
	2298823528208 [label=CudnnBatchNormBackward0]
	2298823527824 -> 2298823528208
	2298823527824 [label=ConvolutionBackward0]
	2298823527968 -> 2298823527824
	2298823527968 [label=ReluBackward0]
	2298823527536 -> 2298823527968
	2298823527536 [label=CudnnBatchNormBackward0]
	2298823527440 -> 2298823527536
	2298823527440 [label=ConvolutionBackward0]
	2298823527248 -> 2298823527440
	2298823527248 [label=ReluBackward0]
	2298823526864 -> 2298823527248
	2298823526864 [label=CudnnBatchNormBackward0]
	2298823527104 -> 2298823526864
	2298823527104 [label=ConvolutionBackward0]
	2298823528448 -> 2298823527104
	2298823528448 [label=ReluBackward0]
	2298823526384 -> 2298823528448
	2298823526384 [label=AddBackward0]
	2298823526624 -> 2298823526384
	2298823526624 [label=CudnnBatchNormBackward0]
	2298823526288 -> 2298823526624
	2298823526288 [label=ConvolutionBackward0]
	2298823526000 -> 2298823526288
	2298823526000 [label=ReluBackward0]
	2298823526048 -> 2298823526000
	2298823526048 [label=CudnnBatchNormBackward0]
	2298823525760 -> 2298823526048
	2298823525760 [label=ConvolutionBackward0]
	2298823525664 -> 2298823525760
	2298823525664 [label=ReluBackward0]
	2298823525328 -> 2298823525664
	2298823525328 [label=CudnnBatchNormBackward0]
	2298823525136 -> 2298823525328
	2298823525136 [label=ConvolutionBackward0]
	2298823526480 -> 2298823525136
	2298823526480 [label=ReluBackward0]
	2298823524848 -> 2298823526480
	2298823524848 [label=AddBackward0]
	2298823524656 -> 2298823524848
	2298823524656 [label=CudnnBatchNormBackward0]
	2298823524704 -> 2298823524656
	2298823524704 [label=ConvolutionBackward0]
	2298823532528 -> 2298823524704
	2298823532528 [label=ReluBackward0]
	2298823532864 -> 2298823532528
	2298823532864 [label=CudnnBatchNormBackward0]
	2298823532960 -> 2298823532864
	2298823532960 [label=ConvolutionBackward0]
	2298823533152 -> 2298823532960
	2298823533152 [label=ReluBackward0]
	2298823533296 -> 2298823533152
	2298823533296 [label=CudnnBatchNormBackward0]
	2298823533392 -> 2298823533296
	2298823533392 [label=ConvolutionBackward0]
	2298823533584 -> 2298823533392
	2298823533584 [label=MaxPool2DWithIndicesBackward0]
	2298823533728 -> 2298823533584
	2298823533728 [label=ReluBackward0]
	2298823533824 -> 2298823533728
	2298823533824 [label=CudnnBatchNormBackward0]
	2298823533920 -> 2298823533824
	2298823533920 [label=ConvolutionBackward0]
	2298823534112 -> 2298823533920
	2298815936656 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	2298815936656 -> 2298823534112
	2298823534112 [label=AccumulateGrad]
	2298823533872 -> 2298823533824
	2298663472016 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2298663472016 -> 2298823533872
	2298823533872 [label=AccumulateGrad]
	2298823533632 -> 2298823533824
	2298663471728 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2298663471728 -> 2298823533632
	2298823533632 [label=AccumulateGrad]
	2298823533536 -> 2298823533392
	2298663471632 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2298663471632 -> 2298823533536
	2298823533536 [label=AccumulateGrad]
	2298823533344 -> 2298823533296
	2298663471536 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2298663471536 -> 2298823533344
	2298823533344 [label=AccumulateGrad]
	2298823533200 -> 2298823533296
	2298663470768 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2298663470768 -> 2298823533200
	2298823533200 [label=AccumulateGrad]
	2298823533104 -> 2298823532960
	2298663470864 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2298663470864 -> 2298823533104
	2298823533104 [label=AccumulateGrad]
	2298823532912 -> 2298823532864
	2298663470960 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2298663470960 -> 2298823532912
	2298823532912 [label=AccumulateGrad]
	2298823532768 -> 2298823532864
	2298663471056 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2298663471056 -> 2298823532768
	2298823532768 [label=AccumulateGrad]
	2298823532672 -> 2298823524704
	2298663471344 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2298663471344 -> 2298823532672
	2298823532672 [label=AccumulateGrad]
	2298823524560 -> 2298823524656
	2298663470384 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	2298663470384 -> 2298823524560
	2298823524560 [label=AccumulateGrad]
	2298823524464 -> 2298823524656
	2298663470288 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	2298663470288 -> 2298823524464
	2298823524464 [label=AccumulateGrad]
	2298823524800 -> 2298823524848
	2298823524800 [label=CudnnBatchNormBackward0]
	2298823533056 -> 2298823524800
	2298823533056 [label=ConvolutionBackward0]
	2298823533584 -> 2298823533056
	2298823533440 -> 2298823533056
	2298663472208 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2298663472208 -> 2298823533440
	2298823533440 [label=AccumulateGrad]
	2298823524608 -> 2298823524800
	2298663472304 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2298663472304 -> 2298823524608
	2298823524608 [label=AccumulateGrad]
	2298823524512 -> 2298823524800
	2298663472400 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2298663472400 -> 2298823524512
	2298823524512 [label=AccumulateGrad]
	2298823524992 -> 2298823525136
	2298663470096 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2298663470096 -> 2298823524992
	2298823524992 [label=AccumulateGrad]
	2298823525280 -> 2298823525328
	2298663469712 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2298663469712 -> 2298823525280
	2298823525280 [label=AccumulateGrad]
	2298823525472 -> 2298823525328
	2298663469424 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2298663469424 -> 2298823525472
	2298823525472 [label=AccumulateGrad]
	2298823525520 -> 2298823525760
	2298663470192 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2298663470192 -> 2298823525520
	2298823525520 [label=AccumulateGrad]
	2298823525808 -> 2298823526048
	2298663470000 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2298663470000 -> 2298823525808
	2298823525808 [label=AccumulateGrad]
	2298823526144 -> 2298823526048
	2298816253584 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2298816253584 -> 2298823526144
	2298823526144 [label=AccumulateGrad]
	2298823525904 -> 2298823526288
	2298816253968 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2298816253968 -> 2298823525904
	2298823525904 [label=AccumulateGrad]
	2298823526528 -> 2298823526624
	2298816254064 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	2298816254064 -> 2298823526528
	2298823526528 [label=AccumulateGrad]
	2298823526432 -> 2298823526624
	2298816254160 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	2298816254160 -> 2298823526432
	2298823526432 [label=AccumulateGrad]
	2298823526480 -> 2298823526384
	2298823526720 -> 2298823527104
	2298816254544 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2298816254544 -> 2298823526720
	2298823526720 [label=AccumulateGrad]
	2298823526960 -> 2298823526864
	2298816254640 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	2298816254640 -> 2298823526960
	2298823526960 [label=AccumulateGrad]
	2298823527200 -> 2298823526864
	2298816254736 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	2298816254736 -> 2298823527200
	2298823527200 [label=AccumulateGrad]
	2298823527488 -> 2298823527440
	2298816255120 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2298816255120 -> 2298823527488
	2298823527488 [label=AccumulateGrad]
	2298823527344 -> 2298823527536
	2298816255216 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	2298816255216 -> 2298823527344
	2298823527344 [label=AccumulateGrad]
	2298823527728 -> 2298823527536
	2298816255312 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	2298816255312 -> 2298823527728
	2298823527728 [label=AccumulateGrad]
	2298823527872 -> 2298823527824
	2298816255696 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2298816255696 -> 2298823527872
	2298823527872 [label=AccumulateGrad]
	2298823528016 -> 2298823528208
	2298816255792 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	2298816255792 -> 2298823528016
	2298823528016 [label=AccumulateGrad]
	2298823528160 -> 2298823528208
	2298816255888 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	2298816255888 -> 2298823528160
	2298823528160 [label=AccumulateGrad]
	2298823528448 -> 2298823528352
	2298823528496 -> 2298823528928
	2298816256848 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2298816256848 -> 2298823528496
	2298823528496 [label=AccumulateGrad]
	2298823528832 -> 2298823529024
	2298816256944 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2298816256944 -> 2298823528832
	2298823528832 [label=AccumulateGrad]
	2298823528784 -> 2298823529024
	2298816257040 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2298816257040 -> 2298823528784
	2298823528784 [label=AccumulateGrad]
	2298823529120 -> 2298823529312
	2298816257424 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2298816257424 -> 2298823529120
	2298823529120 [label=AccumulateGrad]
	2298823529504 -> 2298823529360
	2298816257520 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2298816257520 -> 2298823529504
	2298823529504 [label=AccumulateGrad]
	2298823529456 -> 2298823529360
	2298816257616 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2298816257616 -> 2298823529456
	2298823529456 [label=AccumulateGrad]
	2298823529648 -> 2298823529984
	2298816258000 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2298816258000 -> 2298823529648
	2298823529648 [label=AccumulateGrad]
	2298823529840 -> 2298823529936
	2298816258096 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	2298816258096 -> 2298823529840
	2298823529840 [label=AccumulateGrad]
	2298823529744 -> 2298823529936
	2298816258192 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	2298816258192 -> 2298823529744
	2298823529744 [label=AccumulateGrad]
	2298823530080 -> 2298823530128
	2298823530080 [label=CudnnBatchNormBackward0]
	2298823529168 -> 2298823530080
	2298823529168 [label=ConvolutionBackward0]
	2298823528304 -> 2298823529168
	2298823528688 -> 2298823529168
	2298816256272 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2298816256272 -> 2298823528688
	2298823528688 [label=AccumulateGrad]
	2298823529888 -> 2298823530080
	2298816256368 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2298816256368 -> 2298823529888
	2298823529888 [label=AccumulateGrad]
	2298823529792 -> 2298823530080
	2298816256464 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2298816256464 -> 2298823529792
	2298823529792 [label=AccumulateGrad]
	2298823530272 -> 2298823530416
	2298816258576 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2298816258576 -> 2298823530272
	2298823530272 [label=AccumulateGrad]
	2298823530560 -> 2298823530608
	2298816258672 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2298816258672 -> 2298823530560
	2298823530560 [label=AccumulateGrad]
	2298823530752 -> 2298823530608
	2298816258768 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2298816258768 -> 2298823530752
	2298823530752 [label=AccumulateGrad]
	2298823530800 -> 2298823531040
	2298816259152 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2298816259152 -> 2298823530800
	2298823530800 [label=AccumulateGrad]
	2298823531088 -> 2298823531328
	2298816259248 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2298816259248 -> 2298823531088
	2298823531088 [label=AccumulateGrad]
	2298823531424 -> 2298823531328
	2298816259344 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2298816259344 -> 2298823531424
	2298823531424 [label=AccumulateGrad]
	2298823531184 -> 2298823531568
	2298816259728 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2298816259728 -> 2298823531184
	2298823531184 [label=AccumulateGrad]
	2298823531808 -> 2298823531904
	2298816259824 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	2298816259824 -> 2298823531808
	2298823531808 [label=AccumulateGrad]
	2298823531712 -> 2298823531904
	2298816259920 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	2298816259920 -> 2298823531712
	2298823531712 [label=AccumulateGrad]
	2298823531760 -> 2298823531664
	2298823532000 -> 2298823524752
	2298816260304 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2298816260304 -> 2298823532000
	2298823532000 [label=AccumulateGrad]
	2298823525376 -> 2298823525232
	2298816260400 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	2298816260400 -> 2298823525376
	2298823525376 [label=AccumulateGrad]
	2298823525712 -> 2298823525232
	2298816260496 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	2298816260496 -> 2298823525712
	2298823525712 [label=AccumulateGrad]
	2298823526192 -> 2298823527296
	2298816260880 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2298816260880 -> 2298823526192
	2298823526192 [label=AccumulateGrad]
	2298823527152 -> 2298823527776
	2298816260976 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	2298816260976 -> 2298823527152
	2298823527152 [label=AccumulateGrad]
	2298823528256 -> 2298823527776
	2298816261072 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	2298816261072 -> 2298823528256
	2298823528256 [label=AccumulateGrad]
	2298823528736 -> 2298823529072
	2298816261456 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2298816261456 -> 2298823528736
	2298823528736 [label=AccumulateGrad]
	2298823529696 -> 2298823530176
	2298816261552 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	2298816261552 -> 2298823529696
	2298823529696 [label=AccumulateGrad]
	2298823529552 -> 2298823530176
	2298816261648 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	2298816261648 -> 2298823529552
	2298823529552 [label=AccumulateGrad]
	2298823530032 -> 2298823530656
	2298823531136 -> 2298739375504
	2298816262032 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2298816262032 -> 2298823531136
	2298823531136 [label=AccumulateGrad]
	2298823531952 -> 2298479769056
	2298816262128 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	2298816262128 -> 2298823531952
	2298823531952 [label=AccumulateGrad]
	2298823532096 -> 2298479769056
	2298816262224 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	2298816262224 -> 2298823532096
	2298823532096 [label=AccumulateGrad]
	2298739374976 -> 2298739373152
	2298816262608 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2298816262608 -> 2298739374976
	2298739374976 [label=AccumulateGrad]
	2298739375888 -> 2298739360672
	2298816262704 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	2298816262704 -> 2298739375888
	2298739375888 [label=AccumulateGrad]
	2298739374448 -> 2298739360672
	2298816262800 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	2298816262800 -> 2298739374448
	2298739374448 [label=AccumulateGrad]
	2298739375696 -> 2298739373392
	2298816263184 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2298816263184 -> 2298739375696
	2298739375696 [label=AccumulateGrad]
	2298739373824 -> 2298739371136
	2298816263280 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	2298816263280 -> 2298739373824
	2298739373824 [label=AccumulateGrad]
	2298739362064 -> 2298739371136
	2298816263376 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	2298816263376 -> 2298739362064
	2298739362064 [label=AccumulateGrad]
	2298739375600 -> 2298739374736
	2298739245888 -> 2298739249968
	2298816264336 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2298816264336 -> 2298739245888
	2298739245888 [label=AccumulateGrad]
	2298739248672 -> 2298739252704
	2298816264432 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2298816264432 -> 2298739248672
	2298739248672 [label=AccumulateGrad]
	2298739246560 -> 2298739252704
	2298816264528 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2298816264528 -> 2298739246560
	2298739246560 [label=AccumulateGrad]
	2298739246992 -> 2298739248480
	2298816264912 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2298816264912 -> 2298739246992
	2298739246992 [label=AccumulateGrad]
	2298739249008 -> 2298739252032
	2298816265008 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2298816265008 -> 2298739249008
	2298739249008 [label=AccumulateGrad]
	2298739247520 -> 2298739252032
	2298816265104 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2298816265104 -> 2298739247520
	2298739247520 [label=AccumulateGrad]
	2298739247856 -> 2298739252848
	2298816265488 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2298816265488 -> 2298739247856
	2298739247856 [label=AccumulateGrad]
	2298739245936 -> 2298739249872
	2298816265584 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	2298816265584 -> 2298739245936
	2298739245936 [label=AccumulateGrad]
	2298739246800 -> 2298739249872
	2298816265680 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	2298816265680 -> 2298739246800
	2298739246800 [label=AccumulateGrad]
	2298739252080 -> 2298739251312
	2298739252080 [label=CudnnBatchNormBackward0]
	2298739247808 -> 2298739252080
	2298739247808 [label=ConvolutionBackward0]
	2298739246368 -> 2298739247808
	2298739252560 -> 2298739247808
	2298816263760 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2298816263760 -> 2298739252560
	2298739252560 [label=AccumulateGrad]
	2298739249776 -> 2298739252080
	2298816263856 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	2298816263856 -> 2298739249776
	2298739249776 [label=AccumulateGrad]
	2298739250016 -> 2298739252080
	2298816263952 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	2298816263952 -> 2298739250016
	2298739250016 [label=AccumulateGrad]
	2298739249392 -> 2298739245744
	2298816266064 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2298816266064 -> 2298739249392
	2298739249392 [label=AccumulateGrad]
	2298739251696 -> 2298739246176
	2298816266160 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2298816266160 -> 2298739251696
	2298739251696 [label=AccumulateGrad]
	2298739251936 -> 2298739246176
	2298815922256 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2298815922256 -> 2298739251936
	2298739251936 [label=AccumulateGrad]
	2298739246896 -> 2298739252608
	2298815922640 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2298815922640 -> 2298739246896
	2298739246896 [label=AccumulateGrad]
	2298739248000 -> 2298739252656
	2298815922736 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2298815922736 -> 2298739248000
	2298739248000 [label=AccumulateGrad]
	2298739245168 -> 2298739252656
	2298815922832 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2298815922832 -> 2298739245168
	2298739245168 [label=AccumulateGrad]
	2298739249536 -> 2298739250064
	2298815923216 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2298815923216 -> 2298739249536
	2298739249536 [label=AccumulateGrad]
	2298739251744 -> 2298739251456
	2298815923312 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	2298815923312 -> 2298739251744
	2298739251744 [label=AccumulateGrad]
	2298739252464 -> 2298739251456
	2298815923408 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	2298815923408 -> 2298739252464
	2298739252464 [label=AccumulateGrad]
	2298739246416 -> 2298739251024
	2298739250592 -> 2298739250928
	2298815923792 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2298815923792 -> 2298739250592
	2298739250592 [label=AccumulateGrad]
	2298739246704 -> 2298739252128
	2298815923888 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	2298815923888 -> 2298739246704
	2298739246704 [label=AccumulateGrad]
	2298739251792 -> 2298739252128
	2298815923984 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	2298815923984 -> 2298739251792
	2298739251792 [label=AccumulateGrad]
	2298739246032 -> 2298739246848
	2298815924368 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2298815924368 -> 2298739246032
	2298739246032 [label=AccumulateGrad]
	2298739248768 -> 2298739251888
	2298815924464 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	2298815924464 -> 2298739248768
	2298739248768 [label=AccumulateGrad]
	2298739248864 -> 2298739251888
	2298815924560 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	2298815924560 -> 2298739248864
	2298739248864 [label=AccumulateGrad]
	2298739250496 -> 2298739248192
	2298815924944 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2298815924944 -> 2298739250496
	2298739250496 [label=AccumulateGrad]
	2298739249728 -> 2298739247568
	2298815925040 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	2298815925040 -> 2298739249728
	2298739249728 [label=AccumulateGrad]
	2298739248384 -> 2298739247568
	2298815925136 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	2298815925136 -> 2298739248384
	2298739248384 [label=AccumulateGrad]
	2298739251840 -> 2298739248960
	2298739247424 -> 2298739246512
	2298815925520 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2298815925520 -> 2298739247424
	2298739247424 [label=AccumulateGrad]
	2298739246128 -> 2298739252320
	2298815925616 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	2298815925616 -> 2298739246128
	2298739246128 [label=AccumulateGrad]
	2298739252176 -> 2298739252320
	2298815925712 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	2298815925712 -> 2298739252176
	2298739252176 [label=AccumulateGrad]
	2298739252992 -> 2298739252944
	2298815926096 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2298815926096 -> 2298739252992
	2298739252992 [label=AccumulateGrad]
	2298739251408 -> 2298739253040
	2298815926192 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	2298815926192 -> 2298739251408
	2298739251408 [label=AccumulateGrad]
	2298739253232 -> 2298739253040
	2298815926288 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	2298815926288 -> 2298739253232
	2298739253232 [label=AccumulateGrad]
	2298739253376 -> 2298739253328
	2298815926672 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2298815926672 -> 2298739253376
	2298739253376 [label=AccumulateGrad]
	2298739253520 -> 2298739253712
	2298815926768 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	2298815926768 -> 2298739253520
	2298739253520 [label=AccumulateGrad]
	2298739253664 -> 2298739253712
	2298815926864 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	2298815926864 -> 2298739253664
	2298739253664 [label=AccumulateGrad]
	2298739253952 -> 2298739253856
	2298739253904 -> 2298739254192
	2298815927248 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2298815927248 -> 2298739253904
	2298739253904 [label=AccumulateGrad]
	2298739254432 -> 2298739254336
	2298815927344 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	2298815927344 -> 2298739254432
	2298739254432 [label=AccumulateGrad]
	2298739254384 -> 2298739254336
	2298815927440 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	2298815927440 -> 2298739254384
	2298739254384 [label=AccumulateGrad]
	2298739254480 -> 2298739254912
	2298815927824 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2298815927824 -> 2298739254480
	2298739254480 [label=AccumulateGrad]
	2298739254816 -> 2298739255008
	2298815927920 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	2298815927920 -> 2298739254816
	2298739254816 [label=AccumulateGrad]
	2298739254768 -> 2298739255008
	2298815928016 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	2298815928016 -> 2298739254768
	2298739254768 [label=AccumulateGrad]
	2298739255104 -> 2298739255296
	2298815928400 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2298815928400 -> 2298739255104
	2298739255104 [label=AccumulateGrad]
	2298739255488 -> 2298739255248
	2298815928496 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	2298815928496 -> 2298739255488
	2298739255488 [label=AccumulateGrad]
	2298739255344 -> 2298739255248
	2298815928592 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	2298815928592 -> 2298739255344
	2298739255344 [label=AccumulateGrad]
	2298739255440 -> 2298739255584
	2298739255872 -> 2298739255728
	2298815928976 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2298815928976 -> 2298739255872
	2298739255872 [label=AccumulateGrad]
	2298739255920 -> 2298739256064
	2298815929072 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	2298815929072 -> 2298739255920
	2298739255920 [label=AccumulateGrad]
	2298739256352 -> 2298739256064
	2298815929168 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	2298815929168 -> 2298739256352
	2298739256352 [label=AccumulateGrad]
	2298739256448 -> 2298739256400
	2298815929552 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2298815929552 -> 2298739256448
	2298739256448 [label=AccumulateGrad]
	2298739256544 -> 2298739256592
	2298815929648 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	2298815929648 -> 2298739256544
	2298739256544 [label=AccumulateGrad]
	2298739256736 -> 2298739256592
	2298815929744 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	2298815929744 -> 2298739256736
	2298739256736 [label=AccumulateGrad]
	2298739256784 -> 2298739257024
	2298815930128 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2298815930128 -> 2298739256784
	2298739256784 [label=AccumulateGrad]
	2298739257072 -> 2298739257216
	2298815930224 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	2298815930224 -> 2298739257072
	2298739257072 [label=AccumulateGrad]
	2298739257312 -> 2298739257216
	2298815930320 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	2298815930320 -> 2298739257312
	2298739257312 [label=AccumulateGrad]
	2298739257408 -> 2298739257264
	2298739257552 -> 2298739257888
	2298815931280 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2298815931280 -> 2298739257552
	2298739257552 [label=AccumulateGrad]
	2298739257744 -> 2298739257648
	2298815931376 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2298815931376 -> 2298739257744
	2298739257744 [label=AccumulateGrad]
	2298739257984 -> 2298739257648
	2298815931472 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2298815931472 -> 2298739257984
	2298739257984 [label=AccumulateGrad]
	2298739258272 -> 2298739258224
	2298815931856 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2298815931856 -> 2298739258272
	2298739258272 [label=AccumulateGrad]
	2298739258128 -> 2298739258320
	2298815931952 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2298815931952 -> 2298739258128
	2298739258128 [label=AccumulateGrad]
	2298739258512 -> 2298739258320
	2298815932048 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2298815932048 -> 2298739258512
	2298739258512 [label=AccumulateGrad]
	2298739258656 -> 2298739258608
	2298815932432 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2298815932432 -> 2298739258656
	2298739258656 [label=AccumulateGrad]
	2298739258800 -> 2298739258992
	2298815932528 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	2298815932528 -> 2298739258800
	2298739258800 [label=AccumulateGrad]
	2298739258944 -> 2298739258992
	2298815932624 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	2298815932624 -> 2298739258944
	2298739258944 [label=AccumulateGrad]
	2298739259232 -> 2298739259136
	2298739259232 [label=CudnnBatchNormBackward0]
	2298739258176 -> 2298739259232
	2298739258176 [label=ConvolutionBackward0]
	2298739257504 -> 2298739258176
	2298739257696 -> 2298739258176
	2298815930704 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	2298815930704 -> 2298739257696
	2298739257696 [label=AccumulateGrad]
	2298739258848 -> 2298739259232
	2298815930800 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	2298815930800 -> 2298739258848
	2298739258848 [label=AccumulateGrad]
	2298739258704 -> 2298739259232
	2298815930896 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	2298815930896 -> 2298739258704
	2298739258704 [label=AccumulateGrad]
	2298739259184 -> 2298739259472
	2298815933008 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2298815933008 -> 2298739259184
	2298739259184 [label=AccumulateGrad]
	2298739259712 -> 2298739259616
	2298815933104 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2298815933104 -> 2298739259712
	2298739259712 [label=AccumulateGrad]
	2298739259664 -> 2298739259616
	2298815933200 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2298815933200 -> 2298739259664
	2298739259664 [label=AccumulateGrad]
	2298739259760 -> 2298739260192
	2298815933584 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2298815933584 -> 2298739259760
	2298739259760 [label=AccumulateGrad]
	2298739260096 -> 2298739260288
	2298815933680 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2298815933680 -> 2298739260096
	2298739260096 [label=AccumulateGrad]
	2298739260048 -> 2298739260288
	2298815933776 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2298815933776 -> 2298739260048
	2298739260048 [label=AccumulateGrad]
	2298739260384 -> 2298739260576
	2298815934160 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2298815934160 -> 2298739260384
	2298739260384 [label=AccumulateGrad]
	2298739260768 -> 2298739260528
	2298815934256 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	2298815934256 -> 2298739260768
	2298739260768 [label=AccumulateGrad]
	2298739260624 -> 2298739260528
	2298815934352 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	2298815934352 -> 2298739260624
	2298739260624 [label=AccumulateGrad]
	2298739260720 -> 2298739260864
	2298739261152 -> 2298739261008
	2298815934736 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2298815934736 -> 2298739261152
	2298739261152 [label=AccumulateGrad]
	2298739261200 -> 2298739261344
	2298815934832 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	2298815934832 -> 2298739261200
	2298739261200 [label=AccumulateGrad]
	2298739252272 -> 2298739261344
	2298815934928 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	2298815934928 -> 2298739252272
	2298739252272 [label=AccumulateGrad]
	2298739250400 -> 2298739250352
	2298815935312 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2298815935312 -> 2298739250400
	2298739250400 [label=AccumulateGrad]
	2298739253280 -> 2298739253136
	2298815935408 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	2298815935408 -> 2298739253280
	2298739253280 [label=AccumulateGrad]
	2298739253616 -> 2298739253136
	2298815935504 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	2298815935504 -> 2298739253616
	2298739253616 [label=AccumulateGrad]
	2298739254096 -> 2298739255200
	2298815935888 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2298815935888 -> 2298739254096
	2298739254096 [label=AccumulateGrad]
	2298739255056 -> 2298739255536
	2298815935984 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	2298815935984 -> 2298739255056
	2298739255056 [label=AccumulateGrad]
	2298739255680 -> 2298739255536
	2298815936080 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	2298815936080 -> 2298739255680
	2298739255680 [label=AccumulateGrad]
	2298739256160 -> 2298739256016
	2298739257456 -> 2298739259040
	2298739257456 [label=TBackward0]
	2298739256640 -> 2298739257456
	2298815936752 [label="fc.weight
 (19, 2048)" fillcolor=lightblue]
	2298815936752 -> 2298739256640
	2298739256640 [label=AccumulateGrad]
	2298739259040 -> 2298823063216
}
