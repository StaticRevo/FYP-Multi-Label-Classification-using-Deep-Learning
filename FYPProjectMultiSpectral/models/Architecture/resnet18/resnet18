digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1974607135088 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1974606722528 [label=AddmmBackward0]
	1974606722192 -> 1974606722528
	1974607719952 [label="fc.bias
 (19)" fillcolor=lightblue]
	1974607719952 -> 1974606722192
	1974606722192 [label=AccumulateGrad]
	1974606721568 -> 1974606722528
	1974606721568 [label=ViewBackward0]
	1974606721088 -> 1974606721568
	1974606721088 [label=MeanBackward1]
	1974606720752 -> 1974606721088
	1974606720752 [label=ReluBackward0]
	1974606720272 -> 1974606720752
	1974606720272 [label=AddBackward0]
	1974606719792 -> 1974606720272
	1974606719792 [label=CudnnBatchNormBackward0]
	1974606718688 -> 1974606719792
	1974606718688 [label=ConvolutionBackward0]
	1974606717728 -> 1974606718688
	1974606717728 [label=ReluBackward0]
	1974606717392 -> 1974606717728
	1974606717392 [label=CudnnBatchNormBackward0]
	1974606716912 -> 1974606717392
	1974606716912 [label=ConvolutionBackward0]
	1974606719648 -> 1974606716912
	1974606719648 [label=ReluBackward0]
	1974606715472 -> 1974606719648
	1974606715472 [label=AddBackward0]
	1974606714992 -> 1974606715472
	1974606714992 [label=CudnnBatchNormBackward0]
	1974606713888 -> 1974606714992
	1974606713888 [label=ConvolutionBackward0]
	1974606712928 -> 1974606713888
	1974606712928 [label=ReluBackward0]
	1974606712592 -> 1974606712928
	1974606712592 [label=CudnnBatchNormBackward0]
	1974606712112 -> 1974606712592
	1974606712112 [label=ConvolutionBackward0]
	1974606711152 -> 1974606712112
	1974606711152 [label=ReluBackward0]
	1974606710048 -> 1974606711152
	1974606710048 [label=AddBackward0]
	1974606709568 -> 1974606710048
	1974606709568 [label=CudnnBatchNormBackward0]
	1974606709232 -> 1974606709568
	1974606709232 [label=ConvolutionBackward0]
	1974606724544 -> 1974606709232
	1974606724544 [label=ReluBackward0]
	1974606724160 -> 1974606724544
	1974606724160 [label=CudnnBatchNormBackward0]
	1974606724400 -> 1974606724160
	1974606724400 [label=ConvolutionBackward0]
	1974606710192 -> 1974606724400
	1974606710192 [label=ReluBackward0]
	1974606723680 -> 1974606710192
	1974606723680 [label=AddBackward0]
	1974606723920 -> 1974606723680
	1974606723920 [label=CudnnBatchNormBackward0]
	1974606723584 -> 1974606723920
	1974606723584 [label=ConvolutionBackward0]
	1974606723296 -> 1974606723584
	1974606723296 [label=ReluBackward0]
	1974606723344 -> 1974606723296
	1974606723344 [label=CudnnBatchNormBackward0]
	1974606723056 -> 1974606723344
	1974606723056 [label=ConvolutionBackward0]
	1974606722960 -> 1974606723056
	1974606722960 [label=ReluBackward0]
	1974606722624 -> 1974606722960
	1974606722624 [label=AddBackward0]
	1974606722432 -> 1974606722624
	1974606722432 [label=CudnnBatchNormBackward0]
	1974606722480 -> 1974606722432
	1974606722480 [label=ConvolutionBackward0]
	1974606722096 -> 1974606722480
	1974606722096 [label=ReluBackward0]
	1974606721856 -> 1974606722096
	1974606721856 [label=CudnnBatchNormBackward0]
	1974606721808 -> 1974606721856
	1974606721808 [label=ConvolutionBackward0]
	1974606722576 -> 1974606721808
	1974606722576 [label=ReluBackward0]
	1974606721376 -> 1974606722576
	1974606721376 [label=AddBackward0]
	1974606721328 -> 1974606721376
	1974606721328 [label=CudnnBatchNormBackward0]
	1974606721136 -> 1974606721328
	1974606721136 [label=ConvolutionBackward0]
	1974606721040 -> 1974606721136
	1974606721040 [label=ReluBackward0]
	1974606720704 -> 1974606721040
	1974606720704 [label=CudnnBatchNormBackward0]
	1974606720512 -> 1974606720704
	1974606720512 [label=ConvolutionBackward0]
	1974606720368 -> 1974606720512
	1974606720368 [label=ReluBackward0]
	1974606720176 -> 1974606720368
	1974606720176 [label=AddBackward0]
	1974606719840 -> 1974606720176
	1974606719840 [label=CudnnBatchNormBackward0]
	1974606719888 -> 1974606719840
	1974606719888 [label=ConvolutionBackward0]
	1974606719552 -> 1974606719888
	1974606719552 [label=ReluBackward0]
	1974606719600 -> 1974606719552
	1974606719600 [label=CudnnBatchNormBackward0]
	1974606719504 -> 1974606719600
	1974606719504 [label=ConvolutionBackward0]
	1974606720032 -> 1974606719504
	1974606720032 [label=ReluBackward0]
	1974606719120 -> 1974606720032
	1974606719120 [label=AddBackward0]
	1974606719024 -> 1974606719120
	1974606719024 [label=CudnnBatchNormBackward0]
	1974606718592 -> 1974606719024
	1974606718592 [label=ConvolutionBackward0]
	1974606718448 -> 1974606718592
	1974606718448 [label=ReluBackward0]
	1974606718256 -> 1974606718448
	1974606718256 [label=CudnnBatchNormBackward0]
	1974606717920 -> 1974606718256
	1974606717920 [label=ConvolutionBackward0]
	1974606718928 -> 1974606717920
	1974606718928 [label=MaxPool2DWithIndicesBackward0]
	1974606717776 -> 1974606718928
	1974606717776 [label=ReluBackward0]
	1974606717440 -> 1974606717776
	1974606717440 [label=CudnnBatchNormBackward0]
	1974606717680 -> 1974606717440
	1974606717680 [label=ConvolutionBackward0]
	1974606717296 -> 1974606717680
	1974607719760 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	1974607719760 -> 1974606717296
	1974606717296 [label=AccumulateGrad]
	1974606717536 -> 1974606717440
	1974600093136 [label="bn1.weight
 (64)" fillcolor=lightblue]
	1974600093136 -> 1974606717536
	1974606717536 [label=AccumulateGrad]
	1974606718160 -> 1974606717440
	1974600092368 [label="bn1.bias
 (64)" fillcolor=lightblue]
	1974600092368 -> 1974606718160
	1974606718160 [label=AccumulateGrad]
	1974606718064 -> 1974606717920
	1974600092464 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1974600092464 -> 1974606718064
	1974606718064 [label=AccumulateGrad]
	1974606718112 -> 1974606718256
	1974600092560 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1974600092560 -> 1974606718112
	1974606718112 [label=AccumulateGrad]
	1974606718544 -> 1974606718256
	1974600092656 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1974600092656 -> 1974606718544
	1974606718544 [label=AccumulateGrad]
	1974606718640 -> 1974606718592
	1974600092944 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1974600092944 -> 1974606718640
	1974606718640 [label=AccumulateGrad]
	1974606718736 -> 1974606719024
	1974600091984 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1974600091984 -> 1974606718736
	1974606718736 [label=AccumulateGrad]
	1974606718784 -> 1974606719024
	1974600091888 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1974600091888 -> 1974606718784
	1974606718784 [label=AccumulateGrad]
	1974606718928 -> 1974606719120
	1974606718880 -> 1974606719504
	1974600091024 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1974600091024 -> 1974606718880
	1974606718880 [label=AccumulateGrad]
	1974606719408 -> 1974606719600
	1974600091216 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1974600091216 -> 1974606719408
	1974606719408 [label=AccumulateGrad]
	1974606719360 -> 1974606719600
	1974600091312 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1974600091312 -> 1974606719360
	1974606719360 [label=AccumulateGrad]
	1974606719696 -> 1974606719888
	1974600091792 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1974600091792 -> 1974606719696
	1974606719696 [label=AccumulateGrad]
	1974606720080 -> 1974606719840
	1974600091696 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1974600091696 -> 1974606720080
	1974606720080 [label=AccumulateGrad]
	1974606719936 -> 1974606719840
	1974600090736 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1974600090736 -> 1974606719936
	1974606719936 [label=AccumulateGrad]
	1974606720032 -> 1974606720176
	1974606720560 -> 1974606720512
	1974600090544 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1974600090544 -> 1974606720560
	1974606720560 [label=AccumulateGrad]
	1974606720656 -> 1974606720704
	1974600090448 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1974600090448 -> 1974606720656
	1974606720656 [label=AccumulateGrad]
	1974606720848 -> 1974606720704
	1974607711696 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1974607711696 -> 1974606720848
	1974606720848 [label=AccumulateGrad]
	1974606720896 -> 1974606721136
	1974607712080 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1974607712080 -> 1974606720896
	1974606720896 [label=AccumulateGrad]
	1974606721184 -> 1974606721328
	1974607712176 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1974607712176 -> 1974606721184
	1974606721184 [label=AccumulateGrad]
	1974606721424 -> 1974606721328
	1974607712272 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1974607712272 -> 1974606721424
	1974606721424 [label=AccumulateGrad]
	1974606721520 -> 1974606721376
	1974606721520 [label=CudnnBatchNormBackward0]
	1974606720416 -> 1974606721520
	1974606720416 [label=ConvolutionBackward0]
	1974606720368 -> 1974606720416
	1974606720464 -> 1974606720416
	1974600089776 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1974600089776 -> 1974606720464
	1974606720464 [label=AccumulateGrad]
	1974606720800 -> 1974606721520
	1974600089968 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	1974600089968 -> 1974606720800
	1974606720800 [label=AccumulateGrad]
	1974606720992 -> 1974606721520
	1974600090064 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	1974600090064 -> 1974606720992
	1974606720992 [label=AccumulateGrad]
	1974606721472 -> 1974606721808
	1974607712656 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1974607712656 -> 1974606721472
	1974606721472 [label=AccumulateGrad]
	1974606722000 -> 1974606721856
	1974607712752 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1974607712752 -> 1974606722000
	1974606722000 [label=AccumulateGrad]
	1974606721952 -> 1974606721856
	1974607712848 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1974607712848 -> 1974606721952
	1974606721952 [label=AccumulateGrad]
	1974606722144 -> 1974606722480
	1974607713232 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1974607713232 -> 1974606722144
	1974606722144 [label=AccumulateGrad]
	1974606722336 -> 1974606722432
	1974607713328 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1974607713328 -> 1974606722336
	1974606722336 [label=AccumulateGrad]
	1974606722240 -> 1974606722432
	1974607713424 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1974607713424 -> 1974606722240
	1974606722240 [label=AccumulateGrad]
	1974606722576 -> 1974606722624
	1974606722816 -> 1974606723056
	1974607714384 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1974607714384 -> 1974606722816
	1974606722816 [label=AccumulateGrad]
	1974606723104 -> 1974606723344
	1974607714480 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1974607714480 -> 1974606723104
	1974606723104 [label=AccumulateGrad]
	1974606723440 -> 1974606723344
	1974607714576 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1974607714576 -> 1974606723440
	1974606723440 [label=AccumulateGrad]
	1974606723200 -> 1974606723584
	1974607714960 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1974607714960 -> 1974606723200
	1974606723200 [label=AccumulateGrad]
	1974606723824 -> 1974606723920
	1974607715056 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1974607715056 -> 1974606723824
	1974606723824 [label=AccumulateGrad]
	1974606723728 -> 1974606723920
	1974607715152 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1974607715152 -> 1974606723728
	1974606723728 [label=AccumulateGrad]
	1974606723776 -> 1974606723680
	1974606723776 [label=CudnnBatchNormBackward0]
	1974606722720 -> 1974606723776
	1974606722720 [label=ConvolutionBackward0]
	1974606722960 -> 1974606722720
	1974606722768 -> 1974606722720
	1974607713808 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1974607713808 -> 1974606722768
	1974606722768 [label=AccumulateGrad]
	1974606723392 -> 1974606723776
	1974607713904 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1974607713904 -> 1974606723392
	1974606723392 [label=AccumulateGrad]
	1974606723536 -> 1974606723776
	1974607714000 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1974607714000 -> 1974606723536
	1974606723536 [label=AccumulateGrad]
	1974606724016 -> 1974606724400
	1974607715536 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1974607715536 -> 1974606724016
	1974606724016 [label=AccumulateGrad]
	1974606724256 -> 1974606724160
	1974607715632 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1974607715632 -> 1974606724256
	1974606724256 [label=AccumulateGrad]
	1974606724496 -> 1974606724160
	1974607715728 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1974607715728 -> 1974606724496
	1974606724496 [label=AccumulateGrad]
	1974606724784 -> 1974606709232
	1974607716112 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1974607716112 -> 1974606724784
	1974606724784 [label=AccumulateGrad]
	1974606709088 -> 1974606709568
	1974607716208 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1974607716208 -> 1974606709088
	1974606709088 [label=AccumulateGrad]
	1974606709712 -> 1974606709568
	1974607716304 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1974607716304 -> 1974606709712
	1974606709712 [label=AccumulateGrad]
	1974606710192 -> 1974606710048
	1974606711008 -> 1974606712112
	1974607717264 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1974607717264 -> 1974606711008
	1974606711008 [label=AccumulateGrad]
	1974606711968 -> 1974606712592
	1974607717360 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1974607717360 -> 1974606711968
	1974606711968 [label=AccumulateGrad]
	1974606713072 -> 1974606712592
	1974607717456 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1974607717456 -> 1974606713072
	1974606713072 [label=AccumulateGrad]
	1974606713552 -> 1974606713888
	1974607717840 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1974607717840 -> 1974606713552
	1974606713552 [label=AccumulateGrad]
	1974606714512 -> 1974606714992
	1974607717936 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1974607717936 -> 1974606714512
	1974606714512 [label=AccumulateGrad]
	1974606714368 -> 1974606714992
	1974607718032 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1974607718032 -> 1974606714368
	1974606714368 [label=AccumulateGrad]
	1974606714848 -> 1974606715472
	1974606714848 [label=CudnnBatchNormBackward0]
	1974606711632 -> 1974606714848
	1974606711632 [label=ConvolutionBackward0]
	1974606711152 -> 1974606711632
	1974606710528 -> 1974606711632
	1974607716688 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1974607716688 -> 1974606710528
	1974606710528 [label=AccumulateGrad]
	1974606713408 -> 1974606714848
	1974607716784 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1974607716784 -> 1974606713408
	1974606713408 [label=AccumulateGrad]
	1974606714032 -> 1974606714848
	1974607716880 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1974607716880 -> 1974606714032
	1974606714032 [label=AccumulateGrad]
	1974606715952 -> 1974606716912
	1974607718416 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1974607718416 -> 1974606715952
	1974606715952 [label=AccumulateGrad]
	1974606716768 -> 1974606717392
	1974607718512 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1974607718512 -> 1974606716768
	1974606716768 [label=AccumulateGrad]
	1974606717872 -> 1974606717392
	1974607718608 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1974607718608 -> 1974606717872
	1974606717872 [label=AccumulateGrad]
	1974606718352 -> 1974606718688
	1974607718992 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1974607718992 -> 1974606718352
	1974606718352 [label=AccumulateGrad]
	1974606719312 -> 1974606719792
	1974607719088 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1974607719088 -> 1974606719312
	1974606719312 [label=AccumulateGrad]
	1974606719168 -> 1974606719792
	1974607719184 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1974607719184 -> 1974606719168
	1974606719168 [label=AccumulateGrad]
	1974606719648 -> 1974606720272
	1974606721712 -> 1974606722528
	1974606721712 [label=TBackward0]
	1974606720128 -> 1974606721712
	1974607719856 [label="fc.weight
 (19, 512)" fillcolor=lightblue]
	1974607719856 -> 1974606720128
	1974606720128 [label=AccumulateGrad]
	1974606722528 -> 1974607135088
}
