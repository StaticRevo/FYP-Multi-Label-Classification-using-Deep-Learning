digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2882196769776 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2882086793664 [label=AddmmBackward0]
	2882086793856 -> 2882086793664
	2882289842992 [label="fc.bias
 (19)" fillcolor=lightblue]
	2882289842992 -> 2882086793856
	2882086793856 [label=AccumulateGrad]
	2882086793808 -> 2882086793664
	2882086793808 [label=ViewBackward0]
	2882303944512 -> 2882086793808
	2882303944512 [label=MeanBackward1]
	2882303947488 -> 2882303944512
	2882303947488 [label=ReluBackward0]
	2882303949888 -> 2882303947488
	2882303949888 [label=AddBackward0]
	2882303944704 -> 2882303949888
	2882303944704 [label=CudnnBatchNormBackward0]
	2882303944560 -> 2882303944704
	2882303944560 [label=ConvolutionBackward0]
	2882303948208 -> 2882303944560
	2882303948208 [label=ReluBackward0]
	2882303945856 -> 2882303948208
	2882303945856 [label=CudnnBatchNormBackward0]
	2882303946816 -> 2882303945856
	2882303946816 [label=ConvolutionBackward0]
	2882303945040 -> 2882303946816
	2882303945040 [label=ReluBackward0]
	2882303943600 -> 2882303945040
	2882303943600 [label=AddBackward0]
	2882303945616 -> 2882303943600
	2882303945616 [label=CudnnBatchNormBackward0]
	2882303946720 -> 2882303945616
	2882303946720 [label=ConvolutionBackward0]
	2882303948064 -> 2882303946720
	2882303948064 [label=ReluBackward0]
	2882303942496 -> 2882303948064
	2882303942496 [label=CudnnBatchNormBackward0]
	2882303946528 -> 2882303942496
	2882303946528 [label=ConvolutionBackward0]
	2882303945184 -> 2882303946528
	2882303945184 [label=ReluBackward0]
	2882259014496 -> 2882303945184
	2882259014496 [label=AddBackward0]
	2882259016992 -> 2882259014496
	2882259016992 [label=CudnnBatchNormBackward0]
	2882259021408 -> 2882259016992
	2882259021408 [label=ConvolutionBackward0]
	2882259012480 -> 2882259021408
	2882259012480 [label=ReluBackward0]
	2882259018576 -> 2882259012480
	2882259018576 [label=CudnnBatchNormBackward0]
	2882259010608 -> 2882259018576
	2882259010608 [label=ConvolutionBackward0]
	2882259015456 -> 2882259010608
	2882259015456 [label=ReluBackward0]
	2882259018384 -> 2882259015456
	2882259018384 [label=AddBackward0]
	2882259010752 -> 2882259018384
	2882259010752 [label=CudnnBatchNormBackward0]
	2882259010128 -> 2882259010752
	2882259010128 [label=ConvolutionBackward0]
	2882259011904 -> 2882259010128
	2882259011904 [label=ReluBackward0]
	2882259014544 -> 2882259011904
	2882259014544 [label=CudnnBatchNormBackward0]
	2882259013392 -> 2882259014544
	2882259013392 [label=ConvolutionBackward0]
	2882259016320 -> 2882259013392
	2882259016320 [label=ReluBackward0]
	2882259021024 -> 2882259016320
	2882259021024 [label=AddBackward0]
	2882259016944 -> 2882259021024
	2882259016944 [label=CudnnBatchNormBackward0]
	2882259016368 -> 2882259016944
	2882259016368 [label=ConvolutionBackward0]
	2882259014640 -> 2882259016368
	2882259014640 [label=ReluBackward0]
	2882259023904 -> 2882259014640
	2882259023904 [label=CudnnBatchNormBackward0]
	2882259023568 -> 2882259023904
	2882259023568 [label=ConvolutionBackward0]
	2882259021744 -> 2882259023568
	2882259021744 [label=ReluBackward0]
	2882259020832 -> 2882259021744
	2882259020832 [label=AddBackward0]
	2882259017280 -> 2882259020832
	2882259017280 [label=CudnnBatchNormBackward0]
	2882259012336 -> 2882259017280
	2882259012336 [label=ConvolutionBackward0]
	2882259023088 -> 2882259012336
	2882259023088 [label=ReluBackward0]
	2882259013584 -> 2882259023088
	2882259013584 [label=CudnnBatchNormBackward0]
	2882259018528 -> 2882259013584
	2882259018528 [label=ConvolutionBackward0]
	2882259011952 -> 2882259018528
	2882259011952 [label=ReluBackward0]
	2882259016704 -> 2882259011952
	2882259016704 [label=AddBackward0]
	2882259023808 -> 2882259016704
	2882259023808 [label=CudnnBatchNormBackward0]
	2882259021984 -> 2882259023808
	2882259021984 [label=ConvolutionBackward0]
	2882259024912 -> 2882259021984
	2882259024912 [label=ReluBackward0]
	2882259018000 -> 2882259024912
	2882259018000 [label=CudnnBatchNormBackward0]
	2882259022752 -> 2882259018000
	2882259022752 [label=ConvolutionBackward0]
	2882259016128 -> 2882259022752
	2882259016128 [label=ReluBackward0]
	2882259020064 -> 2882259016128
	2882259020064 [label=AddBackward0]
	2882259014880 -> 2882259020064
	2882259014880 [label=CudnnBatchNormBackward0]
	2882259012144 -> 2882259014880
	2882259012144 [label=ConvolutionBackward0]
	2882259021072 -> 2882259012144
	2882259021072 [label=ReluBackward0]
	2882259020112 -> 2882259021072
	2882259020112 [label=CudnnBatchNormBackward0]
	2882259024720 -> 2882259020112
	2882259024720 [label=ConvolutionBackward0]
	2882259011520 -> 2882259024720
	2882259011520 [label=MaxPool2DWithIndicesBackward0]
	2882259016752 -> 2882259011520
	2882259016752 [label=ReluBackward0]
	2882259024288 -> 2882259016752
	2882259024288 [label=CudnnBatchNormBackward0]
	2882259021504 -> 2882259024288
	2882259021504 [label=ConvolutionBackward0]
	2882259018240 -> 2882259021504
	2882270588144 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	2882270588144 -> 2882259018240
	2882259018240 [label=AccumulateGrad]
	2882259011712 -> 2882259024288
	2882268446992 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2882268446992 -> 2882259011712
	2882259011712 [label=AccumulateGrad]
	2882259018768 -> 2882259024288
	2882268447088 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2882268447088 -> 2882259018768
	2882259018768 [label=AccumulateGrad]
	2882259020400 -> 2882259024720
	2882323251120 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2882323251120 -> 2882259020400
	2882259020400 [label=AccumulateGrad]
	2882259016656 -> 2882259020112
	2882270576720 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2882270576720 -> 2882259016656
	2882259016656 [label=AccumulateGrad]
	2882259021168 -> 2882259020112
	2882270576816 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2882270576816 -> 2882259021168
	2882259021168 [label=AccumulateGrad]
	2882259010800 -> 2882259012144
	2882270577200 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2882270577200 -> 2882259010800
	2882259010800 [label=AccumulateGrad]
	2882259022608 -> 2882259014880
	2882270577296 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2882270577296 -> 2882259022608
	2882259022608 [label=AccumulateGrad]
	2882259013104 -> 2882259014880
	2882270577392 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2882270577392 -> 2882259013104
	2882259013104 [label=AccumulateGrad]
	2882259011520 -> 2882259020064
	2882259017712 -> 2882259022752
	2882270577776 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2882270577776 -> 2882259017712
	2882259017712 [label=AccumulateGrad]
	2882259020352 -> 2882259018000
	2882270577872 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2882270577872 -> 2882259020352
	2882259020352 [label=AccumulateGrad]
	2882259019632 -> 2882259018000
	2882270577968 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2882270577968 -> 2882259019632
	2882259019632 [label=AccumulateGrad]
	2882259022896 -> 2882259021984
	2882270578352 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2882270578352 -> 2882259022896
	2882259022896 [label=AccumulateGrad]
	2882259020496 -> 2882259023808
	2882270578448 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2882270578448 -> 2882259020496
	2882259020496 [label=AccumulateGrad]
	2882259024336 -> 2882259023808
	2882270578544 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2882270578544 -> 2882259024336
	2882259024336 [label=AccumulateGrad]
	2882259016128 -> 2882259016704
	2882259010896 -> 2882259018528
	2882270579504 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2882270579504 -> 2882259010896
	2882259010896 [label=AccumulateGrad]
	2882259010560 -> 2882259013584
	2882270579600 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2882270579600 -> 2882259010560
	2882259010560 [label=AccumulateGrad]
	2882259020784 -> 2882259013584
	2882270579696 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2882270579696 -> 2882259020784
	2882259020784 [label=AccumulateGrad]
	2882259012816 -> 2882259012336
	2882270580080 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2882270580080 -> 2882259012816
	2882259012816 [label=AccumulateGrad]
	2882259016416 -> 2882259017280
	2882270580176 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2882270580176 -> 2882259016416
	2882259016416 [label=AccumulateGrad]
	2882259009936 -> 2882259017280
	2882270580272 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2882270580272 -> 2882259009936
	2882259009936 [label=AccumulateGrad]
	2882259020160 -> 2882259020832
	2882259020160 [label=CudnnBatchNormBackward0]
	2882259015744 -> 2882259020160
	2882259015744 [label=ConvolutionBackward0]
	2882259011952 -> 2882259015744
	2882259019824 -> 2882259015744
	2882270578928 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2882270578928 -> 2882259019824
	2882259019824 [label=AccumulateGrad]
	2882259019152 -> 2882259020160
	2882270579024 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2882270579024 -> 2882259019152
	2882259019152 [label=AccumulateGrad]
	2882259022944 -> 2882259020160
	2882270579120 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2882270579120 -> 2882259022944
	2882259022944 [label=AccumulateGrad]
	2882259012720 -> 2882259023568
	2882270580656 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2882270580656 -> 2882259012720
	2882259012720 [label=AccumulateGrad]
	2882259018912 -> 2882259023904
	2882270580752 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2882270580752 -> 2882259018912
	2882259018912 [label=AccumulateGrad]
	2882259018288 -> 2882259023904
	2882270580848 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2882270580848 -> 2882259018288
	2882259018288 [label=AccumulateGrad]
	2882259012240 -> 2882259016368
	2882270581232 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2882270581232 -> 2882259012240
	2882259012240 [label=AccumulateGrad]
	2882259021840 -> 2882259016944
	2882270581328 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2882270581328 -> 2882259021840
	2882259021840 [label=AccumulateGrad]
	2882259009888 -> 2882259016944
	2882270581424 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2882270581424 -> 2882259009888
	2882259009888 [label=AccumulateGrad]
	2882259021744 -> 2882259021024
	2882259019488 -> 2882259013392
	2882270582384 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2882270582384 -> 2882259019488
	2882259019488 [label=AccumulateGrad]
	2882259015072 -> 2882259014544
	2882270582480 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2882270582480 -> 2882259015072
	2882259015072 [label=AccumulateGrad]
	2882259019680 -> 2882259014544
	2882270582576 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2882270582576 -> 2882259019680
	2882259019680 [label=AccumulateGrad]
	2882259012672 -> 2882259010128
	2882270582960 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2882270582960 -> 2882259012672
	2882259012672 [label=AccumulateGrad]
	2882259019920 -> 2882259010752
	2882270583056 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2882270583056 -> 2882259019920
	2882259019920 [label=AccumulateGrad]
	2882259018672 -> 2882259010752
	2882270583152 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2882270583152 -> 2882259018672
	2882259018672 [label=AccumulateGrad]
	2882259025008 -> 2882259018384
	2882259025008 [label=CudnnBatchNormBackward0]
	2882259022272 -> 2882259025008
	2882259022272 [label=ConvolutionBackward0]
	2882259016320 -> 2882259022272
	2882259012288 -> 2882259022272
	2882270581808 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2882270581808 -> 2882259012288
	2882259012288 [label=AccumulateGrad]
	2882259019200 -> 2882259025008
	2882270581904 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2882270581904 -> 2882259019200
	2882259019200 [label=AccumulateGrad]
	2882259021360 -> 2882259025008
	2882270582000 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2882270582000 -> 2882259021360
	2882259021360 [label=AccumulateGrad]
	2882259019776 -> 2882259010608
	2882270583536 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2882270583536 -> 2882259019776
	2882259019776 [label=AccumulateGrad]
	2882259025392 -> 2882259018576
	2882270583632 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2882270583632 -> 2882259025392
	2882259025392 [label=AccumulateGrad]
	2882259011328 -> 2882259018576
	2882270583728 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2882270583728 -> 2882259011328
	2882259011328 [label=AccumulateGrad]
	2882259024240 -> 2882259021408
	2882270584112 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2882270584112 -> 2882259024240
	2882259024240 [label=AccumulateGrad]
	2882259020304 -> 2882259016992
	2882270584208 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2882270584208 -> 2882259020304
	2882259020304 [label=AccumulateGrad]
	2882259025680 -> 2882259016992
	2882270584304 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2882270584304 -> 2882259025680
	2882259025680 [label=AccumulateGrad]
	2882259015456 -> 2882259014496
	2882303946192 -> 2882303946528
	2882270585264 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2882270585264 -> 2882303946192
	2882303946192 [label=AccumulateGrad]
	2882303943408 -> 2882303942496
	2882270585360 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2882270585360 -> 2882303943408
	2882303943408 [label=AccumulateGrad]
	2882303942304 -> 2882303942496
	2882270585456 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2882270585456 -> 2882303942304
	2882303942304 [label=AccumulateGrad]
	2882303947632 -> 2882303946720
	2882270585840 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2882270585840 -> 2882303947632
	2882303947632 [label=AccumulateGrad]
	2882303944800 -> 2882303945616
	2882270585936 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2882270585936 -> 2882303944800
	2882303944800 [label=AccumulateGrad]
	2882303944464 -> 2882303945616
	2882270586032 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2882270586032 -> 2882303944464
	2882303944464 [label=AccumulateGrad]
	2882303949312 -> 2882303943600
	2882303949312 [label=CudnnBatchNormBackward0]
	2882303946000 -> 2882303949312
	2882303946000 [label=ConvolutionBackward0]
	2882303945184 -> 2882303946000
	2882303945136 -> 2882303946000
	2882270584688 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2882270584688 -> 2882303945136
	2882303945136 [label=AccumulateGrad]
	2882303949744 -> 2882303949312
	2882270584784 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2882270584784 -> 2882303949744
	2882303949744 [label=AccumulateGrad]
	2882303950704 -> 2882303949312
	2882270584880 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2882270584880 -> 2882303950704
	2882303950704 [label=AccumulateGrad]
	2882303945328 -> 2882303946816
	2882270586416 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2882270586416 -> 2882303945328
	2882303945328 [label=AccumulateGrad]
	2882303948736 -> 2882303945856
	2882270586512 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2882270586512 -> 2882303948736
	2882303948736 [label=AccumulateGrad]
	2882303948832 -> 2882303945856
	2882270586608 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2882270586608 -> 2882303948832
	2882303948832 [label=AccumulateGrad]
	2882303944320 -> 2882303944560
	2882270586992 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2882270586992 -> 2882303944320
	2882303944320 [label=AccumulateGrad]
	2882303946144 -> 2882303944704
	2882270587088 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2882270587088 -> 2882303946144
	2882303946144 [label=AccumulateGrad]
	2882303945280 -> 2882303944704
	2882270587184 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2882270587184 -> 2882303945280
	2882303945280 [label=AccumulateGrad]
	2882303945040 -> 2882303949888
	2882303942112 -> 2882086793664
	2882303942112 [label=TBackward0]
	2882303943648 -> 2882303942112
	2882270587856 [label="fc.weight
 (19, 512)" fillcolor=lightblue]
	2882270587856 -> 2882303943648
	2882303943648 [label=AccumulateGrad]
	2882086793664 -> 2882196769776
}
