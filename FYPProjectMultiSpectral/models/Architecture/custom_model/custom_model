digraph {
	graph [size="86.7,86.7"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2026145619824 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2026145789648 [label=AddmmBackward0]
	2026145788544 -> 2026145789648
	2026178479888 [label="29.bias
 (19)" fillcolor=lightblue]
	2026178479888 -> 2026145788544
	2026145788544 [label=AccumulateGrad]
	2026145788688 -> 2026145789648
	2026145788688 [label=NativeDropoutBackward0]
	2026145788208 -> 2026145788688
	2026145788208 [label=ViewBackward0]
	2026145787104 -> 2026145788208
	2026145787104 [label=MeanBackward1]
	2026145786624 -> 2026145787104
	2026145786624 [label=MulBackward0]
	2026145786144 -> 2026145786624
	2026145786144 [label=MulBackward0]
	2026145785808 -> 2026145786144
	2026145785808 [label=ReluBackward0]
	2026145784704 -> 2026145785808
	2026145784704 [label=AddBackward0]
	2026145784224 -> 2026145784704
	2026145784224 [label=CudnnBatchNormBackward0]
	2026145783888 -> 2026145784224
	2026145783888 [label=ConvolutionBackward0]
	2026145782928 -> 2026145783888
	2026145782928 [label=ReluBackward0]
	2026145781824 -> 2026145782928
	2026145781824 [label=CudnnBatchNormBackward0]
	2026145781344 -> 2026145781824
	2026145781344 [label=ConvolutionBackward0]
	2026145784848 -> 2026145781344
	2026145784848 [label=ReluBackward0]
	2026145779904 -> 2026145784848
	2026145779904 [label=CudnnBatchNormBackward0]
	2026145779424 -> 2026145779904
	2026145779424 [label=ConvolutionBackward0]
	2026145778464 -> 2026145779424
	2026145778464 [label=ConvolutionBackward0]
	2026145778128 -> 2026145778464
	2026145778128 [label=MulBackward0]
	2026145777024 -> 2026145778128
	2026145777024 [label=ReluBackward0]
	2026145776688 -> 2026145777024
	2026145776688 [label=AddBackward0]
	2026145776208 -> 2026145776688
	2026145776208 [label=CudnnBatchNormBackward0]
	2026145791520 -> 2026145776208
	2026145791520 [label=ConvolutionBackward0]
	2026145791232 -> 2026145791520
	2026145791232 [label=ReluBackward0]
	2026145791280 -> 2026145791232
	2026145791280 [label=CudnnBatchNormBackward0]
	2026145790992 -> 2026145791280
	2026145790992 [label=ConvolutionBackward0]
	2026145776064 -> 2026145790992
	2026145776064 [label=ConvolutionBackward0]
	2026145790800 -> 2026145776064
	2026145790800 [label=CatBackward0]
	2026145790176 -> 2026145790800
	2026145790176 [label=ConvolutionBackward0]
	2026145790320 -> 2026145790176
	2026145790320 [label=ReluBackward0]
	2026145789696 -> 2026145790320
	2026145789696 [label=CudnnBatchNormBackward0]
	2026145789936 -> 2026145789696
	2026145789936 [label=ConvolutionBackward0]
	2026145789552 -> 2026145789936
	2026145789552 [label=ConvolutionBackward0]
	2026145789312 -> 2026145789552
	2026145789312 [label=MulBackward0]
	2026145789360 -> 2026145789312
	2026145789360 [label=ReluBackward0]
	2026145788928 -> 2026145789360
	2026145788928 [label=AddBackward0]
	2026145788832 -> 2026145788928
	2026145788832 [label=CudnnBatchNormBackward0]
	2026145788880 -> 2026145788832
	2026145788880 [label=ConvolutionBackward0]
	2026145788256 -> 2026145788880
	2026145788256 [label=ReluBackward0]
	2026145788304 -> 2026145788256
	2026145788304 [label=CudnnBatchNormBackward0]
	2026145788160 -> 2026145788304
	2026145788160 [label=ConvolutionBackward0]
	2026145788736 -> 2026145788160
	2026145788736 [label=ConvolutionBackward0]
	2026145787824 -> 2026145788736
	2026145787824 [label=CatBackward0]
	2026145787488 -> 2026145787824
	2026145787488 [label=ConvolutionBackward0]
	2026145787344 -> 2026145787488
	2026145787344 [label=ReluBackward0]
	2026145787008 -> 2026145787344
	2026145787008 [label=CudnnBatchNormBackward0]
	2026145786912 -> 2026145787008
	2026145786912 [label=ConvolutionBackward0]
	2026145786720 -> 2026145786912
	2026145786720 [label=ConvolutionBackward0]
	2026145786336 -> 2026145786720
	2026145786336 [label=MulBackward0]
	2026145786384 -> 2026145786336
	2026145786384 [label=MulBackward0]
	2026145786192 -> 2026145786384
	2026145786192 [label=MulBackward0]
	2026145785952 -> 2026145786192
	2026145785952 [label=ReluBackward0]
	2026145786000 -> 2026145785952
	2026145786000 [label=AddBackward0]
	2026145785712 -> 2026145786000
	2026145785712 [label=CudnnBatchNormBackward0]
	2026145785472 -> 2026145785712
	2026145785472 [label=ConvolutionBackward0]
	2026145785280 -> 2026145785472
	2026145785280 [label=ReluBackward0]
	2026145784896 -> 2026145785280
	2026145784896 [label=CudnnBatchNormBackward0]
	2026145785136 -> 2026145784896
	2026145785136 [label=ConvolutionBackward0]
	2026145785760 -> 2026145785136
	2026145785760 [label=ReluBackward0]
	2026145784416 -> 2026145785760
	2026145784416 [label=CudnnBatchNormBackward0]
	2026145784656 -> 2026145784416
	2026145784656 [label=ConvolutionBackward0]
	2026145784272 -> 2026145784656
	2026145784272 [label=ConvolutionBackward0]
	2026145784032 -> 2026145784272
	2026145784032 [label=ReluBackward0]
	2026145784080 -> 2026145784032
	2026145784080 [label=CudnnBatchNormBackward0]
	2026145783792 -> 2026145784080
	2026145783792 [label=ConvolutionBackward0]
	2026145783696 -> 2026145783792
	2026157041584 [label="0.weight
 (16, 3, 1, 1)" fillcolor=lightblue]
	2026157041584 -> 2026145783696
	2026145783696 [label=AccumulateGrad]
	2026145783840 -> 2026145784080
	2026157040816 [label="1.weight
 (16)" fillcolor=lightblue]
	2026157040816 -> 2026145783840
	2026145783840 [label=AccumulateGrad]
	2026145784176 -> 2026145784080
	2026157040528 [label="1.bias
 (16)" fillcolor=lightblue]
	2026157040528 -> 2026145784176
	2026145784176 [label=AccumulateGrad]
	2026145783936 -> 2026145784272
	2026157041008 [label="3.depthwise.weight
 (16, 1, 3, 3)" fillcolor=lightblue]
	2026157041008 -> 2026145783936
	2026145783936 [label=AccumulateGrad]
	2026145784320 -> 2026145784656
	2026157041104 [label="3.pointwise.weight
 (32, 16, 1, 1)" fillcolor=lightblue]
	2026157041104 -> 2026145784320
	2026145784320 [label=AccumulateGrad]
	2026145784512 -> 2026145784416
	2026157041200 [label="4.weight
 (32)" fillcolor=lightblue]
	2026157041200 -> 2026145784512
	2026145784512 [label=AccumulateGrad]
	2026145785040 -> 2026145784416
	2026157041296 [label="4.bias
 (32)" fillcolor=lightblue]
	2026157041296 -> 2026145785040
	2026145785040 [label=AccumulateGrad]
	2026145784752 -> 2026145785136
	2026157040336 [label="6.conv1.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2026157040336 -> 2026145784752
	2026145784752 [label=AccumulateGrad]
	2026145784992 -> 2026145784896
	2026157039568 [label="6.bn1.weight
 (32)" fillcolor=lightblue]
	2026157039568 -> 2026145784992
	2026145784992 [label=AccumulateGrad]
	2026145785232 -> 2026145784896
	2026157039280 [label="6.bn1.bias
 (32)" fillcolor=lightblue]
	2026157039280 -> 2026145785232
	2026145785232 [label=AccumulateGrad]
	2026145785520 -> 2026145785472
	2026157039760 [label="6.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2026157039760 -> 2026145785520
	2026145785520 [label=AccumulateGrad]
	2026145785376 -> 2026145785712
	2026157039856 [label="6.bn2.weight
 (32)" fillcolor=lightblue]
	2026157039856 -> 2026145785376
	2026145785376 [label=AccumulateGrad]
	2026145785568 -> 2026145785712
	2026157039952 [label="6.bn2.bias
 (32)" fillcolor=lightblue]
	2026157039952 -> 2026145785568
	2026145785568 [label=AccumulateGrad]
	2026145785760 -> 2026145786000
	2026145785856 -> 2026145786192
	2026145785856 [label=ViewBackward0]
	2026145785616 -> 2026145785856
	2026145785616 [label=SigmoidBackward0]
	2026145784800 -> 2026145785616
	2026145784800 [label=AddmmBackward0]
	2026145785088 -> 2026145784800
	2026157037936 [label="7.fc2.bias
 (32)" fillcolor=lightblue]
	2026157037936 -> 2026145785088
	2026145785088 [label=AccumulateGrad]
	2026145784944 -> 2026145784800
	2026145784944 [label=ReluBackward0]
	2026145784464 -> 2026145784944
	2026145784464 [label=AddmmBackward0]
	2026145784128 -> 2026145784464
	2026157039088 [label="7.fc1.bias
 (2)" fillcolor=lightblue]
	2026157039088 -> 2026145784128
	2026145784128 [label=AccumulateGrad]
	2026145783552 -> 2026145784464
	2026145783552 [label=MeanBackward1]
	2026145783600 -> 2026145783552
	2026145783600 [label=ViewBackward0]
	2026145785952 -> 2026145783600
	2026145783648 -> 2026145784464
	2026145783648 [label=TBackward0]
	2026145783360 -> 2026145783648
	2026157039184 [label="7.fc1.weight
 (2, 32)" fillcolor=lightblue]
	2026157039184 -> 2026145783360
	2026145783360 [label=AccumulateGrad]
	2026145785904 -> 2026145784800
	2026145785904 [label=TBackward0]
	2026145783312 -> 2026145785904
	2026157038320 [label="7.fc2.weight
 (32, 2)" fillcolor=lightblue]
	2026157038320 -> 2026145783312
	2026145783312 [label=AccumulateGrad]
	2026145786240 -> 2026145786384
	2026145786240 [label=SigmoidBackward0]
	2026145785424 -> 2026145786240
	2026145785424 [label=ConvolutionBackward0]
	2026145783984 -> 2026145785424
	2026145783984 [label=SplitWithSizesBackward0]
	2026145784608 -> 2026145783984
	2026145784608 [label=ReluBackward0]
	2026145782976 -> 2026145784608
	2026145782976 [label=CudnnBatchNormBackward0]
	2026145783216 -> 2026145782976
	2026145783216 [label=ConvolutionBackward0]
	2026145782832 -> 2026145783216
	2026145782832 [label=CatBackward0]
	2026145782592 -> 2026145782832
	2026145782592 [label=AdaptiveAvgPool2DBackward0]
	2026145786192 -> 2026145782592
	2026145782496 -> 2026145782832
	2026145782496 [label=PermuteBackward0]
	2026145782736 -> 2026145782496
	2026145782736 [label=AdaptiveAvgPool2DBackward0]
	2026145786192 -> 2026145782736
	2026145782880 -> 2026145783216
	2026157038800 [label="8.conv1.weight
 (8, 32, 1, 1)" fillcolor=lightblue]
	2026157038800 -> 2026145782880
	2026145782880 [label=AccumulateGrad]
	2026145783072 -> 2026145782976
	2026157036400 [label="8.bn1.weight
 (8)" fillcolor=lightblue]
	2026157036400 -> 2026145783072
	2026145783072 [label=AccumulateGrad]
	2026145783456 -> 2026145782976
	2026157036592 [label="8.bn1.bias
 (8)" fillcolor=lightblue]
	2026157036592 -> 2026145783456
	2026145783456 [label=AccumulateGrad]
	2026145784560 -> 2026145785424
	2026157038704 [label="8.conv_h.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	2026157038704 -> 2026145784560
	2026145784560 [label=AccumulateGrad]
	2026145786576 -> 2026145786336
	2026145786576 [label=PermuteBackward0]
	2026145786048 -> 2026145786576
	2026145786048 [label=SigmoidBackward0]
	2026145783504 -> 2026145786048
	2026145783504 [label=ConvolutionBackward0]
	2026145783984 -> 2026145783504
	2026145783120 -> 2026145783504
	2026157038992 [label="8.conv_w.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	2026157038992 -> 2026145783120
	2026145783120 [label=AccumulateGrad]
	2026145786528 -> 2026145786720
	2026157038896 [label="9.depthwise.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	2026157038896 -> 2026145786528
	2026145786528 [label=AccumulateGrad]
	2026145786960 -> 2026145786912
	2026178865072 [label="9.pointwise.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	2026178865072 -> 2026145786960
	2026145786960 [label=AccumulateGrad]
	2026145786816 -> 2026145787008
	2026178865168 [label="10.weight
 (64)" fillcolor=lightblue]
	2026178865168 -> 2026145786816
	2026145786816 [label=AccumulateGrad]
	2026145787200 -> 2026145787008
	2026178865264 [label="10.bias
 (64)" fillcolor=lightblue]
	2026178865264 -> 2026145787200
	2026145787200 [label=AccumulateGrad]
	2026145787536 -> 2026145787488
	2026178865648 [label="12.conv_dil1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2026178865648 -> 2026145787536
	2026145787536 [label=AccumulateGrad]
	2026145787392 -> 2026145787488
	2026178865744 [label="12.conv_dil1.bias
 (64)" fillcolor=lightblue]
	2026178865744 -> 2026145787392
	2026145787392 [label=AccumulateGrad]
	2026145787632 -> 2026145787824
	2026145787632 [label=ConvolutionBackward0]
	2026145787344 -> 2026145787632
	2026145787056 -> 2026145787632
	2026178865840 [label="12.conv_dil2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2026178865840 -> 2026145787056
	2026145787056 [label=AccumulateGrad]
	2026145787152 -> 2026145787632
	2026178865936 [label="12.conv_dil2.bias
 (64)" fillcolor=lightblue]
	2026178865936 -> 2026145787152
	2026145787152 [label=AccumulateGrad]
	2026145787680 -> 2026145787824
	2026145787680 [label=ConvolutionBackward0]
	2026145787344 -> 2026145787680
	2026145786096 -> 2026145787680
	2026178866032 [label="12.conv_dil3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2026178866032 -> 2026145786096
	2026145786096 [label=AccumulateGrad]
	2026145786864 -> 2026145787680
	2026178866128 [label="12.conv_dil3.bias
 (64)" fillcolor=lightblue]
	2026178866128 -> 2026145786864
	2026145786864 [label=AccumulateGrad]
	2026145788016 -> 2026145788736
	2026178866224 [label="12.fuse.weight
 (64, 192, 1, 1)" fillcolor=lightblue]
	2026178866224 -> 2026145788016
	2026145788016 [label=AccumulateGrad]
	2026145787968 -> 2026145788736
	2026178866320 [label="12.fuse.bias
 (64)" fillcolor=lightblue]
	2026178866320 -> 2026145787968
	2026145787968 [label=AccumulateGrad]
	2026145787872 -> 2026145788160
	2026178866416 [label="13.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2026178866416 -> 2026145787872
	2026145787872 [label=AccumulateGrad]
	2026145788400 -> 2026145788304
	2026178866512 [label="13.bn1.weight
 (64)" fillcolor=lightblue]
	2026178866512 -> 2026145788400
	2026145788400 [label=AccumulateGrad]
	2026145788352 -> 2026145788304
	2026178866608 [label="13.bn1.bias
 (64)" fillcolor=lightblue]
	2026178866608 -> 2026145788352
	2026145788352 [label=AccumulateGrad]
	2026145788448 -> 2026145788880
	2026178866992 [label="13.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2026178866992 -> 2026145788448
	2026145788448 [label=AccumulateGrad]
	2026145788784 -> 2026145788832
	2026178867088 [label="13.bn2.weight
 (64)" fillcolor=lightblue]
	2026178867088 -> 2026145788784
	2026145788784 [label=AccumulateGrad]
	2026145788976 -> 2026145788832
	2026178867184 [label="13.bn2.bias
 (64)" fillcolor=lightblue]
	2026178867184 -> 2026145788976
	2026145788976 [label=AccumulateGrad]
	2026145788736 -> 2026145788928
	2026145789264 -> 2026145789312
	2026145789264 [label=UnsqueezeBackward0]
	2026145788640 -> 2026145789264
	2026145788640 [label=UnsqueezeBackward0]
	2026145787776 -> 2026145788640
	2026145787776 [label=SigmoidBackward0]
	2026145788496 -> 2026145787776
	2026145788496 [label=SqueezeBackward1]
	2026145787296 -> 2026145788496
	2026145787296 [label=ConvolutionBackward0]
	2026145783024 -> 2026145787296
	2026145783024 [label=UnsqueezeBackward0]
	2026145783168 -> 2026145783024
	2026145783168 [label=SqueezeBackward1]
	2026145782352 -> 2026145783168
	2026145782352 [label=SqueezeBackward1]
	2026145782688 -> 2026145782352
	2026145782688 [label=MeanBackward1]
	2026145789360 -> 2026145782688
	2026145787920 -> 2026145787296
	2026178867568 [label="14.conv.weight
 (1, 1, 3)" fillcolor=lightblue]
	2026178867568 -> 2026145787920
	2026145787920 [label=AccumulateGrad]
	2026145789216 -> 2026145789552
	2026178867664 [label="15.depthwise.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	2026178867664 -> 2026145789216
	2026145789216 [label=AccumulateGrad]
	2026145789600 -> 2026145789936
	2026178867760 [label="15.pointwise.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2026178867760 -> 2026145789600
	2026145789600 [label=AccumulateGrad]
	2026145789792 -> 2026145789696
	2026178867856 [label="16.weight
 (128)" fillcolor=lightblue]
	2026178867856 -> 2026145789792
	2026145789792 [label=AccumulateGrad]
	2026145790032 -> 2026145789696
	2026178867952 [label="16.bias
 (128)" fillcolor=lightblue]
	2026178867952 -> 2026145790032
	2026145790032 [label=AccumulateGrad]
	2026145790224 -> 2026145790176
	2026178868336 [label="18.conv_dil1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2026178868336 -> 2026145790224
	2026145790224 [label=AccumulateGrad]
	2026145790416 -> 2026145790176
	2026178868432 [label="18.conv_dil1.bias
 (128)" fillcolor=lightblue]
	2026178868432 -> 2026145790416
	2026145790416 [label=AccumulateGrad]
	2026145790368 -> 2026145790800
	2026145790368 [label=ConvolutionBackward0]
	2026145790320 -> 2026145790368
	2026145789744 -> 2026145790368
	2026178868528 [label="18.conv_dil2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2026178868528 -> 2026145789744
	2026145789744 [label=AccumulateGrad]
	2026145789888 -> 2026145790368
	2026178868624 [label="18.conv_dil2.bias
 (128)" fillcolor=lightblue]
	2026178868624 -> 2026145789888
	2026145789888 [label=AccumulateGrad]
	2026145790512 -> 2026145790800
	2026145790512 [label=ConvolutionBackward0]
	2026145790320 -> 2026145790512
	2026145789120 -> 2026145790512
	2026178868720 [label="18.conv_dil3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2026178868720 -> 2026145789120
	2026145789120 [label=AccumulateGrad]
	2026145789840 -> 2026145790512
	2026178868816 [label="18.conv_dil3.bias
 (128)" fillcolor=lightblue]
	2026178868816 -> 2026145789840
	2026145789840 [label=AccumulateGrad]
	2026145790704 -> 2026145776064
	2026178868912 [label="18.fuse.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	2026178868912 -> 2026145790704
	2026145790704 [label=AccumulateGrad]
	2026145790656 -> 2026145776064
	2026178869008 [label="18.fuse.bias
 (128)" fillcolor=lightblue]
	2026178869008 -> 2026145790656
	2026145790656 [label=AccumulateGrad]
	2026145790896 -> 2026145790992
	2026178869104 [label="19.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2026178869104 -> 2026145790896
	2026145790896 [label=AccumulateGrad]
	2026145791040 -> 2026145791280
	2026178869200 [label="19.bn1.weight
 (128)" fillcolor=lightblue]
	2026178869200 -> 2026145791040
	2026145791040 [label=AccumulateGrad]
	2026145791376 -> 2026145791280
	2026178869296 [label="19.bn1.bias
 (128)" fillcolor=lightblue]
	2026178869296 -> 2026145791376
	2026145791376 [label=AccumulateGrad]
	2026145791136 -> 2026145791520
	2026178869680 [label="19.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2026178869680 -> 2026145791136
	2026145791136 [label=AccumulateGrad]
	2026145791952 -> 2026145776208
	2026178869776 [label="19.bn2.weight
 (128)" fillcolor=lightblue]
	2026178869776 -> 2026145791952
	2026145791952 [label=AccumulateGrad]
	2026145775728 -> 2026145776208
	2026178869872 [label="19.bn2.bias
 (128)" fillcolor=lightblue]
	2026178869872 -> 2026145775728
	2026145775728 [label=AccumulateGrad]
	2026145776064 -> 2026145776688
	2026145777648 -> 2026145778128
	2026145777648 [label=SigmoidBackward0]
	2026145791472 -> 2026145777648
	2026145791472 [label=ConvolutionBackward0]
	2026145790752 -> 2026145791472
	2026145790752 [label=NativeDropoutBackward0]
	2026145790272 -> 2026145790752
	2026145790272 [label=ReluBackward0]
	2026145788592 -> 2026145790272
	2026145788592 [label=ConvolutionBackward0]
	2026145789456 -> 2026145788592
	2026145789456 [label=MeanBackward1]
	2026145777024 -> 2026145789456
	2026145789408 -> 2026145788592
	2026178870256 [label="20.fc1.weight
 (8, 128, 1, 1)" fillcolor=lightblue]
	2026178870256 -> 2026145789408
	2026145789408 [label=AccumulateGrad]
	2026145791184 -> 2026145788592
	2026178870352 [label="20.fc1.bias
 (8)" fillcolor=lightblue]
	2026178870352 -> 2026145791184
	2026145791184 [label=AccumulateGrad]
	2026145791328 -> 2026145791472
	2026178870448 [label="20.fc2.weight
 (128, 8, 1, 1)" fillcolor=lightblue]
	2026178870448 -> 2026145791328
	2026145791328 [label=AccumulateGrad]
	2026145776544 -> 2026145791472
	2026178870544 [label="20.fc2.bias
 (128)" fillcolor=lightblue]
	2026178870544 -> 2026145776544
	2026145776544 [label=AccumulateGrad]
	2026145777984 -> 2026145778464
	2026178870640 [label="21.depthwise.weight
 (128, 1, 3, 3)" fillcolor=lightblue]
	2026178870640 -> 2026145777984
	2026145777984 [label=AccumulateGrad]
	2026145779088 -> 2026145779424
	2026178870736 [label="21.pointwise.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2026178870736 -> 2026145779088
	2026145779088 [label=AccumulateGrad]
	2026145780048 -> 2026145779904
	2026178870832 [label="22.weight
 (256)" fillcolor=lightblue]
	2026178870832 -> 2026145780048
	2026145780048 [label=AccumulateGrad]
	2026145780864 -> 2026145779904
	2026178870928 [label="22.bias
 (256)" fillcolor=lightblue]
	2026178870928 -> 2026145780864
	2026145780864 [label=AccumulateGrad]
	2026145780384 -> 2026145781344
	2026178478160 [label="24.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2026178478160 -> 2026145780384
	2026145780384 [label=AccumulateGrad]
	2026145781968 -> 2026145781824
	2026178478256 [label="24.bn1.weight
 (256)" fillcolor=lightblue]
	2026178478256 -> 2026145781968
	2026145781968 [label=AccumulateGrad]
	2026145782304 -> 2026145781824
	2026178478352 [label="24.bn1.bias
 (256)" fillcolor=lightblue]
	2026178478352 -> 2026145782304
	2026145782304 [label=AccumulateGrad]
	2026145782784 -> 2026145783888
	2026178478736 [label="24.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2026178478736 -> 2026145782784
	2026145782784 [label=AccumulateGrad]
	2026145783744 -> 2026145784224
	2026178478832 [label="24.bn2.weight
 (256)" fillcolor=lightblue]
	2026178478832 -> 2026145783744
	2026145783744 [label=AccumulateGrad]
	2026145784368 -> 2026145784224
	2026178478928 [label="24.bn2.bias
 (256)" fillcolor=lightblue]
	2026178478928 -> 2026145784368
	2026145784368 [label=AccumulateGrad]
	2026145784848 -> 2026145784704
	2026145785664 -> 2026145786144
	2026145785664 [label=ViewBackward0]
	2026145783264 -> 2026145785664
	2026145783264 [label=SigmoidBackward0]
	2026145781008 -> 2026145783264
	2026145781008 [label=AddmmBackward0]
	2026145782448 -> 2026145781008
	2026178479600 [label="25.channel_att.fc2.bias
 (256)" fillcolor=lightblue]
	2026178479600 -> 2026145782448
	2026145782448 [label=AccumulateGrad]
	2026145781488 -> 2026145781008
	2026145781488 [label=ReluBackward0]
	2026145779568 -> 2026145781488
	2026145779568 [label=AddmmBackward0]
	2026145778608 -> 2026145779568
	2026178479408 [label="25.channel_att.fc1.bias
 (16)" fillcolor=lightblue]
	2026178479408 -> 2026145778608
	2026145778608 [label=AccumulateGrad]
	2026145790848 -> 2026145779568
	2026145790848 [label=MeanBackward1]
	2026145790080 -> 2026145790848
	2026145790080 [label=ViewBackward0]
	2026145785808 -> 2026145790080
	2026145777168 -> 2026145779568
	2026145777168 [label=TBackward0]
	2026145786480 -> 2026145777168
	2026178479312 [label="25.channel_att.fc1.weight
 (16, 256)" fillcolor=lightblue]
	2026178479312 -> 2026145786480
	2026145786480 [label=AccumulateGrad]
	2026145785328 -> 2026145781008
	2026145785328 [label=TBackward0]
	2026145789072 -> 2026145785328
	2026178479504 [label="25.channel_att.fc2.weight
 (256, 16)" fillcolor=lightblue]
	2026178479504 -> 2026145789072
	2026145789072 [label=AccumulateGrad]
	2026145786768 -> 2026145786624
	2026145786768 [label=SigmoidBackward0]
	2026145783408 -> 2026145786768
	2026145783408 [label=ConvolutionBackward0]
	2026145777504 -> 2026145783408
	2026145777504 [label=CatBackward0]
	2026145780528 -> 2026145777504
	2026145780528 [label=MeanBackward1]
	2026145786144 -> 2026145780528
	2026145787440 -> 2026145777504
	2026145787440 [label=MaxBackward0]
	2026145786144 -> 2026145787440
	2026145778944 -> 2026145783408
	2026178479696 [label="25.spatial_att.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	2026178479696 -> 2026145778944
	2026145778944 [label=AccumulateGrad]
	2026145788064 -> 2026145789648
	2026145788064 [label=TBackward0]
	2026145787248 -> 2026145788064
	2026178479792 [label="29.weight
 (19, 256)" fillcolor=lightblue]
	2026178479792 -> 2026145787248
	2026145787248 [label=AccumulateGrad]
	2026145789648 -> 2026145619824
}
