digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1793909372688 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1793909494240 [label=AddmmBackward0]
	1793909494384 -> 1793909494240
	1793976065232 [label="fc.bias
 (19)" fillcolor=lightblue]
	1793976065232 -> 1793909494384
	1793909494384 [label=AccumulateGrad]
	1793909494432 -> 1793909494240
	1793909494432 [label=ViewBackward0]
	1793909494528 -> 1793909494432
	1793909494528 [label=MeanBackward1]
	1793909494672 -> 1793909494528
	1793909494672 [label=ReluBackward0]
	1793909494768 -> 1793909494672
	1793909494768 [label=AddBackward0]
	1793909494864 -> 1793909494768
	1793909494864 [label=CudnnBatchNormBackward0]
	1793909495008 -> 1793909494864
	1793909495008 [label=ConvolutionBackward0]
	1793909495200 -> 1793909495008
	1793909495200 [label=ReluBackward0]
	1793909495344 -> 1793909495200
	1793909495344 [label=CudnnBatchNormBackward0]
	1793909495440 -> 1793909495344
	1793909495440 [label=ConvolutionBackward0]
	1793909494816 -> 1793909495440
	1793909494816 [label=ReluBackward0]
	1793909495728 -> 1793909494816
	1793909495728 [label=AddBackward0]
	1793909495824 -> 1793909495728
	1793909495824 [label=CudnnBatchNormBackward0]
	1793909495968 -> 1793909495824
	1793909495968 [label=ConvolutionBackward0]
	1793909496160 -> 1793909495968
	1793909496160 [label=ReluBackward0]
	1793909496304 -> 1793909496160
	1793909496304 [label=CudnnBatchNormBackward0]
	1793909496400 -> 1793909496304
	1793909496400 [label=ConvolutionBackward0]
	1793909496592 -> 1793909496400
	1793909496592 [label=ReluBackward0]
	1793909496736 -> 1793909496592
	1793909496736 [label=AddBackward0]
	1793909496832 -> 1793909496736
	1793909496832 [label=CudnnBatchNormBackward0]
	1793909496976 -> 1793909496832
	1793909496976 [label=ConvolutionBackward0]
	1793909497168 -> 1793909496976
	1793909497168 [label=ReluBackward0]
	1793909497312 -> 1793909497168
	1793909497312 [label=CudnnBatchNormBackward0]
	1793909497408 -> 1793909497312
	1793909497408 [label=ConvolutionBackward0]
	1793909496784 -> 1793909497408
	1793909496784 [label=ReluBackward0]
	1793909492032 -> 1793909496784
	1793909492032 [label=AddBackward0]
	1793909492128 -> 1793909492032
	1793909492128 [label=CudnnBatchNormBackward0]
	1793909492224 -> 1793909492128
	1793909492224 [label=ConvolutionBackward0]
	1793909492416 -> 1793909492224
	1793909492416 [label=ReluBackward0]
	1793909492560 -> 1793909492416
	1793909492560 [label=CudnnBatchNormBackward0]
	1793909492656 -> 1793909492560
	1793909492656 [label=ConvolutionBackward0]
	1793909492848 -> 1793909492656
	1793909492848 [label=ReluBackward0]
	1793909492992 -> 1793909492848
	1793909492992 [label=AddBackward0]
	1793909493088 -> 1793909492992
	1793909493088 [label=CudnnBatchNormBackward0]
	1793909493232 -> 1793909493088
	1793909493232 [label=ConvolutionBackward0]
	1793909493424 -> 1793909493232
	1793909493424 [label=ReluBackward0]
	1793909493568 -> 1793909493424
	1793909493568 [label=CudnnBatchNormBackward0]
	1793909493664 -> 1793909493568
	1793909493664 [label=ConvolutionBackward0]
	1793909493040 -> 1793909493664
	1793909493040 [label=ReluBackward0]
	1793909497744 -> 1793909493040
	1793909497744 [label=AddBackward0]
	1793909497840 -> 1793909497744
	1793909497840 [label=CudnnBatchNormBackward0]
	1793909497984 -> 1793909497840
	1793909497984 [label=ConvolutionBackward0]
	1793909498176 -> 1793909497984
	1793909498176 [label=ReluBackward0]
	1793909498320 -> 1793909498176
	1793909498320 [label=CudnnBatchNormBackward0]
	1793909498416 -> 1793909498320
	1793909498416 [label=ConvolutionBackward0]
	1793909498608 -> 1793909498416
	1793909498608 [label=ReluBackward0]
	1793909498752 -> 1793909498608
	1793909498752 [label=AddBackward0]
	1793909498848 -> 1793909498752
	1793909498848 [label=CudnnBatchNormBackward0]
	1793909498992 -> 1793909498848
	1793909498992 [label=ConvolutionBackward0]
	1793909499184 -> 1793909498992
	1793909499184 [label=ReluBackward0]
	1793909499328 -> 1793909499184
	1793909499328 [label=CudnnBatchNormBackward0]
	1793909499424 -> 1793909499328
	1793909499424 [label=ConvolutionBackward0]
	1793909498800 -> 1793909499424
	1793909498800 [label=ReluBackward0]
	1793909499712 -> 1793909498800
	1793909499712 [label=AddBackward0]
	1793909499808 -> 1793909499712
	1793909499808 [label=CudnnBatchNormBackward0]
	1793909499952 -> 1793909499808
	1793909499952 [label=ConvolutionBackward0]
	1793909500144 -> 1793909499952
	1793909500144 [label=ReluBackward0]
	1793909500288 -> 1793909500144
	1793909500288 [label=CudnnBatchNormBackward0]
	1793909500384 -> 1793909500288
	1793909500384 [label=ConvolutionBackward0]
	1793909499760 -> 1793909500384
	1793909499760 [label=MaxPool2DWithIndicesBackward0]
	1793909500672 -> 1793909499760
	1793909500672 [label=ReluBackward0]
	1793909500768 -> 1793909500672
	1793909500768 [label=CudnnBatchNormBackward0]
	1793909500864 -> 1793909500768
	1793909500864 [label=ConvolutionBackward0]
	1793909501056 -> 1793909500864
	1793976065040 [label="conv1.weight
 (64, 4, 7, 7)" fillcolor=lightblue]
	1793976065040 -> 1793909501056
	1793909501056 [label=AccumulateGrad]
	1793909500816 -> 1793909500768
	1793980411504 [label="bn1.weight
 (64)" fillcolor=lightblue]
	1793980411504 -> 1793909500816
	1793909500816 [label=AccumulateGrad]
	1793909500480 -> 1793909500768
	1793980411600 [label="bn1.bias
 (64)" fillcolor=lightblue]
	1793980411600 -> 1793909500480
	1793909500480 [label=AccumulateGrad]
	1793909500576 -> 1793909500384
	1793980411984 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1793980411984 -> 1793909500576
	1793909500576 [label=AccumulateGrad]
	1793909500336 -> 1793909500288
	1793980412080 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1793980412080 -> 1793909500336
	1793909500336 [label=AccumulateGrad]
	1793909500192 -> 1793909500288
	1793980412176 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1793980412176 -> 1793909500192
	1793909500192 [label=AccumulateGrad]
	1793909500096 -> 1793909499952
	1793980412560 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1793980412560 -> 1793909500096
	1793909500096 [label=AccumulateGrad]
	1793909499904 -> 1793909499808
	1793980412656 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1793980412656 -> 1793909499904
	1793909499904 [label=AccumulateGrad]
	1793909499856 -> 1793909499808
	1793980412752 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1793980412752 -> 1793909499856
	1793909499856 [label=AccumulateGrad]
	1793909499760 -> 1793909499712
	1793909499616 -> 1793909499424
	1793980413136 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1793980413136 -> 1793909499616
	1793909499616 [label=AccumulateGrad]
	1793909499376 -> 1793909499328
	1793980413232 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1793980413232 -> 1793909499376
	1793909499376 [label=AccumulateGrad]
	1793909499232 -> 1793909499328
	1793980413328 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1793980413328 -> 1793909499232
	1793909499232 [label=AccumulateGrad]
	1793909499136 -> 1793909498992
	1793980413712 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1793980413712 -> 1793909499136
	1793909499136 [label=AccumulateGrad]
	1793909498944 -> 1793909498848
	1793980413808 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1793980413808 -> 1793909498944
	1793909498944 [label=AccumulateGrad]
	1793909498896 -> 1793909498848
	1793980413904 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1793980413904 -> 1793909498896
	1793909498896 [label=AccumulateGrad]
	1793909498800 -> 1793909498752
	1793909498560 -> 1793909498416
	1793980414864 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1793980414864 -> 1793909498560
	1793909498560 [label=AccumulateGrad]
	1793909498368 -> 1793909498320
	1793980414960 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1793980414960 -> 1793909498368
	1793909498368 [label=AccumulateGrad]
	1793909498224 -> 1793909498320
	1793980415056 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1793980415056 -> 1793909498224
	1793909498224 [label=AccumulateGrad]
	1793909498128 -> 1793909497984
	1793980415440 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1793980415440 -> 1793909498128
	1793909498128 [label=AccumulateGrad]
	1793909497936 -> 1793909497840
	1793980415536 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1793980415536 -> 1793909497936
	1793909497936 [label=AccumulateGrad]
	1793909497888 -> 1793909497840
	1793980415632 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1793980415632 -> 1793909497888
	1793909497888 [label=AccumulateGrad]
	1793909497792 -> 1793909497744
	1793909497792 [label=CudnnBatchNormBackward0]
	1793909498512 -> 1793909497792
	1793909498512 [label=ConvolutionBackward0]
	1793909498608 -> 1793909498512
	1793909498656 -> 1793909498512
	1793980414288 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1793980414288 -> 1793909498656
	1793909498656 [label=AccumulateGrad]
	1793909498080 -> 1793909497792
	1793980414384 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	1793980414384 -> 1793909498080
	1793909498080 [label=AccumulateGrad]
	1793909498032 -> 1793909497792
	1793980414480 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	1793980414480 -> 1793909498032
	1793909498032 [label=AccumulateGrad]
	1793909491984 -> 1793909493664
	1793976057936 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1793976057936 -> 1793909491984
	1793909491984 [label=AccumulateGrad]
	1793909493616 -> 1793909493568
	1793976058032 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1793976058032 -> 1793909493616
	1793909493616 [label=AccumulateGrad]
	1793909493472 -> 1793909493568
	1793976058128 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1793976058128 -> 1793909493472
	1793909493472 [label=AccumulateGrad]
	1793909493376 -> 1793909493232
	1793976058512 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1793976058512 -> 1793909493376
	1793909493376 [label=AccumulateGrad]
	1793909493184 -> 1793909493088
	1793976058608 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1793976058608 -> 1793909493184
	1793909493184 [label=AccumulateGrad]
	1793909493136 -> 1793909493088
	1793976058704 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1793976058704 -> 1793909493136
	1793909493136 [label=AccumulateGrad]
	1793909493040 -> 1793909492992
	1793909492800 -> 1793909492656
	1793976059664 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1793976059664 -> 1793909492800
	1793909492800 [label=AccumulateGrad]
	1793909492608 -> 1793909492560
	1793976059760 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1793976059760 -> 1793909492608
	1793909492608 [label=AccumulateGrad]
	1793909492464 -> 1793909492560
	1793976059856 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1793976059856 -> 1793909492464
	1793909492464 [label=AccumulateGrad]
	1793909492368 -> 1793909492224
	1793976060240 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1793976060240 -> 1793909492368
	1793909492368 [label=AccumulateGrad]
	1793909492176 -> 1793909492128
	1793976060336 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1793976060336 -> 1793909492176
	1793909492176 [label=AccumulateGrad]
	1793909492080 -> 1793909492128
	1793976060432 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1793976060432 -> 1793909492080
	1793909492080 [label=AccumulateGrad]
	1793909491888 -> 1793909492032
	1793909491888 [label=CudnnBatchNormBackward0]
	1793909492752 -> 1793909491888
	1793909492752 [label=ConvolutionBackward0]
	1793909492848 -> 1793909492752
	1793909492896 -> 1793909492752
	1793976059088 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1793976059088 -> 1793909492896
	1793909492896 [label=AccumulateGrad]
	1793909492320 -> 1793909491888
	1793976059184 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1793976059184 -> 1793909492320
	1793909492320 [label=AccumulateGrad]
	1793909492272 -> 1793909491888
	1793976059280 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1793976059280 -> 1793909492272
	1793909492272 [label=AccumulateGrad]
	1793909497600 -> 1793909497408
	1793976060816 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1793976060816 -> 1793909497600
	1793909497600 [label=AccumulateGrad]
	1793909497360 -> 1793909497312
	1793976060912 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1793976060912 -> 1793909497360
	1793909497360 [label=AccumulateGrad]
	1793909497216 -> 1793909497312
	1793976061008 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1793976061008 -> 1793909497216
	1793909497216 [label=AccumulateGrad]
	1793909497120 -> 1793909496976
	1793976061392 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1793976061392 -> 1793909497120
	1793909497120 [label=AccumulateGrad]
	1793909496928 -> 1793909496832
	1793976061488 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1793976061488 -> 1793909496928
	1793909496928 [label=AccumulateGrad]
	1793909496880 -> 1793909496832
	1793976061584 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1793976061584 -> 1793909496880
	1793909496880 [label=AccumulateGrad]
	1793909496784 -> 1793909496736
	1793909496544 -> 1793909496400
	1793976062544 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1793976062544 -> 1793909496544
	1793909496544 [label=AccumulateGrad]
	1793909496352 -> 1793909496304
	1793976062640 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1793976062640 -> 1793909496352
	1793909496352 [label=AccumulateGrad]
	1793909496208 -> 1793909496304
	1793976062736 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1793976062736 -> 1793909496208
	1793909496208 [label=AccumulateGrad]
	1793909496112 -> 1793909495968
	1793976063120 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1793976063120 -> 1793909496112
	1793909496112 [label=AccumulateGrad]
	1793909495920 -> 1793909495824
	1793976063216 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1793976063216 -> 1793909495920
	1793909495920 [label=AccumulateGrad]
	1793909495872 -> 1793909495824
	1793976063312 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1793976063312 -> 1793909495872
	1793909495872 [label=AccumulateGrad]
	1793909495776 -> 1793909495728
	1793909495776 [label=CudnnBatchNormBackward0]
	1793909496496 -> 1793909495776
	1793909496496 [label=ConvolutionBackward0]
	1793909496592 -> 1793909496496
	1793909496640 -> 1793909496496
	1793976061968 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1793976061968 -> 1793909496640
	1793909496640 [label=AccumulateGrad]
	1793909496064 -> 1793909495776
	1793976062064 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1793976062064 -> 1793909496064
	1793909496064 [label=AccumulateGrad]
	1793909496016 -> 1793909495776
	1793976062160 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1793976062160 -> 1793909496016
	1793909496016 [label=AccumulateGrad]
	1793909495632 -> 1793909495440
	1793976063696 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1793976063696 -> 1793909495632
	1793909495632 [label=AccumulateGrad]
	1793909495392 -> 1793909495344
	1793976063792 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1793976063792 -> 1793909495392
	1793909495392 [label=AccumulateGrad]
	1793909495248 -> 1793909495344
	1793976063888 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1793976063888 -> 1793909495248
	1793909495248 [label=AccumulateGrad]
	1793909495152 -> 1793909495008
	1793976064272 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1793976064272 -> 1793909495152
	1793909495152 [label=AccumulateGrad]
	1793909494960 -> 1793909494864
	1793976064368 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1793976064368 -> 1793909494960
	1793909494960 [label=AccumulateGrad]
	1793909494912 -> 1793909494864
	1793976064464 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1793976064464 -> 1793909494912
	1793909494912 [label=AccumulateGrad]
	1793909494816 -> 1793909494768
	1793909494480 -> 1793909494240
	1793909494480 [label=TBackward0]
	1793909494720 -> 1793909494480
	1793976065136 [label="fc.weight
 (19, 512)" fillcolor=lightblue]
	1793976065136 -> 1793909494720
	1793909494720 [label=AccumulateGrad]
	1793909494240 -> 1793909372688
}
