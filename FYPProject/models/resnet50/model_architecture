digraph {
	graph [size="152.25,152.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1984792650448 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1984405769376 [label=SigmoidBackward0]
	1984405769136 -> 1984405769376
	1984405769136 [label=AddmmBackward0]
	1984405768944 -> 1984405769136
	1984792270736 [label="model.fc.bias
 (19)" fillcolor=lightblue]
	1984792270736 -> 1984405768944
	1984405768944 [label=AccumulateGrad]
	1984405777296 -> 1984405769136
	1984405777296 [label=ViewBackward0]
	1984405768608 -> 1984405777296
	1984405768608 [label=MeanBackward1]
	1984405768368 -> 1984405768608
	1984405768368 [label=ReluBackward0]
	1984405776288 -> 1984405768368
	1984405776288 [label=AddBackward0]
	1984405776192 -> 1984405776288
	1984405776192 [label=CudnnBatchNormBackward0]
	1984405775904 -> 1984405776192
	1984405775904 [label=ConvolutionBackward0]
	1984405775520 -> 1984405775904
	1984405775520 [label=ReluBackward0]
	1984405775328 -> 1984405775520
	1984405775328 [label=CudnnBatchNormBackward0]
	1984405766640 -> 1984405775328
	1984405766640 [label=ConvolutionBackward0]
	1984405774512 -> 1984405766640
	1984405774512 [label=ReluBackward0]
	1984405777680 -> 1984405774512
	1984405777680 [label=CudnnBatchNormBackward0]
	1984405774752 -> 1984405777680
	1984405774752 [label=ConvolutionBackward0]
	1984405767936 -> 1984405774752
	1984405767936 [label=ReluBackward0]
	1984405781040 -> 1984405767936
	1984405781040 [label=AddBackward0]
	1984405780176 -> 1984405781040
	1984405780176 [label=CudnnBatchNormBackward0]
	1984405778688 -> 1984405780176
	1984405778688 [label=ConvolutionBackward0]
	1984405769040 -> 1984405778688
	1984405769040 [label=ReluBackward0]
	1984405769424 -> 1984405769040
	1984405769424 [label=CudnnBatchNormBackward0]
	1984405779984 -> 1984405769424
	1984405779984 [label=ConvolutionBackward0]
	1984405778448 -> 1984405779984
	1984405778448 [label=ReluBackward0]
	1984405770576 -> 1984405778448
	1984405770576 [label=CudnnBatchNormBackward0]
	1984404733520 -> 1984405770576
	1984404733520 [label=ConvolutionBackward0]
	1984405780560 -> 1984404733520
	1984405780560 [label=ReluBackward0]
	1984404724640 -> 1984405780560
	1984404724640 [label=AddBackward0]
	1984404724352 -> 1984404724640
	1984404724352 [label=CudnnBatchNormBackward0]
	1984404732080 -> 1984404724352
	1984404732080 [label=ConvolutionBackward0]
	1984404731408 -> 1984404732080
	1984404731408 [label=ReluBackward0]
	1984404730688 -> 1984404731408
	1984404730688 [label=CudnnBatchNormBackward0]
	1984404730496 -> 1984404730688
	1984404730496 [label=ConvolutionBackward0]
	1984404728816 -> 1984404730496
	1984404728816 [label=ReluBackward0]
	1984404727952 -> 1984404728816
	1984404727952 [label=CudnnBatchNormBackward0]
	1984404726800 -> 1984404727952
	1984404726800 [label=ConvolutionBackward0]
	1984404730736 -> 1984404726800
	1984404730736 [label=ReluBackward0]
	1984404728480 -> 1984404730736
	1984404728480 [label=AddBackward0]
	1984404723632 -> 1984404728480
	1984404723632 [label=CudnnBatchNormBackward0]
	1984404729776 -> 1984404723632
	1984404729776 [label=ConvolutionBackward0]
	1984404732512 -> 1984404729776
	1984404732512 [label=ReluBackward0]
	1984404730304 -> 1984404732512
	1984404730304 [label=CudnnBatchNormBackward0]
	1984404726992 -> 1984404730304
	1984404726992 [label=ConvolutionBackward0]
	1984404726848 -> 1984404726992
	1984404726848 [label=ReluBackward0]
	1984404728144 -> 1984404726848
	1984404728144 [label=CudnnBatchNormBackward0]
	1984404725264 -> 1984404728144
	1984404725264 [label=ConvolutionBackward0]
	1984404732800 -> 1984404725264
	1984404732800 [label=ReluBackward0]
	1984404728000 -> 1984404732800
	1984404728000 [label=AddBackward0]
	1984404726896 -> 1984404728000
	1984404726896 [label=CudnnBatchNormBackward0]
	1984404723824 -> 1984404726896
	1984404723824 [label=ConvolutionBackward0]
	1984404723296 -> 1984404723824
	1984404723296 [label=ReluBackward0]
	1984404729632 -> 1984404723296
	1984404729632 [label=CudnnBatchNormBackward0]
	1984404725552 -> 1984404729632
	1984404725552 [label=ConvolutionBackward0]
	1984404726944 -> 1984404725552
	1984404726944 [label=ReluBackward0]
	1984404726416 -> 1984404726944
	1984404726416 [label=CudnnBatchNormBackward0]
	1984404724688 -> 1984404726416
	1984404724688 [label=ConvolutionBackward0]
	1984404725936 -> 1984404724688
	1984404725936 [label=ReluBackward0]
	1984404730016 -> 1984404725936
	1984404730016 [label=AddBackward0]
	1984404725408 -> 1984404730016
	1984404725408 [label=CudnnBatchNormBackward0]
	1984404726656 -> 1984404725408
	1984404726656 [label=ConvolutionBackward0]
	1984404726032 -> 1984404726656
	1984404726032 [label=ReluBackward0]
	1984404723008 -> 1984404726032
	1984404723008 [label=CudnnBatchNormBackward0]
	1984404728288 -> 1984404723008
	1984404728288 [label=ConvolutionBackward0]
	1984404722960 -> 1984404728288
	1984404722960 [label=ReluBackward0]
	1984404723776 -> 1984404722960
	1984404723776 [label=CudnnBatchNormBackward0]
	1984404725024 -> 1984404723776
	1984404725024 [label=ConvolutionBackward0]
	1984404724928 -> 1984404725024
	1984404724928 [label=ReluBackward0]
	1984404732032 -> 1984404724928
	1984404732032 [label=AddBackward0]
	1984404733088 -> 1984404732032
	1984404733088 [label=CudnnBatchNormBackward0]
	1984404728912 -> 1984404733088
	1984404728912 [label=ConvolutionBackward0]
	1984404726512 -> 1984404728912
	1984404726512 [label=ReluBackward0]
	1984404725504 -> 1984404726512
	1984404725504 [label=CudnnBatchNormBackward0]
	1984404728720 -> 1984404725504
	1984404728720 [label=ConvolutionBackward0]
	1984404731456 -> 1984404728720
	1984404731456 [label=ReluBackward0]
	1984404733328 -> 1984404731456
	1984404733328 [label=CudnnBatchNormBackward0]
	1984404733856 -> 1984404733328
	1984404733856 [label=ConvolutionBackward0]
	1984404733040 -> 1984404733856
	1984404733040 [label=ReluBackward0]
	1984404726464 -> 1984404733040
	1984404726464 [label=AddBackward0]
	1984404728528 -> 1984404726464
	1984404728528 [label=CudnnBatchNormBackward0]
	1984404732272 -> 1984404728528
	1984404732272 [label=ConvolutionBackward0]
	1984404731792 -> 1984404732272
	1984404731792 [label=ReluBackward0]
	1984404725216 -> 1984404731792
	1984404725216 [label=CudnnBatchNormBackward0]
	1984404731024 -> 1984404725216
	1984404731024 [label=ConvolutionBackward0]
	1984792559872 -> 1984404731024
	1984792559872 [label=ReluBackward0]
	1984792560016 -> 1984792559872
	1984792560016 [label=CudnnBatchNormBackward0]
	1984792560112 -> 1984792560016
	1984792560112 [label=ConvolutionBackward0]
	1984404733232 -> 1984792560112
	1984404733232 [label=ReluBackward0]
	1984792560400 -> 1984404733232
	1984792560400 [label=AddBackward0]
	1984792560496 -> 1984792560400
	1984792560496 [label=CudnnBatchNormBackward0]
	1984792560640 -> 1984792560496
	1984792560640 [label=ConvolutionBackward0]
	1984792560832 -> 1984792560640
	1984792560832 [label=ReluBackward0]
	1984792560976 -> 1984792560832
	1984792560976 [label=CudnnBatchNormBackward0]
	1984792561072 -> 1984792560976
	1984792561072 [label=ConvolutionBackward0]
	1984792561264 -> 1984792561072
	1984792561264 [label=ReluBackward0]
	1984792561408 -> 1984792561264
	1984792561408 [label=CudnnBatchNormBackward0]
	1984792561504 -> 1984792561408
	1984792561504 [label=ConvolutionBackward0]
	1984792561696 -> 1984792561504
	1984792561696 [label=ReluBackward0]
	1984792561840 -> 1984792561696
	1984792561840 [label=AddBackward0]
	1984792561936 -> 1984792561840
	1984792561936 [label=CudnnBatchNormBackward0]
	1984792562080 -> 1984792561936
	1984792562080 [label=ConvolutionBackward0]
	1984792562272 -> 1984792562080
	1984792562272 [label=ReluBackward0]
	1984792562416 -> 1984792562272
	1984792562416 [label=CudnnBatchNormBackward0]
	1984792562512 -> 1984792562416
	1984792562512 [label=ConvolutionBackward0]
	1984792562704 -> 1984792562512
	1984792562704 [label=ReluBackward0]
	1984792562848 -> 1984792562704
	1984792562848 [label=CudnnBatchNormBackward0]
	1984792562944 -> 1984792562848
	1984792562944 [label=ConvolutionBackward0]
	1984792561888 -> 1984792562944
	1984792561888 [label=ReluBackward0]
	1984792563232 -> 1984792561888
	1984792563232 [label=AddBackward0]
	1984792563328 -> 1984792563232
	1984792563328 [label=CudnnBatchNormBackward0]
	1984792563472 -> 1984792563328
	1984792563472 [label=ConvolutionBackward0]
	1984792563664 -> 1984792563472
	1984792563664 [label=ReluBackward0]
	1984792563808 -> 1984792563664
	1984792563808 [label=CudnnBatchNormBackward0]
	1984792563904 -> 1984792563808
	1984792563904 [label=ConvolutionBackward0]
	1984792564096 -> 1984792563904
	1984792564096 [label=ReluBackward0]
	1984792564240 -> 1984792564096
	1984792564240 [label=CudnnBatchNormBackward0]
	1984792564336 -> 1984792564240
	1984792564336 [label=ConvolutionBackward0]
	1984792563280 -> 1984792564336
	1984792563280 [label=ReluBackward0]
	1984792564624 -> 1984792563280
	1984792564624 [label=AddBackward0]
	1984792564720 -> 1984792564624
	1984792564720 [label=CudnnBatchNormBackward0]
	1984792564864 -> 1984792564720
	1984792564864 [label=ConvolutionBackward0]
	1984792565056 -> 1984792564864
	1984792565056 [label=ReluBackward0]
	1984792565200 -> 1984792565056
	1984792565200 [label=CudnnBatchNormBackward0]
	1984792565296 -> 1984792565200
	1984792565296 [label=ConvolutionBackward0]
	1984792565488 -> 1984792565296
	1984792565488 [label=ReluBackward0]
	1984792565632 -> 1984792565488
	1984792565632 [label=CudnnBatchNormBackward0]
	1984792565728 -> 1984792565632
	1984792565728 [label=ConvolutionBackward0]
	1984792564672 -> 1984792565728
	1984792564672 [label=ReluBackward0]
	1984792566016 -> 1984792564672
	1984792566016 [label=AddBackward0]
	1984792566112 -> 1984792566016
	1984792566112 [label=CudnnBatchNormBackward0]
	1984792566256 -> 1984792566112
	1984792566256 [label=ConvolutionBackward0]
	1984792566448 -> 1984792566256
	1984792566448 [label=ReluBackward0]
	1984792566592 -> 1984792566448
	1984792566592 [label=CudnnBatchNormBackward0]
	1984792566688 -> 1984792566592
	1984792566688 [label=ConvolutionBackward0]
	1984792566880 -> 1984792566688
	1984792566880 [label=ReluBackward0]
	1984792567024 -> 1984792566880
	1984792567024 [label=CudnnBatchNormBackward0]
	1984792567120 -> 1984792567024
	1984792567120 [label=ConvolutionBackward0]
	1984792567312 -> 1984792567120
	1984792567312 [label=ReluBackward0]
	1984792567456 -> 1984792567312
	1984792567456 [label=AddBackward0]
	1984792567552 -> 1984792567456
	1984792567552 [label=CudnnBatchNormBackward0]
	1984792567696 -> 1984792567552
	1984792567696 [label=ConvolutionBackward0]
	1984792567888 -> 1984792567696
	1984792567888 [label=ReluBackward0]
	1984792568032 -> 1984792567888
	1984792568032 [label=CudnnBatchNormBackward0]
	1984792568128 -> 1984792568032
	1984792568128 [label=ConvolutionBackward0]
	1984792568320 -> 1984792568128
	1984792568320 [label=ReluBackward0]
	1984792568464 -> 1984792568320
	1984792568464 [label=CudnnBatchNormBackward0]
	1984792568560 -> 1984792568464
	1984792568560 [label=ConvolutionBackward0]
	1984792567504 -> 1984792568560
	1984792567504 [label=ReluBackward0]
	1984792568848 -> 1984792567504
	1984792568848 [label=AddBackward0]
	1984792568944 -> 1984792568848
	1984792568944 [label=CudnnBatchNormBackward0]
	1984792569088 -> 1984792568944
	1984792569088 [label=ConvolutionBackward0]
	1984792569280 -> 1984792569088
	1984792569280 [label=ReluBackward0]
	1984792569424 -> 1984792569280
	1984792569424 [label=CudnnBatchNormBackward0]
	1984792569520 -> 1984792569424
	1984792569520 [label=ConvolutionBackward0]
	1984792569712 -> 1984792569520
	1984792569712 [label=ReluBackward0]
	1984792569856 -> 1984792569712
	1984792569856 [label=CudnnBatchNormBackward0]
	1984792569952 -> 1984792569856
	1984792569952 [label=ConvolutionBackward0]
	1984792568896 -> 1984792569952
	1984792568896 [label=ReluBackward0]
	1984792570240 -> 1984792568896
	1984792570240 [label=AddBackward0]
	1984792570336 -> 1984792570240
	1984792570336 [label=CudnnBatchNormBackward0]
	1984792570480 -> 1984792570336
	1984792570480 [label=ConvolutionBackward0]
	1984792570672 -> 1984792570480
	1984792570672 [label=ReluBackward0]
	1984792570816 -> 1984792570672
	1984792570816 [label=CudnnBatchNormBackward0]
	1984792570912 -> 1984792570816
	1984792570912 [label=ConvolutionBackward0]
	1984792571104 -> 1984792570912
	1984792571104 [label=ReluBackward0]
	1984792571248 -> 1984792571104
	1984792571248 [label=CudnnBatchNormBackward0]
	1984792571344 -> 1984792571248
	1984792571344 [label=ConvolutionBackward0]
	1984792571536 -> 1984792571344
	1984792571536 [label=MaxPool2DWithIndicesBackward0]
	1984792571680 -> 1984792571536
	1984792571680 [label=ReluBackward0]
	1984792571776 -> 1984792571680
	1984792571776 [label=CudnnBatchNormBackward0]
	1984792571872 -> 1984792571776
	1984792571872 [label=ConvolutionBackward0]
	1984792572064 -> 1984792571872
	1984791912976 [label="model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	1984791912976 -> 1984792572064
	1984792572064 [label=AccumulateGrad]
	1984792571824 -> 1984792571776
	1984791913072 [label="model.bn1.weight
 (64)" fillcolor=lightblue]
	1984791913072 -> 1984792571824
	1984792571824 [label=AccumulateGrad]
	1984792571584 -> 1984792571776
	1984791913168 [label="model.bn1.bias
 (64)" fillcolor=lightblue]
	1984791913168 -> 1984792571584
	1984792571584 [label=AccumulateGrad]
	1984792571488 -> 1984792571344
	1984791914128 [label="model.layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	1984791914128 -> 1984792571488
	1984792571488 [label=AccumulateGrad]
	1984792571296 -> 1984792571248
	1984791914224 [label="model.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1984791914224 -> 1984792571296
	1984792571296 [label=AccumulateGrad]
	1984792571152 -> 1984792571248
	1984791914320 [label="model.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1984791914320 -> 1984792571152
	1984792571152 [label=AccumulateGrad]
	1984792571056 -> 1984792570912
	1984791914704 [label="model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1984791914704 -> 1984792571056
	1984792571056 [label=AccumulateGrad]
	1984792570864 -> 1984792570816
	1984791914800 [label="model.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1984791914800 -> 1984792570864
	1984792570864 [label=AccumulateGrad]
	1984792570720 -> 1984792570816
	1984791914896 [label="model.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1984791914896 -> 1984792570720
	1984792570720 [label=AccumulateGrad]
	1984792570624 -> 1984792570480
	1984791915280 [label="model.layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1984791915280 -> 1984792570624
	1984792570624 [label=AccumulateGrad]
	1984792570432 -> 1984792570336
	1984791915376 [label="model.layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	1984791915376 -> 1984792570432
	1984792570432 [label=AccumulateGrad]
	1984792570384 -> 1984792570336
	1984791915472 [label="model.layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	1984791915472 -> 1984792570384
	1984792570384 [label=AccumulateGrad]
	1984792570288 -> 1984792570240
	1984792570288 [label=CudnnBatchNormBackward0]
	1984792571008 -> 1984792570288
	1984792571008 [label=ConvolutionBackward0]
	1984792571536 -> 1984792571008
	1984792571392 -> 1984792571008
	1984791913552 [label="model.layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1984791913552 -> 1984792571392
	1984792571392 [label=AccumulateGrad]
	1984792570576 -> 1984792570288
	1984791913648 [label="model.layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1984791913648 -> 1984792570576
	1984792570576 [label=AccumulateGrad]
	1984792570528 -> 1984792570288
	1984791913744 [label="model.layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1984791913744 -> 1984792570528
	1984792570528 [label=AccumulateGrad]
	1984792570144 -> 1984792569952
	1984791915856 [label="model.layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1984791915856 -> 1984792570144
	1984792570144 [label=AccumulateGrad]
	1984792569904 -> 1984792569856
	1984791915952 [label="model.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1984791915952 -> 1984792569904
	1984792569904 [label=AccumulateGrad]
	1984792569760 -> 1984792569856
	1984791916048 [label="model.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1984791916048 -> 1984792569760
	1984792569760 [label=AccumulateGrad]
	1984792569664 -> 1984792569520
	1984791916432 [label="model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1984791916432 -> 1984792569664
	1984792569664 [label=AccumulateGrad]
	1984792569472 -> 1984792569424
	1984408867024 [label="model.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1984408867024 -> 1984792569472
	1984792569472 [label=AccumulateGrad]
	1984792569328 -> 1984792569424
	1984408866736 [label="model.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1984408866736 -> 1984792569328
	1984792569328 [label=AccumulateGrad]
	1984792569232 -> 1984792569088
	1984408866256 [label="model.layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1984408866256 -> 1984792569232
	1984792569232 [label=AccumulateGrad]
	1984792569040 -> 1984792568944
	1984408866064 [label="model.layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	1984408866064 -> 1984792569040
	1984792569040 [label=AccumulateGrad]
	1984792568992 -> 1984792568944
	1984408866352 [label="model.layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	1984408866352 -> 1984792568992
	1984792568992 [label=AccumulateGrad]
	1984792568896 -> 1984792568848
	1984792568752 -> 1984792568560
	1984791916720 [label="model.layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1984791916720 -> 1984792568752
	1984792568752 [label=AccumulateGrad]
	1984792568512 -> 1984792568464
	1984791916816 [label="model.layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	1984791916816 -> 1984792568512
	1984792568512 [label=AccumulateGrad]
	1984792568368 -> 1984792568464
	1984791916912 [label="model.layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	1984791916912 -> 1984792568368
	1984792568368 [label=AccumulateGrad]
	1984792568272 -> 1984792568128
	1984791917296 [label="model.layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1984791917296 -> 1984792568272
	1984792568272 [label=AccumulateGrad]
	1984792568080 -> 1984792568032
	1984791917392 [label="model.layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	1984791917392 -> 1984792568080
	1984792568080 [label=AccumulateGrad]
	1984792567936 -> 1984792568032
	1984791917488 [label="model.layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	1984791917488 -> 1984792567936
	1984792567936 [label=AccumulateGrad]
	1984792567840 -> 1984792567696
	1984791917872 [label="model.layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1984791917872 -> 1984792567840
	1984792567840 [label=AccumulateGrad]
	1984792567648 -> 1984792567552
	1984791917968 [label="model.layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	1984791917968 -> 1984792567648
	1984792567648 [label=AccumulateGrad]
	1984792567600 -> 1984792567552
	1984791918064 [label="model.layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	1984791918064 -> 1984792567600
	1984792567600 [label=AccumulateGrad]
	1984792567504 -> 1984792567456
	1984792567264 -> 1984792567120
	1984791919024 [label="model.layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	1984791919024 -> 1984792567264
	1984792567264 [label=AccumulateGrad]
	1984792567072 -> 1984792567024
	1984791919120 [label="model.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1984791919120 -> 1984792567072
	1984792567072 [label=AccumulateGrad]
	1984792566928 -> 1984792567024
	1984791919216 [label="model.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1984791919216 -> 1984792566928
	1984792566928 [label=AccumulateGrad]
	1984792566832 -> 1984792566688
	1984791919600 [label="model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1984791919600 -> 1984792566832
	1984792566832 [label=AccumulateGrad]
	1984792566640 -> 1984792566592
	1984791919696 [label="model.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1984791919696 -> 1984792566640
	1984792566640 [label=AccumulateGrad]
	1984792566496 -> 1984792566592
	1984791919792 [label="model.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1984791919792 -> 1984792566496
	1984792566496 [label=AccumulateGrad]
	1984792566400 -> 1984792566256
	1984791920176 [label="model.layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1984791920176 -> 1984792566400
	1984792566400 [label=AccumulateGrad]
	1984792566208 -> 1984792566112
	1984791920272 [label="model.layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	1984791920272 -> 1984792566208
	1984792566208 [label=AccumulateGrad]
	1984792566160 -> 1984792566112
	1984791920368 [label="model.layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	1984791920368 -> 1984792566160
	1984792566160 [label=AccumulateGrad]
	1984792566064 -> 1984792566016
	1984792566064 [label=CudnnBatchNormBackward0]
	1984792566784 -> 1984792566064
	1984792566784 [label=ConvolutionBackward0]
	1984792567312 -> 1984792566784
	1984792567168 -> 1984792566784
	1984791918448 [label="model.layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1984791918448 -> 1984792567168
	1984792567168 [label=AccumulateGrad]
	1984792566352 -> 1984792566064
	1984791918544 [label="model.layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1984791918544 -> 1984792566352
	1984792566352 [label=AccumulateGrad]
	1984792566304 -> 1984792566064
	1984791918640 [label="model.layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1984791918640 -> 1984792566304
	1984792566304 [label=AccumulateGrad]
	1984792565920 -> 1984792565728
	1984792019120 [label="model.layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1984792019120 -> 1984792565920
	1984792565920 [label=AccumulateGrad]
	1984792565680 -> 1984792565632
	1984792019216 [label="model.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1984792019216 -> 1984792565680
	1984792565680 [label=AccumulateGrad]
	1984792565536 -> 1984792565632
	1984792019312 [label="model.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1984792019312 -> 1984792565536
	1984792565536 [label=AccumulateGrad]
	1984792565440 -> 1984792565296
	1984792019696 [label="model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1984792019696 -> 1984792565440
	1984792565440 [label=AccumulateGrad]
	1984792565248 -> 1984792565200
	1984792019792 [label="model.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1984792019792 -> 1984792565248
	1984792565248 [label=AccumulateGrad]
	1984792565104 -> 1984792565200
	1984792019888 [label="model.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1984792019888 -> 1984792565104
	1984792565104 [label=AccumulateGrad]
	1984792565008 -> 1984792564864
	1984792020272 [label="model.layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1984792020272 -> 1984792565008
	1984792565008 [label=AccumulateGrad]
	1984792564816 -> 1984792564720
	1984792020368 [label="model.layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	1984792020368 -> 1984792564816
	1984792564816 [label=AccumulateGrad]
	1984792564768 -> 1984792564720
	1984792020464 [label="model.layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	1984792020464 -> 1984792564768
	1984792564768 [label=AccumulateGrad]
	1984792564672 -> 1984792564624
	1984792564528 -> 1984792564336
	1984792020848 [label="model.layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1984792020848 -> 1984792564528
	1984792564528 [label=AccumulateGrad]
	1984792564288 -> 1984792564240
	1984792020944 [label="model.layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	1984792020944 -> 1984792564288
	1984792564288 [label=AccumulateGrad]
	1984792564144 -> 1984792564240
	1984792021040 [label="model.layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	1984792021040 -> 1984792564144
	1984792564144 [label=AccumulateGrad]
	1984792564048 -> 1984792563904
	1984792021424 [label="model.layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1984792021424 -> 1984792564048
	1984792564048 [label=AccumulateGrad]
	1984792563856 -> 1984792563808
	1984792021520 [label="model.layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	1984792021520 -> 1984792563856
	1984792563856 [label=AccumulateGrad]
	1984792563712 -> 1984792563808
	1984792021616 [label="model.layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	1984792021616 -> 1984792563712
	1984792563712 [label=AccumulateGrad]
	1984792563616 -> 1984792563472
	1984792022000 [label="model.layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1984792022000 -> 1984792563616
	1984792563616 [label=AccumulateGrad]
	1984792563424 -> 1984792563328
	1984792022096 [label="model.layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	1984792022096 -> 1984792563424
	1984792563424 [label=AccumulateGrad]
	1984792563376 -> 1984792563328
	1984792022192 [label="model.layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	1984792022192 -> 1984792563376
	1984792563376 [label=AccumulateGrad]
	1984792563280 -> 1984792563232
	1984792563136 -> 1984792562944
	1984792022576 [label="model.layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1984792022576 -> 1984792563136
	1984792563136 [label=AccumulateGrad]
	1984792562896 -> 1984792562848
	1984792022672 [label="model.layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	1984792022672 -> 1984792562896
	1984792562896 [label=AccumulateGrad]
	1984792562752 -> 1984792562848
	1984792022768 [label="model.layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	1984792022768 -> 1984792562752
	1984792562752 [label=AccumulateGrad]
	1984792562656 -> 1984792562512
	1984792023152 [label="model.layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1984792023152 -> 1984792562656
	1984792562656 [label=AccumulateGrad]
	1984792562464 -> 1984792562416
	1984792023248 [label="model.layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	1984792023248 -> 1984792562464
	1984792562464 [label=AccumulateGrad]
	1984792562320 -> 1984792562416
	1984792023344 [label="model.layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	1984792023344 -> 1984792562320
	1984792562320 [label=AccumulateGrad]
	1984792562224 -> 1984792562080
	1984792023728 [label="model.layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1984792023728 -> 1984792562224
	1984792562224 [label=AccumulateGrad]
	1984792562032 -> 1984792561936
	1984792023824 [label="model.layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	1984792023824 -> 1984792562032
	1984792562032 [label=AccumulateGrad]
	1984792561984 -> 1984792561936
	1984792023920 [label="model.layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	1984792023920 -> 1984792561984
	1984792561984 [label=AccumulateGrad]
	1984792561888 -> 1984792561840
	1984792561648 -> 1984792561504
	1984792024880 [label="model.layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	1984792024880 -> 1984792561648
	1984792561648 [label=AccumulateGrad]
	1984792561456 -> 1984792561408
	1984792024976 [label="model.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1984792024976 -> 1984792561456
	1984792561456 [label=AccumulateGrad]
	1984792561312 -> 1984792561408
	1984792025072 [label="model.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1984792025072 -> 1984792561312
	1984792561312 [label=AccumulateGrad]
	1984792561216 -> 1984792561072
	1984792025456 [label="model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1984792025456 -> 1984792561216
	1984792561216 [label=AccumulateGrad]
	1984792561024 -> 1984792560976
	1984792025552 [label="model.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1984792025552 -> 1984792561024
	1984792561024 [label=AccumulateGrad]
	1984792560880 -> 1984792560976
	1984792025648 [label="model.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1984792025648 -> 1984792560880
	1984792560880 [label=AccumulateGrad]
	1984792560784 -> 1984792560640
	1984792026032 [label="model.layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1984792026032 -> 1984792560784
	1984792560784 [label=AccumulateGrad]
	1984792560592 -> 1984792560496
	1984792026128 [label="model.layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	1984792026128 -> 1984792560592
	1984792560592 [label=AccumulateGrad]
	1984792560544 -> 1984792560496
	1984792026224 [label="model.layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	1984792026224 -> 1984792560544
	1984792560544 [label=AccumulateGrad]
	1984792560448 -> 1984792560400
	1984792560448 [label=CudnnBatchNormBackward0]
	1984792561168 -> 1984792560448
	1984792561168 [label=ConvolutionBackward0]
	1984792561696 -> 1984792561168
	1984792561552 -> 1984792561168
	1984792024304 [label="model.layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	1984792024304 -> 1984792561552
	1984792561552 [label=AccumulateGrad]
	1984792560736 -> 1984792560448
	1984792024400 [label="model.layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	1984792024400 -> 1984792560736
	1984792560736 [label=AccumulateGrad]
	1984792560688 -> 1984792560448
	1984792024496 [label="model.layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	1984792024496 -> 1984792560688
	1984792560688 [label=AccumulateGrad]
	1984792560304 -> 1984792560112
	1984792026608 [label="model.layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1984792026608 -> 1984792560304
	1984792560304 [label=AccumulateGrad]
	1984792560064 -> 1984792560016
	1984792026704 [label="model.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1984792026704 -> 1984792560064
	1984792560064 [label=AccumulateGrad]
	1984792559920 -> 1984792560016
	1984792026800 [label="model.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1984792026800 -> 1984792559920
	1984792559920 [label=AccumulateGrad]
	1984792559824 -> 1984404731024
	1984792027184 [label="model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1984792027184 -> 1984792559824
	1984792559824 [label=AccumulateGrad]
	1984404733808 -> 1984404725216
	1984792027280 [label="model.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1984792027280 -> 1984404733808
	1984404733808 [label=AccumulateGrad]
	1984792559680 -> 1984404725216
	1984792027376 [label="model.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1984792027376 -> 1984792559680
	1984792559680 [label=AccumulateGrad]
	1984404727136 -> 1984404732272
	1984792027760 [label="model.layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1984792027760 -> 1984404727136
	1984404727136 [label=AccumulateGrad]
	1984404727760 -> 1984404728528
	1984792027856 [label="model.layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	1984792027856 -> 1984404727760
	1984404727760 [label=AccumulateGrad]
	1984404723056 -> 1984404728528
	1984792027952 [label="model.layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	1984792027952 -> 1984404723056
	1984404723056 [label=AccumulateGrad]
	1984404733232 -> 1984404726464
	1984404726368 -> 1984404733856
	1984792028336 [label="model.layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1984792028336 -> 1984404726368
	1984404726368 [label=AccumulateGrad]
	1984404723392 -> 1984404733328
	1984792028432 [label="model.layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	1984792028432 -> 1984404723392
	1984404723392 [label=AccumulateGrad]
	1984404731168 -> 1984404733328
	1984792028528 [label="model.layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	1984792028528 -> 1984404731168
	1984404731168 [label=AccumulateGrad]
	1984404731600 -> 1984404728720
	1984792028912 [label="model.layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1984792028912 -> 1984404731600
	1984404731600 [label=AccumulateGrad]
	1984404731744 -> 1984404725504
	1984792029008 [label="model.layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	1984792029008 -> 1984404731744
	1984404731744 [label=AccumulateGrad]
	1984404732368 -> 1984404725504
	1984792029104 [label="model.layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	1984792029104 -> 1984404732368
	1984404732368 [label=AccumulateGrad]
	1984404729536 -> 1984404728912
	1984792029488 [label="model.layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1984792029488 -> 1984404729536
	1984404729536 [label=AccumulateGrad]
	1984404730880 -> 1984404733088
	1984792029584 [label="model.layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	1984792029584 -> 1984404730880
	1984404730880 [label=AccumulateGrad]
	1984404729296 -> 1984404733088
	1984792029680 [label="model.layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	1984792029680 -> 1984404729296
	1984404729296 [label=AccumulateGrad]
	1984404733040 -> 1984404732032
	1984404730640 -> 1984404725024
	1984792030064 [label="model.layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1984792030064 -> 1984404730640
	1984404730640 [label=AccumulateGrad]
	1984404730832 -> 1984404723776
	1984792030160 [label="model.layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	1984792030160 -> 1984404730832
	1984404730832 [label=AccumulateGrad]
	1984404727184 -> 1984404723776
	1984792030256 [label="model.layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	1984792030256 -> 1984404727184
	1984404727184 [label=AccumulateGrad]
	1984404727232 -> 1984404728288
	1984792030640 [label="model.layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1984792030640 -> 1984404727232
	1984404727232 [label=AccumulateGrad]
	1984404731696 -> 1984404723008
	1984792030736 [label="model.layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	1984792030736 -> 1984404731696
	1984404731696 [label=AccumulateGrad]
	1984404724400 -> 1984404723008
	1984792030832 [label="model.layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	1984792030832 -> 1984404724400
	1984404724400 [label=AccumulateGrad]
	1984404724736 -> 1984404726656
	1984792031216 [label="model.layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1984792031216 -> 1984404724736
	1984404724736 [label=AccumulateGrad]
	1984404732128 -> 1984404725408
	1984792031312 [label="model.layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	1984792031312 -> 1984404732128
	1984404732128 [label=AccumulateGrad]
	1984404723536 -> 1984404725408
	1984792031408 [label="model.layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	1984792031408 -> 1984404723536
	1984404723536 [label=AccumulateGrad]
	1984404724928 -> 1984404730016
	1984404728432 -> 1984404724688
	1984792031792 [label="model.layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1984792031792 -> 1984404728432
	1984404728432 [label=AccumulateGrad]
	1984404726224 -> 1984404726416
	1984792031888 [label="model.layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	1984792031888 -> 1984404726224
	1984404726224 [label=AccumulateGrad]
	1984404725360 -> 1984404726416
	1984792031984 [label="model.layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	1984792031984 -> 1984404725360
	1984404725360 [label=AccumulateGrad]
	1984404725792 -> 1984404725552
	1984792032368 [label="model.layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1984792032368 -> 1984404725792
	1984404725792 [label=AccumulateGrad]
	1984404730928 -> 1984404729632
	1984792032464 [label="model.layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	1984792032464 -> 1984404730928
	1984404730928 [label=AccumulateGrad]
	1984404724976 -> 1984404729632
	1984792032560 [label="model.layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	1984792032560 -> 1984404724976
	1984404724976 [label=AccumulateGrad]
	1984404726608 -> 1984404723824
	1984792032944 [label="model.layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1984792032944 -> 1984404726608
	1984404726608 [label=AccumulateGrad]
	1984404725168 -> 1984404726896
	1984792033040 [label="model.layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	1984792033040 -> 1984404725168
	1984404725168 [label=AccumulateGrad]
	1984404727472 -> 1984404726896
	1984792033136 [label="model.layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	1984792033136 -> 1984404727472
	1984404727472 [label=AccumulateGrad]
	1984404725936 -> 1984404728000
	1984404728768 -> 1984404725264
	1984792033520 [label="model.layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1984792033520 -> 1984404728768
	1984404728768 [label=AccumulateGrad]
	1984404725312 -> 1984404728144
	1984792033616 [label="model.layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	1984792033616 -> 1984404725312
	1984404725312 [label=AccumulateGrad]
	1984404728096 -> 1984404728144
	1984792033712 [label="model.layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	1984792033712 -> 1984404728096
	1984404728096 [label=AccumulateGrad]
	1984404725888 -> 1984404726992
	1984792034096 [label="model.layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1984792034096 -> 1984404725888
	1984404725888 [label=AccumulateGrad]
	1984404732560 -> 1984404730304
	1984792034192 [label="model.layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	1984792034192 -> 1984404732560
	1984404732560 [label=AccumulateGrad]
	1984404727664 -> 1984404730304
	1984792034288 [label="model.layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	1984792034288 -> 1984404727664
	1984404727664 [label=AccumulateGrad]
	1984404728192 -> 1984404729776
	1984792034672 [label="model.layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1984792034672 -> 1984404728192
	1984404728192 [label=AccumulateGrad]
	1984404727280 -> 1984404723632
	1984792034768 [label="model.layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	1984792034768 -> 1984404727280
	1984404727280 [label=AccumulateGrad]
	1984404727088 -> 1984404723632
	1984792034864 [label="model.layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	1984792034864 -> 1984404727088
	1984404727088 [label=AccumulateGrad]
	1984404732800 -> 1984404728480
	1984404733712 -> 1984404726800
	1984792265264 [label="model.layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	1984792265264 -> 1984404733712
	1984404733712 [label=AccumulateGrad]
	1984404727904 -> 1984404727952
	1984792265360 [label="model.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1984792265360 -> 1984404727904
	1984404727904 [label=AccumulateGrad]
	1984404728672 -> 1984404727952
	1984792265456 [label="model.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1984792265456 -> 1984404728672
	1984404728672 [label=AccumulateGrad]
	1984404729824 -> 1984404730496
	1984792265840 [label="model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1984792265840 -> 1984404729824
	1984404729824 [label=AccumulateGrad]
	1984404730592 -> 1984404730688
	1984792265936 [label="model.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1984792265936 -> 1984404730592
	1984404730592 [label=AccumulateGrad]
	1984404723200 -> 1984404730688
	1984792266032 [label="model.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1984792266032 -> 1984404723200
	1984404723200 [label=AccumulateGrad]
	1984404723680 -> 1984404732080
	1984792266416 [label="model.layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1984792266416 -> 1984404723680
	1984404723680 [label=AccumulateGrad]
	1984404724160 -> 1984404724352
	1984792266512 [label="model.layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	1984792266512 -> 1984404724160
	1984404724160 [label=AccumulateGrad]
	1984404724304 -> 1984404724352
	1984792266608 [label="model.layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	1984792266608 -> 1984404724304
	1984404724304 [label=AccumulateGrad]
	1984404732848 -> 1984404724640
	1984404732848 [label=CudnnBatchNormBackward0]
	1984404730064 -> 1984404732848
	1984404730064 [label=ConvolutionBackward0]
	1984404730736 -> 1984404730064
	1984404726704 -> 1984404730064
	1984792035248 [label="model.layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	1984792035248 -> 1984404726704
	1984404726704 [label=AccumulateGrad]
	1984404731936 -> 1984404732848
	1984792264784 [label="model.layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	1984792264784 -> 1984404731936
	1984404731936 [label=AccumulateGrad]
	1984404723872 -> 1984404732848
	1984792264880 [label="model.layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	1984792264880 -> 1984404723872
	1984404723872 [label=AccumulateGrad]
	1984404732944 -> 1984404733520
	1984792266992 [label="model.layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1984792266992 -> 1984404732944
	1984404732944 [label=AccumulateGrad]
	1984404725600 -> 1984405770576
	1984792267088 [label="model.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1984792267088 -> 1984404725600
	1984404725600 [label=AccumulateGrad]
	1984404725696 -> 1984405770576
	1984792267184 [label="model.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1984792267184 -> 1984404725696
	1984404725696 [label=AccumulateGrad]
	1984405770192 -> 1984405779984
	1984792267568 [label="model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1984792267568 -> 1984405770192
	1984405770192 [label=AccumulateGrad]
	1984405774944 -> 1984405769424
	1984792267664 [label="model.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1984792267664 -> 1984405774944
	1984405774944 [label=AccumulateGrad]
	1984405778016 -> 1984405769424
	1984792267760 [label="model.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1984792267760 -> 1984405778016
	1984405778016 [label=AccumulateGrad]
	1984405773456 -> 1984405778688
	1984792268144 [label="model.layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1984792268144 -> 1984405773456
	1984405773456 [label=AccumulateGrad]
	1984405781712 -> 1984405780176
	1984792268240 [label="model.layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	1984792268240 -> 1984405781712
	1984405781712 [label=AccumulateGrad]
	1984405775760 -> 1984405780176
	1984792268336 [label="model.layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	1984792268336 -> 1984405775760
	1984405775760 [label=AccumulateGrad]
	1984405780560 -> 1984405781040
	1984405782432 -> 1984405774752
	1984792268720 [label="model.layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1984792268720 -> 1984405782432
	1984405782432 [label=AccumulateGrad]
	1984405772448 -> 1984405777680
	1984792268816 [label="model.layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	1984792268816 -> 1984405772448
	1984405772448 [label=AccumulateGrad]
	1984405766208 -> 1984405777680
	1984792268912 [label="model.layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	1984792268912 -> 1984405766208
	1984405766208 [label=AccumulateGrad]
	1984405774608 -> 1984405766640
	1984792269296 [label="model.layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1984792269296 -> 1984405774608
	1984405774608 [label=AccumulateGrad]
	1984405766688 -> 1984405775328
	1984792269392 [label="model.layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	1984792269392 -> 1984405766688
	1984405766688 [label=AccumulateGrad]
	1984405767264 -> 1984405775328
	1984792269488 [label="model.layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	1984792269488 -> 1984405767264
	1984405767264 [label=AccumulateGrad]
	1984405775568 -> 1984405775904
	1984792269872 [label="model.layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1984792269872 -> 1984405775568
	1984405775568 [label=AccumulateGrad]
	1984405767744 -> 1984405776192
	1984792269968 [label="model.layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	1984792269968 -> 1984405767744
	1984405767744 [label=AccumulateGrad]
	1984405775952 -> 1984405776192
	1984792270064 [label="model.layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	1984792270064 -> 1984405775952
	1984405775952 [label=AccumulateGrad]
	1984405767936 -> 1984405776288
	1984405777488 -> 1984405769136
	1984405777488 [label=TBackward0]
	1984405768128 -> 1984405777488
	1984792270640 [label="model.fc.weight
 (19, 2048)" fillcolor=lightblue]
	1984792270640 -> 1984405768128
	1984405768128 [label=AccumulateGrad]
	1984405769376 -> 1984792650448
}
