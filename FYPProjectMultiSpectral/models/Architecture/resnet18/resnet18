digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1361760812304 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1361827584352 [label=AddmmBackward0]
	1361827582960 -> 1361827584352
	1361829851600 [label="fc.bias
 (19)" fillcolor=lightblue]
	1361829851600 -> 1361827582960
	1361827582960 [label=AccumulateGrad]
	1361827585216 -> 1361827584352
	1361827585216 [label=ViewBackward0]
	1361827585600 -> 1361827585216
	1361827585600 [label=MeanBackward1]
	1361827584448 -> 1361827585600
	1361827584448 [label=ReluBackward0]
	1361827585264 -> 1361827584448
	1361827585264 [label=AddBackward0]
	1361827584880 -> 1361827585264
	1361827584880 [label=CudnnBatchNormBackward0]
	1361827586608 -> 1361827584880
	1361827586608 [label=ConvolutionBackward0]
	1361827584640 -> 1361827586608
	1361827584640 [label=ReluBackward0]
	1361827586272 -> 1361827584640
	1361827586272 [label=CudnnBatchNormBackward0]
	1361827591648 -> 1361827586272
	1361827591648 [label=ConvolutionBackward0]
	1361827585840 -> 1361827591648
	1361827585840 [label=ReluBackward0]
	1361827586896 -> 1361827585840
	1361827586896 [label=AddBackward0]
	1361827584256 -> 1361827586896
	1361827584256 [label=CudnnBatchNormBackward0]
	1361827583728 -> 1361827584256
	1361827583728 [label=ConvolutionBackward0]
	1361827591360 -> 1361827583728
	1361827591360 [label=ReluBackward0]
	1361827585792 -> 1361827591360
	1361827585792 [label=CudnnBatchNormBackward0]
	1361827585408 -> 1361827585792
	1361827585408 [label=ConvolutionBackward0]
	1361827584592 -> 1361827585408
	1361827584592 [label=ReluBackward0]
	1361827591312 -> 1361827584592
	1361827591312 [label=AddBackward0]
	1361827586848 -> 1361827591312
	1361827586848 [label=CudnnBatchNormBackward0]
	1361827585072 -> 1361827586848
	1361827585072 [label=ConvolutionBackward0]
	1361827585456 -> 1361827585072
	1361827585456 [label=ReluBackward0]
	1361827591072 -> 1361827585456
	1361827591072 [label=CudnnBatchNormBackward0]
	1361827585552 -> 1361827591072
	1361827585552 [label=ConvolutionBackward0]
	1361827585648 -> 1361827585552
	1361827585648 [label=ReluBackward0]
	1361827587328 -> 1361827585648
	1361827587328 [label=AddBackward0]
	1361827588768 -> 1361827587328
	1361827588768 [label=CudnnBatchNormBackward0]
	1361827585984 -> 1361827588768
	1361827585984 [label=ConvolutionBackward0]
	1361827578352 -> 1361827585984
	1361827578352 [label=ReluBackward0]
	1361827577968 -> 1361827578352
	1361827577968 [label=CudnnBatchNormBackward0]
	1361827578256 -> 1361827577968
	1361827578256 [label=ConvolutionBackward0]
	1361827578832 -> 1361827578256
	1361827578832 [label=ReluBackward0]
	1361827580368 -> 1361827578832
	1361827580368 [label=AddBackward0]
	1361827580848 -> 1361827580368
	1361827580848 [label=CudnnBatchNormBackward0]
	1361827579984 -> 1361827580848
	1361827579984 [label=ConvolutionBackward0]
	1361827580560 -> 1361827579984
	1361827580560 [label=ReluBackward0]
	1361827582288 -> 1361827580560
	1361827582288 [label=CudnnBatchNormBackward0]
	1361827582576 -> 1361827582288
	1361827582576 [label=ConvolutionBackward0]
	1361827579456 -> 1361827582576
	1361827579456 [label=ReluBackward0]
	1361827590976 -> 1361827579456
	1361827590976 [label=AddBackward0]
	1361827585120 -> 1361827590976
	1361827585120 [label=CudnnBatchNormBackward0]
	1361827585024 -> 1361827585120
	1361827585024 [label=ConvolutionBackward0]
	1361827586080 -> 1361827585024
	1361827586080 [label=ReluBackward0]
	1361827581472 -> 1361827586080
	1361827581472 [label=CudnnBatchNormBackward0]
	1361827583488 -> 1361827581472
	1361827583488 [label=ConvolutionBackward0]
	1361827582240 -> 1361827583488
	1361827582240 [label=ReluBackward0]
	1361827581328 -> 1361827582240
	1361827581328 [label=AddBackward0]
	1361827583200 -> 1361827581328
	1361827583200 [label=CudnnBatchNormBackward0]
	1361827580656 -> 1361827583200
	1361827580656 [label=ConvolutionBackward0]
	1361827582384 -> 1361827580656
	1361827582384 [label=ReluBackward0]
	1361827582672 -> 1361827582384
	1361827582672 [label=CudnnBatchNormBackward0]
	1361827580704 -> 1361827582672
	1361827580704 [label=ConvolutionBackward0]
	1361827579504 -> 1361827580704
	1361827579504 [label=ReluBackward0]
	1361827580752 -> 1361827579504
	1361827580752 [label=AddBackward0]
	1361827581520 -> 1361827580752
	1361827581520 [label=CudnnBatchNormBackward0]
	1361827579936 -> 1361827581520
	1361827579936 [label=ConvolutionBackward0]
	1361827582432 -> 1361827579936
	1361827582432 [label=ReluBackward0]
	1361827582048 -> 1361827582432
	1361827582048 [label=CudnnBatchNormBackward0]
	1361827580176 -> 1361827582048
	1361827580176 [label=ConvolutionBackward0]
	1361827581664 -> 1361827580176
	1361827581664 [label=MaxPool2DWithIndicesBackward0]
	1361827587760 -> 1361827581664
	1361827587760 [label=ReluBackward0]
	1361827580944 -> 1361827587760
	1361827580944 [label=CudnnBatchNormBackward0]
	1361827578976 -> 1361827580944
	1361827578976 [label=ConvolutionBackward0]
	1361827577920 -> 1361827578976
	1361829851408 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	1361829851408 -> 1361827577920
	1361827577920 [label=AccumulateGrad]
	1361827580320 -> 1361827580944
	1361829839792 [label="bn1.weight
 (64)" fillcolor=lightblue]
	1361829839792 -> 1361827580320
	1361827580320 [label=AccumulateGrad]
	1361827578208 -> 1361827580944
	1361829839984 [label="bn1.bias
 (64)" fillcolor=lightblue]
	1361829839984 -> 1361827578208
	1361827578208 [label=AccumulateGrad]
	1361827581904 -> 1361827580176
	1361829840272 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1361829840272 -> 1361827581904
	1361827581904 [label=AccumulateGrad]
	1361827580896 -> 1361827582048
	1361829840368 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1361829840368 -> 1361827580896
	1361827580896 [label=AccumulateGrad]
	1361827580032 -> 1361827582048
	1361829840464 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1361829840464 -> 1361827580032
	1361827580032 [label=AccumulateGrad]
	1361827578496 -> 1361827579936
	1361829840848 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1361829840848 -> 1361827578496
	1361827578496 [label=AccumulateGrad]
	1361827580800 -> 1361827581520
	1361829840944 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1361829840944 -> 1361827580800
	1361827580800 [label=AccumulateGrad]
	1361827580416 -> 1361827581520
	1361829841040 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1361829841040 -> 1361827580416
	1361827580416 [label=AccumulateGrad]
	1361827581664 -> 1361827580752
	1361827585696 -> 1361827580704
	1361829841424 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1361829841424 -> 1361827585696
	1361827585696 [label=AccumulateGrad]
	1361827586944 -> 1361827582672
	1361829841520 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1361829841520 -> 1361827586944
	1361827586944 [label=AccumulateGrad]
	1361827579312 -> 1361827582672
	1361829841616 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1361829841616 -> 1361827579312
	1361827579312 [label=AccumulateGrad]
	1361827583248 -> 1361827580656
	1361829842000 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1361829842000 -> 1361827583248
	1361827583248 [label=AccumulateGrad]
	1361827581184 -> 1361827583200
	1361829842096 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1361829842096 -> 1361827581184
	1361827581184 [label=AccumulateGrad]
	1361827583008 -> 1361827583200
	1361829842192 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1361829842192 -> 1361827583008
	1361827583008 [label=AccumulateGrad]
	1361827579504 -> 1361827581328
	1361827584112 -> 1361827583488
	1361829843152 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1361829843152 -> 1361827584112
	1361827584112 [label=AccumulateGrad]
	1361827584016 -> 1361827581472
	1361829843248 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1361829843248 -> 1361827584016
	1361827584016 [label=AccumulateGrad]
	1361827583584 -> 1361827581472
	1361829843344 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1361829843344 -> 1361827583584
	1361827583584 [label=AccumulateGrad]
	1361827585168 -> 1361827585024
	1361829843728 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1361829843728 -> 1361827585168
	1361827585168 [label=AccumulateGrad]
	1361827582864 -> 1361827585120
	1361829843824 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1361829843824 -> 1361827582864
	1361827582864 [label=AccumulateGrad]
	1361827580512 -> 1361827585120
	1361829843920 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1361829843920 -> 1361827580512
	1361827580512 [label=AccumulateGrad]
	1361827583104 -> 1361827590976
	1361827583104 [label=CudnnBatchNormBackward0]
	1361827582192 -> 1361827583104
	1361827582192 [label=ConvolutionBackward0]
	1361827582240 -> 1361827582192
	1361827582000 -> 1361827582192
	1361829842576 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1361829842576 -> 1361827582000
	1361827582000 [label=AccumulateGrad]
	1361827582816 -> 1361827583104
	1361829842672 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	1361829842672 -> 1361827582816
	1361827582816 [label=AccumulateGrad]
	1361827584784 -> 1361827583104
	1361829842768 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	1361829842768 -> 1361827584784
	1361827584784 [label=AccumulateGrad]
	1361827587232 -> 1361827582576
	1361829844304 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1361829844304 -> 1361827587232
	1361827587232 [label=AccumulateGrad]
	1361827581232 -> 1361827582288
	1361829844400 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1361829844400 -> 1361827581232
	1361827581232 [label=AccumulateGrad]
	1361827581856 -> 1361827582288
	1361829844496 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1361829844496 -> 1361827581856
	1361827581856 [label=AccumulateGrad]
	1361827582096 -> 1361827579984
	1361829844880 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1361829844880 -> 1361827582096
	1361827582096 [label=AccumulateGrad]
	1361827580608 -> 1361827580848
	1361829844976 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1361829844976 -> 1361827580608
	1361827580608 [label=AccumulateGrad]
	1361827579168 -> 1361827580848
	1361829845072 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1361829845072 -> 1361827579168
	1361827579168 [label=AccumulateGrad]
	1361827579456 -> 1361827580368
	1361827579072 -> 1361827578256
	1361829846032 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1361829846032 -> 1361827579072
	1361827579072 [label=AccumulateGrad]
	1361827579840 -> 1361827577968
	1361829846128 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1361829846128 -> 1361827579840
	1361827579840 [label=AccumulateGrad]
	1361827578640 -> 1361827577968
	1361829846224 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1361829846224 -> 1361827578640
	1361827578640 [label=AccumulateGrad]
	1361827578304 -> 1361827585984
	1361829846608 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1361829846608 -> 1361827578304
	1361827578304 [label=AccumulateGrad]
	1361827588480 -> 1361827588768
	1361829846704 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1361829846704 -> 1361827588480
	1361827588480 [label=AccumulateGrad]
	1361827579120 -> 1361827588768
	1361829846800 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1361829846800 -> 1361827579120
	1361827579120 [label=AccumulateGrad]
	1361827587520 -> 1361827587328
	1361827587520 [label=CudnnBatchNormBackward0]
	1361827578544 -> 1361827587520
	1361827578544 [label=ConvolutionBackward0]
	1361827578832 -> 1361827578544
	1361827580080 -> 1361827578544
	1361829845456 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1361829845456 -> 1361827580080
	1361827580080 [label=AccumulateGrad]
	1361827587904 -> 1361827587520
	1361829845552 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1361829845552 -> 1361827587904
	1361827587904 [label=AccumulateGrad]
	1361827588144 -> 1361827587520
	1361829845648 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1361829845648 -> 1361827588144
	1361827588144 [label=AccumulateGrad]
	1361827585360 -> 1361827585552
	1361829847184 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1361829847184 -> 1361827585360
	1361827585360 [label=AccumulateGrad]
	1361827583968 -> 1361827591072
	1361829847280 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1361829847280 -> 1361827583968
	1361827583968 [label=AccumulateGrad]
	1361827591216 -> 1361827591072
	1361829847376 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1361829847376 -> 1361827591216
	1361827591216 [label=AccumulateGrad]
	1361827584400 -> 1361827585072
	1361829847760 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1361829847760 -> 1361827584400
	1361827584400 [label=AccumulateGrad]
	1361827586992 -> 1361827586848
	1361829847856 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1361829847856 -> 1361827586992
	1361827586992 [label=AccumulateGrad]
	1361827582624 -> 1361827586848
	1361829847952 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1361829847952 -> 1361827582624
	1361827582624 [label=AccumulateGrad]
	1361827585648 -> 1361827591312
	1361827591120 -> 1361827585408
	1361829848912 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1361829848912 -> 1361827591120
	1361827591120 [label=AccumulateGrad]
	1361827585744 -> 1361827585792
	1361829849008 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1361829849008 -> 1361827585744
	1361827585744 [label=AccumulateGrad]
	1361827585888 -> 1361827585792
	1361829849104 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1361829849104 -> 1361827585888
	1361827585888 [label=AccumulateGrad]
	1361827591024 -> 1361827583728
	1361829849488 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1361829849488 -> 1361827591024
	1361827591024 [label=AccumulateGrad]
	1361827586224 -> 1361827584256
	1361829849584 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1361829849584 -> 1361827586224
	1361827586224 [label=AccumulateGrad]
	1361827585312 -> 1361827584256
	1361829849680 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1361829849680 -> 1361827585312
	1361827585312 [label=AccumulateGrad]
	1361827584544 -> 1361827586896
	1361827584544 [label=CudnnBatchNormBackward0]
	1361827584208 -> 1361827584544
	1361827584208 [label=ConvolutionBackward0]
	1361827584592 -> 1361827584208
	1361827584064 -> 1361827584208
	1361829848336 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1361829848336 -> 1361827584064
	1361827584064 [label=AccumulateGrad]
	1361827584928 -> 1361827584544
	1361829848432 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1361829848432 -> 1361827584928
	1361827584928 [label=AccumulateGrad]
	1361827591792 -> 1361827584544
	1361829848528 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1361829848528 -> 1361827591792
	1361827591792 [label=AccumulateGrad]
	1361827592128 -> 1361827591648
	1361829850064 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1361829850064 -> 1361827592128
	1361827592128 [label=AccumulateGrad]
	1361827591168 -> 1361827586272
	1361829850160 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1361829850160 -> 1361827591168
	1361827591168 [label=AccumulateGrad]
	1361827586128 -> 1361827586272
	1361829850256 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1361829850256 -> 1361827586128
	1361827586128 [label=AccumulateGrad]
	1361827584832 -> 1361827586608
	1361829850640 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1361829850640 -> 1361827584832
	1361827584832 [label=AccumulateGrad]
	1361827584160 -> 1361827584880
	1361829850736 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1361829850736 -> 1361827584160
	1361827584160 [label=AccumulateGrad]
	1361827586320 -> 1361827584880
	1361829850832 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1361829850832 -> 1361827586320
	1361827586320 [label=AccumulateGrad]
	1361827585840 -> 1361827585264
	1361827583776 -> 1361827584352
	1361827583776 [label=TBackward0]
	1361827584736 -> 1361827583776
	1361829851504 [label="fc.weight
 (19, 512)" fillcolor=lightblue]
	1361829851504 -> 1361827584736
	1361827584736 [label=AccumulateGrad]
	1361827584352 -> 1361760812304
}
