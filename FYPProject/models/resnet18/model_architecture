digraph {
	graph [size="59.849999999999994,59.849999999999994"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2040912105968 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2040889628976 [label=SigmoidBackward0]
	2040889633968 -> 2040889628976
	2040889633968 [label=AddmmBackward0]
	2040889634112 -> 2040889633968
	2040911850832 [label="model.fc.bias
 (19)" fillcolor=lightblue]
	2040911850832 -> 2040889634112
	2040889634112 [label=AccumulateGrad]
	2040889633872 -> 2040889633968
	2040889633872 [label=ViewBackward0]
	2040889634160 -> 2040889633872
	2040889634160 [label=MeanBackward1]
	2040889634736 -> 2040889634160
	2040889634736 [label=ReluBackward0]
	2040889634832 -> 2040889634736
	2040889634832 [label=AddBackward0]
	2040889635696 -> 2040889634832
	2040889635696 [label=CudnnBatchNormBackward0]
	2040889635840 -> 2040889635696
	2040889635840 [label=ConvolutionBackward0]
	2040889636032 -> 2040889635840
	2040889636032 [label=ReluBackward0]
	2040889636176 -> 2040889636032
	2040889636176 [label=CudnnBatchNormBackward0]
	2040889624800 -> 2040889636176
	2040889624800 [label=ConvolutionBackward0]
	2040889635648 -> 2040889624800
	2040889635648 [label=ReluBackward0]
	2040889634208 -> 2040889635648
	2040889634208 [label=AddBackward0]
	2040889634304 -> 2040889634208
	2040889634304 [label=CudnnBatchNormBackward0]
	2040889638096 -> 2040889634304
	2040889638096 [label=ConvolutionBackward0]
	2040889638288 -> 2040889638096
	2040889638288 [label=ReluBackward0]
	2040889638432 -> 2040889638288
	2040889638432 [label=CudnnBatchNormBackward0]
	2040889638528 -> 2040889638432
	2040889638528 [label=ConvolutionBackward0]
	2040889636560 -> 2040889638528
	2040889636560 [label=ReluBackward0]
	2040889637136 -> 2040889636560
	2040889637136 [label=AddBackward0]
	2040889637472 -> 2040889637136
	2040889637472 [label=CudnnBatchNormBackward0]
	2040889637568 -> 2040889637472
	2040889637568 [label=ConvolutionBackward0]
	2040889637616 -> 2040889637568
	2040889637616 [label=ReluBackward0]
	2040889638000 -> 2040889637616
	2040889638000 [label=CudnnBatchNormBackward0]
	2040889627776 -> 2040889638000
	2040889627776 [label=ConvolutionBackward0]
	2040889636992 -> 2040889627776
	2040889636992 [label=ReluBackward0]
	2040912183600 -> 2040889636992
	2040912183600 [label=AddBackward0]
	2040912183696 -> 2040912183600
	2040912183696 [label=CudnnBatchNormBackward0]
	2040912183840 -> 2040912183696
	2040912183840 [label=ConvolutionBackward0]
	2040912184032 -> 2040912183840
	2040912184032 [label=ReluBackward0]
	2040912184176 -> 2040912184032
	2040912184176 [label=CudnnBatchNormBackward0]
	2040912184272 -> 2040912184176
	2040912184272 [label=ConvolutionBackward0]
	2040912184464 -> 2040912184272
	2040912184464 [label=ReluBackward0]
	2040912184608 -> 2040912184464
	2040912184608 [label=AddBackward0]
	2040912184704 -> 2040912184608
	2040912184704 [label=CudnnBatchNormBackward0]
	2040912184848 -> 2040912184704
	2040912184848 [label=ConvolutionBackward0]
	2040912185040 -> 2040912184848
	2040912185040 [label=ReluBackward0]
	2040912185184 -> 2040912185040
	2040912185184 [label=CudnnBatchNormBackward0]
	2040912185280 -> 2040912185184
	2040912185280 [label=ConvolutionBackward0]
	2040912184656 -> 2040912185280
	2040912184656 [label=ReluBackward0]
	2040912185568 -> 2040912184656
	2040912185568 [label=AddBackward0]
	2040912185664 -> 2040912185568
	2040912185664 [label=CudnnBatchNormBackward0]
	2040912185808 -> 2040912185664
	2040912185808 [label=ConvolutionBackward0]
	2040912186000 -> 2040912185808
	2040912186000 [label=ReluBackward0]
	2040912186144 -> 2040912186000
	2040912186144 [label=CudnnBatchNormBackward0]
	2040912186240 -> 2040912186144
	2040912186240 [label=ConvolutionBackward0]
	2040912186432 -> 2040912186240
	2040912186432 [label=ReluBackward0]
	2040912186576 -> 2040912186432
	2040912186576 [label=AddBackward0]
	2040912186672 -> 2040912186576
	2040912186672 [label=CudnnBatchNormBackward0]
	2040912186816 -> 2040912186672
	2040912186816 [label=ConvolutionBackward0]
	2040912187008 -> 2040912186816
	2040912187008 [label=ReluBackward0]
	2040912187152 -> 2040912187008
	2040912187152 [label=CudnnBatchNormBackward0]
	2040912187200 -> 2040912187152
	2040912187200 [label=ConvolutionBackward0]
	2040912186624 -> 2040912187200
	2040912186624 [label=ReluBackward0]
	2040912187584 -> 2040912186624
	2040912187584 [label=AddBackward0]
	2040912187632 -> 2040912187584
	2040912187632 [label=CudnnBatchNormBackward0]
	2040912187872 -> 2040912187632
	2040912187872 [label=ConvolutionBackward0]
	2040912188064 -> 2040912187872
	2040912188064 [label=ReluBackward0]
	2040912188208 -> 2040912188064
	2040912188208 [label=CudnnBatchNormBackward0]
	2040912188256 -> 2040912188208
	2040912188256 [label=ConvolutionBackward0]
	2040912187392 -> 2040912188256
	2040912187392 [label=MaxPool2DWithIndicesBackward0]
	2040912188640 -> 2040912187392
	2040912188640 [label=ReluBackward0]
	2040912188688 -> 2040912188640
	2040912188688 [label=CudnnBatchNormBackward0]
	2040912188832 -> 2040912188688
	2040912188832 [label=ConvolutionBackward0]
	2040912189120 -> 2040912188832
	2040889755216 [label="model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2040889755216 -> 2040912189120
	2040912189120 [label=AccumulateGrad]
	2040912188784 -> 2040912188688
	2040889759728 [label="model.bn1.weight
 (64)" fillcolor=lightblue]
	2040889759728 -> 2040912188784
	2040912188784 [label=AccumulateGrad]
	2040912188928 -> 2040912188688
	2040889759632 [label="model.bn1.bias
 (64)" fillcolor=lightblue]
	2040889759632 -> 2040912188928
	2040912188928 [label=AccumulateGrad]
	2040912188544 -> 2040912188256
	2040911805808 [label="model.layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2040911805808 -> 2040912188544
	2040912188544 [label=AccumulateGrad]
	2040912188112 -> 2040912188208
	2040911805712 [label="model.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2040911805712 -> 2040912188112
	2040912188112 [label=AccumulateGrad]
	2040912188352 -> 2040912188208
	2040911839600 [label="model.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2040911839600 -> 2040912188352
	2040912188352 [label=AccumulateGrad]
	2040912188016 -> 2040912187872
	2040911840176 [label="model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2040911840176 -> 2040912188016
	2040912188016 [label=AccumulateGrad]
	2040912187824 -> 2040912187632
	2040911840272 [label="model.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2040911840272 -> 2040912187824
	2040912187824 [label=AccumulateGrad]
	2040912187776 -> 2040912187632
	2040911840368 [label="model.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2040911840368 -> 2040912187776
	2040912187776 [label=AccumulateGrad]
	2040912187392 -> 2040912187584
	2040912187488 -> 2040912187200
	2040911840752 [label="model.layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2040911840752 -> 2040912187488
	2040912187488 [label=AccumulateGrad]
	2040912187056 -> 2040912187152
	2040911840848 [label="model.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2040911840848 -> 2040912187056
	2040912187056 [label=AccumulateGrad]
	2040912187296 -> 2040912187152
	2040911840944 [label="model.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2040911840944 -> 2040912187296
	2040912187296 [label=AccumulateGrad]
	2040912186960 -> 2040912186816
	2040911841328 [label="model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2040911841328 -> 2040912186960
	2040912186960 [label=AccumulateGrad]
	2040912186768 -> 2040912186672
	2040911841424 [label="model.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2040911841424 -> 2040912186768
	2040912186768 [label=AccumulateGrad]
	2040912186720 -> 2040912186672
	2040911841520 [label="model.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2040911841520 -> 2040912186720
	2040912186720 [label=AccumulateGrad]
	2040912186624 -> 2040912186576
	2040912186384 -> 2040912186240
	2040911842480 [label="model.layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2040911842480 -> 2040912186384
	2040912186384 [label=AccumulateGrad]
	2040912186192 -> 2040912186144
	2040911842576 [label="model.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2040911842576 -> 2040912186192
	2040912186192 [label=AccumulateGrad]
	2040912186048 -> 2040912186144
	2040911842672 [label="model.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2040911842672 -> 2040912186048
	2040912186048 [label=AccumulateGrad]
	2040912185952 -> 2040912185808
	2040911843056 [label="model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2040911843056 -> 2040912185952
	2040912185952 [label=AccumulateGrad]
	2040912185760 -> 2040912185664
	2040911843152 [label="model.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2040911843152 -> 2040912185760
	2040912185760 [label=AccumulateGrad]
	2040912185712 -> 2040912185664
	2040911843248 [label="model.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2040911843248 -> 2040912185712
	2040912185712 [label=AccumulateGrad]
	2040912185616 -> 2040912185568
	2040912185616 [label=CudnnBatchNormBackward0]
	2040912186336 -> 2040912185616
	2040912186336 [label=ConvolutionBackward0]
	2040912186432 -> 2040912186336
	2040912186480 -> 2040912186336
	2040911841904 [label="model.layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2040911841904 -> 2040912186480
	2040912186480 [label=AccumulateGrad]
	2040912185904 -> 2040912185616
	2040911842000 [label="model.layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2040911842000 -> 2040912185904
	2040912185904 [label=AccumulateGrad]
	2040912185856 -> 2040912185616
	2040911842096 [label="model.layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2040911842096 -> 2040912185856
	2040912185856 [label=AccumulateGrad]
	2040912185472 -> 2040912185280
	2040911843632 [label="model.layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2040911843632 -> 2040912185472
	2040912185472 [label=AccumulateGrad]
	2040912185232 -> 2040912185184
	2040911843728 [label="model.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2040911843728 -> 2040912185232
	2040912185232 [label=AccumulateGrad]
	2040912185088 -> 2040912185184
	2040911843824 [label="model.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2040911843824 -> 2040912185088
	2040912185088 [label=AccumulateGrad]
	2040912184992 -> 2040912184848
	2040911844208 [label="model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2040911844208 -> 2040912184992
	2040912184992 [label=AccumulateGrad]
	2040912184800 -> 2040912184704
	2040911844304 [label="model.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2040911844304 -> 2040912184800
	2040912184800 [label=AccumulateGrad]
	2040912184752 -> 2040912184704
	2040911844400 [label="model.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2040911844400 -> 2040912184752
	2040912184752 [label=AccumulateGrad]
	2040912184656 -> 2040912184608
	2040912184416 -> 2040912184272
	2040911845360 [label="model.layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2040911845360 -> 2040912184416
	2040912184416 [label=AccumulateGrad]
	2040912184224 -> 2040912184176
	2040911845456 [label="model.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2040911845456 -> 2040912184224
	2040912184224 [label=AccumulateGrad]
	2040912184080 -> 2040912184176
	2040911845552 [label="model.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2040911845552 -> 2040912184080
	2040912184080 [label=AccumulateGrad]
	2040912183984 -> 2040912183840
	2040911845936 [label="model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2040911845936 -> 2040912183984
	2040912183984 [label=AccumulateGrad]
	2040912183792 -> 2040912183696
	2040911846032 [label="model.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2040911846032 -> 2040912183792
	2040912183792 [label=AccumulateGrad]
	2040912183744 -> 2040912183696
	2040911846128 [label="model.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2040911846128 -> 2040912183744
	2040912183744 [label=AccumulateGrad]
	2040912183648 -> 2040912183600
	2040912183648 [label=CudnnBatchNormBackward0]
	2040912184368 -> 2040912183648
	2040912184368 [label=ConvolutionBackward0]
	2040912184464 -> 2040912184368
	2040912184512 -> 2040912184368
	2040911844784 [label="model.layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2040911844784 -> 2040912184512
	2040912184512 [label=AccumulateGrad]
	2040912183936 -> 2040912183648
	2040911844880 [label="model.layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2040911844880 -> 2040912183936
	2040912183936 [label=AccumulateGrad]
	2040912183888 -> 2040912183648
	2040911844976 [label="model.layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2040911844976 -> 2040912183888
	2040912183888 [label=AccumulateGrad]
	2040912183504 -> 2040889627776
	2040911846512 [label="model.layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2040911846512 -> 2040912183504
	2040912183504 [label=AccumulateGrad]
	2040889637904 -> 2040889638000
	2040911846608 [label="model.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2040911846608 -> 2040889637904
	2040889637904 [label=AccumulateGrad]
	2040889638864 -> 2040889638000
	2040911846704 [label="model.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2040911846704 -> 2040889638864
	2040889638864 [label=AccumulateGrad]
	2040889637424 -> 2040889637568
	2040911847088 [label="model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2040911847088 -> 2040889637424
	2040889637424 [label=AccumulateGrad]
	2040889637232 -> 2040889637472
	2040911847184 [label="model.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2040911847184 -> 2040889637232
	2040889637232 [label=AccumulateGrad]
	2040889637088 -> 2040889637472
	2040911847280 [label="model.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2040911847280 -> 2040889637088
	2040889637088 [label=AccumulateGrad]
	2040889636992 -> 2040889637136
	2040889638768 -> 2040889638528
	2040911848240 [label="model.layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2040911848240 -> 2040889638768
	2040889638768 [label=AccumulateGrad]
	2040889638480 -> 2040889638432
	2040911848336 [label="model.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2040911848336 -> 2040889638480
	2040889638480 [label=AccumulateGrad]
	2040889638336 -> 2040889638432
	2040911848432 [label="model.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2040911848432 -> 2040889638336
	2040889638336 [label=AccumulateGrad]
	2040889638240 -> 2040889638096
	2040911848816 [label="model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2040911848816 -> 2040889638240
	2040889638240 [label=AccumulateGrad]
	2040889638048 -> 2040889634304
	2040911848912 [label="model.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2040911848912 -> 2040889638048
	2040889638048 [label=AccumulateGrad]
	2040889634352 -> 2040889634304
	2040911849008 [label="model.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2040911849008 -> 2040889634352
	2040889634352 [label=AccumulateGrad]
	2040889634256 -> 2040889634208
	2040889634256 [label=CudnnBatchNormBackward0]
	2040889638720 -> 2040889634256
	2040889638720 [label=ConvolutionBackward0]
	2040889636560 -> 2040889638720
	2040889636512 -> 2040889638720
	2040911847664 [label="model.layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2040911847664 -> 2040889636512
	2040889636512 [label=AccumulateGrad]
	2040889638192 -> 2040889634256
	2040911847760 [label="model.layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2040911847760 -> 2040889638192
	2040889638192 [label=AccumulateGrad]
	2040889638144 -> 2040889634256
	2040911847856 [label="model.layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2040911847856 -> 2040889638144
	2040889638144 [label=AccumulateGrad]
	2040889628736 -> 2040889624800
	2040911849392 [label="model.layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2040911849392 -> 2040889628736
	2040889628736 [label=AccumulateGrad]
	2040889636224 -> 2040889636176
	2040911849488 [label="model.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2040911849488 -> 2040889636224
	2040889636224 [label=AccumulateGrad]
	2040889636080 -> 2040889636176
	2040911849584 [label="model.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2040911849584 -> 2040889636080
	2040889636080 [label=AccumulateGrad]
	2040889635984 -> 2040889635840
	2040911849968 [label="model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2040911849968 -> 2040889635984
	2040889635984 [label=AccumulateGrad]
	2040889635792 -> 2040889635696
	2040911850064 [label="model.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2040911850064 -> 2040889635792
	2040889635792 [label=AccumulateGrad]
	2040889635744 -> 2040889635696
	2040911850160 [label="model.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2040911850160 -> 2040889635744
	2040889635744 [label=AccumulateGrad]
	2040889635648 -> 2040889634832
	2040889634064 -> 2040889633968
	2040889634064 [label=TBackward0]
	2040889634784 -> 2040889634064
	2040911850736 [label="model.fc.weight
 (19, 512)" fillcolor=lightblue]
	2040911850736 -> 2040889634784
	2040889634784 [label=AccumulateGrad]
	2040889628976 -> 2040912105968
}
