digraph {
	graph [size="59.849999999999994,59.849999999999994"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2243814625488 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2243793185728 [label=SigmoidBackward0]
	2243793185872 -> 2243793185728
	2243793185872 [label=AddmmBackward0]
	2243793186016 -> 2243793185872
	2243814370352 [label="model.fc.bias
 (19)" fillcolor=lightblue]
	2243814370352 -> 2243793186016
	2243793186016 [label=AccumulateGrad]
	2243793185824 -> 2243793185872
	2243793185824 [label=ViewBackward0]
	2243793186064 -> 2243793185824
	2243793186064 [label=MeanBackward1]
	2243793186256 -> 2243793186064
	2243793186256 [label=ReluBackward0]
	2243793186352 -> 2243793186256
	2243793186352 [label=AddBackward0]
	2243793186448 -> 2243793186352
	2243793186448 [label=CudnnBatchNormBackward0]
	2243793186592 -> 2243793186448
	2243793186592 [label=ConvolutionBackward0]
	2243793186784 -> 2243793186592
	2243793186784 [label=ReluBackward0]
	2243793187696 -> 2243793186784
	2243793187696 [label=CudnnBatchNormBackward0]
	2243793185152 -> 2243793187696
	2243793185152 [label=ConvolutionBackward0]
	2243793186400 -> 2243793185152
	2243793186400 [label=ReluBackward0]
	2243793189904 -> 2243793186400
	2243793189904 [label=AddBackward0]
	2243793190144 -> 2243793189904
	2243793190144 [label=CudnnBatchNormBackward0]
	2243793190000 -> 2243793190144
	2243793190000 [label=ConvolutionBackward0]
	2243793176032 -> 2243793190000
	2243793176032 [label=ReluBackward0]
	2243793184432 -> 2243793176032
	2243793184432 [label=CudnnBatchNormBackward0]
	2243793188176 -> 2243793184432
	2243793188176 [label=ConvolutionBackward0]
	2243793188368 -> 2243793188176
	2243793188368 [label=ReluBackward0]
	2243793188512 -> 2243793188368
	2243793188512 [label=AddBackward0]
	2243793188608 -> 2243793188512
	2243793188608 [label=CudnnBatchNormBackward0]
	2243793188848 -> 2243793188608
	2243793188848 [label=ConvolutionBackward0]
	2243793190192 -> 2243793188848
	2243793190192 [label=ReluBackward0]
	2243793190816 -> 2243793190192
	2243793190816 [label=CudnnBatchNormBackward0]
	2243793190528 -> 2243793190816
	2243793190528 [label=ConvolutionBackward0]
	2243793188560 -> 2243793190528
	2243793188560 [label=ReluBackward0]
	2243793188992 -> 2243793188560
	2243793188992 [label=AddBackward0]
	2243793188128 -> 2243793188992
	2243793188128 [label=CudnnBatchNormBackward0]
	2243793177232 -> 2243793188128
	2243793177232 [label=ConvolutionBackward0]
	2243793177520 -> 2243793177232
	2243793177520 [label=ReluBackward0]
	2243793177712 -> 2243793177520
	2243793177712 [label=CudnnBatchNormBackward0]
	2243793177616 -> 2243793177712
	2243793177616 [label=ConvolutionBackward0]
	2243793177808 -> 2243793177616
	2243793177808 [label=ReluBackward0]
	2243793178144 -> 2243793177808
	2243793178144 [label=AddBackward0]
	2243793178480 -> 2243793178144
	2243793178480 [label=CudnnBatchNormBackward0]
	2243793177472 -> 2243793178480
	2243793177472 [label=ConvolutionBackward0]
	2243793178912 -> 2243793177472
	2243793178912 [label=ReluBackward0]
	2243793179296 -> 2243793178912
	2243793179296 [label=CudnnBatchNormBackward0]
	2243793179248 -> 2243793179296
	2243793179248 [label=ConvolutionBackward0]
	2243793178336 -> 2243793179248
	2243793178336 [label=ReluBackward0]
	2242031075728 -> 2243793178336
	2242031075728 [label=AddBackward0]
	2242031075824 -> 2242031075728
	2242031075824 [label=CudnnBatchNormBackward0]
	2242031075968 -> 2242031075824
	2242031075968 [label=ConvolutionBackward0]
	2242031076160 -> 2242031075968
	2242031076160 [label=ReluBackward0]
	2242031076304 -> 2242031076160
	2242031076304 [label=CudnnBatchNormBackward0]
	2242031076400 -> 2242031076304
	2242031076400 [label=ConvolutionBackward0]
	2242031076592 -> 2242031076400
	2242031076592 [label=ReluBackward0]
	2242031076736 -> 2242031076592
	2242031076736 [label=AddBackward0]
	2242031076832 -> 2242031076736
	2242031076832 [label=CudnnBatchNormBackward0]
	2242031076976 -> 2242031076832
	2242031076976 [label=ConvolutionBackward0]
	2242031077168 -> 2242031076976
	2242031077168 [label=ReluBackward0]
	2242031077312 -> 2242031077168
	2242031077312 [label=CudnnBatchNormBackward0]
	2242031077360 -> 2242031077312
	2242031077360 [label=ConvolutionBackward0]
	2242031076784 -> 2242031077360
	2242031076784 [label=ReluBackward0]
	2242031077744 -> 2242031076784
	2242031077744 [label=AddBackward0]
	2242031077792 -> 2242031077744
	2242031077792 [label=CudnnBatchNormBackward0]
	2242031078032 -> 2242031077792
	2242031078032 [label=ConvolutionBackward0]
	2242031078224 -> 2242031078032
	2242031078224 [label=ReluBackward0]
	2242031078368 -> 2242031078224
	2242031078368 [label=CudnnBatchNormBackward0]
	2242031078416 -> 2242031078368
	2242031078416 [label=ConvolutionBackward0]
	2242031077552 -> 2242031078416
	2242031077552 [label=MaxPool2DWithIndicesBackward0]
	2242031078800 -> 2242031077552
	2242031078800 [label=ReluBackward0]
	2242031078848 -> 2242031078800
	2242031078848 [label=CudnnBatchNormBackward0]
	2242031078992 -> 2242031078848
	2242031078992 [label=ConvolutionBackward0]
	2242031079280 -> 2242031078992
	2243793257776 [label="model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2243793257776 -> 2242031079280
	2242031079280 [label=AccumulateGrad]
	2242031078944 -> 2242031078848
	2243793262288 [label="model.bn1.weight
 (64)" fillcolor=lightblue]
	2243793262288 -> 2242031078944
	2242031078944 [label=AccumulateGrad]
	2242031079088 -> 2242031078848
	2243793262192 [label="model.bn1.bias
 (64)" fillcolor=lightblue]
	2243793262192 -> 2242031079088
	2242031079088 [label=AccumulateGrad]
	2242031078704 -> 2242031078416
	2243814325328 [label="model.layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2243814325328 -> 2242031078704
	2242031078704 [label=AccumulateGrad]
	2242031078272 -> 2242031078368
	2243814325232 [label="model.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2243814325232 -> 2242031078272
	2242031078272 [label=AccumulateGrad]
	2242031078512 -> 2242031078368
	2243814359216 [label="model.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2243814359216 -> 2242031078512
	2242031078512 [label=AccumulateGrad]
	2242031078176 -> 2242031078032
	2243814359696 [label="model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2243814359696 -> 2242031078176
	2242031078176 [label=AccumulateGrad]
	2242031077984 -> 2242031077792
	2243814359792 [label="model.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2243814359792 -> 2242031077984
	2242031077984 [label=AccumulateGrad]
	2242031077936 -> 2242031077792
	2243814359888 [label="model.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2243814359888 -> 2242031077936
	2242031077936 [label=AccumulateGrad]
	2242031077552 -> 2242031077744
	2242031077648 -> 2242031077360
	2243814360272 [label="model.layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2243814360272 -> 2242031077648
	2242031077648 [label=AccumulateGrad]
	2242031077216 -> 2242031077312
	2243814360368 [label="model.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2243814360368 -> 2242031077216
	2242031077216 [label=AccumulateGrad]
	2242031077456 -> 2242031077312
	2243814360464 [label="model.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2243814360464 -> 2242031077456
	2242031077456 [label=AccumulateGrad]
	2242031077120 -> 2242031076976
	2243814360848 [label="model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2243814360848 -> 2242031077120
	2242031077120 [label=AccumulateGrad]
	2242031076928 -> 2242031076832
	2243814360944 [label="model.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2243814360944 -> 2242031076928
	2242031076928 [label=AccumulateGrad]
	2242031076880 -> 2242031076832
	2243814361040 [label="model.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2243814361040 -> 2242031076880
	2242031076880 [label=AccumulateGrad]
	2242031076784 -> 2242031076736
	2242031076544 -> 2242031076400
	2243814362000 [label="model.layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2243814362000 -> 2242031076544
	2242031076544 [label=AccumulateGrad]
	2242031076352 -> 2242031076304
	2243814362096 [label="model.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2243814362096 -> 2242031076352
	2242031076352 [label=AccumulateGrad]
	2242031076208 -> 2242031076304
	2243814362192 [label="model.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2243814362192 -> 2242031076208
	2242031076208 [label=AccumulateGrad]
	2242031076112 -> 2242031075968
	2243814362576 [label="model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2243814362576 -> 2242031076112
	2242031076112 [label=AccumulateGrad]
	2242031075920 -> 2242031075824
	2243814362672 [label="model.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2243814362672 -> 2242031075920
	2242031075920 [label=AccumulateGrad]
	2242031075872 -> 2242031075824
	2243814362768 [label="model.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2243814362768 -> 2242031075872
	2242031075872 [label=AccumulateGrad]
	2242031075776 -> 2242031075728
	2242031075776 [label=CudnnBatchNormBackward0]
	2242031076496 -> 2242031075776
	2242031076496 [label=ConvolutionBackward0]
	2242031076592 -> 2242031076496
	2242031076640 -> 2242031076496
	2243814361424 [label="model.layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2243814361424 -> 2242031076640
	2242031076640 [label=AccumulateGrad]
	2242031076064 -> 2242031075776
	2243814361520 [label="model.layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2243814361520 -> 2242031076064
	2242031076064 [label=AccumulateGrad]
	2242031076016 -> 2242031075776
	2243814361616 [label="model.layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2243814361616 -> 2242031076016
	2242031076016 [label=AccumulateGrad]
	2242031075632 -> 2243793179248
	2243814363152 [label="model.layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2243814363152 -> 2242031075632
	2242031075632 [label=AccumulateGrad]
	2242031075392 -> 2243793179296
	2243814363248 [label="model.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2243814363248 -> 2242031075392
	2242031075392 [label=AccumulateGrad]
	2242031075440 -> 2243793179296
	2243814363344 [label="model.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2243814363344 -> 2242031075440
	2242031075440 [label=AccumulateGrad]
	2243793177376 -> 2243793177472
	2243814363728 [label="model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2243814363728 -> 2243793177376
	2243793177376 [label=AccumulateGrad]
	2243793178432 -> 2243793178480
	2243814363824 [label="model.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2243814363824 -> 2243793178432
	2243793178432 [label=AccumulateGrad]
	2243793178048 -> 2243793178480
	2243814363920 [label="model.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2243814363920 -> 2243793178048
	2243793178048 [label=AccumulateGrad]
	2243793178336 -> 2243793178144
	2243793177952 -> 2243793177616
	2243814364880 [label="model.layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2243814364880 -> 2243793177952
	2243793177952 [label=AccumulateGrad]
	2243793177664 -> 2243793177712
	2243814364976 [label="model.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2243814364976 -> 2243793177664
	2243793177664 [label=AccumulateGrad]
	2243793179440 -> 2243793177712
	2243814365072 [label="model.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2243814365072 -> 2243793179440
	2243793179440 [label=AccumulateGrad]
	2243793177088 -> 2243793177232
	2243814365456 [label="model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2243814365456 -> 2243793177088
	2243793177088 [label=AccumulateGrad]
	2243793177904 -> 2243793188128
	2243814365552 [label="model.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2243814365552 -> 2243793177904
	2243793177904 [label=AccumulateGrad]
	2243793188032 -> 2243793188128
	2243814365648 [label="model.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2243814365648 -> 2243793188032
	2243793188032 [label=AccumulateGrad]
	2243793188944 -> 2243793188992
	2243793188944 [label=CudnnBatchNormBackward0]
	2243793178000 -> 2243793188944
	2243793178000 [label=ConvolutionBackward0]
	2243793177808 -> 2243793178000
	2243793178240 -> 2243793178000
	2243814364304 [label="model.layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2243814364304 -> 2243793178240
	2243793178240 [label=AccumulateGrad]
	2243793177136 -> 2243793188944
	2243814364400 [label="model.layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2243814364400 -> 2243793177136
	2243793177136 [label=AccumulateGrad]
	2243793177184 -> 2243793188944
	2243814364496 [label="model.layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2243814364496 -> 2243793177184
	2243793177184 [label=AccumulateGrad]
	2243793190720 -> 2243793190528
	2243814366032 [label="model.layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2243814366032 -> 2243793190720
	2243793190720 [label=AccumulateGrad]
	2243793190384 -> 2243793190816
	2243814366128 [label="model.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2243814366128 -> 2243793190384
	2243793190384 [label=AccumulateGrad]
	2243793190432 -> 2243793190816
	2243814366224 [label="model.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2243814366224 -> 2243793190432
	2243793190432 [label=AccumulateGrad]
	2243793189808 -> 2243793188848
	2243814366608 [label="model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2243814366608 -> 2243793189808
	2243793189808 [label=AccumulateGrad]
	2243793188704 -> 2243793188608
	2243814366704 [label="model.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2243814366704 -> 2243793188704
	2243793188704 [label=AccumulateGrad]
	2243793188656 -> 2243793188608
	2243814366800 [label="model.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2243814366800 -> 2243793188656
	2243793188656 [label=AccumulateGrad]
	2243793188560 -> 2243793188512
	2243793188320 -> 2243793188176
	2243814367760 [label="model.layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2243814367760 -> 2243793188320
	2243793188320 [label=AccumulateGrad]
	2243793184480 -> 2243793184432
	2243814367856 [label="model.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2243814367856 -> 2243793184480
	2243793184480 [label=AccumulateGrad]
	2243793184336 -> 2243793184432
	2243814367952 [label="model.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2243814367952 -> 2243793184336
	2243793184336 [label=AccumulateGrad]
	2243793175888 -> 2243793190000
	2243814368336 [label="model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2243814368336 -> 2243793175888
	2243793175888 [label=AccumulateGrad]
	2243793190048 -> 2243793190144
	2243814368432 [label="model.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2243814368432 -> 2243793190048
	2243793190048 [label=AccumulateGrad]
	2243793190624 -> 2243793190144
	2243814368528 [label="model.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2243814368528 -> 2243793190624
	2243793190624 [label=AccumulateGrad]
	2243793189952 -> 2243793189904
	2243793189952 [label=CudnnBatchNormBackward0]
	2243793188272 -> 2243793189952
	2243793188272 [label=ConvolutionBackward0]
	2243793188368 -> 2243793188272
	2243793188416 -> 2243793188272
	2243814367184 [label="model.layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2243814367184 -> 2243793188416
	2243793188416 [label=AccumulateGrad]
	2243793177856 -> 2243793189952
	2243814367280 [label="model.layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2243814367280 -> 2243793177856
	2243793177856 [label=AccumulateGrad]
	2243793179632 -> 2243793189952
	2243814367376 [label="model.layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2243814367376 -> 2243793179632
	2243793179632 [label=AccumulateGrad]
	2243793189712 -> 2243793185152
	2243814368912 [label="model.layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2243814368912 -> 2243793189712
	2243793189712 [label=AccumulateGrad]
	2243793187744 -> 2243793187696
	2243814369008 [label="model.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2243814369008 -> 2243793187744
	2243793187744 [label=AccumulateGrad]
	2243793186832 -> 2243793187696
	2243814369104 [label="model.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2243814369104 -> 2243793186832
	2243793186832 [label=AccumulateGrad]
	2243793186736 -> 2243793186592
	2243814369488 [label="model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2243814369488 -> 2243793186736
	2243793186736 [label=AccumulateGrad]
	2243793186544 -> 2243793186448
	2243814369584 [label="model.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2243814369584 -> 2243793186544
	2243793186544 [label=AccumulateGrad]
	2243793186496 -> 2243793186448
	2243814369680 [label="model.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2243814369680 -> 2243793186496
	2243793186496 [label=AccumulateGrad]
	2243793186400 -> 2243793186352
	2243793185968 -> 2243793185872
	2243793185968 [label=TBackward0]
	2243793186304 -> 2243793185968
	2243814370256 [label="model.fc.weight
 (19, 512)" fillcolor=lightblue]
	2243814370256 -> 2243793186304
	2243793186304 [label=AccumulateGrad]
	2243793185728 -> 2243814625488
}
