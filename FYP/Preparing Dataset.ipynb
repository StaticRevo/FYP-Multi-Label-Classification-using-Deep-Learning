{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eaeba4b-17d7-4561-9b1e-7fc8d91a96ba",
   "metadata": {},
   "source": [
    "# Dataset Preparation - Stage 1\r\n",
    "This Jupyter Notebook is the first Notebook from a series of Notebooks that make use of a Convolutional Neural Network to perform land classification. This notebook outlines the steps involved in preparing the EuroSAT Sentinel 2 Dataset for the training of the CNN model. The preparation process of the dataset include:\n",
    "1. The **importing** of the necessary librares including os, shutil, random and gdal\n",
    "2. **Reducing** the amount of images found within the dataset to reduce load times and process times.\n",
    "3. The **organisation** of the dataset into appropriate sub-directories including the **Train, Test and Valid** directories within the dataset directory.\n",
    "4. **Conversion** of TIFF images to JPEG is performed and any unwanted XML files and .DS_Store files are appropriately managed,\n",
    "5. Files are appropriatly **shuffled and split** into training (80%), validation (10%) and test (10%) based on predifined indices.\n",
    "6. Lastly the files themsleves are moved to the respective directories based on the splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df66bba-b711-496d-ae89-7b2a9d06efa4",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782f8f38-0bac-4d23-80b7-ba38394fdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module for interacting with the operating system's file system\n",
    "import os\n",
    "# Import the shutil module for high-level file operations such as copying and moving files\n",
    "import shutil\n",
    "# Import the random module for generating random numbers and making random selections\n",
    "import random\n",
    "# Import the subprocess module for running external commands\n",
    "import subprocess\n",
    "# Import tqdm for displaying progress bars\n",
    "from tqdm import tqdm  \n",
    "# Import the gdal module from the osgeo package for working with geospatial data formats\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4ab93-9081-4516-9dc0-fda786c5b443",
   "metadata": {},
   "source": [
    "### Setting the Base path and Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d920193-2e21-4b0d-b383-8e3f4b888318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the datasets directory\n",
    "path = \"C:/Users/isaac/datasets/eurosat-dataset\"\n",
    "\n",
    "# Set the random seed for reproducibility, this ensures that the random operations produce the same result every time the code is run\n",
    "SEED = random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d26991-33e4-4862-8620-5b282f894110",
   "metadata": {},
   "source": [
    "### Collecting Category Names and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d8367c-666b-4282-9421-a7f433896659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store category names and file paths\n",
    "categories = []  # List to hold the names of the categories (subdirectories)\n",
    "tif_files = []   # List to hold the paths of all .jpg files\n",
    "\n",
    "# Walk through the directory tree starting from the specified path\n",
    "# os.walk generates the file names in a directory tree by walking the tree either top-down or bottom-up\n",
    "for dirpath, dirnames, filenames in os.walk(path):\n",
    "    # Add the directory names (categories) to the categories list\n",
    "    categories.extend(dirnames)\n",
    "    # Iterate over all filenames in the current directory\n",
    "    for filename in filenames:\n",
    "        # Check if the file has a .jpg extension\n",
    "        if filename.endswith('.jpg'):\n",
    "            # Add the full path of the .jpg file to the tif_files list\n",
    "            tif_files.append(os.path.join(dirpath, filename))\n",
    "\n",
    "# Print the list of categories (subdirectory names)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c3e63d-c7c7-4dc2-8012-478fa8827e00",
   "metadata": {},
   "source": [
    "### Reducing the Dataset by half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf3695c-7ccb-49ec-8354-eb80d9db1a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction of images in each category by 50% completed.\n"
     ]
    }
   ],
   "source": [
    "# Reduce the number of images in each category by 50% to reduce load times and process times\n",
    "for category in categories:\n",
    "    # Construct the path to the current category\n",
    "    category_path = os.path.join(path, category)\n",
    "    \n",
    "    # Filter tif_files to get only the files in the current category\n",
    "    category_files = [file for file in tif_files if file.startswith(category_path)]\n",
    "\n",
    "    # If there are more than one file in the category, reduce the number by 50%\n",
    "    if len(category_files) > 1:\n",
    "        # Calculate the number of files to keep (50% of the total)\n",
    "        num_files_to_keep = len(category_files) // 2\n",
    "        \n",
    "        # Randomly select a subset of files to keep\n",
    "        files_to_keep = random.sample(category_files, num_files_to_keep)\n",
    "        \n",
    "        # Determine the files to remove (those not in the files_to_keep list)\n",
    "        files_to_remove = set(category_files) - set(files_to_keep)\n",
    "        \n",
    "        # Iterate over the files to remove and delete them\n",
    "        for file_to_remove in files_to_remove:\n",
    "            os.remove(file_to_remove)  # Delete the file\n",
    "\n",
    "# Print a completion message\n",
    "print(\"Reduction of images in each category by 50% completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e91c8-eed1-498e-b453-f1d2ff42608b",
   "metadata": {},
   "source": [
    "### Creating and Organising Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc293a2-4d7e-4792-9778-5e9bdbb49ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\n",
      "\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\AnnualCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\Forest\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\HerbaceousVegetation\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\Highway\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\Industrial\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\Pasture\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\PermanentCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\Residential\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\River\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\SeaLake\n",
      "Created folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\n",
      "\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\AnnualCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\Forest\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\HerbaceousVegetation\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\Highway\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\Industrial\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\Pasture\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\PermanentCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\Residential\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\River\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\SeaLake\n",
      "Created folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\n",
      "\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\AnnualCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\Forest\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\HerbaceousVegetation\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\Highway\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\Industrial\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\Pasture\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\PermanentCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\Residential\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\River\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\SeaLake\n",
      "All folders created successfully.\n"
     ]
    }
   ],
   "source": [
    "# List of split names\n",
    "split_names = ['train', 'test', 'valid']\n",
    "\n",
    "# Create new folders for train, test, and valid sets with subfolders for all categories\n",
    "for sp_name in split_names:\n",
    "    directory = os.path.join(path, 'dataset_splits', sp_name)  # Path to the split folder\n",
    "    if not os.path.exists(directory):  # Check if the split folder doesn't exist\n",
    "        os.makedirs(directory)  # Create the split folder if it doesn't exist\n",
    "        print(f\"Created folder: {directory}\")\n",
    "        print()\n",
    "    # Create category folders within each split\n",
    "    for category in categories:\n",
    "        dir_cat = os.path.join(directory, category)  # Path to the category folder within the split\n",
    "        if not os.path.exists(dir_cat):  # Check if the category folder doesn't exist\n",
    "            os.makedirs(dir_cat)  # Create the category folder if it doesn't exist\n",
    "            print(f\"Created category folder: {dir_cat}\")\n",
    "\n",
    "print(\"All folders created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d188d-7c5a-458f-9c2e-0b02ff208c01",
   "metadata": {},
   "source": [
    "### Converting TIFF to JPEG and Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d16c279c-7c94-404b-9563-9189795260e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting AnnualCrop TIFFs: 100%|██████████| 1500/1500 [01:02<00:00, 23.92it/s]\n",
      "Converting Forest TIFFs: 100%|██████████| 1500/1500 [01:02<00:00, 24.13it/s]\n",
      "Converting HerbaceousVegetation TIFFs: 100%|██████████| 1500/1500 [01:05<00:00, 22.85it/s]\n",
      "Converting Highway TIFFs: 100%|██████████| 1250/1250 [00:52<00:00, 23.99it/s]\n",
      "Converting Industrial TIFFs: 100%|██████████| 1250/1250 [00:50<00:00, 24.96it/s]\n",
      "Converting Pasture TIFFs: 100%|██████████| 1000/1000 [00:43<00:00, 22.82it/s]\n",
      "Converting PermanentCrop TIFFs: 100%|██████████| 1250/1250 [00:54<00:00, 22.93it/s]\n",
      "Converting Residential TIFFs: 100%|██████████| 1500/1500 [01:02<00:00, 24.10it/s]\n",
      "Converting River TIFFs: 100%|██████████| 1250/1250 [00:50<00:00, 24.89it/s]\n",
      "Converting SeaLake TIFFs: 100%|██████████| 1500/1500 [01:00<00:00, 24.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to convert TIFF to JPEG using GDAL\n",
    "def convert_tiff_to_jpeg(input_file, output_file, bands=[1, 2, 3]):\n",
    "    try:\n",
    "        # Construct the gdal_translate command\n",
    "        command = ['gdal_translate', '-of', 'JPEG']\n",
    "        for band in bands:\n",
    "            command.extend(['-b', str(band)])\n",
    "        command.extend(['-scale', input_file, output_file])\n",
    "        # Run the command\n",
    "        subprocess.run(command, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error converting {input_file} to {output_file}: {e}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Iterate through each category\n",
    "for category in categories:\n",
    "    # Define directories for input TIFF files and output JPEG files\n",
    "    directory = os.path.join(path, category)  # Input TIFF directory\n",
    "    directory_train = os.path.join(path, 'dataset_splits', 'train', category)  # Output JPEG directory for training set\n",
    "    directory_valid = os.path.join(path, 'dataset_splits', 'test', category)  # Output JPEG directory for validation set\n",
    "    directory_test = os.path.join(path, 'dataset_splits', 'valid', category)  # Output JPEG directory for test set\n",
    "    \n",
    "    # Create output directories if they do not exist\n",
    "    os.makedirs(directory_train, exist_ok=True)\n",
    "    os.makedirs(directory_valid, exist_ok=True)\n",
    "    os.makedirs(directory_test, exist_ok=True)\n",
    "    \n",
    "    # List all files in the input TIFF directory\n",
    "    try:\n",
    "        cat_files = os.listdir(directory)\n",
    "    except FileNotFoundError:\n",
    "        continue  # Skip the category if the directory does not exist\n",
    "    \n",
    "    # Remove any unwanted files (e.g., .DS_Store)\n",
    "    if '.DS_Store' in cat_files:\n",
    "        cat_files.remove('.DS_Store')\n",
    "    \n",
    "    # Convert TIFF files to JPEG format and move them to the training directory\n",
    "    with tqdm(total=len(cat_files), desc=f'Converting {category} TIFFs') as pbar:  # Initialize tqdm progress bar\n",
    "        for file in cat_files:\n",
    "            file_no_ext = file.split('.')[0]  # Remove file extension\n",
    "            img_in = os.path.join(directory, file)  # Input TIFF file path\n",
    "            img_out = os.path.join(directory_train, file_no_ext + '.jpeg')  # Output JPEG file path\n",
    "                \n",
    "            # Check if the converted JPEG file already exists in the training directory\n",
    "            if not os.path.exists(img_out):\n",
    "                # Convert the TIFF to JPEG\n",
    "                success = convert_tiff_to_jpeg(img_in, img_out, bands=[1, 2, 3])\n",
    "                if not success:\n",
    "                    print(f\"Conversion failed for {img_in}\")\n",
    "            \n",
    "            pbar.update(1)  # Update progress bar\n",
    "    \n",
    "    # Remove any XML files that were generated during the conversion process\n",
    "    for item in os.listdir(directory_train):  # Iterate over files in the training directory\n",
    "        if item.endswith(\".xml\"):\n",
    "            os.remove(os.path.join(directory_train, item))  # Remove XML file\n",
    "                \n",
    "    # Sort files into test and validation folders\n",
    "    filenames = os.listdir(directory_train)  # List JPEG files in the training directory\n",
    "    filenames.sort()  # Sort filenames alphabetically\n",
    "    if '.DS_Store' in filenames:\n",
    "        filenames.remove('.DS_Store')\n",
    "        \n",
    "    random.shuffle(filenames)  # Shuffle filenames randomly\n",
    "    split_1 = int(0.8 * len(filenames))  # Split index for training-validation split\n",
    "    split_2 = int(0.9 * len(filenames))  # Split index for validation-test split\n",
    "    train_filenames = filenames[:split_1]  # Filenames for training set\n",
    "    valid_filenames = filenames[split_1:split_2]  # Filenames for validation set\n",
    "    test_filenames = filenames[split_2:]  # Filenames for test set\n",
    "        \n",
    "    for file in os.listdir(directory_train):\n",
    "        if file in valid_filenames:\n",
    "            shutil.move(os.path.join(directory_train, file), os.path.join(directory_valid, file))  # Move to validation directory\n",
    "        elif file in test_filenames:\n",
    "            shutil.move(os.path.join(directory_train, file), os.path.join(directory_test, file))  # Move to test directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b4035f-4625-4bae-a90c-f1f45314a6ff",
   "metadata": {},
   "source": [
    "By employing a structured approach, I ensure that the dataset is well-organised and ready for the training, validation and the testing phases of the development of the CNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
