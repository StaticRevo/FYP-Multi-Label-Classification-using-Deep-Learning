digraph {
	graph [size="206.7,206.7"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2508328246672 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2508401225696 [label=AddmmBackward0]
	2508401224688 -> 2508401225696
	2508327522320 [label="classifier.1.bias
 (19)" fillcolor=lightblue]
	2508327522320 -> 2508401224688
	2508401224688 [label=AccumulateGrad]
	2508401224832 -> 2508401225696
	2508401224832 [label=AsStridedBackward0]
	2508401224064 -> 2508401224832
	2508401224064 [label=CopySlices]
	2508401214464 -> 2508401224064
	2508401214464 [label=MeanBackward1]
	2508401214608 -> 2508401214464
	2508401214608 [label=SiluBackward0]
	2508401215472 -> 2508401214608
	2508401215472 [label=CudnnBatchNormBackward0]
	2508401214704 -> 2508401215472
	2508401214704 [label=ConvolutionBackward0]
	2508401228576 -> 2508401214704
	2508401228576 [label=CudnnBatchNormBackward0]
	2508401225984 -> 2508401228576
	2508401225984 [label=ConvolutionBackward0]
	2508401214032 -> 2508401225984
	2508401214032 [label=MulBackward0]
	2508401214800 -> 2508401214032
	2508401214800 [label=SigmoidBackward0]
	2508401226992 -> 2508401214800
	2508401226992 [label=ConvolutionBackward0]
	2508401227904 -> 2508401226992
	2508401227904 [label=SiluBackward0]
	2508401226944 -> 2508401227904
	2508401226944 [label=ConvolutionBackward0]
	2508401226224 -> 2508401226944
	2508401226224 [label=MeanBackward1]
	2508401214224 -> 2508401226224
	2508401214224 [label=SiluBackward0]
	2508401213600 -> 2508401214224
	2508401213600 [label=CudnnBatchNormBackward0]
	2508401229776 -> 2508401213600
	2508401229776 [label=ConvolutionBackward0]
	2508401228672 -> 2508401229776
	2508401228672 [label=SiluBackward0]
	2508401226176 -> 2508401228672
	2508401226176 [label=CudnnBatchNormBackward0]
	2508401225072 -> 2508401226176
	2508401225072 [label=ConvolutionBackward0]
	2508401222384 -> 2508401225072
	2508401222384 [label=AddBackward0]
	2508401223104 -> 2508401222384
	2508401223104 [label=MulBackward0]
	2508401213792 -> 2508401223104
	2508401213792 [label=CudnnBatchNormBackward0]
	2508401222240 -> 2508401213792
	2508401222240 [label=ConvolutionBackward0]
	2508401221568 -> 2508401222240
	2508401221568 [label=MulBackward0]
	2508401213888 -> 2508401221568
	2508401213888 [label=SigmoidBackward0]
	2508401215520 -> 2508401213888
	2508401215520 [label=ConvolutionBackward0]
	2508401229152 -> 2508401215520
	2508401229152 [label=SiluBackward0]
	2508401215040 -> 2508401229152
	2508401215040 [label=ConvolutionBackward0]
	2508401220704 -> 2508401215040
	2508401220704 [label=MeanBackward1]
	2508401214560 -> 2508401220704
	2508401214560 [label=SiluBackward0]
	2508401221856 -> 2508401214560
	2508401221856 [label=CudnnBatchNormBackward0]
	2508401220896 -> 2508401221856
	2508401220896 [label=ConvolutionBackward0]
	2508401221232 -> 2508401220896
	2508401221232 [label=SiluBackward0]
	2508401227136 -> 2508401221232
	2508401227136 [label=CudnnBatchNormBackward0]
	2508401224448 -> 2508401227136
	2508401224448 [label=ConvolutionBackward0]
	2508401225216 -> 2508401224448
	2508401225216 [label=AddBackward0]
	2508401229488 -> 2508401225216
	2508401229488 [label=MulBackward0]
	2508401226464 -> 2508401229488
	2508401226464 [label=CudnnBatchNormBackward0]
	2508401224496 -> 2508401226464
	2508401224496 [label=ConvolutionBackward0]
	2508401227088 -> 2508401224496
	2508401227088 [label=MulBackward0]
	2508401217824 -> 2508401227088
	2508401217824 [label=SigmoidBackward0]
	2508401229008 -> 2508401217824
	2508401229008 [label=ConvolutionBackward0]
	2508401215376 -> 2508401229008
	2508401215376 [label=SiluBackward0]
	2508401218400 -> 2508401215376
	2508401218400 [label=ConvolutionBackward0]
	2508401220416 -> 2508401218400
	2508401220416 [label=MeanBackward1]
	2508401220992 -> 2508401220416
	2508401220992 [label=SiluBackward0]
	2508401219456 -> 2508401220992
	2508401219456 [label=CudnnBatchNormBackward0]
	2508401217968 -> 2508401219456
	2508401217968 [label=ConvolutionBackward0]
	2508401225168 -> 2508401217968
	2508401225168 [label=SiluBackward0]
	2508401225552 -> 2508401225168
	2508401225552 [label=CudnnBatchNormBackward0]
	2508401222480 -> 2508401225552
	2508401222480 [label=ConvolutionBackward0]
	2508401216192 -> 2508401222480
	2508401216192 [label=AddBackward0]
	2508401226608 -> 2508401216192
	2508401226608 [label=MulBackward0]
	2508401222720 -> 2508401226608
	2508401222720 [label=CudnnBatchNormBackward0]
	2508401216048 -> 2508401222720
	2508401216048 [label=ConvolutionBackward0]
	2508401223392 -> 2508401216048
	2508401223392 [label=MulBackward0]
	2508401218544 -> 2508401223392
	2508401218544 [label=SigmoidBackward0]
	2508401226656 -> 2508401218544
	2508401226656 [label=ConvolutionBackward0]
	2508401220656 -> 2508401226656
	2508401220656 [label=SiluBackward0]
	2508401225120 -> 2508401220656
	2508401225120 [label=ConvolutionBackward0]
	2508401216384 -> 2508401225120
	2508401216384 [label=MeanBackward1]
	2508401214896 -> 2508401216384
	2508401214896 [label=SiluBackward0]
	2508401224736 -> 2508401214896
	2508401224736 [label=CudnnBatchNormBackward0]
	2508401225792 -> 2508401224736
	2508401225792 [label=ConvolutionBackward0]
	2508401224112 -> 2508401225792
	2508401224112 [label=SiluBackward0]
	2508401216144 -> 2508401224112
	2508401216144 [label=CudnnBatchNormBackward0]
	2508401219552 -> 2508401216144
	2508401219552 [label=ConvolutionBackward0]
	2508401226368 -> 2508401219552
	2508401226368 [label=CudnnBatchNormBackward0]
	2508401228528 -> 2508401226368
	2508401228528 [label=ConvolutionBackward0]
	2508401224400 -> 2508401228528
	2508401224400 [label=MulBackward0]
	2508401223728 -> 2508401224400
	2508401223728 [label=SigmoidBackward0]
	2508401214848 -> 2508401223728
	2508401214848 [label=ConvolutionBackward0]
	2508401222528 -> 2508401214848
	2508401222528 [label=SiluBackward0]
	2508401214080 -> 2508401222528
	2508401214080 [label=ConvolutionBackward0]
	2508401228912 -> 2508401214080
	2508401228912 [label=MeanBackward1]
	2508401217488 -> 2508401228912
	2508401217488 [label=SiluBackward0]
	2508401216336 -> 2508401217488
	2508401216336 [label=CudnnBatchNormBackward0]
	2508401218064 -> 2508401216336
	2508401218064 [label=ConvolutionBackward0]
	2508401226128 -> 2508401218064
	2508401226128 [label=SiluBackward0]
	2508401229440 -> 2508401226128
	2508401229440 [label=CudnnBatchNormBackward0]
	2508401227616 -> 2508401229440
	2508401227616 [label=ConvolutionBackward0]
	2508401214320 -> 2508401227616
	2508401214320 [label=AddBackward0]
	2508401222096 -> 2508401214320
	2508401222096 [label=MulBackward0]
	2508401214992 -> 2508401222096
	2508401214992 [label=CudnnBatchNormBackward0]
	2508401217872 -> 2508401214992
	2508401217872 [label=ConvolutionBackward0]
	2508401217248 -> 2508401217872
	2508401217248 [label=MulBackward0]
	2508401224784 -> 2508401217248
	2508401224784 [label=SigmoidBackward0]
	2508401225744 -> 2508401224784
	2508401225744 [label=ConvolutionBackward0]
	2508401221808 -> 2508401225744
	2508401221808 [label=SiluBackward0]
	2508401217008 -> 2508401221808
	2508401217008 [label=ConvolutionBackward0]
	2508401224304 -> 2508401217008
	2508401224304 [label=MeanBackward1]
	2508401214128 -> 2508401224304
	2508401214128 [label=SiluBackward0]
	2508401100064 -> 2508401214128
	2508401100064 [label=CudnnBatchNormBackward0]
	2508401099680 -> 2508401100064
	2508401099680 [label=ConvolutionBackward0]
	2508401101744 -> 2508401099680
	2508401101744 [label=SiluBackward0]
	2508401104000 -> 2508401101744
	2508401104000 [label=CudnnBatchNormBackward0]
	2508401098864 -> 2508401104000
	2508401098864 [label=ConvolutionBackward0]
	2508401220368 -> 2508401098864
	2508401220368 [label=AddBackward0]
	2508401099392 -> 2508401220368
	2508401099392 [label=MulBackward0]
	2508401112160 -> 2508401099392
	2508401112160 [label=CudnnBatchNormBackward0]
	2508401105392 -> 2508401112160
	2508401105392 [label=ConvolutionBackward0]
	2508401104096 -> 2508401105392
	2508401104096 [label=MulBackward0]
	2508401100832 -> 2508401104096
	2508401100832 [label=SigmoidBackward0]
	2508401103904 -> 2508401100832
	2508401103904 [label=ConvolutionBackward0]
	2508401100256 -> 2508401103904
	2508401100256 [label=SiluBackward0]
	2508401105104 -> 2508401100256
	2508401105104 [label=ConvolutionBackward0]
	2508401100976 -> 2508401105104
	2508401100976 [label=MeanBackward1]
	2508401100784 -> 2508401100976
	2508401100784 [label=SiluBackward0]
	2508401104864 -> 2508401100784
	2508401104864 [label=CudnnBatchNormBackward0]
	2508401107072 -> 2508401104864
	2508401107072 [label=ConvolutionBackward0]
	2508401108272 -> 2508401107072
	2508401108272 [label=SiluBackward0]
	2508401105536 -> 2508401108272
	2508401105536 [label=CudnnBatchNormBackward0]
	2508401105344 -> 2508401105536
	2508401105344 [label=ConvolutionBackward0]
	2508401110864 -> 2508401105344
	2508401110864 [label=CudnnBatchNormBackward0]
	2508401108464 -> 2508401110864
	2508401108464 [label=ConvolutionBackward0]
	2508401107888 -> 2508401108464
	2508401107888 [label=MulBackward0]
	2508401111440 -> 2508401107888
	2508401111440 [label=SigmoidBackward0]
	2508401104960 -> 2508401111440
	2508401104960 [label=ConvolutionBackward0]
	2508401110816 -> 2508401104960
	2508401110816 [label=SiluBackward0]
	2508401109280 -> 2508401110816
	2508401109280 [label=ConvolutionBackward0]
	2508401108992 -> 2508401109280
	2508401108992 [label=MeanBackward1]
	2508401101456 -> 2508401108992
	2508401101456 [label=SiluBackward0]
	2508401114272 -> 2508401101456
	2508401114272 [label=CudnnBatchNormBackward0]
	2508401115088 -> 2508401114272
	2508401115088 [label=ConvolutionBackward0]
	2508401113072 -> 2508401115088
	2508401113072 [label=SiluBackward0]
	2508401112256 -> 2508401113072
	2508401112256 [label=CudnnBatchNormBackward0]
	2508401103664 -> 2508401112256
	2508401103664 [label=ConvolutionBackward0]
	2508401114176 -> 2508401103664
	2508401114176 [label=AddBackward0]
	2508401111056 -> 2508401114176
	2508401111056 [label=MulBackward0]
	2508401108080 -> 2508401111056
	2508401108080 [label=CudnnBatchNormBackward0]
	2508401113840 -> 2508401108080
	2508401113840 [label=ConvolutionBackward0]
	2508401113744 -> 2508401113840
	2508401113744 [label=MulBackward0]
	2508401104384 -> 2508401113744
	2508401104384 [label=SigmoidBackward0]
	2508401112016 -> 2508401104384
	2508401112016 [label=ConvolutionBackward0]
	2508401113408 -> 2508401112016
	2508401113408 [label=SiluBackward0]
	2508401111104 -> 2508401113408
	2508401111104 [label=ConvolutionBackward0]
	2508401108800 -> 2508401111104
	2508401108800 [label=MeanBackward1]
	2508401113552 -> 2508401108800
	2508401113552 [label=SiluBackward0]
	2508401112496 -> 2508401113552
	2508401112496 [label=CudnnBatchNormBackward0]
	2508401109904 -> 2508401112496
	2508401109904 [label=ConvolutionBackward0]
	2508401108848 -> 2508401109904
	2508401108848 [label=SiluBackward0]
	2508401106496 -> 2508401108848
	2508401106496 [label=CudnnBatchNormBackward0]
	2508401109568 -> 2508401106496
	2508401109568 [label=ConvolutionBackward0]
	2508401110000 -> 2508401109568
	2508401110000 [label=AddBackward0]
	2508401102752 -> 2508401110000
	2508401102752 [label=MulBackward0]
	2508401110720 -> 2508401102752
	2508401110720 [label=CudnnBatchNormBackward0]
	2508401110288 -> 2508401110720
	2508401110288 [label=ConvolutionBackward0]
	2508401109856 -> 2508401110288
	2508401109856 [label=MulBackward0]
	2508401110192 -> 2508401109856
	2508401110192 [label=SigmoidBackward0]
	2508401109712 -> 2508401110192
	2508401109712 [label=ConvolutionBackward0]
	2508401108224 -> 2508401109712
	2508401108224 [label=SiluBackward0]
	2508401108032 -> 2508401108224
	2508401108032 [label=ConvolutionBackward0]
	2508401109136 -> 2508401108032
	2508401109136 [label=MeanBackward1]
	2508401110144 -> 2508401109136
	2508401110144 [label=SiluBackward0]
	2508401108128 -> 2508401110144
	2508401108128 [label=CudnnBatchNormBackward0]
	2508401107168 -> 2508401108128
	2508401107168 [label=ConvolutionBackward0]
	2508401107408 -> 2508401107168
	2508401107408 [label=SiluBackward0]
	2508401102320 -> 2508401107408
	2508401102320 [label=CudnnBatchNormBackward0]
	2508401106160 -> 2508401102320
	2508401106160 [label=ConvolutionBackward0]
	2508401109616 -> 2508401106160
	2508401109616 [label=CudnnBatchNormBackward0]
	2508401107360 -> 2508401109616
	2508401107360 [label=ConvolutionBackward0]
	2508401106016 -> 2508401107360
	2508401106016 [label=MulBackward0]
	2508401101120 -> 2508401106016
	2508401101120 [label=SigmoidBackward0]
	2508401104336 -> 2508401101120
	2508401104336 [label=ConvolutionBackward0]
	2508401104480 -> 2508401104336
	2508401104480 [label=SiluBackward0]
	2508401105968 -> 2508401104480
	2508401105968 [label=ConvolutionBackward0]
	2508401099728 -> 2508401105968
	2508401099728 [label=MeanBackward1]
	2508401106832 -> 2508401099728
	2508401106832 [label=SiluBackward0]
	2508401100544 -> 2508401106832
	2508401100544 [label=CudnnBatchNormBackward0]
	2508401105200 -> 2508401100544
	2508401105200 [label=ConvolutionBackward0]
	2508401104816 -> 2508401105200
	2508401104816 [label=SiluBackward0]
	2508401101216 -> 2508401104816
	2508401101216 [label=CudnnBatchNormBackward0]
	2508401101264 -> 2508401101216
	2508401101264 [label=ConvolutionBackward0]
	2508401103136 -> 2508401101264
	2508401103136 [label=AddBackward0]
	2508401103568 -> 2508401103136
	2508401103568 [label=MulBackward0]
	2508401099968 -> 2508401103568
	2508401099968 [label=CudnnBatchNormBackward0]
	2508401099008 -> 2508401099968
	2508401099008 [label=ConvolutionBackward0]
	2508401101888 -> 2508401099008
	2508401101888 [label=MulBackward0]
	2508401102848 -> 2508401101888
	2508401102848 [label=SigmoidBackward0]
	2508401101840 -> 2508401102848
	2508401101840 [label=ConvolutionBackward0]
	2508401103040 -> 2508401101840
	2508401103040 [label=SiluBackward0]
	2508401102464 -> 2508401103040
	2508401102464 [label=ConvolutionBackward0]
	2508401114608 -> 2508401102464
	2508401114608 [label=MeanBackward1]
	2508401101360 -> 2508401114608
	2508401101360 [label=SiluBackward0]
	2508401113888 -> 2508401101360
	2508401113888 [label=CudnnBatchNormBackward0]
	2508401114320 -> 2508401113888
	2508401114320 [label=ConvolutionBackward0]
	2508401112736 -> 2508401114320
	2508401112736 [label=SiluBackward0]
	2508401114128 -> 2508401112736
	2508401114128 [label=CudnnBatchNormBackward0]
	2508401114032 -> 2508401114128
	2508401114032 [label=ConvolutionBackward0]
	2508401100160 -> 2508401114032
	2508401100160 [label=CudnnBatchNormBackward0]
	2508401114224 -> 2508401100160
	2508401114224 [label=ConvolutionBackward0]
	2508401110336 -> 2508401114224
	2508401110336 [label=MulBackward0]
	2508401114512 -> 2508401110336
	2508401114512 [label=SigmoidBackward0]
	2508401111344 -> 2508401114512
	2508401111344 [label=ConvolutionBackward0]
	2508401113264 -> 2508401111344
	2508401113264 [label=SiluBackward0]
	2508401111296 -> 2508401113264
	2508401111296 [label=ConvolutionBackward0]
	2508328124528 -> 2508401111296
	2508328124528 [label=MeanBackward1]
	2508401099536 -> 2508328124528
	2508401099536 [label=SiluBackward0]
	2508328124672 -> 2508401099536
	2508328124672 [label=CudnnBatchNormBackward0]
	2508328124912 -> 2508328124672
	2508328124912 [label=ConvolutionBackward0]
	2508328125200 -> 2508328124912
	2508328125200 [label=SiluBackward0]
	2508328125344 -> 2508328125200
	2508328125344 [label=CudnnBatchNormBackward0]
	2508328125392 -> 2508328125344
	2508328125392 [label=ConvolutionBackward0]
	2508328125680 -> 2508328125392
	2508328125680 [label=AddBackward0]
	2508328125824 -> 2508328125680
	2508328125824 [label=MulBackward0]
	2508328125968 -> 2508328125824
	2508328125968 [label=CudnnBatchNormBackward0]
	2508328126064 -> 2508328125968
	2508328126064 [label=ConvolutionBackward0]
	2508328126256 -> 2508328126064
	2508328126256 [label=MulBackward0]
	2508328126400 -> 2508328126256
	2508328126400 [label=SigmoidBackward0]
	2508328126544 -> 2508328126400
	2508328126544 [label=ConvolutionBackward0]
	2508328126592 -> 2508328126544
	2508328126592 [label=SiluBackward0]
	2508328126880 -> 2508328126592
	2508328126880 [label=ConvolutionBackward0]
	2508328126928 -> 2508328126880
	2508328126928 [label=MeanBackward1]
	2508328126352 -> 2508328126928
	2508328126352 [label=SiluBackward0]
	2508328127120 -> 2508328126352
	2508328127120 [label=CudnnBatchNormBackward0]
	2508328127360 -> 2508328127120
	2508328127360 [label=ConvolutionBackward0]
	2508328127648 -> 2508328127360
	2508328127648 [label=SiluBackward0]
	2508328127792 -> 2508328127648
	2508328127792 [label=CudnnBatchNormBackward0]
	2508328127840 -> 2508328127792
	2508328127840 [label=ConvolutionBackward0]
	2508328125776 -> 2508328127840
	2508328125776 [label=CudnnBatchNormBackward0]
	2508328128224 -> 2508328125776
	2508328128224 [label=ConvolutionBackward0]
	2508328128416 -> 2508328128224
	2508328128416 [label=MulBackward0]
	2508328128560 -> 2508328128416
	2508328128560 [label=SigmoidBackward0]
	2508328128704 -> 2508328128560
	2508328128704 [label=ConvolutionBackward0]
	2508328128752 -> 2508328128704
	2508328128752 [label=SiluBackward0]
	2508328129040 -> 2508328128752
	2508328129040 [label=ConvolutionBackward0]
	2508328129088 -> 2508328129040
	2508328129088 [label=MeanBackward1]
	2508328128512 -> 2508328129088
	2508328128512 [label=SiluBackward0]
	2508328129280 -> 2508328128512
	2508328129280 [label=CudnnBatchNormBackward0]
	2508328129520 -> 2508328129280
	2508328129520 [label=ConvolutionBackward0]
	2508328129808 -> 2508328129520
	2508328129808 [label=SiluBackward0]
	2508328129952 -> 2508328129808
	2508328129952 [label=CudnnBatchNormBackward0]
	2508328130000 -> 2508328129952
	2508328130000 [label=ConvolutionBackward0]
	2508328130288 -> 2508328130000
	2508328130288 [label=CudnnBatchNormBackward0]
	2508328130432 -> 2508328130288
	2508328130432 [label=ConvolutionBackward0]
	2508328130624 -> 2508328130432
	2508328130624 [label=MulBackward0]
	2508328130768 -> 2508328130624
	2508328130768 [label=SigmoidBackward0]
	2508328130912 -> 2508328130768
	2508328130912 [label=ConvolutionBackward0]
	2508328130960 -> 2508328130912
	2508328130960 [label=SiluBackward0]
	2508328131248 -> 2508328130960
	2508328131248 [label=ConvolutionBackward0]
	2508328131296 -> 2508328131248
	2508328131296 [label=MeanBackward1]
	2508328130720 -> 2508328131296
	2508328130720 [label=SiluBackward0]
	2508328131488 -> 2508328130720
	2508328131488 [label=CudnnBatchNormBackward0]
	2508328131728 -> 2508328131488
	2508328131728 [label=ConvolutionBackward0]
	2508328132016 -> 2508328131728
	2508328132016 [label=SiluBackward0]
	2508328132160 -> 2508328132016
	2508328132160 [label=CudnnBatchNormBackward0]
	2508328132208 -> 2508328132160
	2508328132208 [label=ConvolutionBackward0]
	2508328132496 -> 2508328132208
	2508327522128 [label="features.0.0.weight
 (32, 12, 3, 3)" fillcolor=lightblue]
	2508327522128 -> 2508328132496
	2508328132496 [label=AccumulateGrad]
	2508328132064 -> 2508328132160
	2508374297200 [label="features.0.1.weight
 (32)" fillcolor=lightblue]
	2508374297200 -> 2508328132064
	2508328132064 [label=AccumulateGrad]
	2508328132304 -> 2508328132160
	2508374296432 [label="features.0.1.bias
 (32)" fillcolor=lightblue]
	2508374296432 -> 2508328132304
	2508328132304 [label=AccumulateGrad]
	2508328131968 -> 2508328131728
	2508374296624 [label="features.1.0.block.0.0.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	2508374296624 -> 2508328131968
	2508328131968 [label=AccumulateGrad]
	2508328131680 -> 2508328131488
	2508374296720 [label="features.1.0.block.0.1.weight
 (32)" fillcolor=lightblue]
	2508374296720 -> 2508328131680
	2508328131680 [label=AccumulateGrad]
	2508328131824 -> 2508328131488
	2508374296816 [label="features.1.0.block.0.1.bias
 (32)" fillcolor=lightblue]
	2508374296816 -> 2508328131824
	2508328131824 [label=AccumulateGrad]
	2508328131152 -> 2508328131248
	2508374296048 [label="features.1.0.block.1.fc1.weight
 (8, 32, 1, 1)" fillcolor=lightblue]
	2508374296048 -> 2508328131152
	2508328131152 [label=AccumulateGrad]
	2508328131392 -> 2508328131248
	2508374295952 [label="features.1.0.block.1.fc1.bias
 (8)" fillcolor=lightblue]
	2508374295952 -> 2508328131392
	2508328131392 [label=AccumulateGrad]
	2508328130816 -> 2508328130912
	2508374295184 [label="features.1.0.block.1.fc2.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	2508374295184 -> 2508328130816
	2508328130816 [label=AccumulateGrad]
	2508328131056 -> 2508328130912
	2508374294896 [label="features.1.0.block.1.fc2.bias
 (32)" fillcolor=lightblue]
	2508374294896 -> 2508328131056
	2508328131056 [label=AccumulateGrad]
	2508328130720 -> 2508328130624
	2508328130576 -> 2508328130432
	2508374294992 [label="features.1.0.block.2.0.weight
 (16, 32, 1, 1)" fillcolor=lightblue]
	2508374294992 -> 2508328130576
	2508328130576 [label=AccumulateGrad]
	2508328130384 -> 2508328130288
	2508374295088 [label="features.1.0.block.2.1.weight
 (16)" fillcolor=lightblue]
	2508374295088 -> 2508328130384
	2508328130384 [label=AccumulateGrad]
	2508328130336 -> 2508328130288
	2508374295280 [label="features.1.0.block.2.1.bias
 (16)" fillcolor=lightblue]
	2508374295280 -> 2508328130336
	2508328130336 [label=AccumulateGrad]
	2508328130240 -> 2508328130000
	2508374295664 [label="features.2.0.block.0.0.weight
 (96, 16, 1, 1)" fillcolor=lightblue]
	2508374295664 -> 2508328130240
	2508328130240 [label=AccumulateGrad]
	2508328129856 -> 2508328129952
	2508374295856 [label="features.2.0.block.0.1.weight
 (96)" fillcolor=lightblue]
	2508374295856 -> 2508328129856
	2508328129856 [label=AccumulateGrad]
	2508328130096 -> 2508328129952
	2508374295760 [label="features.2.0.block.0.1.bias
 (96)" fillcolor=lightblue]
	2508374295760 -> 2508328130096
	2508328130096 [label=AccumulateGrad]
	2508328129760 -> 2508328129520
	2508378815856 [label="features.2.0.block.1.0.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	2508378815856 -> 2508328129760
	2508328129760 [label=AccumulateGrad]
	2508328129472 -> 2508328129280
	2508378815472 [label="features.2.0.block.1.1.weight
 (96)" fillcolor=lightblue]
	2508378815472 -> 2508328129472
	2508328129472 [label=AccumulateGrad]
	2508328129616 -> 2508328129280
	2508378816336 [label="features.2.0.block.1.1.bias
 (96)" fillcolor=lightblue]
	2508378816336 -> 2508328129616
	2508328129616 [label=AccumulateGrad]
	2508328128944 -> 2508328129040
	2508378815952 [label="features.2.0.block.2.fc1.weight
 (4, 96, 1, 1)" fillcolor=lightblue]
	2508378815952 -> 2508328128944
	2508328128944 [label=AccumulateGrad]
	2508328129184 -> 2508328129040
	2508378816144 [label="features.2.0.block.2.fc1.bias
 (4)" fillcolor=lightblue]
	2508378816144 -> 2508328129184
	2508328129184 [label=AccumulateGrad]
	2508328128608 -> 2508328128704
	2508378816240 [label="features.2.0.block.2.fc2.weight
 (96, 4, 1, 1)" fillcolor=lightblue]
	2508378816240 -> 2508328128608
	2508328128608 [label=AccumulateGrad]
	2508328128848 -> 2508328128704
	2508378816432 [label="features.2.0.block.2.fc2.bias
 (96)" fillcolor=lightblue]
	2508378816432 -> 2508328128848
	2508328128848 [label=AccumulateGrad]
	2508328128512 -> 2508328128416
	2508328128368 -> 2508328128224
	2508326639120 [label="features.2.0.block.3.0.weight
 (24, 96, 1, 1)" fillcolor=lightblue]
	2508326639120 -> 2508328128368
	2508328128368 [label=AccumulateGrad]
	2508328128176 -> 2508328125776
	2508326639216 [label="features.2.0.block.3.1.weight
 (24)" fillcolor=lightblue]
	2508326639216 -> 2508328128176
	2508328128176 [label=AccumulateGrad]
	2508328128032 -> 2508328125776
	2508326639312 [label="features.2.0.block.3.1.bias
 (24)" fillcolor=lightblue]
	2508326639312 -> 2508328128032
	2508328128032 [label=AccumulateGrad]
	2508328128128 -> 2508328127840
	2508326639696 [label="features.2.1.block.0.0.weight
 (144, 24, 1, 1)" fillcolor=lightblue]
	2508326639696 -> 2508328128128
	2508328128128 [label=AccumulateGrad]
	2508328127696 -> 2508328127792
	2508326639792 [label="features.2.1.block.0.1.weight
 (144)" fillcolor=lightblue]
	2508326639792 -> 2508328127696
	2508328127696 [label=AccumulateGrad]
	2508328127936 -> 2508328127792
	2508326639888 [label="features.2.1.block.0.1.bias
 (144)" fillcolor=lightblue]
	2508326639888 -> 2508328127936
	2508328127936 [label=AccumulateGrad]
	2508328127600 -> 2508328127360
	2508326640272 [label="features.2.1.block.1.0.weight
 (144, 1, 3, 3)" fillcolor=lightblue]
	2508326640272 -> 2508328127600
	2508328127600 [label=AccumulateGrad]
	2508328127312 -> 2508328127120
	2508326640368 [label="features.2.1.block.1.1.weight
 (144)" fillcolor=lightblue]
	2508326640368 -> 2508328127312
	2508328127312 [label=AccumulateGrad]
	2508328127456 -> 2508328127120
	2508326640464 [label="features.2.1.block.1.1.bias
 (144)" fillcolor=lightblue]
	2508326640464 -> 2508328127456
	2508328127456 [label=AccumulateGrad]
	2508328126784 -> 2508328126880
	2508326640848 [label="features.2.1.block.2.fc1.weight
 (6, 144, 1, 1)" fillcolor=lightblue]
	2508326640848 -> 2508328126784
	2508328126784 [label=AccumulateGrad]
	2508328127024 -> 2508328126880
	2508326640944 [label="features.2.1.block.2.fc1.bias
 (6)" fillcolor=lightblue]
	2508326640944 -> 2508328127024
	2508328127024 [label=AccumulateGrad]
	2508328126448 -> 2508328126544
	2508326641040 [label="features.2.1.block.2.fc2.weight
 (144, 6, 1, 1)" fillcolor=lightblue]
	2508326641040 -> 2508328126448
	2508328126448 [label=AccumulateGrad]
	2508328126688 -> 2508328126544
	2508326641136 [label="features.2.1.block.2.fc2.bias
 (144)" fillcolor=lightblue]
	2508326641136 -> 2508328126688
	2508328126688 [label=AccumulateGrad]
	2508328126352 -> 2508328126256
	2508328126208 -> 2508328126064
	2508326641232 [label="features.2.1.block.3.0.weight
 (24, 144, 1, 1)" fillcolor=lightblue]
	2508326641232 -> 2508328126208
	2508328126208 [label=AccumulateGrad]
	2508328126016 -> 2508328125968
	2508326641328 [label="features.2.1.block.3.1.weight
 (24)" fillcolor=lightblue]
	2508326641328 -> 2508328126016
	2508328126016 [label=AccumulateGrad]
	2508328125872 -> 2508328125968
	2508326641424 [label="features.2.1.block.3.1.bias
 (24)" fillcolor=lightblue]
	2508326641424 -> 2508328125872
	2508328125872 [label=AccumulateGrad]
	2508328125776 -> 2508328125680
	2508328125632 -> 2508328125392
	2508326641808 [label="features.3.0.block.0.0.weight
 (144, 24, 1, 1)" fillcolor=lightblue]
	2508326641808 -> 2508328125632
	2508328125632 [label=AccumulateGrad]
	2508328125248 -> 2508328125344
	2508326641904 [label="features.3.0.block.0.1.weight
 (144)" fillcolor=lightblue]
	2508326641904 -> 2508328125248
	2508328125248 [label=AccumulateGrad]
	2508328125488 -> 2508328125344
	2508326642000 [label="features.3.0.block.0.1.bias
 (144)" fillcolor=lightblue]
	2508326642000 -> 2508328125488
	2508328125488 [label=AccumulateGrad]
	2508328125152 -> 2508328124912
	2508326642384 [label="features.3.0.block.1.0.weight
 (144, 1, 5, 5)" fillcolor=lightblue]
	2508326642384 -> 2508328125152
	2508328125152 [label=AccumulateGrad]
	2508328124864 -> 2508328124672
	2508326642480 [label="features.3.0.block.1.1.weight
 (144)" fillcolor=lightblue]
	2508326642480 -> 2508328124864
	2508328124864 [label=AccumulateGrad]
	2508328125008 -> 2508328124672
	2508326642576 [label="features.3.0.block.1.1.bias
 (144)" fillcolor=lightblue]
	2508326642576 -> 2508328125008
	2508328125008 [label=AccumulateGrad]
	2508328124480 -> 2508401111296
	2508326642960 [label="features.3.0.block.2.fc1.weight
 (6, 144, 1, 1)" fillcolor=lightblue]
	2508326642960 -> 2508328124480
	2508328124480 [label=AccumulateGrad]
	2508328124576 -> 2508401111296
	2508326643056 [label="features.3.0.block.2.fc1.bias
 (6)" fillcolor=lightblue]
	2508326643056 -> 2508328124576
	2508328124576 [label=AccumulateGrad]
	2508401108944 -> 2508401111344
	2508326643152 [label="features.3.0.block.2.fc2.weight
 (144, 6, 1, 1)" fillcolor=lightblue]
	2508326643152 -> 2508401108944
	2508401108944 [label=AccumulateGrad]
	2508401107984 -> 2508401111344
	2508326643248 [label="features.3.0.block.2.fc2.bias
 (144)" fillcolor=lightblue]
	2508326643248 -> 2508401107984
	2508401107984 [label=AccumulateGrad]
	2508401099536 -> 2508401110336
	2508401111824 -> 2508401114224
	2508326643344 [label="features.3.0.block.3.0.weight
 (40, 144, 1, 1)" fillcolor=lightblue]
	2508326643344 -> 2508401111824
	2508401111824 [label=AccumulateGrad]
	2508401110912 -> 2508401100160
	2508326643440 [label="features.3.0.block.3.1.weight
 (40)" fillcolor=lightblue]
	2508326643440 -> 2508401110912
	2508401110912 [label=AccumulateGrad]
	2508401109040 -> 2508401100160
	2508326643536 [label="features.3.0.block.3.1.bias
 (40)" fillcolor=lightblue]
	2508326643536 -> 2508401109040
	2508401109040 [label=AccumulateGrad]
	2508401109808 -> 2508401114032
	2508326643920 [label="features.3.1.block.0.0.weight
 (240, 40, 1, 1)" fillcolor=lightblue]
	2508326643920 -> 2508401109808
	2508401109808 [label=AccumulateGrad]
	2508401112304 -> 2508401114128
	2508326644016 [label="features.3.1.block.0.1.weight
 (240)" fillcolor=lightblue]
	2508326644016 -> 2508401112304
	2508401112304 [label=AccumulateGrad]
	2508401113312 -> 2508401114128
	2508326644112 [label="features.3.1.block.0.1.bias
 (240)" fillcolor=lightblue]
	2508326644112 -> 2508401113312
	2508401113312 [label=AccumulateGrad]
	2508401112448 -> 2508401114320
	2508326644496 [label="features.3.1.block.1.0.weight
 (240, 1, 5, 5)" fillcolor=lightblue]
	2508326644496 -> 2508401112448
	2508401112448 [label=AccumulateGrad]
	2508401106976 -> 2508401113888
	2508326644592 [label="features.3.1.block.1.1.weight
 (240)" fillcolor=lightblue]
	2508326644592 -> 2508401106976
	2508401106976 [label=AccumulateGrad]
	2508401108512 -> 2508401113888
	2508326644688 [label="features.3.1.block.1.1.bias
 (240)" fillcolor=lightblue]
	2508326644688 -> 2508401108512
	2508401108512 [label=AccumulateGrad]
	2508401102512 -> 2508401102464
	2508326645072 [label="features.3.1.block.2.fc1.weight
 (10, 240, 1, 1)" fillcolor=lightblue]
	2508326645072 -> 2508401102512
	2508401102512 [label=AccumulateGrad]
	2508401113360 -> 2508401102464
	2508326645168 [label="features.3.1.block.2.fc1.bias
 (10)" fillcolor=lightblue]
	2508326645168 -> 2508401113360
	2508401113360 [label=AccumulateGrad]
	2508401102944 -> 2508401101840
	2508326645264 [label="features.3.1.block.2.fc2.weight
 (240, 10, 1, 1)" fillcolor=lightblue]
	2508326645264 -> 2508401102944
	2508401102944 [label=AccumulateGrad]
	2508401099296 -> 2508401101840
	2508326645360 [label="features.3.1.block.2.fc2.bias
 (240)" fillcolor=lightblue]
	2508326645360 -> 2508401099296
	2508401099296 [label=AccumulateGrad]
	2508401101360 -> 2508401101888
	2508401103328 -> 2508401099008
	2508326645456 [label="features.3.1.block.3.0.weight
 (40, 240, 1, 1)" fillcolor=lightblue]
	2508326645456 -> 2508401103328
	2508401103328 [label=AccumulateGrad]
	2508401103184 -> 2508401099968
	2508326645552 [label="features.3.1.block.3.1.weight
 (40)" fillcolor=lightblue]
	2508326645552 -> 2508401103184
	2508401103184 [label=AccumulateGrad]
	2508401103616 -> 2508401099968
	2508326645648 [label="features.3.1.block.3.1.bias
 (40)" fillcolor=lightblue]
	2508326645648 -> 2508401103616
	2508401103616 [label=AccumulateGrad]
	2508401100160 -> 2508401103136
	2508401103472 -> 2508401101264
	2508326646032 [label="features.4.0.block.0.0.weight
 (240, 40, 1, 1)" fillcolor=lightblue]
	2508326646032 -> 2508401103472
	2508401103472 [label=AccumulateGrad]
	2508401104144 -> 2508401101216
	2508326646128 [label="features.4.0.block.0.1.weight
 (240)" fillcolor=lightblue]
	2508326646128 -> 2508401104144
	2508401104144 [label=AccumulateGrad]
	2508401099488 -> 2508401101216
	2508326646224 [label="features.4.0.block.0.1.bias
 (240)" fillcolor=lightblue]
	2508326646224 -> 2508401099488
	2508401099488 [label=AccumulateGrad]
	2508401100400 -> 2508401105200
	2508326646608 [label="features.4.0.block.1.0.weight
 (240, 1, 3, 3)" fillcolor=lightblue]
	2508326646608 -> 2508401100400
	2508401100400 [label=AccumulateGrad]
	2508401105056 -> 2508401100544
	2508326646704 [label="features.4.0.block.1.1.weight
 (240)" fillcolor=lightblue]
	2508326646704 -> 2508401105056
	2508401105056 [label=AccumulateGrad]
	2508401102992 -> 2508401100544
	2508326646800 [label="features.4.0.block.1.1.bias
 (240)" fillcolor=lightblue]
	2508326646800 -> 2508401102992
	2508401102992 [label=AccumulateGrad]
	2508401103760 -> 2508401105968
	2508326647184 [label="features.4.0.block.2.fc1.weight
 (10, 240, 1, 1)" fillcolor=lightblue]
	2508326647184 -> 2508401103760
	2508401103760 [label=AccumulateGrad]
	2508401102896 -> 2508401105968
	2508326647280 [label="features.4.0.block.2.fc1.bias
 (10)" fillcolor=lightblue]
	2508326647280 -> 2508401102896
	2508401102896 [label=AccumulateGrad]
	2508401106688 -> 2508401104336
	2508326647376 [label="features.4.0.block.2.fc2.weight
 (240, 10, 1, 1)" fillcolor=lightblue]
	2508326647376 -> 2508401106688
	2508401106688 [label=AccumulateGrad]
	2508401106208 -> 2508401104336
	2508326647472 [label="features.4.0.block.2.fc2.bias
 (240)" fillcolor=lightblue]
	2508326647472 -> 2508401106208
	2508401106208 [label=AccumulateGrad]
	2508401106832 -> 2508401106016
	2508401100496 -> 2508401107360
	2508326647568 [label="features.4.0.block.3.0.weight
 (80, 240, 1, 1)" fillcolor=lightblue]
	2508326647568 -> 2508401100496
	2508401100496 [label=AccumulateGrad]
	2508401100448 -> 2508401109616
	2508326647664 [label="features.4.0.block.3.1.weight
 (80)" fillcolor=lightblue]
	2508326647664 -> 2508401100448
	2508401100448 [label=AccumulateGrad]
	2508401101984 -> 2508401109616
	2508326647760 [label="features.4.0.block.3.1.bias
 (80)" fillcolor=lightblue]
	2508326647760 -> 2508401101984
	2508401101984 [label=AccumulateGrad]
	2508401107312 -> 2508401106160
	2508326648144 [label="features.4.1.block.0.0.weight
 (480, 80, 1, 1)" fillcolor=lightblue]
	2508326648144 -> 2508401107312
	2508401107312 [label=AccumulateGrad]
	2508401107264 -> 2508401102320
	2508326648240 [label="features.4.1.block.0.1.weight
 (480)" fillcolor=lightblue]
	2508326648240 -> 2508401107264
	2508401107264 [label=AccumulateGrad]
	2508401103952 -> 2508401102320
	2508326648336 [label="features.4.1.block.0.1.bias
 (480)" fillcolor=lightblue]
	2508326648336 -> 2508401103952
	2508401103952 [label=AccumulateGrad]
	2508401106064 -> 2508401107168
	2508326648720 [label="features.4.1.block.1.0.weight
 (480, 1, 3, 3)" fillcolor=lightblue]
	2508326648720 -> 2508401106064
	2508401106064 [label=AccumulateGrad]
	2508401108416 -> 2508401108128
	2508326648816 [label="features.4.1.block.1.1.weight
 (480)" fillcolor=lightblue]
	2508326648816 -> 2508401108416
	2508401108416 [label=AccumulateGrad]
	2508401105488 -> 2508401108128
	2508326648912 [label="features.4.1.block.1.1.bias
 (480)" fillcolor=lightblue]
	2508326648912 -> 2508401105488
	2508401105488 [label=AccumulateGrad]
	2508401103520 -> 2508401108032
	2508326649296 [label="features.4.1.block.2.fc1.weight
 (20, 480, 1, 1)" fillcolor=lightblue]
	2508326649296 -> 2508401103520
	2508401103520 [label=AccumulateGrad]
	2508401108176 -> 2508401108032
	2508326649392 [label="features.4.1.block.2.fc1.bias
 (20)" fillcolor=lightblue]
	2508326649392 -> 2508401108176
	2508401108176 [label=AccumulateGrad]
	2508401109328 -> 2508401109712
	2508326649488 [label="features.4.1.block.2.fc2.weight
 (480, 20, 1, 1)" fillcolor=lightblue]
	2508326649488 -> 2508401109328
	2508401109328 [label=AccumulateGrad]
	2508401105584 -> 2508401109712
	2508326649584 [label="features.4.1.block.2.fc2.bias
 (480)" fillcolor=lightblue]
	2508326649584 -> 2508401105584
	2508401105584 [label=AccumulateGrad]
	2508401110144 -> 2508401109856
	2508401106448 -> 2508401110288
	2508326649680 [label="features.4.1.block.3.0.weight
 (80, 480, 1, 1)" fillcolor=lightblue]
	2508326649680 -> 2508401106448
	2508401106448 [label=AccumulateGrad]
	2508401107456 -> 2508401110720
	2508326649776 [label="features.4.1.block.3.1.weight
 (80)" fillcolor=lightblue]
	2508326649776 -> 2508401107456
	2508401107456 [label=AccumulateGrad]
	2508401109472 -> 2508401110720
	2508327092304 [label="features.4.1.block.3.1.bias
 (80)" fillcolor=lightblue]
	2508327092304 -> 2508401109472
	2508401109472 [label=AccumulateGrad]
	2508401109616 -> 2508401110000
	2508401100016 -> 2508401109568
	2508327092688 [label="features.4.2.block.0.0.weight
 (480, 80, 1, 1)" fillcolor=lightblue]
	2508327092688 -> 2508401100016
	2508401100016 [label=AccumulateGrad]
	2508401111680 -> 2508401106496
	2508327092784 [label="features.4.2.block.0.1.weight
 (480)" fillcolor=lightblue]
	2508327092784 -> 2508401111680
	2508401111680 [label=AccumulateGrad]
	2508401107600 -> 2508401106496
	2508327092880 [label="features.4.2.block.0.1.bias
 (480)" fillcolor=lightblue]
	2508327092880 -> 2508401107600
	2508401107600 [label=AccumulateGrad]
	2508401109520 -> 2508401109904
	2508327093264 [label="features.4.2.block.1.0.weight
 (480, 1, 3, 3)" fillcolor=lightblue]
	2508327093264 -> 2508401109520
	2508401109520 [label=AccumulateGrad]
	2508401107744 -> 2508401112496
	2508327093360 [label="features.4.2.block.1.1.weight
 (480)" fillcolor=lightblue]
	2508327093360 -> 2508401107744
	2508401107744 [label=AccumulateGrad]
	2508401108608 -> 2508401112496
	2508327093456 [label="features.4.2.block.1.1.bias
 (480)" fillcolor=lightblue]
	2508327093456 -> 2508401108608
	2508401108608 [label=AccumulateGrad]
	2508401111392 -> 2508401111104
	2508327093840 [label="features.4.2.block.2.fc1.weight
 (20, 480, 1, 1)" fillcolor=lightblue]
	2508327093840 -> 2508401111392
	2508401111392 [label=AccumulateGrad]
	2508401107024 -> 2508401111104
	2508327093936 [label="features.4.2.block.2.fc1.bias
 (20)" fillcolor=lightblue]
	2508327093936 -> 2508401107024
	2508401107024 [label=AccumulateGrad]
	2508401113504 -> 2508401112016
	2508327094032 [label="features.4.2.block.2.fc2.weight
 (480, 20, 1, 1)" fillcolor=lightblue]
	2508327094032 -> 2508401113504
	2508401113504 [label=AccumulateGrad]
	2508401112880 -> 2508401112016
	2508327094128 [label="features.4.2.block.2.fc2.bias
 (480)" fillcolor=lightblue]
	2508327094128 -> 2508401112880
	2508401112880 [label=AccumulateGrad]
	2508401113552 -> 2508401113744
	2508401112544 -> 2508401113840
	2508327094224 [label="features.4.2.block.3.0.weight
 (80, 480, 1, 1)" fillcolor=lightblue]
	2508327094224 -> 2508401112544
	2508401112544 [label=AccumulateGrad]
	2508401113024 -> 2508401108080
	2508327094320 [label="features.4.2.block.3.1.weight
 (80)" fillcolor=lightblue]
	2508327094320 -> 2508401113024
	2508401113024 [label=AccumulateGrad]
	2508401111008 -> 2508401108080
	2508327094416 [label="features.4.2.block.3.1.bias
 (80)" fillcolor=lightblue]
	2508327094416 -> 2508401111008
	2508401111008 [label=AccumulateGrad]
	2508401110000 -> 2508401114176
	2508401114800 -> 2508401103664
	2508327094800 [label="features.5.0.block.0.0.weight
 (480, 80, 1, 1)" fillcolor=lightblue]
	2508327094800 -> 2508401114800
	2508401114800 [label=AccumulateGrad]
	2508401113600 -> 2508401112256
	2508327094896 [label="features.5.0.block.0.1.weight
 (480)" fillcolor=lightblue]
	2508327094896 -> 2508401113600
	2508401113600 [label=AccumulateGrad]
	2508401114896 -> 2508401112256
	2508327094992 [label="features.5.0.block.0.1.bias
 (480)" fillcolor=lightblue]
	2508327094992 -> 2508401114896
	2508401114896 [label=AccumulateGrad]
	2508401114992 -> 2508401115088
	2508327095376 [label="features.5.0.block.1.0.weight
 (480, 1, 5, 5)" fillcolor=lightblue]
	2508327095376 -> 2508401114992
	2508401114992 [label=AccumulateGrad]
	2508401112640 -> 2508401114272
	2508327095472 [label="features.5.0.block.1.1.weight
 (480)" fillcolor=lightblue]
	2508327095472 -> 2508401112640
	2508401112640 [label=AccumulateGrad]
	2508401113936 -> 2508401114272
	2508327095568 [label="features.5.0.block.1.1.bias
 (480)" fillcolor=lightblue]
	2508327095568 -> 2508401113936
	2508401113936 [label=AccumulateGrad]
	2508401112592 -> 2508401109280
	2508327095952 [label="features.5.0.block.2.fc1.weight
 (20, 480, 1, 1)" fillcolor=lightblue]
	2508327095952 -> 2508401112592
	2508401112592 [label=AccumulateGrad]
	2508401113696 -> 2508401109280
	2508327096048 [label="features.5.0.block.2.fc1.bias
 (20)" fillcolor=lightblue]
	2508327096048 -> 2508401113696
	2508401113696 [label=AccumulateGrad]
	2508401110576 -> 2508401104960
	2508327096144 [label="features.5.0.block.2.fc2.weight
 (480, 20, 1, 1)" fillcolor=lightblue]
	2508327096144 -> 2508401110576
	2508401110576 [label=AccumulateGrad]
	2508401105296 -> 2508401104960
	2508327096240 [label="features.5.0.block.2.fc2.bias
 (480)" fillcolor=lightblue]
	2508327096240 -> 2508401105296
	2508401105296 [label=AccumulateGrad]
	2508401101456 -> 2508401107888
	2508401110480 -> 2508401108464
	2508327096336 [label="features.5.0.block.3.0.weight
 (112, 480, 1, 1)" fillcolor=lightblue]
	2508327096336 -> 2508401110480
	2508401110480 [label=AccumulateGrad]
	2508401109232 -> 2508401110864
	2508327096432 [label="features.5.0.block.3.1.weight
 (112)" fillcolor=lightblue]
	2508327096432 -> 2508401109232
	2508401109232 [label=AccumulateGrad]
	2508401103712 -> 2508401110864
	2508327096528 [label="features.5.0.block.3.1.bias
 (112)" fillcolor=lightblue]
	2508327096528 -> 2508401103712
	2508401103712 [label=AccumulateGrad]
	2508401109664 -> 2508401105344
	2508327096912 [label="features.5.1.block.0.0.weight
 (672, 112, 1, 1)" fillcolor=lightblue]
	2508327096912 -> 2508401109664
	2508401109664 [label=AccumulateGrad]
	2508401107648 -> 2508401105536
	2508327097008 [label="features.5.1.block.0.1.weight
 (672)" fillcolor=lightblue]
	2508327097008 -> 2508401107648
	2508401107648 [label=AccumulateGrad]
	2508401108656 -> 2508401105536
	2508327097104 [label="features.5.1.block.0.1.bias
 (672)" fillcolor=lightblue]
	2508327097104 -> 2508401108656
	2508401108656 [label=AccumulateGrad]
	2508401101696 -> 2508401107072
	2508327097488 [label="features.5.1.block.1.0.weight
 (672, 1, 5, 5)" fillcolor=lightblue]
	2508327097488 -> 2508401101696
	2508401101696 [label=AccumulateGrad]
	2508401106640 -> 2508401104864
	2508327097584 [label="features.5.1.block.1.1.weight
 (672)" fillcolor=lightblue]
	2508327097584 -> 2508401106640
	2508401106640 [label=AccumulateGrad]
	2508401106592 -> 2508401104864
	2508327097680 [label="features.5.1.block.1.1.bias
 (672)" fillcolor=lightblue]
	2508327097680 -> 2508401106592
	2508401106592 [label=AccumulateGrad]
	2508401104768 -> 2508401105104
	2508327098064 [label="features.5.1.block.2.fc1.weight
 (28, 672, 1, 1)" fillcolor=lightblue]
	2508327098064 -> 2508401104768
	2508401104768 [label=AccumulateGrad]
	2508401098960 -> 2508401105104
	2508327098160 [label="features.5.1.block.2.fc1.bias
 (28)" fillcolor=lightblue]
	2508327098160 -> 2508401098960
	2508401098960 [label=AccumulateGrad]
	2508401101792 -> 2508401103904
	2508327098256 [label="features.5.1.block.2.fc2.weight
 (672, 28, 1, 1)" fillcolor=lightblue]
	2508327098256 -> 2508401101792
	2508401101792 [label=AccumulateGrad]
	2508401102128 -> 2508401103904
	2508327098352 [label="features.5.1.block.2.fc2.bias
 (672)" fillcolor=lightblue]
	2508327098352 -> 2508401102128
	2508401102128 [label=AccumulateGrad]
	2508401100784 -> 2508401104096
	2508401111248 -> 2508401105392
	2508327098448 [label="features.5.1.block.3.0.weight
 (112, 672, 1, 1)" fillcolor=lightblue]
	2508327098448 -> 2508401111248
	2508401111248 [label=AccumulateGrad]
	2508401104672 -> 2508401112160
	2508327098544 [label="features.5.1.block.3.1.weight
 (112)" fillcolor=lightblue]
	2508327098544 -> 2508401104672
	2508401104672 [label=AccumulateGrad]
	2508401099344 -> 2508401112160
	2508327098640 [label="features.5.1.block.3.1.bias
 (112)" fillcolor=lightblue]
	2508327098640 -> 2508401099344
	2508401099344 [label=AccumulateGrad]
	2508401110864 -> 2508401220368
	2508401102272 -> 2508401098864
	2508327099024 [label="features.5.2.block.0.0.weight
 (672, 112, 1, 1)" fillcolor=lightblue]
	2508327099024 -> 2508401102272
	2508401102272 [label=AccumulateGrad]
	2508401099872 -> 2508401104000
	2508327099120 [label="features.5.2.block.0.1.weight
 (672)" fillcolor=lightblue]
	2508327099120 -> 2508401099872
	2508401099872 [label=AccumulateGrad]
	2508401099776 -> 2508401104000
	2508327099216 [label="features.5.2.block.0.1.bias
 (672)" fillcolor=lightblue]
	2508327099216 -> 2508401099776
	2508401099776 [label=AccumulateGrad]
	2508401100592 -> 2508401099680
	2508327099600 [label="features.5.2.block.1.0.weight
 (672, 1, 5, 5)" fillcolor=lightblue]
	2508327099600 -> 2508401100592
	2508401100592 [label=AccumulateGrad]
	2508401112400 -> 2508401100064
	2508327099696 [label="features.5.2.block.1.1.weight
 (672)" fillcolor=lightblue]
	2508327099696 -> 2508401112400
	2508401112400 [label=AccumulateGrad]
	2508401099632 -> 2508401100064
	2508327099792 [label="features.5.2.block.1.1.bias
 (672)" fillcolor=lightblue]
	2508327099792 -> 2508401099632
	2508401099632 [label=AccumulateGrad]
	2508401215088 -> 2508401217008
	2508327100176 [label="features.5.2.block.2.fc1.weight
 (28, 672, 1, 1)" fillcolor=lightblue]
	2508327100176 -> 2508401215088
	2508401215088 [label=AccumulateGrad]
	2508401099584 -> 2508401217008
	2508327100272 [label="features.5.2.block.2.fc1.bias
 (28)" fillcolor=lightblue]
	2508327100272 -> 2508401099584
	2508401099584 [label=AccumulateGrad]
	2508401223968 -> 2508401225744
	2508327100368 [label="features.5.2.block.2.fc2.weight
 (672, 28, 1, 1)" fillcolor=lightblue]
	2508327100368 -> 2508401223968
	2508401223968 [label=AccumulateGrad]
	2508401228240 -> 2508401225744
	2508327100464 [label="features.5.2.block.2.fc2.bias
 (672)" fillcolor=lightblue]
	2508327100464 -> 2508401228240
	2508401228240 [label=AccumulateGrad]
	2508401214128 -> 2508401217248
	2508401222672 -> 2508401217872
	2508327100560 [label="features.5.2.block.3.0.weight
 (112, 672, 1, 1)" fillcolor=lightblue]
	2508327100560 -> 2508401222672
	2508401222672 [label=AccumulateGrad]
	2508401219504 -> 2508401214992
	2508327100656 [label="features.5.2.block.3.1.weight
 (112)" fillcolor=lightblue]
	2508327100656 -> 2508401219504
	2508401219504 [label=AccumulateGrad]
	2508401215232 -> 2508401214992
	2508327100752 [label="features.5.2.block.3.1.bias
 (112)" fillcolor=lightblue]
	2508327100752 -> 2508401215232
	2508401215232 [label=AccumulateGrad]
	2508401220368 -> 2508401214320
	2508401228384 -> 2508401227616
	2508327101136 [label="features.6.0.block.0.0.weight
 (672, 112, 1, 1)" fillcolor=lightblue]
	2508327101136 -> 2508401228384
	2508401228384 [label=AccumulateGrad]
	2508401217536 -> 2508401229440
	2508327101232 [label="features.6.0.block.0.1.weight
 (672)" fillcolor=lightblue]
	2508327101232 -> 2508401217536
	2508401217536 [label=AccumulateGrad]
	2508401213984 -> 2508401229440
	2508327101328 [label="features.6.0.block.0.1.bias
 (672)" fillcolor=lightblue]
	2508327101328 -> 2508401213984
	2508401213984 [label=AccumulateGrad]
	2508401220032 -> 2508401218064
	2508327101712 [label="features.6.0.block.1.0.weight
 (672, 1, 5, 5)" fillcolor=lightblue]
	2508327101712 -> 2508401220032
	2508401220032 [label=AccumulateGrad]
	2508401215280 -> 2508401216336
	2508327101808 [label="features.6.0.block.1.1.weight
 (672)" fillcolor=lightblue]
	2508327101808 -> 2508401215280
	2508401215280 [label=AccumulateGrad]
	2508401225936 -> 2508401216336
	2508327101904 [label="features.6.0.block.1.1.bias
 (672)" fillcolor=lightblue]
	2508327101904 -> 2508401225936
	2508401225936 [label=AccumulateGrad]
	2508401219312 -> 2508401214080
	2508327102288 [label="features.6.0.block.2.fc1.weight
 (28, 672, 1, 1)" fillcolor=lightblue]
	2508327102288 -> 2508401219312
	2508401219312 [label=AccumulateGrad]
	2508401228192 -> 2508401214080
	2508327102384 [label="features.6.0.block.2.fc1.bias
 (28)" fillcolor=lightblue]
	2508327102384 -> 2508401228192
	2508401228192 [label=AccumulateGrad]
	2508401229392 -> 2508401214848
	2508327102480 [label="features.6.0.block.2.fc2.weight
 (672, 28, 1, 1)" fillcolor=lightblue]
	2508327102480 -> 2508401229392
	2508401229392 [label=AccumulateGrad]
	2508401223296 -> 2508401214848
	2508327102576 [label="features.6.0.block.2.fc2.bias
 (672)" fillcolor=lightblue]
	2508327102576 -> 2508401223296
	2508401223296 [label=AccumulateGrad]
	2508401217488 -> 2508401224400
	2508401217344 -> 2508401228528
	2508327102672 [label="features.6.0.block.3.0.weight
 (192, 672, 1, 1)" fillcolor=lightblue]
	2508327102672 -> 2508401217344
	2508401217344 [label=AccumulateGrad]
	2508401214416 -> 2508401226368
	2508327102768 [label="features.6.0.block.3.1.weight
 (192)" fillcolor=lightblue]
	2508327102768 -> 2508401214416
	2508401214416 [label=AccumulateGrad]
	2508401220224 -> 2508401226368
	2508327102864 [label="features.6.0.block.3.1.bias
 (192)" fillcolor=lightblue]
	2508327102864 -> 2508401220224
	2508401220224 [label=AccumulateGrad]
	2508401220128 -> 2508401219552
	2508327103344 [label="features.6.1.block.0.0.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	2508327103344 -> 2508401220128
	2508401220128 [label=AccumulateGrad]
	2508401216432 -> 2508401216144
	2508327103440 [label="features.6.1.block.0.1.weight
 (1152)" fillcolor=lightblue]
	2508327103440 -> 2508401216432
	2508401216432 [label=AccumulateGrad]
	2508401227424 -> 2508401216144
	2508327103536 [label="features.6.1.block.0.1.bias
 (1152)" fillcolor=lightblue]
	2508327103536 -> 2508401227424
	2508401227424 [label=AccumulateGrad]
	2508401227664 -> 2508401225792
	2508327103920 [label="features.6.1.block.1.0.weight
 (1152, 1, 5, 5)" fillcolor=lightblue]
	2508327103920 -> 2508401227664
	2508401227664 [label=AccumulateGrad]
	2508401225312 -> 2508401224736
	2508327104016 [label="features.6.1.block.1.1.weight
 (1152)" fillcolor=lightblue]
	2508327104016 -> 2508401225312
	2508401225312 [label=AccumulateGrad]
	2508401225360 -> 2508401224736
	2508327104112 [label="features.6.1.block.1.1.bias
 (1152)" fillcolor=lightblue]
	2508327104112 -> 2508401225360
	2508401225360 [label=AccumulateGrad]
	2508401222048 -> 2508401225120
	2508327104496 [label="features.6.1.block.2.fc1.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	2508327104496 -> 2508401222048
	2508401222048 [label=AccumulateGrad]
	2508401215952 -> 2508401225120
	2508327104592 [label="features.6.1.block.2.fc1.bias
 (48)" fillcolor=lightblue]
	2508327104592 -> 2508401215952
	2508401215952 [label=AccumulateGrad]
	2508401224880 -> 2508401226656
	2508327104688 [label="features.6.1.block.2.fc2.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	2508327104688 -> 2508401224880
	2508401224880 [label=AccumulateGrad]
	2508401226032 -> 2508401226656
	2508327104784 [label="features.6.1.block.2.fc2.bias
 (1152)" fillcolor=lightblue]
	2508327104784 -> 2508401226032
	2508401226032 [label=AccumulateGrad]
	2508401214896 -> 2508401223392
	2508401216720 -> 2508401216048
	2508327104880 [label="features.6.1.block.3.0.weight
 (192, 1152, 1, 1)" fillcolor=lightblue]
	2508327104880 -> 2508401216720
	2508401216720 [label=AccumulateGrad]
	2508401227040 -> 2508401222720
	2508327104976 [label="features.6.1.block.3.1.weight
 (192)" fillcolor=lightblue]
	2508327104976 -> 2508401227040
	2508401227040 [label=AccumulateGrad]
	2508401215760 -> 2508401222720
	2508327105072 [label="features.6.1.block.3.1.bias
 (192)" fillcolor=lightblue]
	2508327105072 -> 2508401215760
	2508401215760 [label=AccumulateGrad]
	2508401226368 -> 2508401216192
	2508401217776 -> 2508401222480
	2508327105456 [label="features.6.2.block.0.0.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	2508327105456 -> 2508401217776
	2508401217776 [label=AccumulateGrad]
	2508401218688 -> 2508401225552
	2508327105552 [label="features.6.2.block.0.1.weight
 (1152)" fillcolor=lightblue]
	2508327105552 -> 2508401218688
	2508401218688 [label=AccumulateGrad]
	2508401216672 -> 2508401225552
	2508327105648 [label="features.6.2.block.0.1.bias
 (1152)" fillcolor=lightblue]
	2508327105648 -> 2508401216672
	2508401216672 [label=AccumulateGrad]
	2508401223632 -> 2508401217968
	2508327106032 [label="features.6.2.block.1.0.weight
 (1152, 1, 5, 5)" fillcolor=lightblue]
	2508327106032 -> 2508401223632
	2508401223632 [label=AccumulateGrad]
	2508401223680 -> 2508401219456
	2508327106128 [label="features.6.2.block.1.1.weight
 (1152)" fillcolor=lightblue]
	2508327106128 -> 2508401223680
	2508401223680 [label=AccumulateGrad]
	2508401218448 -> 2508401219456
	2508327106224 [label="features.6.2.block.1.1.bias
 (1152)" fillcolor=lightblue]
	2508327106224 -> 2508401218448
	2508401218448 [label=AccumulateGrad]
	2508401228144 -> 2508401218400
	2508327106608 [label="features.6.2.block.2.fc1.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	2508327106608 -> 2508401228144
	2508401228144 [label=AccumulateGrad]
	2508401228096 -> 2508401218400
	2508327106704 [label="features.6.2.block.2.fc1.bias
 (48)" fillcolor=lightblue]
	2508327106704 -> 2508401228096
	2508401228096 [label=AccumulateGrad]
	2508401213744 -> 2508401229008
	2508327106800 [label="features.6.2.block.2.fc2.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	2508327106800 -> 2508401213744
	2508401213744 [label=AccumulateGrad]
	2508401225264 -> 2508401229008
	2508327106896 [label="features.6.2.block.2.fc2.bias
 (1152)" fillcolor=lightblue]
	2508327106896 -> 2508401225264
	2508401225264 [label=AccumulateGrad]
	2508401220992 -> 2508401227088
	2508401222144 -> 2508401224496
	2508327106992 [label="features.6.2.block.3.0.weight
 (192, 1152, 1, 1)" fillcolor=lightblue]
	2508327106992 -> 2508401222144
	2508401222144 [label=AccumulateGrad]
	2508401216816 -> 2508401226464
	2508327107088 [label="features.6.2.block.3.1.weight
 (192)" fillcolor=lightblue]
	2508327107088 -> 2508401216816
	2508401216816 [label=AccumulateGrad]
	2508401228480 -> 2508401226464
	2508327107184 [label="features.6.2.block.3.1.bias
 (192)" fillcolor=lightblue]
	2508327107184 -> 2508401228480
	2508401228480 [label=AccumulateGrad]
	2508401216192 -> 2508401225216
	2508401223584 -> 2508401224448
	2508327107472 [label="features.6.3.block.0.0.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	2508327107472 -> 2508401223584
	2508401223584 [label=AccumulateGrad]
	2508401219168 -> 2508401227136
	2508327107568 [label="features.6.3.block.0.1.weight
 (1152)" fillcolor=lightblue]
	2508327107568 -> 2508401219168
	2508401219168 [label=AccumulateGrad]
	2508401214512 -> 2508401227136
	2508327107664 [label="features.6.3.block.0.1.bias
 (1152)" fillcolor=lightblue]
	2508327107664 -> 2508401214512
	2508401214512 [label=AccumulateGrad]
	2508401227328 -> 2508401220896
	2508327108048 [label="features.6.3.block.1.0.weight
 (1152, 1, 5, 5)" fillcolor=lightblue]
	2508327108048 -> 2508401227328
	2508401227328 [label=AccumulateGrad]
	2508401224976 -> 2508401221856
	2508327108144 [label="features.6.3.block.1.1.weight
 (1152)" fillcolor=lightblue]
	2508327108144 -> 2508401224976
	2508401224976 [label=AccumulateGrad]
	2508401222432 -> 2508401221856
	2508327108240 [label="features.6.3.block.1.1.bias
 (1152)" fillcolor=lightblue]
	2508327108240 -> 2508401222432
	2508401222432 [label=AccumulateGrad]
	2508401213840 -> 2508401215040
	2508327518288 [label="features.6.3.block.2.fc1.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	2508327518288 -> 2508401213840
	2508401213840 [label=AccumulateGrad]
	2508401216576 -> 2508401215040
	2508327518384 [label="features.6.3.block.2.fc1.bias
 (48)" fillcolor=lightblue]
	2508327518384 -> 2508401216576
	2508401216576 [label=AccumulateGrad]
	2508401215568 -> 2508401215520
	2508327518480 [label="features.6.3.block.2.fc2.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	2508327518480 -> 2508401215568
	2508401215568 [label=AccumulateGrad]
	2508401215664 -> 2508401215520
	2508327518576 [label="features.6.3.block.2.fc2.bias
 (1152)" fillcolor=lightblue]
	2508327518576 -> 2508401215664
	2508401215664 [label=AccumulateGrad]
	2508401214560 -> 2508401221568
	2508401222624 -> 2508401222240
	2508327518672 [label="features.6.3.block.3.0.weight
 (192, 1152, 1, 1)" fillcolor=lightblue]
	2508327518672 -> 2508401222624
	2508401222624 [label=AccumulateGrad]
	2508401223056 -> 2508401213792
	2508327518768 [label="features.6.3.block.3.1.weight
 (192)" fillcolor=lightblue]
	2508327518768 -> 2508401223056
	2508401223056 [label=AccumulateGrad]
	2508401221760 -> 2508401213792
	2508327518864 [label="features.6.3.block.3.1.bias
 (192)" fillcolor=lightblue]
	2508327518864 -> 2508401221760
	2508401221760 [label=AccumulateGrad]
	2508401225216 -> 2508401222384
	2508401224016 -> 2508401225072
	2508327519248 [label="features.7.0.block.0.0.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	2508327519248 -> 2508401224016
	2508401224016 [label=AccumulateGrad]
	2508401228624 -> 2508401226176
	2508327519344 [label="features.7.0.block.0.1.weight
 (1152)" fillcolor=lightblue]
	2508327519344 -> 2508401228624
	2508401228624 [label=AccumulateGrad]
	2508401229056 -> 2508401226176
	2508327519440 [label="features.7.0.block.0.1.bias
 (1152)" fillcolor=lightblue]
	2508327519440 -> 2508401229056
	2508401229056 [label=AccumulateGrad]
	2508401223008 -> 2508401229776
	2508327519824 [label="features.7.0.block.1.0.weight
 (1152, 1, 3, 3)" fillcolor=lightblue]
	2508327519824 -> 2508401223008
	2508401223008 [label=AccumulateGrad]
	2508401213696 -> 2508401213600
	2508327519920 [label="features.7.0.block.1.1.weight
 (1152)" fillcolor=lightblue]
	2508327519920 -> 2508401213696
	2508401213696 [label=AccumulateGrad]
	2508401223536 -> 2508401213600
	2508327520016 [label="features.7.0.block.1.1.bias
 (1152)" fillcolor=lightblue]
	2508327520016 -> 2508401223536
	2508401223536 [label=AccumulateGrad]
	2508401224928 -> 2508401226944
	2508327520400 [label="features.7.0.block.2.fc1.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	2508327520400 -> 2508401224928
	2508401224928 [label=AccumulateGrad]
	2508401227472 -> 2508401226944
	2508327520496 [label="features.7.0.block.2.fc1.bias
 (48)" fillcolor=lightblue]
	2508327520496 -> 2508401227472
	2508401227472 [label=AccumulateGrad]
	2508401227376 -> 2508401226992
	2508327520592 [label="features.7.0.block.2.fc2.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	2508327520592 -> 2508401227376
	2508401227376 [label=AccumulateGrad]
	2508401227232 -> 2508401226992
	2508327520688 [label="features.7.0.block.2.fc2.bias
 (1152)" fillcolor=lightblue]
	2508327520688 -> 2508401227232
	2508401227232 [label=AccumulateGrad]
	2508401214224 -> 2508401214032
	2508401225504 -> 2508401225984
	2508327520784 [label="features.7.0.block.3.0.weight
 (320, 1152, 1, 1)" fillcolor=lightblue]
	2508327520784 -> 2508401225504
	2508401225504 [label=AccumulateGrad]
	2508401228336 -> 2508401228576
	2508327520880 [label="features.7.0.block.3.1.weight
 (320)" fillcolor=lightblue]
	2508327520880 -> 2508401228336
	2508401228336 [label=AccumulateGrad]
	2508401228960 -> 2508401228576
	2508327520976 [label="features.7.0.block.3.1.bias
 (320)" fillcolor=lightblue]
	2508327520976 -> 2508401228960
	2508401228960 [label=AccumulateGrad]
	2508401228288 -> 2508401214704
	2508327521360 [label="features.8.0.weight
 (1280, 320, 1, 1)" fillcolor=lightblue]
	2508327521360 -> 2508401228288
	2508401228288 [label=AccumulateGrad]
	2508401215712 -> 2508401215472
	2508327521456 [label="features.8.1.weight
 (1280)" fillcolor=lightblue]
	2508327521456 -> 2508401215712
	2508401215712 [label=AccumulateGrad]
	2508401220464 -> 2508401215472
	2508327521552 [label="features.8.1.bias
 (1280)" fillcolor=lightblue]
	2508327521552 -> 2508401220464
	2508401220464 [label=AccumulateGrad]
	2508401229200 -> 2508401225696
	2508401229200 [label=TBackward0]
	2508401213648 -> 2508401229200
	2508327522224 [label="classifier.1.weight
 (19, 1280)" fillcolor=lightblue]
	2508327522224 -> 2508401213648
	2508401213648 [label=AccumulateGrad]
	2508401225696 -> 2508328246672
}
