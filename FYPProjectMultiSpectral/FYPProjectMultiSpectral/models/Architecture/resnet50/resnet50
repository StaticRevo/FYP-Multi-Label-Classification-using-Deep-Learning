digraph {
	graph [size="151.95,151.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1422671888752 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1422708946304 [label=AddmmBackward0]
	1422708945968 -> 1422708946304
	1422705918992 [label="fc.bias
 (19)" fillcolor=lightblue]
	1422705918992 -> 1422708945968
	1422708945968 [label=AccumulateGrad]
	1422708945344 -> 1422708946304
	1422708945344 [label=ViewBackward0]
	1422708944864 -> 1422708945344
	1422708944864 [label=MeanBackward1]
	1422708944528 -> 1422708944864
	1422708944528 [label=ReluBackward0]
	1422708944048 -> 1422708944528
	1422708944048 [label=AddBackward0]
	1422708943568 -> 1422708944048
	1422708943568 [label=CudnnBatchNormBackward0]
	1422708942464 -> 1422708943568
	1422708942464 [label=ConvolutionBackward0]
	1422708941504 -> 1422708942464
	1422708941504 [label=ReluBackward0]
	1422708941168 -> 1422708941504
	1422708941168 [label=CudnnBatchNormBackward0]
	1422708940688 -> 1422708941168
	1422708940688 [label=ConvolutionBackward0]
	1422708939728 -> 1422708940688
	1422708939728 [label=ReluBackward0]
	1422708938624 -> 1422708939728
	1422708938624 [label=CudnnBatchNormBackward0]
	1422708938144 -> 1422708938624
	1422708938144 [label=ConvolutionBackward0]
	1422708943424 -> 1422708938144
	1422708943424 [label=ReluBackward0]
	1422708936704 -> 1422708943424
	1422708936704 [label=AddBackward0]
	1422708936224 -> 1422708936704
	1422708936224 [label=CudnnBatchNormBackward0]
	1422708935024 -> 1422708936224
	1422708935024 [label=ConvolutionBackward0]
	1422708934064 -> 1422708935024
	1422708934064 [label=ReluBackward0]
	1422708948800 -> 1422708934064
	1422708948800 [label=CudnnBatchNormBackward0]
	1422708948608 -> 1422708948800
	1422708948608 [label=ConvolutionBackward0]
	1422708948464 -> 1422708948608
	1422708948464 [label=ReluBackward0]
	1422708948272 -> 1422708948464
	1422708948272 [label=CudnnBatchNormBackward0]
	1422708947936 -> 1422708948272
	1422708947936 [label=ConvolutionBackward0]
	1422708936848 -> 1422708947936
	1422708936848 [label=ReluBackward0]
	1422708947792 -> 1422708936848
	1422708947792 [label=AddBackward0]
	1422708947456 -> 1422708947792
	1422708947456 [label=CudnnBatchNormBackward0]
	1422708947504 -> 1422708947456
	1422708947504 [label=ConvolutionBackward0]
	1422708947168 -> 1422708947504
	1422708947168 [label=ReluBackward0]
	1422708947216 -> 1422708947168
	1422708947216 [label=CudnnBatchNormBackward0]
	1422708947120 -> 1422708947216
	1422708947120 [label=ConvolutionBackward0]
	1422708946496 -> 1422708947120
	1422708946496 [label=ReluBackward0]
	1422708946544 -> 1422708946496
	1422708946544 [label=CudnnBatchNormBackward0]
	1422708946400 -> 1422708946544
	1422708946400 [label=ConvolutionBackward0]
	1422708946112 -> 1422708946400
	1422708946112 [label=ReluBackward0]
	1422708946160 -> 1422708946112
	1422708946160 [label=AddBackward0]
	1422708945872 -> 1422708946160
	1422708945872 [label=CudnnBatchNormBackward0]
	1422708945632 -> 1422708945872
	1422708945632 [label=ConvolutionBackward0]
	1422708945440 -> 1422708945632
	1422708945440 [label=ReluBackward0]
	1422708945056 -> 1422708945440
	1422708945056 [label=CudnnBatchNormBackward0]
	1422708945296 -> 1422708945056
	1422708945296 [label=ConvolutionBackward0]
	1422708944912 -> 1422708945296
	1422708944912 [label=ReluBackward0]
	1422708944672 -> 1422708944912
	1422708944672 [label=CudnnBatchNormBackward0]
	1422708944624 -> 1422708944672
	1422708944624 [label=ConvolutionBackward0]
	1422708945920 -> 1422708944624
	1422708945920 [label=ReluBackward0]
	1422708944192 -> 1422708945920
	1422708944192 [label=AddBackward0]
	1422708944144 -> 1422708944192
	1422708944144 [label=CudnnBatchNormBackward0]
	1422708943952 -> 1422708944144
	1422708943952 [label=ConvolutionBackward0]
	1422708943856 -> 1422708943952
	1422708943856 [label=ReluBackward0]
	1422708943520 -> 1422708943856
	1422708943520 [label=CudnnBatchNormBackward0]
	1422708943328 -> 1422708943520
	1422708943328 [label=ConvolutionBackward0]
	1422708943184 -> 1422708943328
	1422708943184 [label=ReluBackward0]
	1422708942992 -> 1422708943184
	1422708942992 [label=CudnnBatchNormBackward0]
	1422708942656 -> 1422708942992
	1422708942656 [label=ConvolutionBackward0]
	1422708944336 -> 1422708942656
	1422708944336 [label=ReluBackward0]
	1422708942512 -> 1422708944336
	1422708942512 [label=AddBackward0]
	1422708942176 -> 1422708942512
	1422708942176 [label=CudnnBatchNormBackward0]
	1422708942224 -> 1422708942176
	1422708942224 [label=ConvolutionBackward0]
	1422708941888 -> 1422708942224
	1422708941888 [label=ReluBackward0]
	1422708941936 -> 1422708941888
	1422708941936 [label=CudnnBatchNormBackward0]
	1422708941840 -> 1422708941936
	1422708941840 [label=ConvolutionBackward0]
	1422708941216 -> 1422708941840
	1422708941216 [label=ReluBackward0]
	1422708941264 -> 1422708941216
	1422708941264 [label=CudnnBatchNormBackward0]
	1422708941120 -> 1422708941264
	1422708941120 [label=ConvolutionBackward0]
	1422708942368 -> 1422708941120
	1422708942368 [label=ReluBackward0]
	1422708940784 -> 1422708942368
	1422708940784 [label=AddBackward0]
	1422708940640 -> 1422708940784
	1422708940640 [label=CudnnBatchNormBackward0]
	1422708940256 -> 1422708940640
	1422708940256 [label=ConvolutionBackward0]
	1422708940400 -> 1422708940256
	1422708940400 [label=ReluBackward0]
	1422708939968 -> 1422708940400
	1422708939968 [label=CudnnBatchNormBackward0]
	1422708939872 -> 1422708939968
	1422708939872 [label=ConvolutionBackward0]
	1422708939680 -> 1422708939872
	1422708939680 [label=ReluBackward0]
	1422708939296 -> 1422708939680
	1422708939296 [label=CudnnBatchNormBackward0]
	1422708939536 -> 1422708939296
	1422708939536 [label=ConvolutionBackward0]
	1422708940880 -> 1422708939536
	1422708940880 [label=ReluBackward0]
	1422708938816 -> 1422708940880
	1422708938816 [label=AddBackward0]
	1422708939056 -> 1422708938816
	1422708939056 [label=CudnnBatchNormBackward0]
	1422708938720 -> 1422708939056
	1422708938720 [label=ConvolutionBackward0]
	1422708938432 -> 1422708938720
	1422708938432 [label=ReluBackward0]
	1422708938480 -> 1422708938432
	1422708938480 [label=CudnnBatchNormBackward0]
	1422708938192 -> 1422708938480
	1422708938192 [label=ConvolutionBackward0]
	1422708938096 -> 1422708938192
	1422708938096 [label=ReluBackward0]
	1422708937760 -> 1422708938096
	1422708937760 [label=CudnnBatchNormBackward0]
	1422708937568 -> 1422708937760
	1422708937568 [label=ConvolutionBackward0]
	1422708938912 -> 1422708937568
	1422708938912 [label=ReluBackward0]
	1422708937280 -> 1422708938912
	1422708937280 [label=AddBackward0]
	1422708937088 -> 1422708937280
	1422708937088 [label=CudnnBatchNormBackward0]
	1422708937136 -> 1422708937088
	1422708937136 [label=ConvolutionBackward0]
	1422708936752 -> 1422708937136
	1422708936752 [label=ReluBackward0]
	1422708936512 -> 1422708936752
	1422708936512 [label=CudnnBatchNormBackward0]
	1422708936464 -> 1422708936512
	1422708936464 [label=ConvolutionBackward0]
	1422708936128 -> 1422708936464
	1422708936128 [label=ReluBackward0]
	1422708936176 -> 1422708936128
	1422708936176 [label=CudnnBatchNormBackward0]
	1422708933728 -> 1422708936176
	1422708933728 [label=ConvolutionBackward0]
	1422708934544 -> 1422708933728
	1422708934544 [label=ReluBackward0]
	1422708933536 -> 1422708934544
	1422708933536 [label=AddBackward0]
	1422708934784 -> 1422708933536
	1422708934784 [label=CudnnBatchNormBackward0]
	1422708932816 -> 1422708934784
	1422708932816 [label=ConvolutionBackward0]
	1422708935600 -> 1422708932816
	1422708935600 [label=ReluBackward0]
	1422708934832 -> 1422708935600
	1422708934832 [label=CudnnBatchNormBackward0]
	1422708934496 -> 1422708934832
	1422708934496 [label=ConvolutionBackward0]
	1422708935312 -> 1422708934496
	1422708935312 [label=ReluBackward0]
	1422708933824 -> 1422708935312
	1422708933824 [label=CudnnBatchNormBackward0]
	1422708935120 -> 1422708933824
	1422708935120 [label=ConvolutionBackward0]
	1422708932672 -> 1422708935120
	1422708932672 [label=ReluBackward0]
	1422708933248 -> 1422708932672
	1422708933248 [label=AddBackward0]
	1422555672592 -> 1422708933248
	1422555672592 [label=CudnnBatchNormBackward0]
	1422555672208 -> 1422555672592
	1422555672208 [label=ConvolutionBackward0]
	1422555669760 -> 1422555672208
	1422555669760 [label=ReluBackward0]
	1422555672736 -> 1422555669760
	1422555672736 [label=CudnnBatchNormBackward0]
	1422555669664 -> 1422555672736
	1422555669664 [label=ConvolutionBackward0]
	1422555675136 -> 1422555669664
	1422555675136 [label=ReluBackward0]
	1422555674320 -> 1422555675136
	1422555674320 [label=CudnnBatchNormBackward0]
	1422555676192 -> 1422555674320
	1422555676192 [label=ConvolutionBackward0]
	1422555672112 -> 1422555676192
	1422555672112 [label=ReluBackward0]
	1422555670048 -> 1422555672112
	1422555670048 [label=AddBackward0]
	1422555673504 -> 1422555670048
	1422555673504 [label=CudnnBatchNormBackward0]
	1422555674608 -> 1422555673504
	1422555674608 [label=ConvolutionBackward0]
	1422555670960 -> 1422555674608
	1422555670960 [label=ReluBackward0]
	1422555675328 -> 1422555670960
	1422555675328 [label=CudnnBatchNormBackward0]
	1422555670624 -> 1422555675328
	1422555670624 [label=ConvolutionBackward0]
	1422555671440 -> 1422555670624
	1422555671440 [label=ReluBackward0]
	1422555675904 -> 1422555671440
	1422555675904 [label=CudnnBatchNormBackward0]
	1422555671296 -> 1422555675904
	1422555671296 [label=ConvolutionBackward0]
	1422555673840 -> 1422555671296
	1422555673840 [label=ReluBackward0]
	1422555671008 -> 1422555673840
	1422555671008 [label=AddBackward0]
	1422555672832 -> 1422555671008
	1422555672832 [label=CudnnBatchNormBackward0]
	1422555673456 -> 1422555672832
	1422555673456 [label=ConvolutionBackward0]
	1422555674944 -> 1422555673456
	1422555674944 [label=ReluBackward0]
	1422555670144 -> 1422555674944
	1422555670144 [label=CudnnBatchNormBackward0]
	1422555670432 -> 1422555670144
	1422555670432 [label=ConvolutionBackward0]
	1422555673792 -> 1422555670432
	1422555673792 [label=ReluBackward0]
	1422555673120 -> 1422555673792
	1422555673120 [label=CudnnBatchNormBackward0]
	1422555676288 -> 1422555673120
	1422555676288 [label=ConvolutionBackward0]
	1422709132592 -> 1422555676288
	1422709132592 [label=ReluBackward0]
	1422671759968 -> 1422709132592
	1422671759968 [label=AddBackward0]
	1422671759488 -> 1422671759968
	1422671759488 [label=CudnnBatchNormBackward0]
	1422671759152 -> 1422671759488
	1422671759152 [label=ConvolutionBackward0]
	1422671758192 -> 1422671759152
	1422671758192 [label=ReluBackward0]
	1422671760544 -> 1422671758192
	1422671760544 [label=CudnnBatchNormBackward0]
	1422671760352 -> 1422671760544
	1422671760352 [label=ConvolutionBackward0]
	1422671760208 -> 1422671760352
	1422671760208 [label=ReluBackward0]
	1422671760016 -> 1422671760208
	1422671760016 [label=CudnnBatchNormBackward0]
	1422671759680 -> 1422671760016
	1422671759680 [label=ConvolutionBackward0]
	1422671760112 -> 1422671759680
	1422671760112 [label=ReluBackward0]
	1422671759536 -> 1422671760112
	1422671759536 [label=AddBackward0]
	1422671759200 -> 1422671759536
	1422671759200 [label=CudnnBatchNormBackward0]
	1422671759248 -> 1422671759200
	1422671759248 [label=ConvolutionBackward0]
	1422671758912 -> 1422671759248
	1422671758912 [label=ReluBackward0]
	1422671758960 -> 1422671758912
	1422671758960 [label=CudnnBatchNormBackward0]
	1422671758864 -> 1422671758960
	1422671758864 [label=ConvolutionBackward0]
	1422671758240 -> 1422671758864
	1422671758240 [label=ReluBackward0]
	1422671758288 -> 1422671758240
	1422671758288 [label=CudnnBatchNormBackward0]
	1422671758144 -> 1422671758288
	1422671758144 [label=ConvolutionBackward0]
	1422671759392 -> 1422671758144
	1422671759392 [label=ReluBackward0]
	1422671757808 -> 1422671759392
	1422671757808 [label=AddBackward0]
	1422671757664 -> 1422671757808
	1422671757664 [label=CudnnBatchNormBackward0]
	1422671757376 -> 1422671757664
	1422671757376 [label=ConvolutionBackward0]
	1422671761024 -> 1422671757376
	1422671761024 [label=ReluBackward0]
	1422671761360 -> 1422671761024
	1422671761360 [label=CudnnBatchNormBackward0]
	1422671761456 -> 1422671761360
	1422671761456 [label=ConvolutionBackward0]
	1422671761648 -> 1422671761456
	1422671761648 [label=ReluBackward0]
	1422671761792 -> 1422671761648
	1422671761792 [label=CudnnBatchNormBackward0]
	1422671761888 -> 1422671761792
	1422671761888 [label=ConvolutionBackward0]
	1422671762080 -> 1422671761888
	1422671762080 [label=MaxPool2DWithIndicesBackward0]
	1422671762224 -> 1422671762080
	1422671762224 [label=ReluBackward0]
	1422671762320 -> 1422671762224
	1422671762320 [label=CudnnBatchNormBackward0]
	1422671762416 -> 1422671762320
	1422671762416 [label=ConvolutionBackward0]
	1422671762608 -> 1422671762416
	1422705918800 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	1422705918800 -> 1422671762608
	1422671762608 [label=AccumulateGrad]
	1422671762368 -> 1422671762320
	1422692718096 [label="bn1.weight
 (64)" fillcolor=lightblue]
	1422692718096 -> 1422671762368
	1422671762368 [label=AccumulateGrad]
	1422671762128 -> 1422671762320
	1422692717808 [label="bn1.bias
 (64)" fillcolor=lightblue]
	1422692717808 -> 1422671762128
	1422671762128 [label=AccumulateGrad]
	1422671762032 -> 1422671761888
	1422692717712 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	1422692717712 -> 1422671762032
	1422671762032 [label=AccumulateGrad]
	1422671761840 -> 1422671761792
	1422692717616 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1422692717616 -> 1422671761840
	1422671761840 [label=AccumulateGrad]
	1422671761696 -> 1422671761792
	1422692716848 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1422692716848 -> 1422671761696
	1422671761696 [label=AccumulateGrad]
	1422671761600 -> 1422671761456
	1422692716944 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1422692716944 -> 1422671761600
	1422671761600 [label=AccumulateGrad]
	1422671761408 -> 1422671761360
	1422692717040 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1422692717040 -> 1422671761408
	1422671761408 [label=AccumulateGrad]
	1422671761264 -> 1422671761360
	1422692717136 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1422692717136 -> 1422671761264
	1422671761264 [label=AccumulateGrad]
	1422671761168 -> 1422671757376
	1422692717424 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1422692717424 -> 1422671761168
	1422671761168 [label=AccumulateGrad]
	1422671757472 -> 1422671757664
	1422692716464 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	1422692716464 -> 1422671757472
	1422671757472 [label=AccumulateGrad]
	1422671757616 -> 1422671757664
	1422692716368 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	1422692716368 -> 1422671757616
	1422671757616 [label=AccumulateGrad]
	1422671757904 -> 1422671757808
	1422671757904 [label=CudnnBatchNormBackward0]
	1422671761552 -> 1422671757904
	1422671761552 [label=ConvolutionBackward0]
	1422671762080 -> 1422671761552
	1422671761936 -> 1422671761552
	1422692718288 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1422692718288 -> 1422671761936
	1422671761936 [label=AccumulateGrad]
	1422671757424 -> 1422671757904
	1422692718384 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1422692718384 -> 1422671757424
	1422671757424 [label=AccumulateGrad]
	1422671757520 -> 1422671757904
	1422692718480 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1422692718480 -> 1422671757520
	1422671757520 [label=AccumulateGrad]
	1422671757856 -> 1422671758144
	1422692713680 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1422692713680 -> 1422671757856
	1422671757856 [label=AccumulateGrad]
	1422671758384 -> 1422671758288
	1422692713872 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1422692713872 -> 1422671758384
	1422671758384 [label=AccumulateGrad]
	1422671758336 -> 1422671758288
	1422692715504 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1422692715504 -> 1422671758336
	1422671758336 [label=AccumulateGrad]
	1422671758432 -> 1422671758864
	1422692716272 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1422692716272 -> 1422671758432
	1422671758432 [label=AccumulateGrad]
	1422671758768 -> 1422671758960
	1422692716176 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1422692716176 -> 1422671758768
	1422671758768 [label=AccumulateGrad]
	1422671758720 -> 1422671758960
	1422692702480 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1422692702480 -> 1422671758720
	1422671758720 [label=AccumulateGrad]
	1422671759056 -> 1422671759248
	1422692702864 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1422692702864 -> 1422671759056
	1422671759056 [label=AccumulateGrad]
	1422671759440 -> 1422671759200
	1422692702960 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	1422692702960 -> 1422671759440
	1422671759440 [label=AccumulateGrad]
	1422671759296 -> 1422671759200
	1422692703056 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	1422692703056 -> 1422671759296
	1422671759296 [label=AccumulateGrad]
	1422671759392 -> 1422671759536
	1422671759824 -> 1422671759680
	1422692703440 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1422692703440 -> 1422671759824
	1422671759824 [label=AccumulateGrad]
	1422671759872 -> 1422671760016
	1422692703536 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	1422692703536 -> 1422671759872
	1422671759872 [label=AccumulateGrad]
	1422671760304 -> 1422671760016
	1422692703632 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	1422692703632 -> 1422671760304
	1422671760304 [label=AccumulateGrad]
	1422671760400 -> 1422671760352
	1422692704016 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1422692704016 -> 1422671760400
	1422671760400 [label=AccumulateGrad]
	1422671760496 -> 1422671760544
	1422692704112 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	1422692704112 -> 1422671760496
	1422671760496 [label=AccumulateGrad]
	1422671757568 -> 1422671760544
	1422692704208 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	1422692704208 -> 1422671757568
	1422671757568 [label=AccumulateGrad]
	1422671758048 -> 1422671759152
	1422692704592 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1422692704592 -> 1422671758048
	1422671758048 [label=AccumulateGrad]
	1422671759008 -> 1422671759488
	1422692704688 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	1422692704688 -> 1422671759008
	1422671759008 [label=AccumulateGrad]
	1422671759632 -> 1422671759488
	1422692704784 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	1422692704784 -> 1422671759632
	1422671759632 [label=AccumulateGrad]
	1422671760112 -> 1422671759968
	1422555672304 -> 1422555676288
	1422692705744 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	1422692705744 -> 1422555672304
	1422555672304 [label=AccumulateGrad]
	1422555671776 -> 1422555673120
	1422692705840 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1422692705840 -> 1422555671776
	1422555671776 [label=AccumulateGrad]
	1422555671104 -> 1422555673120
	1422692705936 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1422692705936 -> 1422555671104
	1422555671104 [label=AccumulateGrad]
	1422555676576 -> 1422555670432
	1422692706320 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1422692706320 -> 1422555676576
	1422555676576 [label=AccumulateGrad]
	1422555671824 -> 1422555670144
	1422692706416 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1422692706416 -> 1422555671824
	1422555671824 [label=AccumulateGrad]
	1422555673744 -> 1422555670144
	1422692706512 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1422692706512 -> 1422555673744
	1422555673744 [label=AccumulateGrad]
	1422555675568 -> 1422555673456
	1422692706896 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1422692706896 -> 1422555675568
	1422555675568 [label=AccumulateGrad]
	1422555669808 -> 1422555672832
	1422692706992 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	1422692706992 -> 1422555669808
	1422555669808 [label=AccumulateGrad]
	1422555673648 -> 1422555672832
	1422692707088 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	1422692707088 -> 1422555673648
	1422555673648 [label=AccumulateGrad]
	1422555675040 -> 1422555671008
	1422555675040 [label=CudnnBatchNormBackward0]
	1422555672688 -> 1422555675040
	1422555672688 [label=ConvolutionBackward0]
	1422709132592 -> 1422555672688
	1422555673216 -> 1422555672688
	1422692705168 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1422692705168 -> 1422555673216
	1422555673216 [label=AccumulateGrad]
	1422555670864 -> 1422555675040
	1422692705264 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1422692705264 -> 1422555670864
	1422555670864 [label=AccumulateGrad]
	1422555675808 -> 1422555675040
	1422692705360 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1422692705360 -> 1422555675808
	1422555675808 [label=AccumulateGrad]
	1422555671920 -> 1422555671296
	1422692707472 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1422692707472 -> 1422555671920
	1422555671920 [label=AccumulateGrad]
	1422555670384 -> 1422555675904
	1422692707568 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1422692707568 -> 1422555670384
	1422555670384 [label=AccumulateGrad]
	1422555673600 -> 1422555675904
	1422692707664 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1422692707664 -> 1422555673600
	1422555673600 [label=AccumulateGrad]
	1422555676336 -> 1422555670624
	1422692708048 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1422692708048 -> 1422555676336
	1422555676336 [label=AccumulateGrad]
	1422555673312 -> 1422555675328
	1422692708144 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1422692708144 -> 1422555673312
	1422555673312 [label=AccumulateGrad]
	1422555676096 -> 1422555675328
	1422692708240 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1422692708240 -> 1422555676096
	1422555676096 [label=AccumulateGrad]
	1422555673264 -> 1422555674608
	1422692708624 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1422692708624 -> 1422555673264
	1422555673264 [label=AccumulateGrad]
	1422555674272 -> 1422555673504
	1422692708720 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	1422692708720 -> 1422555674272
	1422555674272 [label=AccumulateGrad]
	1422555675184 -> 1422555673504
	1422692708816 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	1422692708816 -> 1422555675184
	1422555675184 [label=AccumulateGrad]
	1422555673840 -> 1422555670048
	1422555676048 -> 1422555676192
	1422692709200 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1422692709200 -> 1422555676048
	1422555676048 [label=AccumulateGrad]
	1422555670672 -> 1422555674320
	1422692709296 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	1422692709296 -> 1422555670672
	1422555670672 [label=AccumulateGrad]
	1422555674560 -> 1422555674320
	1422692709392 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	1422692709392 -> 1422555674560
	1422555674560 [label=AccumulateGrad]
	1422555670576 -> 1422555669664
	1422692709776 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1422692709776 -> 1422555670576
	1422555670576 [label=AccumulateGrad]
	1422555670480 -> 1422555672736
	1422692709872 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	1422692709872 -> 1422555670480
	1422555670480 [label=AccumulateGrad]
	1422555669568 -> 1422555672736
	1422692709968 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	1422692709968 -> 1422555669568
	1422555669568 [label=AccumulateGrad]
	1422555670528 -> 1422555672208
	1422692710352 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1422692710352 -> 1422555670528
	1422555670528 [label=AccumulateGrad]
	1422555672160 -> 1422555672592
	1422692710448 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	1422692710448 -> 1422555672160
	1422555672160 [label=AccumulateGrad]
	1422555673696 -> 1422555672592
	1422692710544 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	1422692710544 -> 1422555673696
	1422555673696 [label=AccumulateGrad]
	1422555672112 -> 1422708933248
	1422708935936 -> 1422708935120
	1422692710928 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1422692710928 -> 1422708935936
	1422708935936 [label=AccumulateGrad]
	1422708935168 -> 1422708933824
	1422692711024 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	1422692711024 -> 1422708935168
	1422708935168 [label=AccumulateGrad]
	1422708935264 -> 1422708933824
	1422692711120 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	1422692711120 -> 1422708935264
	1422708935264 [label=AccumulateGrad]
	1422708934736 -> 1422708934496
	1422692711504 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1422692711504 -> 1422708934736
	1422708934736 [label=AccumulateGrad]
	1422708933968 -> 1422708934832
	1422692711600 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	1422692711600 -> 1422708933968
	1422708933968 [label=AccumulateGrad]
	1422708935984 -> 1422708934832
	1422692711696 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	1422692711696 -> 1422708935984
	1422708935984 [label=AccumulateGrad]
	1422708933488 -> 1422708932816
	1422692712080 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1422692712080 -> 1422708933488
	1422708933488 [label=AccumulateGrad]
	1422708934208 -> 1422708934784
	1422692712176 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	1422692712176 -> 1422708934208
	1422708934208 [label=AccumulateGrad]
	1422708933920 -> 1422708934784
	1422692712272 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	1422692712272 -> 1422708933920
	1422708933920 [label=AccumulateGrad]
	1422708932672 -> 1422708933536
	1422708935696 -> 1422708933728
	1422706148176 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	1422706148176 -> 1422708935696
	1422708935696 [label=AccumulateGrad]
	1422708933680 -> 1422708936176
	1422706148272 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1422706148272 -> 1422708933680
	1422708933680 [label=AccumulateGrad]
	1422708935888 -> 1422708936176
	1422706148368 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1422706148368 -> 1422708935888
	1422708935888 [label=AccumulateGrad]
	1422708936272 -> 1422708936464
	1422706148752 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1422706148752 -> 1422708936272
	1422708936272 [label=AccumulateGrad]
	1422708936656 -> 1422708936512
	1422706148848 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1422706148848 -> 1422708936656
	1422708936656 [label=AccumulateGrad]
	1422708936608 -> 1422708936512
	1422706148944 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1422706148944 -> 1422708936608
	1422708936608 [label=AccumulateGrad]
	1422708936800 -> 1422708937136
	1422706149328 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1422706149328 -> 1422708936800
	1422708936800 [label=AccumulateGrad]
	1422708936992 -> 1422708937088
	1422706149424 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	1422706149424 -> 1422708936992
	1422708936992 [label=AccumulateGrad]
	1422708936896 -> 1422708937088
	1422706149520 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	1422706149520 -> 1422708936896
	1422708936896 [label=AccumulateGrad]
	1422708937232 -> 1422708937280
	1422708937232 [label=CudnnBatchNormBackward0]
	1422708936320 -> 1422708937232
	1422708936320 [label=ConvolutionBackward0]
	1422708934544 -> 1422708936320
	1422708932912 -> 1422708936320
	1422706147600 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	1422706147600 -> 1422708932912
	1422708932912 [label=AccumulateGrad]
	1422708937040 -> 1422708937232
	1422706147696 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	1422706147696 -> 1422708937040
	1422708937040 [label=AccumulateGrad]
	1422708936944 -> 1422708937232
	1422706147792 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	1422706147792 -> 1422708936944
	1422708936944 [label=AccumulateGrad]
	1422708937424 -> 1422708937568
	1422706149904 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1422706149904 -> 1422708937424
	1422708937424 [label=AccumulateGrad]
	1422708937712 -> 1422708937760
	1422706150000 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1422706150000 -> 1422708937712
	1422708937712 [label=AccumulateGrad]
	1422708937904 -> 1422708937760
	1422706150096 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1422706150096 -> 1422708937904
	1422708937904 [label=AccumulateGrad]
	1422708937952 -> 1422708938192
	1422706150480 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1422706150480 -> 1422708937952
	1422708937952 [label=AccumulateGrad]
	1422708938240 -> 1422708938480
	1422706150576 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1422706150576 -> 1422708938240
	1422708938240 [label=AccumulateGrad]
	1422708938576 -> 1422708938480
	1422706150672 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1422706150672 -> 1422708938576
	1422708938576 [label=AccumulateGrad]
	1422708938336 -> 1422708938720
	1422706151056 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1422706151056 -> 1422708938336
	1422708938336 [label=AccumulateGrad]
	1422708938960 -> 1422708939056
	1422706151152 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	1422706151152 -> 1422708938960
	1422708938960 [label=AccumulateGrad]
	1422708938864 -> 1422708939056
	1422706151248 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	1422706151248 -> 1422708938864
	1422708938864 [label=AccumulateGrad]
	1422708938912 -> 1422708938816
	1422708939152 -> 1422708939536
	1422706151632 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1422706151632 -> 1422708939152
	1422708939152 [label=AccumulateGrad]
	1422708939392 -> 1422708939296
	1422706151728 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	1422706151728 -> 1422708939392
	1422708939392 [label=AccumulateGrad]
	1422708939632 -> 1422708939296
	1422706151824 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	1422706151824 -> 1422708939632
	1422708939632 [label=AccumulateGrad]
	1422708939920 -> 1422708939872
	1422706152208 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1422706152208 -> 1422708939920
	1422708939920 [label=AccumulateGrad]
	1422708939776 -> 1422708939968
	1422706152304 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	1422706152304 -> 1422708939776
	1422708939776 [label=AccumulateGrad]
	1422708940160 -> 1422708939968
	1422706152400 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	1422706152400 -> 1422708940160
	1422708940160 [label=AccumulateGrad]
	1422708940304 -> 1422708940256
	1422706152784 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1422706152784 -> 1422708940304
	1422708940304 [label=AccumulateGrad]
	1422708940448 -> 1422708940640
	1422706152880 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	1422706152880 -> 1422708940448
	1422708940448 [label=AccumulateGrad]
	1422708940592 -> 1422708940640
	1422706152976 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	1422706152976 -> 1422708940592
	1422708940592 [label=AccumulateGrad]
	1422708940880 -> 1422708940784
	1422708940832 -> 1422708941120
	1422706153360 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1422706153360 -> 1422708940832
	1422708940832 [label=AccumulateGrad]
	1422708941360 -> 1422708941264
	1422706153456 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	1422706153456 -> 1422708941360
	1422708941360 [label=AccumulateGrad]
	1422708941312 -> 1422708941264
	1422706153552 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	1422706153552 -> 1422708941312
	1422708941312 [label=AccumulateGrad]
	1422708941408 -> 1422708941840
	1422706153936 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1422706153936 -> 1422708941408
	1422708941408 [label=AccumulateGrad]
	1422708941744 -> 1422708941936
	1422706154032 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	1422706154032 -> 1422708941744
	1422708941744 [label=AccumulateGrad]
	1422708941696 -> 1422708941936
	1422706154128 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	1422706154128 -> 1422708941696
	1422708941696 [label=AccumulateGrad]
	1422708942032 -> 1422708942224
	1422706154512 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1422706154512 -> 1422708942032
	1422708942032 [label=AccumulateGrad]
	1422708942416 -> 1422708942176
	1422706154608 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	1422706154608 -> 1422708942416
	1422708942416 [label=AccumulateGrad]
	1422708942272 -> 1422708942176
	1422706154704 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	1422706154704 -> 1422708942272
	1422708942272 [label=AccumulateGrad]
	1422708942368 -> 1422708942512
	1422708942800 -> 1422708942656
	1422706155088 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1422706155088 -> 1422708942800
	1422708942800 [label=AccumulateGrad]
	1422708942848 -> 1422708942992
	1422706155184 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	1422706155184 -> 1422708942848
	1422708942848 [label=AccumulateGrad]
	1422708943280 -> 1422708942992
	1422706155280 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	1422706155280 -> 1422708943280
	1422708943280 [label=AccumulateGrad]
	1422708943376 -> 1422708943328
	1422706155664 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1422706155664 -> 1422708943376
	1422708943376 [label=AccumulateGrad]
	1422708943472 -> 1422708943520
	1422706155760 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	1422706155760 -> 1422708943472
	1422708943472 [label=AccumulateGrad]
	1422708943664 -> 1422708943520
	1422706155856 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	1422706155856 -> 1422708943664
	1422708943664 [label=AccumulateGrad]
	1422708943712 -> 1422708943952
	1422706156240 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1422706156240 -> 1422708943712
	1422708943712 [label=AccumulateGrad]
	1422708944000 -> 1422708944144
	1422706156336 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	1422706156336 -> 1422708944000
	1422708944000 [label=AccumulateGrad]
	1422708944240 -> 1422708944144
	1422706156432 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	1422706156432 -> 1422708944240
	1422708944240 [label=AccumulateGrad]
	1422708944336 -> 1422708944192
	1422708944288 -> 1422708944624
	1422706156816 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1422706156816 -> 1422708944288
	1422708944288 [label=AccumulateGrad]
	1422708944816 -> 1422708944672
	1422706156912 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	1422706156912 -> 1422708944816
	1422708944816 [label=AccumulateGrad]
	1422708944768 -> 1422708944672
	1422706157008 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	1422706157008 -> 1422708944768
	1422708944768 [label=AccumulateGrad]
	1422708944960 -> 1422708945296
	1422706157392 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1422706157392 -> 1422708944960
	1422708944960 [label=AccumulateGrad]
	1422708945152 -> 1422708945056
	1422706157488 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	1422706157488 -> 1422708945152
	1422708945152 [label=AccumulateGrad]
	1422708945392 -> 1422708945056
	1422706157584 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	1422706157584 -> 1422708945392
	1422708945392 [label=AccumulateGrad]
	1422708945680 -> 1422708945632
	1422706157968 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1422706157968 -> 1422708945680
	1422708945680 [label=AccumulateGrad]
	1422708945536 -> 1422708945872
	1422706158064 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	1422706158064 -> 1422708945536
	1422708945536 [label=AccumulateGrad]
	1422708945728 -> 1422708945872
	1422706158160 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	1422706158160 -> 1422708945728
	1422708945728 [label=AccumulateGrad]
	1422708945920 -> 1422708946160
	1422708946016 -> 1422708946400
	1422706159120 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	1422706159120 -> 1422708946016
	1422708946016 [label=AccumulateGrad]
	1422708946640 -> 1422708946544
	1422706159216 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1422706159216 -> 1422708946640
	1422708946640 [label=AccumulateGrad]
	1422708946592 -> 1422708946544
	1422706159312 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1422706159312 -> 1422708946592
	1422708946592 [label=AccumulateGrad]
	1422708946688 -> 1422708947120
	1422706159696 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1422706159696 -> 1422708946688
	1422708946688 [label=AccumulateGrad]
	1422708947024 -> 1422708947216
	1422706159792 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1422706159792 -> 1422708947024
	1422708947024 [label=AccumulateGrad]
	1422708946976 -> 1422708947216
	1422706159888 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1422706159888 -> 1422708946976
	1422708946976 [label=AccumulateGrad]
	1422708947312 -> 1422708947504
	1422706160272 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1422706160272 -> 1422708947312
	1422708947312 [label=AccumulateGrad]
	1422708947696 -> 1422708947456
	1422706160368 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	1422706160368 -> 1422708947696
	1422708947696 [label=AccumulateGrad]
	1422708947552 -> 1422708947456
	1422706160464 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	1422706160464 -> 1422708947552
	1422708947552 [label=AccumulateGrad]
	1422708947648 -> 1422708947792
	1422708947648 [label=CudnnBatchNormBackward0]
	1422708946832 -> 1422708947648
	1422708946832 [label=ConvolutionBackward0]
	1422708946112 -> 1422708946832
	1422708946352 -> 1422708946832
	1422706158544 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	1422706158544 -> 1422708946352
	1422708946352 [label=AccumulateGrad]
	1422708947360 -> 1422708947648
	1422706158640 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	1422706158640 -> 1422708947360
	1422708947360 [label=AccumulateGrad]
	1422708947600 -> 1422708947648
	1422706158736 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	1422706158736 -> 1422708947600
	1422708947600 [label=AccumulateGrad]
	1422708948080 -> 1422708947936
	1422706160848 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1422706160848 -> 1422708948080
	1422708948080 [label=AccumulateGrad]
	1422708948128 -> 1422708948272
	1422706160944 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1422706160944 -> 1422708948128
	1422708948128 [label=AccumulateGrad]
	1422708948560 -> 1422708948272
	1422706161040 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1422706161040 -> 1422708948560
	1422708948560 [label=AccumulateGrad]
	1422708948656 -> 1422708948608
	1422706161424 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1422706161424 -> 1422708948656
	1422708948656 [label=AccumulateGrad]
	1422708948752 -> 1422708948800
	1422706161520 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1422706161520 -> 1422708948752
	1422708948752 [label=AccumulateGrad]
	1422708948896 -> 1422708948800
	1422706161616 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1422706161616 -> 1422708948896
	1422708948896 [label=AccumulateGrad]
	1422708933440 -> 1422708935024
	1422706162000 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1422706162000 -> 1422708933440
	1422708933440 [label=AccumulateGrad]
	1422708934352 -> 1422708936224
	1422706162096 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	1422706162096 -> 1422708934352
	1422708934352 [label=AccumulateGrad]
	1422708936368 -> 1422708936224
	1422706162192 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	1422706162192 -> 1422708936368
	1422708936368 [label=AccumulateGrad]
	1422708936848 -> 1422708936704
	1422708937184 -> 1422708938144
	1422706162576 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1422706162576 -> 1422708937184
	1422708937184 [label=AccumulateGrad]
	1422708938768 -> 1422708938624
	1422706162672 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	1422706162672 -> 1422708938768
	1422708938768 [label=AccumulateGrad]
	1422708939104 -> 1422708938624
	1422706162768 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	1422706162768 -> 1422708939104
	1422708939104 [label=AccumulateGrad]
	1422708939584 -> 1422708940688
	1422706163152 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1422706163152 -> 1422708939584
	1422708939584 [label=AccumulateGrad]
	1422708940544 -> 1422708941168
	1422706163248 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	1422706163248 -> 1422708940544
	1422708940544 [label=AccumulateGrad]
	1422708941648 -> 1422708941168
	1422706163344 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	1422706163344 -> 1422708941648
	1422708941648 [label=AccumulateGrad]
	1422708942128 -> 1422708942464
	1422705918032 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1422705918032 -> 1422708942128
	1422708942128 [label=AccumulateGrad]
	1422708943088 -> 1422708943568
	1422705918128 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	1422705918128 -> 1422708943088
	1422708943088 [label=AccumulateGrad]
	1422708942944 -> 1422708943568
	1422705918224 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	1422705918224 -> 1422708942944
	1422708942944 [label=AccumulateGrad]
	1422708943424 -> 1422708944048
	1422708945488 -> 1422708946304
	1422708945488 [label=TBackward0]
	1422708943904 -> 1422708945488
	1422705918896 [label="fc.weight
 (19, 2048)" fillcolor=lightblue]
	1422705918896 -> 1422708943904
	1422708943904 [label=AccumulateGrad]
	1422708946304 -> 1422671888752
}
