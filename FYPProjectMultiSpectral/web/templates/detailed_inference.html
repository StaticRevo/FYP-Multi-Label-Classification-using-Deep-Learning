{% extends "base.html" %}
{% block title %}Detailed Model Comparison{% endblock %}

{% macro safe_round(value, decimals=3) %}
    {% if value is string and value|float is number %}
        {{ (value|float)|round(decimals, 'common') }}
    {% elif value is number %}
        {{ value|round(decimals, 'common') }}
    {% else %}
        {{ value|default("N/A") }}
    {% endif %}
{% endmacro %}

{% block content %}
<div class="container mt-4">
  <h1 class="mb-4">Detailed Model Comparison</h1>

<!-- Performance Summary Comparison Table -->
<div class="card mb-4">
  <div class="card-header">
    <h2>Performance Summary Comparison</h2>
    <p>Comparing experiments:</p>
    <ul class="list-inline">
      {% for exp in selected_experiments %}
        <li class="list-inline-item">
          <span class="badge {{ exp_colour_map[exp] }} text-break" 
                style="font-size: 0.8rem; overflow-wrap: anywhere; white-space: normal;">
            {{ exp }}
          </span>
        </li>
      {% endfor %}
    </ul>
  </div>
  <div class="card-body">
    <div class="table-responsive mb-4">
      <table class="table table-bordered table-sm">
        <thead>
          <tr>
            <th>Metric</th>
            {% for exp in selected_experiments %}
              <th class="text-break" style="overflow-wrap: anywhere; white-space: normal;">
                {{ exp }}
              </th>
            {% endfor %}
          </tr>
        </thead>
        <tbody>
          {# Define metrics to display, matching experiment_detail.html with added Accuracy and Loss #}
          {% set metrics_list = [
            {'name': 'Accuracy', 'key': 'test_acc', 'source': 'testing_comparison_data', 'minimize': False},
            {'name': 'Loss', 'key': 'test_loss', 'source': 'testing_comparison_data', 'minimize': True},
            {'name': 'Precision', 'key': 'precision_micro', 'source': 'aggregated_metrics', 'minimize': False},
            {'name': 'Recall', 'key': 'recall_micro', 'source': 'aggregated_metrics', 'minimize': False},
            {'name': 'F1 Score', 'key': 'f1_micro', 'source': 'aggregated_metrics', 'minimize': False},
            {'name': 'F2 Score', 'key': 'f2_micro', 'source': 'aggregated_metrics', 'minimize': False},
            {'name': 'Avg Precision', 'key': 'test_avg_precision', 'source': 'testing_comparison_data', 'minimize': False},
            {'name': 'Hamming Loss', 'key': 'hamming_loss', 'source': 'aggregated_metrics', 'minimize': True},
            {'name': 'One Error', 'key': 'test_one_error', 'source': 'testing_comparison_data', 'minimize': True},
            {'name': 'Inference Time (imgs/s)', 'key': 'inference_rate_images_per_sec', 'source': 'best_metrics', 'minimize': False},
            {'name': 'Training Time (hr/min)', 'key': 'training_time_formatted', 'compare_key': 'training_time_sec', 'source': 'best_metrics', 'minimize': True, 'no_round': True},
            {'name': 'Model Size (MB)', 'key': 'model_size_MB', 'source': 'best_metrics', 'minimize': True}
          ] %}
          {% for metric in metrics_list %}
            {# Determine the best experiment for this metric #}
            {% set ns = namespace(best_exp=None, best_value=None) %}
            {% for exp in selected_experiments %}
              {% set source = metric.source %}
              {% set key = metric.key %}
              {% set compare_key = metric.compare_key|default(key) %}
              {% set value = 'N/A' %}
              {% set compare_value = 'N/A' %}
              {# Handle different sources #}
              {% if source == 'aggregated_metrics' %}
                {% set value = experiments_data[exp].aggregated_metrics.get(key, 'N/A') if experiments_data[exp].aggregated_metrics %}
                {% set compare_value = value %}
              {% elif source == 'best_metrics' %}
                {% set value = experiments_data[exp].best_metrics.get(key, 'N/A') if experiments_data[exp].best_metrics %}
                {% set compare_value = experiments_data[exp].best_metrics.get(compare_key, 'N/A') if experiments_data[exp].best_metrics %}
              {% elif source == 'testing_comparison_data' %}
                {% set value = testing_comparison_data.get(key, {}).get(exp, 'N/A') %}
                {% set compare_value = value %}
              {% endif %}
              {% if compare_value != 'N/A' and compare_value is not none %}
                {% set current = compare_value|float if compare_value is string and compare_value|float is number else compare_value %}
                {% if ns.best_value is none %}
                  {% set ns.best_value = current %}
                  {% set ns.best_exp = exp %}
                {% else %}
                  {% if metric.minimize %}
                    {% if current is number and current < ns.best_value %}
                      {% set ns.best_value = current %}
                      {% set ns.best_exp = exp %}
                    {% endif %}
                  {% else %}
                    {% if current is number and current > ns.best_value %}
                      {% set ns.best_value = current %}
                      {% set ns.best_exp = exp %}
                    {% endif %}
                  {% endif %}
                {% endif %}
              {% endif %}
            {% endfor %}
            <tr>
              <td>{{ metric.name }}</td>
              {% for exp in selected_experiments %}
                {% set source = metric.source %}
                {% set key = metric.key %}
                {% set value = 'N/A' %}
                {% if source == 'aggregated_metrics' %}
                  {% set value = experiments_data[exp].aggregated_metrics.get(key, 'N/A') if experiments_data[exp].aggregated_metrics %}
                {% elif source == 'best_metrics' %}
                  {% set value = experiments_data[exp].best_metrics.get(key, 'N/A') if experiments_data[exp].best_metrics %}
                {% elif source == 'testing_comparison_data' %}
                  {% set value = testing_comparison_data.get(key, {}).get(exp, 'N/A') %}
                {% endif %}
                <td>
                  {% if value != 'N/A' and value is not none %}
                    {% if exp == ns.best_exp %}
                      <span class="badge {{ exp_colour_map[exp] }} text-break" 
                            style="font-size: 0.8rem; overflow-wrap: anywhere; white-space: normal;">
                        {% if metric.no_round|default(False) %}
                          {{ value }}
                        {% else %}
                          {{ safe_round(value) }}
                        {% endif %}
                      </span>
                    {% else %}
                      {% if metric.no_round|default(False) %}
                        {{ value }}
                      {% else %}
                        {{ safe_round(value) }}
                      {% endif %}
                    {% endif %}
                  {% else %}
                    N/A
                  {% endif %}
                </td>
              {% endfor %}
            </tr>
          {% endfor %}
        </tbody>
      </table>
    </div>
  </div>
</div>

  <!-- Per Class Metrics Comparison -->
  {% if experiments_data[selected_experiments[0]].per_class_metrics %}
  <div class="card mb-4">
    <div class="card-header">
      <strong>Per Class Metrics Comparison</strong>
    </div>
    <div class="card-body">
      <table class="table table-bordered table-striped">
        <thead>
          <tr>
            <th>Class</th>
            {% for exp in selected_experiments %}
              <th>{{ exp }}</th>
            {% endfor %}
          </tr>
        </thead>
        <tbody>
          {% for i in range(experiments_data[selected_experiments[0]].per_class_metrics.class_labels|length) %}
            <tr>
              <td>{{ experiments_data[selected_experiments[0]].per_class_metrics.class_labels[i] }}</td>
              {% for exp in selected_experiments %}
                {% set per_class = experiments_data[exp].per_class_metrics %}
                <td>
                  Precision: {{ per_class.precision[i] | float | round(3) }}<br>
                  Recall: {{ per_class.recall[i] | float | round(3) }}<br>
                  F1: {{ per_class.f1[i] | float | round(3) }}<br>
                  F2: {{ per_class.f2[i] | float | round(3) }}<br>
                  Accuracy: {{ per_class.accuracy[i] | float | round(3) }}
                </td>
              {% endfor %}
            </tr>
          {% endfor %}
        </tbody>
      </table>
    </div>
  </div>
  {% endif %}

  <!-- Insights & Observations Section -->
  {% if observations and observations|length > 0 %}
  <div class="card mb-4">
    <div class="card-header">
      <h2>Insights & Observations</h2>
    </div>
    <div class="card-body">
      <ul class="list-unstyled">
        {% for line in observations %}
          <li class="mb-2">{{ line }}</li>
        {% endfor %}
      </ul>
    </div>
  </div>
  {% endif %}

  <!-- Detailed Experiment Information -->
  <div class="card mb-4">
    <div class="card-header">
      <h2>Detailed Experiment Information</h2>
    </div>
    <div class="card-body">
      {# Wrap the experiment cards in a horizontally scrollable container #}
      <div style="overflow-x: auto;">
        <div class="d-flex">
          {% for exp in selected_experiments %}
            <div class="p-2" style="min-width: 300px;">
              <div class="card">
                <div class="card-header text-center">
                  <h4>
                    <span class="badge {{ exp_colour_map[exp] }} text-break" 
                          style="font-size: 0.8rem; overflow-wrap: anywhere; white-space: normal;">
                      {{ exp }}
                    </span>
                  </h4>
                </div>
                <div class="card-body text-break" style="overflow-wrap: anywhere; white-space: normal;">
                  <!-- Performance Summary -->
                  {% if experiments_data[exp].best_metrics %}
                    {% set bm = experiments_data[exp].best_metrics %}
                    <h5>Performance Summary</h5>
                    <p>
                      <strong>Val Acc:</strong> {{ bm.best_metrics.val_acc | default("N/A") }}<br>
                      <strong>Val Recall:</strong> {{ bm.best_metrics.val_recall | default("N/A") }}<br>
                      <strong>Val F1:</strong> {{ bm.best_metrics.val_f1 | default("N/A") }}<br>
                      <strong>Val Precision:</strong> {{ bm.best_metrics.val_precision | default("N/A") }}<br>
                      <strong>Inference Time:</strong> {{ bm.inference_rate_images_per_sec | default("N/A") }} imgs/s<br>
                      <strong>Training Time:</strong> {{ bm.training_time_formatted | default("N/A") }}
                    </p>
                  {% else %}
                    <p>No performance summary available.</p>
                  {% endif %}

                  <!-- Hyperparameters -->
                  {% if experiments_data[exp].hyperparams %}
                    <h5>Hyperparameters</h5>
                    <p style="white-space: pre-wrap;">{{ experiments_data[exp].hyperparams }}</p>
                  {% endif %}

                  <!-- Visualizations -->
                  {% if experiments_data[exp].visualizations %}
                    <h5>Visualizations</h5>
                    {% if experiments_data[exp].visualizations.confusion_matrices %}
                      <p><strong>Confusion Matrix:</strong></p>
                      <img src="{{ url_for('experiment_file', experiment_name=exp, filename=experiments_data[exp].visualizations.confusion_matrices) }}"
                           class="img-fluid" alt="Confusion Matrix for {{ exp }}">
                    {% endif %}
                    {% if experiments_data[exp].visualizations.roc_auc %}
                      <p><strong>ROC AUC Curve:</strong></p>
                      <img src="{{ url_for('experiment_file', experiment_name=exp, filename=experiments_data[exp].visualizations.roc_auc) }}"
                           class="img-fluid" alt="ROC AUC Curve for {{ exp }}">
                    {% endif %}
                    {% if experiments_data[exp].visualizations.cooccurrence %}
                      <p><strong>Co-occurrence Matrix:</strong></p>
                      <img src="{{ url_for('experiment_file', experiment_name=exp, filename=experiments_data[exp].visualizations.cooccurrence) }}"
                           class="img-fluid" alt="Co-occurrence Matrix for {{ exp }}">
                    {% endif %}
                  {% endif %}

                  <!-- TensorBoard Graphs -->
                  {% if experiments_data[exp].tensorboard_graphs and experiments_data[exp].tensorboard_graphs|length > 0 %}
                    <h5>TensorBoard Graphs</h5>
                    <div class="d-flex flex-wrap gap-3">
                      {% for graph in experiments_data[exp].tensorboard_graphs %}
                        <div class="p-2">
                          <img src="{{ url_for('experiment_file', experiment_name=exp, filename='results/tensorboard_graphs/' ~ graph) }}" 
                               class="img-fluid" alt="TensorBoard Graph: {{ graph }}">
                        </div>
                      {% endfor %}
                    </div>
                  {% endif %}
                </div>
              </div>
            </div>
          {% endfor %}
        </div>
      </div>
    </div>
  </div>

  <div class="text-end">
    <a href="{{ url_for('index') }}" class="btn btn-secondary">Return Home</a>
  </div>
</div>
{% endblock %}