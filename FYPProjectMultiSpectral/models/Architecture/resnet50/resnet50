digraph {
	graph [size="151.95,151.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	3001464756400 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	3001453688960 [label=AddmmBackward0]
	3001453690400 -> 3001453688960
	3001464864688 [label="fc.bias
 (19)" fillcolor=lightblue]
	3001464864688 -> 3001453690400
	3001453690400 [label=AccumulateGrad]
	3001453689152 -> 3001453688960
	3001453689152 [label=ViewBackward0]
	3001453690256 -> 3001453689152
	3001453690256 [label=MeanBackward1]
	3001453682096 -> 3001453690256
	3001453682096 [label=ReluBackward0]
	3001453684256 -> 3001453682096
	3001453684256 [label=AddBackward0]
	3001453685888 -> 3001453684256
	3001453685888 [label=CudnnBatchNormBackward0]
	3001453682000 -> 3001453685888
	3001453682000 [label=ConvolutionBackward0]
	3001453689536 -> 3001453682000
	3001453689536 [label=ReluBackward0]
	3001453689920 -> 3001453689536
	3001453689920 [label=CudnnBatchNormBackward0]
	3001453685696 -> 3001453689920
	3001453685696 [label=ConvolutionBackward0]
	3001453690736 -> 3001453685696
	3001453690736 [label=ReluBackward0]
	3001453690784 -> 3001453690736
	3001453690784 [label=CudnnBatchNormBackward0]
	3001453689296 -> 3001453690784
	3001453689296 [label=ConvolutionBackward0]
	3001453679504 -> 3001453689296
	3001453679504 [label=ReluBackward0]
	3001453682576 -> 3001453679504
	3001453682576 [label=AddBackward0]
	3001453681136 -> 3001453682576
	3001453681136 [label=CudnnBatchNormBackward0]
	3001453688288 -> 3001453681136
	3001453688288 [label=ConvolutionBackward0]
	3001453686272 -> 3001453688288
	3001453686272 [label=ReluBackward0]
	3001453675088 -> 3001453686272
	3001453675088 [label=CudnnBatchNormBackward0]
	3001453680368 -> 3001453675088
	3001453680368 [label=ConvolutionBackward0]
	3001453685504 -> 3001453680368
	3001453685504 [label=ReluBackward0]
	3001453676720 -> 3001453685504
	3001453676720 [label=CudnnBatchNormBackward0]
	3001453675616 -> 3001453676720
	3001453675616 [label=ConvolutionBackward0]
	3001453683776 -> 3001453675616
	3001453683776 [label=ReluBackward0]
	3001453685312 -> 3001453683776
	3001453685312 [label=AddBackward0]
	3001453687376 -> 3001453685312
	3001453687376 [label=CudnnBatchNormBackward0]
	3001453675136 -> 3001453687376
	3001453675136 [label=ConvolutionBackward0]
	3001453688768 -> 3001453675136
	3001453688768 [label=ReluBackward0]
	3001453683680 -> 3001453688768
	3001453683680 [label=CudnnBatchNormBackward0]
	3001453675232 -> 3001453683680
	3001453675232 [label=ConvolutionBackward0]
	3001453689344 -> 3001453675232
	3001453689344 [label=ReluBackward0]
	3001453684400 -> 3001453689344
	3001453684400 [label=CudnnBatchNormBackward0]
	3001453683872 -> 3001453684400
	3001453683872 [label=ConvolutionBackward0]
	3001453688864 -> 3001453683872
	3001453688864 [label=ReluBackward0]
	3001453689632 -> 3001453688864
	3001453689632 [label=AddBackward0]
	3001453684352 -> 3001453689632
	3001453684352 [label=CudnnBatchNormBackward0]
	3001453676096 -> 3001453684352
	3001453676096 [label=ConvolutionBackward0]
	3001453687712 -> 3001453676096
	3001453687712 [label=ReluBackward0]
	3001453685408 -> 3001453687712
	3001453685408 [label=CudnnBatchNormBackward0]
	3001453690064 -> 3001453685408
	3001453690064 [label=ConvolutionBackward0]
	3001453685264 -> 3001453690064
	3001453685264 [label=ReluBackward0]
	3001453688048 -> 3001453685264
	3001453688048 [label=CudnnBatchNormBackward0]
	3001453679840 -> 3001453688048
	3001453679840 [label=ConvolutionBackward0]
	3001453688144 -> 3001453679840
	3001453688144 [label=ReluBackward0]
	3001453688672 -> 3001453688144
	3001453688672 [label=AddBackward0]
	3001453681808 -> 3001453688672
	3001453681808 [label=CudnnBatchNormBackward0]
	3001453676336 -> 3001453681808
	3001453676336 [label=ConvolutionBackward0]
	3001453681184 -> 3001453676336
	3001453681184 [label=ReluBackward0]
	3001453685456 -> 3001453681184
	3001453685456 [label=CudnnBatchNormBackward0]
	3001453677440 -> 3001453685456
	3001453677440 [label=ConvolutionBackward0]
	3001453688192 -> 3001453677440
	3001453688192 [label=ReluBackward0]
	3001453679024 -> 3001453688192
	3001453679024 [label=CudnnBatchNormBackward0]
	3001453679456 -> 3001453679024
	3001453679456 [label=ConvolutionBackward0]
	3001453686416 -> 3001453679456
	3001453686416 [label=ReluBackward0]
	3001453681712 -> 3001453686416
	3001453681712 [label=AddBackward0]
	3001453690016 -> 3001453681712
	3001453690016 [label=CudnnBatchNormBackward0]
	3001453686560 -> 3001453690016
	3001453686560 [label=ConvolutionBackward0]
	3001453680608 -> 3001453686560
	3001453680608 [label=ReluBackward0]
	3001453678304 -> 3001453680608
	3001453678304 [label=CudnnBatchNormBackward0]
	3001453689440 -> 3001453678304
	3001453689440 [label=ConvolutionBackward0]
	3001464653328 -> 3001453689440
	3001464653328 [label=ReluBackward0]
	3001464653472 -> 3001464653328
	3001464653472 [label=CudnnBatchNormBackward0]
	3001464653568 -> 3001464653472
	3001464653568 [label=ConvolutionBackward0]
	3001453685744 -> 3001464653568
	3001453685744 [label=ReluBackward0]
	3001464653856 -> 3001453685744
	3001464653856 [label=AddBackward0]
	3001464653952 -> 3001464653856
	3001464653952 [label=CudnnBatchNormBackward0]
	3001464654096 -> 3001464653952
	3001464654096 [label=ConvolutionBackward0]
	3001464654288 -> 3001464654096
	3001464654288 [label=ReluBackward0]
	3001464654432 -> 3001464654288
	3001464654432 [label=CudnnBatchNormBackward0]
	3001464654528 -> 3001464654432
	3001464654528 [label=ConvolutionBackward0]
	3001464654720 -> 3001464654528
	3001464654720 [label=ReluBackward0]
	3001464654864 -> 3001464654720
	3001464654864 [label=CudnnBatchNormBackward0]
	3001464654960 -> 3001464654864
	3001464654960 [label=ConvolutionBackward0]
	3001464653904 -> 3001464654960
	3001464653904 [label=ReluBackward0]
	3001464655248 -> 3001464653904
	3001464655248 [label=AddBackward0]
	3001464655344 -> 3001464655248
	3001464655344 [label=CudnnBatchNormBackward0]
	3001464655488 -> 3001464655344
	3001464655488 [label=ConvolutionBackward0]
	3001464655680 -> 3001464655488
	3001464655680 [label=ReluBackward0]
	3001464655824 -> 3001464655680
	3001464655824 [label=CudnnBatchNormBackward0]
	3001464655920 -> 3001464655824
	3001464655920 [label=ConvolutionBackward0]
	3001464656112 -> 3001464655920
	3001464656112 [label=ReluBackward0]
	3001464656256 -> 3001464656112
	3001464656256 [label=CudnnBatchNormBackward0]
	3001464656352 -> 3001464656256
	3001464656352 [label=ConvolutionBackward0]
	3001464655296 -> 3001464656352
	3001464655296 [label=ReluBackward0]
	3001464656640 -> 3001464655296
	3001464656640 [label=AddBackward0]
	3001464656736 -> 3001464656640
	3001464656736 [label=CudnnBatchNormBackward0]
	3001464656880 -> 3001464656736
	3001464656880 [label=ConvolutionBackward0]
	3001464657072 -> 3001464656880
	3001464657072 [label=ReluBackward0]
	3001464657216 -> 3001464657072
	3001464657216 [label=CudnnBatchNormBackward0]
	3001464657312 -> 3001464657216
	3001464657312 [label=ConvolutionBackward0]
	3001464657504 -> 3001464657312
	3001464657504 [label=ReluBackward0]
	3001464657648 -> 3001464657504
	3001464657648 [label=CudnnBatchNormBackward0]
	3001464657744 -> 3001464657648
	3001464657744 [label=ConvolutionBackward0]
	3001464657936 -> 3001464657744
	3001464657936 [label=ReluBackward0]
	3001464658080 -> 3001464657936
	3001464658080 [label=AddBackward0]
	3001464658176 -> 3001464658080
	3001464658176 [label=CudnnBatchNormBackward0]
	3001464658320 -> 3001464658176
	3001464658320 [label=ConvolutionBackward0]
	3001464658512 -> 3001464658320
	3001464658512 [label=ReluBackward0]
	3001464658656 -> 3001464658512
	3001464658656 [label=CudnnBatchNormBackward0]
	3001464658752 -> 3001464658656
	3001464658752 [label=ConvolutionBackward0]
	3001464658944 -> 3001464658752
	3001464658944 [label=ReluBackward0]
	3001464659088 -> 3001464658944
	3001464659088 [label=CudnnBatchNormBackward0]
	3001464659184 -> 3001464659088
	3001464659184 [label=ConvolutionBackward0]
	3001464658128 -> 3001464659184
	3001464658128 [label=ReluBackward0]
	3001464659472 -> 3001464658128
	3001464659472 [label=AddBackward0]
	3001464659568 -> 3001464659472
	3001464659568 [label=CudnnBatchNormBackward0]
	3001464659712 -> 3001464659568
	3001464659712 [label=ConvolutionBackward0]
	3001464659904 -> 3001464659712
	3001464659904 [label=ReluBackward0]
	3001464660048 -> 3001464659904
	3001464660048 [label=CudnnBatchNormBackward0]
	3001464660144 -> 3001464660048
	3001464660144 [label=ConvolutionBackward0]
	3001464660336 -> 3001464660144
	3001464660336 [label=ReluBackward0]
	3001464660480 -> 3001464660336
	3001464660480 [label=CudnnBatchNormBackward0]
	3001464660576 -> 3001464660480
	3001464660576 [label=ConvolutionBackward0]
	3001464659520 -> 3001464660576
	3001464659520 [label=ReluBackward0]
	3001464660864 -> 3001464659520
	3001464660864 [label=AddBackward0]
	3001464660960 -> 3001464660864
	3001464660960 [label=CudnnBatchNormBackward0]
	3001464661104 -> 3001464660960
	3001464661104 [label=ConvolutionBackward0]
	3001464661296 -> 3001464661104
	3001464661296 [label=ReluBackward0]
	3001464661440 -> 3001464661296
	3001464661440 [label=CudnnBatchNormBackward0]
	3001464661536 -> 3001464661440
	3001464661536 [label=ConvolutionBackward0]
	3001464661728 -> 3001464661536
	3001464661728 [label=ReluBackward0]
	3001464661872 -> 3001464661728
	3001464661872 [label=CudnnBatchNormBackward0]
	3001464661968 -> 3001464661872
	3001464661968 [label=ConvolutionBackward0]
	3001464660912 -> 3001464661968
	3001464660912 [label=ReluBackward0]
	3001464662256 -> 3001464660912
	3001464662256 [label=AddBackward0]
	3001464662352 -> 3001464662256
	3001464662352 [label=CudnnBatchNormBackward0]
	3001464662496 -> 3001464662352
	3001464662496 [label=ConvolutionBackward0]
	3001464662688 -> 3001464662496
	3001464662688 [label=ReluBackward0]
	3001464662832 -> 3001464662688
	3001464662832 [label=CudnnBatchNormBackward0]
	3001464662928 -> 3001464662832
	3001464662928 [label=ConvolutionBackward0]
	3001464663120 -> 3001464662928
	3001464663120 [label=ReluBackward0]
	3001464663264 -> 3001464663120
	3001464663264 [label=CudnnBatchNormBackward0]
	3001464663360 -> 3001464663264
	3001464663360 [label=ConvolutionBackward0]
	3001464663552 -> 3001464663360
	3001464663552 [label=ReluBackward0]
	3001464663696 -> 3001464663552
	3001464663696 [label=AddBackward0]
	3001464663792 -> 3001464663696
	3001464663792 [label=CudnnBatchNormBackward0]
	3001464663936 -> 3001464663792
	3001464663936 [label=ConvolutionBackward0]
	3001464664128 -> 3001464663936
	3001464664128 [label=ReluBackward0]
	3001464664272 -> 3001464664128
	3001464664272 [label=CudnnBatchNormBackward0]
	3001464664368 -> 3001464664272
	3001464664368 [label=ConvolutionBackward0]
	3001464664560 -> 3001464664368
	3001464664560 [label=ReluBackward0]
	3001464664704 -> 3001464664560
	3001464664704 [label=CudnnBatchNormBackward0]
	3001464664800 -> 3001464664704
	3001464664800 [label=ConvolutionBackward0]
	3001464663744 -> 3001464664800
	3001464663744 [label=ReluBackward0]
	3001464665088 -> 3001464663744
	3001464665088 [label=AddBackward0]
	3001464665184 -> 3001464665088
	3001464665184 [label=CudnnBatchNormBackward0]
	3001464665328 -> 3001464665184
	3001464665328 [label=ConvolutionBackward0]
	3001464665520 -> 3001464665328
	3001464665520 [label=ReluBackward0]
	3001464665664 -> 3001464665520
	3001464665664 [label=CudnnBatchNormBackward0]
	3001464665760 -> 3001464665664
	3001464665760 [label=ConvolutionBackward0]
	3001464665952 -> 3001464665760
	3001464665952 [label=ReluBackward0]
	3001464666096 -> 3001464665952
	3001464666096 [label=CudnnBatchNormBackward0]
	3001464666192 -> 3001464666096
	3001464666192 [label=ConvolutionBackward0]
	3001464665136 -> 3001464666192
	3001464665136 [label=ReluBackward0]
	3001464666480 -> 3001464665136
	3001464666480 [label=AddBackward0]
	3001464666576 -> 3001464666480
	3001464666576 [label=CudnnBatchNormBackward0]
	3001464666720 -> 3001464666576
	3001464666720 [label=ConvolutionBackward0]
	3001464666912 -> 3001464666720
	3001464666912 [label=ReluBackward0]
	3001464667056 -> 3001464666912
	3001464667056 [label=CudnnBatchNormBackward0]
	3001464667152 -> 3001464667056
	3001464667152 [label=ConvolutionBackward0]
	3001464667344 -> 3001464667152
	3001464667344 [label=ReluBackward0]
	3001464667488 -> 3001464667344
	3001464667488 [label=CudnnBatchNormBackward0]
	3001464667584 -> 3001464667488
	3001464667584 [label=ConvolutionBackward0]
	3001464667776 -> 3001464667584
	3001464667776 [label=MaxPool2DWithIndicesBackward0]
	3001464667920 -> 3001464667776
	3001464667920 [label=ReluBackward0]
	3001464668016 -> 3001464667920
	3001464668016 [label=CudnnBatchNormBackward0]
	3001464668112 -> 3001464668016
	3001464668112 [label=ConvolutionBackward0]
	3001457737936 -> 3001464668112
	3001457642480 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	3001457642480 -> 3001457737936
	3001457737936 [label=AccumulateGrad]
	3001464668064 -> 3001464668016
	3001460507856 [label="bn1.weight
 (64)" fillcolor=lightblue]
	3001460507856 -> 3001464668064
	3001464668064 [label=AccumulateGrad]
	3001464667824 -> 3001464668016
	3001460507952 [label="bn1.bias
 (64)" fillcolor=lightblue]
	3001460507952 -> 3001464667824
	3001464667824 [label=AccumulateGrad]
	3001464667728 -> 3001464667584
	3001460508912 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	3001460508912 -> 3001464667728
	3001464667728 [label=AccumulateGrad]
	3001464667536 -> 3001464667488
	3001460509008 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	3001460509008 -> 3001464667536
	3001464667536 [label=AccumulateGrad]
	3001464667392 -> 3001464667488
	3001460509104 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	3001460509104 -> 3001464667392
	3001464667392 [label=AccumulateGrad]
	3001464667296 -> 3001464667152
	3001460509584 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3001460509584 -> 3001464667296
	3001464667296 [label=AccumulateGrad]
	3001464667104 -> 3001464667056
	3001460509680 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	3001460509680 -> 3001464667104
	3001464667104 [label=AccumulateGrad]
	3001464666960 -> 3001464667056
	3001460509776 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	3001460509776 -> 3001464666960
	3001464666960 [label=AccumulateGrad]
	3001464666864 -> 3001464666720
	3001460510160 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	3001460510160 -> 3001464666864
	3001464666864 [label=AccumulateGrad]
	3001464666672 -> 3001464666576
	3001460510256 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	3001460510256 -> 3001464666672
	3001464666672 [label=AccumulateGrad]
	3001464666624 -> 3001464666576
	3001460510352 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	3001460510352 -> 3001464666624
	3001464666624 [label=AccumulateGrad]
	3001464666528 -> 3001464666480
	3001464666528 [label=CudnnBatchNormBackward0]
	3001464667248 -> 3001464666528
	3001464667248 [label=ConvolutionBackward0]
	3001464667776 -> 3001464667248
	3001464667632 -> 3001464667248
	3001460508336 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	3001460508336 -> 3001464667632
	3001464667632 [label=AccumulateGrad]
	3001464666816 -> 3001464666528
	3001460508432 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	3001460508432 -> 3001464666816
	3001464666816 [label=AccumulateGrad]
	3001464666768 -> 3001464666528
	3001460508528 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	3001460508528 -> 3001464666768
	3001464666768 [label=AccumulateGrad]
	3001464666384 -> 3001464666192
	3001460510736 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	3001460510736 -> 3001464666384
	3001464666384 [label=AccumulateGrad]
	3001464666144 -> 3001464666096
	3001460510832 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	3001460510832 -> 3001464666144
	3001464666144 [label=AccumulateGrad]
	3001464666000 -> 3001464666096
	3001460510928 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	3001460510928 -> 3001464666000
	3001464666000 [label=AccumulateGrad]
	3001464665904 -> 3001464665760
	3001460511312 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3001460511312 -> 3001464665904
	3001464665904 [label=AccumulateGrad]
	3001464665712 -> 3001464665664
	3001460511408 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	3001460511408 -> 3001464665712
	3001464665712 [label=AccumulateGrad]
	3001464665568 -> 3001464665664
	3001460511504 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	3001460511504 -> 3001464665568
	3001464665568 [label=AccumulateGrad]
	3001464665472 -> 3001464665328
	3001460511888 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	3001460511888 -> 3001464665472
	3001464665472 [label=AccumulateGrad]
	3001464665280 -> 3001464665184
	3001460511984 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	3001460511984 -> 3001464665280
	3001464665280 [label=AccumulateGrad]
	3001464665232 -> 3001464665184
	3001460512080 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	3001460512080 -> 3001464665232
	3001464665232 [label=AccumulateGrad]
	3001464665136 -> 3001464665088
	3001464664992 -> 3001464664800
	3001460512464 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	3001460512464 -> 3001464664992
	3001464664992 [label=AccumulateGrad]
	3001464664752 -> 3001464664704
	3001460512560 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	3001460512560 -> 3001464664752
	3001464664752 [label=AccumulateGrad]
	3001464664608 -> 3001464664704
	3001460512656 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	3001460512656 -> 3001464664608
	3001464664608 [label=AccumulateGrad]
	3001464664512 -> 3001464664368
	3001460513040 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3001460513040 -> 3001464664512
	3001464664512 [label=AccumulateGrad]
	3001464664320 -> 3001464664272
	3001460513136 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	3001460513136 -> 3001464664320
	3001464664320 [label=AccumulateGrad]
	3001464664176 -> 3001464664272
	3001460513232 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	3001460513232 -> 3001464664176
	3001464664176 [label=AccumulateGrad]
	3001464664080 -> 3001464663936
	3001460513616 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	3001460513616 -> 3001464664080
	3001464664080 [label=AccumulateGrad]
	3001464663888 -> 3001464663792
	3001460513712 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	3001460513712 -> 3001464663888
	3001464663888 [label=AccumulateGrad]
	3001464663840 -> 3001464663792
	3001460513808 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	3001460513808 -> 3001464663840
	3001464663840 [label=AccumulateGrad]
	3001464663744 -> 3001464663696
	3001464663504 -> 3001464663360
	3001460514768 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	3001460514768 -> 3001464663504
	3001464663504 [label=AccumulateGrad]
	3001464663312 -> 3001464663264
	3001460514864 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	3001460514864 -> 3001464663312
	3001464663312 [label=AccumulateGrad]
	3001464663168 -> 3001464663264
	3001460514960 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	3001460514960 -> 3001464663168
	3001464663168 [label=AccumulateGrad]
	3001464663072 -> 3001464662928
	3001460515344 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3001460515344 -> 3001464663072
	3001464663072 [label=AccumulateGrad]
	3001464662880 -> 3001464662832
	3001460515440 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	3001460515440 -> 3001464662880
	3001464662880 [label=AccumulateGrad]
	3001464662736 -> 3001464662832
	3001460515536 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	3001460515536 -> 3001464662736
	3001464662736 [label=AccumulateGrad]
	3001464662640 -> 3001464662496
	3001460515920 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	3001460515920 -> 3001464662640
	3001464662640 [label=AccumulateGrad]
	3001464662448 -> 3001464662352
	3001460516016 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	3001460516016 -> 3001464662448
	3001464662448 [label=AccumulateGrad]
	3001464662400 -> 3001464662352
	3001460516112 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	3001460516112 -> 3001464662400
	3001464662400 [label=AccumulateGrad]
	3001464662304 -> 3001464662256
	3001464662304 [label=CudnnBatchNormBackward0]
	3001464663024 -> 3001464662304
	3001464663024 [label=ConvolutionBackward0]
	3001464663552 -> 3001464663024
	3001464663408 -> 3001464663024
	3001460514192 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	3001460514192 -> 3001464663408
	3001464663408 [label=AccumulateGrad]
	3001464662592 -> 3001464662304
	3001460514288 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	3001460514288 -> 3001464662592
	3001464662592 [label=AccumulateGrad]
	3001464662544 -> 3001464662304
	3001460514384 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	3001460514384 -> 3001464662544
	3001464662544 [label=AccumulateGrad]
	3001464662160 -> 3001464661968
	3001460516496 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	3001460516496 -> 3001464662160
	3001464662160 [label=AccumulateGrad]
	3001464661920 -> 3001464661872
	3001460516592 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	3001460516592 -> 3001464661920
	3001464661920 [label=AccumulateGrad]
	3001464661776 -> 3001464661872
	3001460516688 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	3001460516688 -> 3001464661776
	3001464661776 [label=AccumulateGrad]
	3001464661680 -> 3001464661536
	3001460517072 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3001460517072 -> 3001464661680
	3001464661680 [label=AccumulateGrad]
	3001464661488 -> 3001464661440
	3001460517168 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	3001460517168 -> 3001464661488
	3001464661488 [label=AccumulateGrad]
	3001464661344 -> 3001464661440
	3001460517264 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	3001460517264 -> 3001464661344
	3001464661344 [label=AccumulateGrad]
	3001464661248 -> 3001464661104
	3001460517648 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	3001460517648 -> 3001464661248
	3001464661248 [label=AccumulateGrad]
	3001464661056 -> 3001464660960
	3001460517744 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	3001460517744 -> 3001464661056
	3001464661056 [label=AccumulateGrad]
	3001464661008 -> 3001464660960
	3001460517840 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	3001460517840 -> 3001464661008
	3001464661008 [label=AccumulateGrad]
	3001464660912 -> 3001464660864
	3001464660768 -> 3001464660576
	3001460518224 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	3001460518224 -> 3001464660768
	3001464660768 [label=AccumulateGrad]
	3001464660528 -> 3001464660480
	3001460518320 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	3001460518320 -> 3001464660528
	3001464660528 [label=AccumulateGrad]
	3001464660384 -> 3001464660480
	3001460518416 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	3001460518416 -> 3001464660384
	3001464660384 [label=AccumulateGrad]
	3001464660288 -> 3001464660144
	3001460518800 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3001460518800 -> 3001464660288
	3001464660288 [label=AccumulateGrad]
	3001464660096 -> 3001464660048
	3001460518896 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	3001460518896 -> 3001464660096
	3001464660096 [label=AccumulateGrad]
	3001464659952 -> 3001464660048
	3001460518992 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	3001460518992 -> 3001464659952
	3001464659952 [label=AccumulateGrad]
	3001464659856 -> 3001464659712
	3001460519376 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	3001460519376 -> 3001464659856
	3001464659856 [label=AccumulateGrad]
	3001464659664 -> 3001464659568
	3001460519472 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	3001460519472 -> 3001464659664
	3001464659664 [label=AccumulateGrad]
	3001464659616 -> 3001464659568
	3001460519568 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	3001460519568 -> 3001464659616
	3001464659616 [label=AccumulateGrad]
	3001464659520 -> 3001464659472
	3001464659376 -> 3001464659184
	3001460519952 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	3001460519952 -> 3001464659376
	3001464659376 [label=AccumulateGrad]
	3001464659136 -> 3001464659088
	3001460520048 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	3001460520048 -> 3001464659136
	3001464659136 [label=AccumulateGrad]
	3001464658992 -> 3001464659088
	3001460520144 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	3001460520144 -> 3001464658992
	3001464658992 [label=AccumulateGrad]
	3001464658896 -> 3001464658752
	3001460520528 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3001460520528 -> 3001464658896
	3001464658896 [label=AccumulateGrad]
	3001464658704 -> 3001464658656
	3001460520624 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	3001460520624 -> 3001464658704
	3001464658704 [label=AccumulateGrad]
	3001464658560 -> 3001464658656
	3001460520720 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	3001460520720 -> 3001464658560
	3001464658560 [label=AccumulateGrad]
	3001464658464 -> 3001464658320
	3001460521104 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	3001460521104 -> 3001464658464
	3001464658464 [label=AccumulateGrad]
	3001464658272 -> 3001464658176
	3001460521200 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	3001460521200 -> 3001464658272
	3001464658272 [label=AccumulateGrad]
	3001464658224 -> 3001464658176
	3001460521296 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	3001460521296 -> 3001464658224
	3001464658224 [label=AccumulateGrad]
	3001464658128 -> 3001464658080
	3001464657888 -> 3001464657744
	3001460522256 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	3001460522256 -> 3001464657888
	3001464657888 [label=AccumulateGrad]
	3001464657696 -> 3001464657648
	3001460522352 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	3001460522352 -> 3001464657696
	3001464657696 [label=AccumulateGrad]
	3001464657552 -> 3001464657648
	3001460522448 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	3001460522448 -> 3001464657552
	3001464657552 [label=AccumulateGrad]
	3001464657456 -> 3001464657312
	3001460522832 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3001460522832 -> 3001464657456
	3001464657456 [label=AccumulateGrad]
	3001464657264 -> 3001464657216
	3001460522928 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	3001460522928 -> 3001464657264
	3001464657264 [label=AccumulateGrad]
	3001464657120 -> 3001464657216
	3001456312400 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	3001456312400 -> 3001464657120
	3001464657120 [label=AccumulateGrad]
	3001464657024 -> 3001464656880
	3001456312784 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	3001456312784 -> 3001464657024
	3001464657024 [label=AccumulateGrad]
	3001464656832 -> 3001464656736
	3001456312880 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	3001456312880 -> 3001464656832
	3001464656832 [label=AccumulateGrad]
	3001464656784 -> 3001464656736
	3001456312976 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	3001456312976 -> 3001464656784
	3001464656784 [label=AccumulateGrad]
	3001464656688 -> 3001464656640
	3001464656688 [label=CudnnBatchNormBackward0]
	3001464657408 -> 3001464656688
	3001464657408 [label=ConvolutionBackward0]
	3001464657936 -> 3001464657408
	3001464657792 -> 3001464657408
	3001460521680 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	3001460521680 -> 3001464657792
	3001464657792 [label=AccumulateGrad]
	3001464656976 -> 3001464656688
	3001460521776 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	3001460521776 -> 3001464656976
	3001464656976 [label=AccumulateGrad]
	3001464656928 -> 3001464656688
	3001460521872 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	3001460521872 -> 3001464656928
	3001464656928 [label=AccumulateGrad]
	3001464656544 -> 3001464656352
	3001454396816 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	3001454396816 -> 3001464656544
	3001464656544 [label=AccumulateGrad]
	3001464656304 -> 3001464656256
	3001454397968 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	3001454397968 -> 3001464656304
	3001464656304 [label=AccumulateGrad]
	3001464656160 -> 3001464656256
	3001454396528 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	3001454396528 -> 3001464656160
	3001464656160 [label=AccumulateGrad]
	3001464656064 -> 3001464655920
	3001454402192 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3001454402192 -> 3001464656064
	3001464656064 [label=AccumulateGrad]
	3001464655872 -> 3001464655824
	3001454402288 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	3001454402288 -> 3001464655872
	3001464655872 [label=AccumulateGrad]
	3001464655728 -> 3001464655824
	3001454402384 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	3001454402384 -> 3001464655728
	3001464655728 [label=AccumulateGrad]
	3001464655632 -> 3001464655488
	3001454402768 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	3001454402768 -> 3001464655632
	3001464655632 [label=AccumulateGrad]
	3001464655440 -> 3001464655344
	3001454402864 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	3001454402864 -> 3001464655440
	3001464655440 [label=AccumulateGrad]
	3001464655392 -> 3001464655344
	3001454402960 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	3001454402960 -> 3001464655392
	3001464655392 [label=AccumulateGrad]
	3001464655296 -> 3001464655248
	3001464655152 -> 3001464654960
	3001454403344 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	3001454403344 -> 3001464655152
	3001464655152 [label=AccumulateGrad]
	3001464654912 -> 3001464654864
	3001454403440 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	3001454403440 -> 3001464654912
	3001464654912 [label=AccumulateGrad]
	3001464654768 -> 3001464654864
	3001454403536 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	3001454403536 -> 3001464654768
	3001464654768 [label=AccumulateGrad]
	3001464654672 -> 3001464654528
	3001454403920 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3001454403920 -> 3001464654672
	3001464654672 [label=AccumulateGrad]
	3001464654480 -> 3001464654432
	3001454404016 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	3001454404016 -> 3001464654480
	3001464654480 [label=AccumulateGrad]
	3001464654336 -> 3001464654432
	3001454404112 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	3001454404112 -> 3001464654336
	3001464654336 [label=AccumulateGrad]
	3001464654240 -> 3001464654096
	3001454404496 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	3001454404496 -> 3001464654240
	3001464654240 [label=AccumulateGrad]
	3001464654048 -> 3001464653952
	3001454404592 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	3001454404592 -> 3001464654048
	3001464654048 [label=AccumulateGrad]
	3001464654000 -> 3001464653952
	3001454404688 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	3001454404688 -> 3001464654000
	3001464654000 [label=AccumulateGrad]
	3001464653904 -> 3001464653856
	3001464653760 -> 3001464653568
	3001454405072 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	3001454405072 -> 3001464653760
	3001464653760 [label=AccumulateGrad]
	3001464653520 -> 3001464653472
	3001454405168 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	3001454405168 -> 3001464653520
	3001464653520 [label=AccumulateGrad]
	3001464653376 -> 3001464653472
	3001454405264 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	3001454405264 -> 3001464653376
	3001464653376 [label=AccumulateGrad]
	3001464653280 -> 3001453689440
	3001454405648 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3001454405648 -> 3001464653280
	3001464653280 [label=AccumulateGrad]
	3001453685840 -> 3001453678304
	3001454405744 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	3001454405744 -> 3001453685840
	3001453685840 [label=AccumulateGrad]
	3001453674704 -> 3001453678304
	3001454405840 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	3001454405840 -> 3001453674704
	3001453674704 [label=AccumulateGrad]
	3001453678208 -> 3001453686560
	3001454406224 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	3001454406224 -> 3001453678208
	3001453678208 [label=AccumulateGrad]
	3001453690352 -> 3001453690016
	3001454406320 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	3001454406320 -> 3001453690352
	3001453690352 [label=AccumulateGrad]
	3001453675760 -> 3001453690016
	3001454406416 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	3001454406416 -> 3001453675760
	3001453675760 [label=AccumulateGrad]
	3001453685744 -> 3001453681712
	3001453677344 -> 3001453679456
	3001454406800 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	3001454406800 -> 3001453677344
	3001453677344 [label=AccumulateGrad]
	3001453680944 -> 3001453679024
	3001454406896 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	3001454406896 -> 3001453680944
	3001453680944 [label=AccumulateGrad]
	3001453690688 -> 3001453679024
	3001454406992 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	3001454406992 -> 3001453690688
	3001453690688 [label=AccumulateGrad]
	3001453676960 -> 3001453677440
	3001454407376 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3001454407376 -> 3001453676960
	3001453676960 [label=AccumulateGrad]
	3001453686464 -> 3001453685456
	3001454407472 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	3001454407472 -> 3001453686464
	3001453686464 [label=AccumulateGrad]
	3001453690496 -> 3001453685456
	3001454407568 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	3001454407568 -> 3001453690496
	3001453690496 [label=AccumulateGrad]
	3001453678640 -> 3001453676336
	3001454407952 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	3001454407952 -> 3001453678640
	3001453678640 [label=AccumulateGrad]
	3001453681856 -> 3001453681808
	3001454408048 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	3001454408048 -> 3001453681856
	3001453681856 [label=AccumulateGrad]
	3001453675952 -> 3001453681808
	3001454408144 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	3001454408144 -> 3001453675952
	3001453675952 [label=AccumulateGrad]
	3001453686416 -> 3001453688672
	3001453687280 -> 3001453679840
	3001454408528 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	3001454408528 -> 3001453687280
	3001453687280 [label=AccumulateGrad]
	3001453683248 -> 3001453688048
	3001454408624 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	3001454408624 -> 3001453683248
	3001453683248 [label=AccumulateGrad]
	3001453686320 -> 3001453688048
	3001454408720 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	3001454408720 -> 3001453686320
	3001453686320 [label=AccumulateGrad]
	3001453678064 -> 3001453690064
	3001454409104 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3001454409104 -> 3001453678064
	3001453678064 [label=AccumulateGrad]
	3001453686848 -> 3001453685408
	3001454409200 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	3001454409200 -> 3001453686848
	3001453686848 [label=AccumulateGrad]
	3001453687520 -> 3001453685408
	3001454409296 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	3001454409296 -> 3001453687520
	3001453687520 [label=AccumulateGrad]
	3001453690112 -> 3001453676096
	3001454409680 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	3001454409680 -> 3001453690112
	3001453690112 [label=AccumulateGrad]
	3001453688240 -> 3001453684352
	3001454409776 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	3001454409776 -> 3001453688240
	3001453688240 [label=AccumulateGrad]
	3001453677920 -> 3001453684352
	3001454409872 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	3001454409872 -> 3001453677920
	3001453677920 [label=AccumulateGrad]
	3001453688144 -> 3001453689632
	3001453684448 -> 3001453683872
	3001454410928 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	3001454410928 -> 3001453684448
	3001453684448 [label=AccumulateGrad]
	3001453686656 -> 3001453684400
	3001454411024 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	3001454411024 -> 3001453686656
	3001453686656 [label=AccumulateGrad]
	3001453679984 -> 3001453684400
	3001454411120 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	3001454411120 -> 3001453679984
	3001453679984 [label=AccumulateGrad]
	3001453690592 -> 3001453675232
	3001454411504 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3001454411504 -> 3001453690592
	3001453690592 [label=AccumulateGrad]
	3001453682336 -> 3001453683680
	3001454411600 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	3001454411600 -> 3001453682336
	3001453682336 [label=AccumulateGrad]
	3001453683008 -> 3001453683680
	3001454411696 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	3001454411696 -> 3001453683008
	3001453683008 [label=AccumulateGrad]
	3001453678256 -> 3001453675136
	3001464568336 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	3001464568336 -> 3001453678256
	3001453678256 [label=AccumulateGrad]
	3001453683824 -> 3001453687376
	3001464568432 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	3001464568432 -> 3001453683824
	3001453683824 [label=AccumulateGrad]
	3001453681328 -> 3001453687376
	3001464568528 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	3001464568528 -> 3001453681328
	3001453681328 [label=AccumulateGrad]
	3001453687136 -> 3001453685312
	3001453687136 [label=CudnnBatchNormBackward0]
	3001453684304 -> 3001453687136
	3001453684304 [label=ConvolutionBackward0]
	3001453688864 -> 3001453684304
	3001453684112 -> 3001453684304
	3001454410352 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	3001454410352 -> 3001453684112
	3001453684112 [label=AccumulateGrad]
	3001453674560 -> 3001453687136
	3001454410448 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	3001454410448 -> 3001453674560
	3001453674560 [label=AccumulateGrad]
	3001453676384 -> 3001453687136
	3001454410544 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	3001454410544 -> 3001453676384
	3001453676384 [label=AccumulateGrad]
	3001453686128 -> 3001453675616
	3001464568912 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	3001464568912 -> 3001453686128
	3001453686128 [label=AccumulateGrad]
	3001453678832 -> 3001453676720
	3001464569008 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	3001464569008 -> 3001453678832
	3001453678832 [label=AccumulateGrad]
	3001453684064 -> 3001453676720
	3001464569104 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	3001464569104 -> 3001453684064
	3001453684064 [label=AccumulateGrad]
	3001453688432 -> 3001453680368
	3001464569488 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3001464569488 -> 3001453688432
	3001453688432 [label=AccumulateGrad]
	3001453677632 -> 3001453675088
	3001464569584 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	3001464569584 -> 3001453677632
	3001453677632 [label=AccumulateGrad]
	3001453686608 -> 3001453675088
	3001464569680 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	3001464569680 -> 3001453686608
	3001453686608 [label=AccumulateGrad]
	3001453682048 -> 3001453688288
	3001457639696 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	3001457639696 -> 3001453682048
	3001453682048 [label=AccumulateGrad]
	3001453687568 -> 3001453681136
	3001457639792 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	3001457639792 -> 3001453687568
	3001453687568 [label=AccumulateGrad]
	3001453690544 -> 3001453681136
	3001457639888 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	3001457639888 -> 3001453690544
	3001453690544 [label=AccumulateGrad]
	3001453683776 -> 3001453682576
	3001453674800 -> 3001453689296
	3001457640272 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	3001457640272 -> 3001453674800
	3001453674800 [label=AccumulateGrad]
	3001453682912 -> 3001453690784
	3001457640368 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	3001457640368 -> 3001453682912
	3001453682912 [label=AccumulateGrad]
	3001453690640 -> 3001453690784
	3001457640464 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	3001457640464 -> 3001453690640
	3001453690640 [label=AccumulateGrad]
	3001453680032 -> 3001453685696
	3001457640848 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3001457640848 -> 3001453680032
	3001453680032 [label=AccumulateGrad]
	3001453676768 -> 3001453689920
	3001457640944 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	3001457640944 -> 3001453676768
	3001453676768 [label=AccumulateGrad]
	3001453684736 -> 3001453689920
	3001457641040 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	3001457641040 -> 3001453684736
	3001453684736 [label=AccumulateGrad]
	3001453678592 -> 3001453682000
	3001457641424 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	3001457641424 -> 3001453678592
	3001453678592 [label=AccumulateGrad]
	3001453676480 -> 3001453685888
	3001457641520 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	3001457641520 -> 3001453676480
	3001453676480 [label=AccumulateGrad]
	3001453688720 -> 3001453685888
	3001457641616 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	3001457641616 -> 3001453688720
	3001453688720 [label=AccumulateGrad]
	3001453679504 -> 3001453684256
	3001453681760 -> 3001453688960
	3001453681760 [label=TBackward0]
	3001453674848 -> 3001453681760
	3001457642288 [label="fc.weight
 (19, 2048)" fillcolor=lightblue]
	3001457642288 -> 3001453674848
	3001453674848 [label=AccumulateGrad]
	3001453688960 -> 3001464756400
}
