{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Library modules\n",
    "import os  # Operating system interactions, such as reading and writing files.\n",
    "import shutil  # High-level file operations like copying and moving files.\n",
    "import random  # Random number generation for various tasks.\n",
    "import textwrap  # Formatting text into paragraphs of a specified width.\n",
    "import warnings  # Warning control context manager.\n",
    "import zipfile  # Work with ZIP archives.\n",
    "import platform  # Access to underlying platformâ€™s identifying data.\n",
    "import itertools  # Functions creating iterators for efficient looping.\n",
    "from dataclasses import dataclass, field  # Class decorator for adding special methods to classes.\n",
    "\n",
    "# PyTorch and Deep Learning Libaries\n",
    "import torch  # Core PyTorch library for tensor computations.\n",
    "import torch.nn as nn  # Neural network module for defining layers and architectures.\n",
    "from torch.nn import functional as F  # Functional module for defining functions and loss functions.\n",
    "import torch.optim as optim  # Optimizer module for training models (SGD, Adam, etc.).\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split  # Data handling and batching\n",
    "import torchvision  # PyTorch's computer vision library.\n",
    "from torchvision import datasets, transforms  # Image datasets and transformations.\n",
    "import torchvision.datasets as datasets  # Specific datasets for vision tasks.\n",
    "import torchvision.transforms as transforms  # Transformations for image preprocessing.\n",
    "from torchvision.utils import make_grid  # Grid for displaying images.\n",
    "import torchvision.models as models  # Pretrained models for transfer learning.\n",
    "from torchvision.datasets import MNIST, EuroSAT  # Standard datasets.\n",
    "import torchvision.transforms.functional as TF  # Functional transformations.\n",
    "from torchvision.models import ResNet18_Weights  # ResNet-18 model with pretrained weights.\n",
    "from torchsummary import summary  # Model summary.\n",
    "import torchmetrics  # Model evaluation metrics.\n",
    "from torchmetrics import MeanMetric, Accuracy  # Accuracy metrics.\n",
    "from torchmetrics.classification import (\n",
    "    MultilabelF1Score, MultilabelRecall, MultilabelPrecision, MultilabelAccuracy\n",
    ")  # Classification metrics.\n",
    "from torchviz import make_dot  # Model visualization.\n",
    "from torchvision.ops import sigmoid_focal_loss  # Focal loss for class imbalance.\n",
    "from torchcam.methods import GradCAM  # Grad-CAM for model interpretability.\n",
    "from torchcam.utils import overlay_mask  # Overlay mask for visualizations.\n",
    "import pytorch_lightning as pl  # Training management.\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping, Callback  # Callbacks.\n",
    "from pytorch_lightning.loggers import TensorBoardLogger  # Logger for TensorBoard.\n",
    "\n",
    "# Geospatial Data Processing Libraries\n",
    "import rasterio  # Reading and writing geospatial raster data.\n",
    "from rasterio.warp import calculate_default_transform, reproject  # Reprojection and transformation.\n",
    "from rasterio.enums import Resampling  # Resampling for raster resizing.\n",
    "from rasterio.plot import show  # Visualization of raster data.\n",
    "\n",
    "# Data Manipulation, Analysis and Visualization Libraries\n",
    "import pandas as pd  # Data analysis and manipulation.\n",
    "import numpy as np  # Array operations and computations.\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score  # Evaluation metrics.\n",
    "import matplotlib.pyplot as plt  # Static and interactive plotting.\n",
    "import seaborn as sns  # High-level interface for statistical graphics.\n",
    "\n",
    "# Utility Libraries\n",
    "from tqdm import tqdm  # Progress bar for loops.\n",
    "from PIL import Image  # Image handling and manipulation.\n",
    "import ast  # Parsing Python code.\n",
    "import requests  # HTTP requests.\n",
    "import zstandard as zstd  # Compression and decompression.\n",
    "from collections import Counter  # Counting hashable objects.\n",
    "import certifi  # Certificates for HTTPS.\n",
    "import ssl  # Secure connections.\n",
    "import urllib.request  # URL handling.\n",
    "import kaggle  # Kaggle API for datasets.\n",
    "from IPython.display import Image  # Display images in notebooks.\n",
    "from pathlib import Path # File system path handling.\n",
    "from typing import Dict, List, Tuple  # Type hints.\n",
    "import sys  # System-specific parameters and functions.\n",
    "import time # Time access and conversions.\n",
    "import logging # Logging facility for Python.\n",
    "import json # JSON encoder and decoder.\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from contextlib import redirect_stdout\n",
    "# Custom Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42  \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"upb\"\n",
    "\n",
    "\n",
    "# Render plots\n",
    "%matplotlib inline\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device} {'(GPU: ' + torch.cuda.get_device_name(0) + ')' if device.type == 'cuda' else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def clean_and_parse_labels(label_string):\n",
    "    cleaned_labels = label_string.replace(\" '\", \", '\").replace(\"[\", \"[\").replace(\"]\", \"]\")\n",
    "    return ast.literal_eval(cleaned_labels)\n",
    "\n",
    "def calculate_class_weights(metadata_path):\n",
    "    metadata_csv = pd.read_csv(metadata_path)\n",
    "    metadata_csv['labels'] = metadata_csv['labels'].apply(clean_and_parse_labels)\n",
    "\n",
    "    class_labels = set()\n",
    "    for labels in metadata_csv['labels']:\n",
    "        class_labels.update(labels)\n",
    "\n",
    "    label_counts = metadata_csv['labels'].explode().value_counts()\n",
    "    total_counts = label_counts.sum()\n",
    "    class_weights = {label: total_counts / count for label, count in label_counts.items()}\n",
    "    class_weights_array = np.array([class_weights[label] for label in class_labels])\n",
    "\n",
    "    return class_labels, class_weights, class_weights_array, metadata_csv\n",
    "\n",
    "# Helper functions\n",
    "def denormalize(tensors, *, mean, std):\n",
    "    for c in range(DatasetConfig.band_channels):\n",
    "        tensors[:, c, :, :].mul_(std[c]).add_(mean[c])\n",
    "\n",
    "    return torch.clamp(tensors, min=0.0, max=1.0)\n",
    "\n",
    "def encode_label(label: list, num_classes=DatasetConfig.num_classes):\n",
    "    target = torch.zeros(num_classes)\n",
    "    for l in label:\n",
    "        if l in DatasetConfig.class_labels_dict:\n",
    "            target[DatasetConfig.class_labels_dict[l]] = 1.0\n",
    "    return target\n",
    "\n",
    "def decode_target(\n",
    "    target: list,\n",
    "    text_labels: bool = False,\n",
    "    threshold: float = 0.4,\n",
    "    cls_labels: dict = None,\n",
    "):\n",
    "    result = []\n",
    "    for i, x in enumerate(target):\n",
    "        if x >= threshold:\n",
    "            if text_labels:\n",
    "                result.append(cls_labels[i] + \"(\" + str(i) + \")\")\n",
    "            else:\n",
    "                result.append(str(i))\n",
    "    return \" \".join(result)\n",
    "\n",
    "\n",
    "def get_band_indices(band_names, all_band_names):\n",
    "    return [all_band_names.index(band) for band in band_names]\n",
    "\n",
    "\n",
    "\n",
    "def get_labels_for_image(image_path, model, transform, patch_to_labels):\n",
    "    # Load and preprocess the image\n",
    "    with rasterio.open(image_path) as src:\n",
    "        bands = [2, 3, 4]  # Bands to combine for display\n",
    "        image = np.stack([src.read(band) for band in bands], axis=-1)\n",
    "        image = transform(image).unsqueeze(0).to(model.device)  # Add batch dimension and move to device\n",
    "\n",
    "    # Get the predicted labels\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(image).sigmoid() > 0.5  # Apply sigmoid and threshold at 0.5\n",
    "        preds = preds.cpu().numpy().astype(int).flatten()\n",
    "\n",
    "    # Get the true labels\n",
    "    patch_id = os.path.basename(image_path).split('.')[0]\n",
    "    true_labels = patch_to_labels[patch_id]\n",
    "\n",
    "    return preds, true_labels, image\n",
    "\n",
    "def display_image(image_path):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        bands = [2, 3, 4]  # Bands to combine for display\n",
    "        image = np.stack([src.read(band) for band in bands], axis=-1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Image with Bands 2, 3, and 4\")\n",
    "        plt.show()\n",
    "\n",
    "def display_image_and_labels(image_path, model, transform, patch_to_labels):\n",
    "    # Display the image\n",
    "    display_image(image_path)\n",
    "\n",
    "    # Get predicted and true labels\n",
    "    preds, true_labels, _ = get_labels_for_image(image_path, model, transform, patch_to_labels)\n",
    "    print(f\"Predicted Labels: {preds}\")\n",
    "    print(f\"True Labels: {true_labels}\")\n",
    "\n",
    "def extract_number(string):\n",
    "    number_str = string.split('%')[0]\n",
    "    try:\n",
    "        number = float(number_str)\n",
    "        if number.is_integer():\n",
    "            return int(number)\n",
    "        return number\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Cannot extract a number from the string: {string}\")\n",
    "    \n",
    "\n",
    "# Define the hook function\n",
    "activations = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Visualize activations function\n",
    "def visualize_activations(layer_names, activations):\n",
    "    images_per_row = 16\n",
    "    for layer_name in layer_names:\n",
    "        layer_activation = activations[layer_name].squeeze().cpu().numpy()\n",
    "        n_features = layer_activation.shape[0] \n",
    "        size = layer_activation.shape[1] \n",
    "        n_cols = n_features // images_per_row  \n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "        for col in range(n_cols):  \n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[col * images_per_row + row]\n",
    "                channel_image -= channel_image.mean() \n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size,  \n",
    "                             row * size : (row + 1) * size] = channel_image\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BandNormalisation:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, image):\n",
    "        for i in range(image.shape[0]):\n",
    "            print(f\"Channel {i} - Mean: {self.mean[i]}, Std: {self.std[i]}\")\n",
    "            image[i] = (image[i] - self.mean[i]) / self.std[i]\n",
    "            print(f\"Channel {i} after normalization: {image[i]}\")\n",
    "        return image\n",
    "    \n",
    "class BandUnnormalisation:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, image):\n",
    "        for i in range(image.shape[0]):\n",
    "            image[i] = (image[i] * self.std[i]) + self.mean[i]\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Configuration file for the project\n",
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    metadata_path = r\"C:\\\\Users\\\\isaac\\\\Desktop\\BigEarthTests\\\\50%_BigEarthNet\\\\metadata_50_percent.csv\"\n",
    "    dataset_paths = {\n",
    "        \"0.5\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\0.5%_BigEarthNet\\CombinedImages\",\n",
    "        \"1\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\1%_BigEarthNet\\CombinedImages\",\n",
    "        \"5\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\5%_BigEarthNet\\CombinedImages\",\n",
    "        \"10\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\10%_BigEarthNet\\CombinedImages\",\n",
    "        \"50\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\50%_BigEarthNet\\CombinedImages\",\n",
    "        \"100\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\100%_BigEarthNet\\CombinedImages\"\n",
    "    }\n",
    "    metadata_paths = {\n",
    "        \"0.5\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\0.5%_BigEarthNet\\metadata_0.5_percent.csv\",\n",
    "        \"1\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\1%_BigEarthNet\\metadata_1_percent.csv\",\n",
    "        \"5\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\5%_BigEarthNet\\metadata_5_percent.csv\",\n",
    "        \"10\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\10%_BigEarthNet\\metadata_10_percent.csv\",\n",
    "        \"50\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\50%_BigEarthNet\\metadata_50_percent.csv\",\n",
    "        \"100\": r\"C:\\Users\\isaac\\Desktop\\BigEarthTests\\100%_BigEarthNet\\metadata_100_percent.csv\"\n",
    "    }\n",
    "    unwanted_metadata_file: str = r'C:\\Users\\isaac\\Downloads\\metadata_for_patches_with_snow_cloud_or_shadow.parquet'\n",
    "    unwanted_metadata_csv = pd.read_parquet(unwanted_metadata_file)\n",
    "\n",
    "    class_labels = calculate_class_labels(pd.read_csv(metadata_path))\n",
    "    class_labels = class_labels\n",
    "    class_labels_dict = {label: idx for idx, label in enumerate(class_labels)}\n",
    "    reversed_class_labels_dict = {idx: label for label, idx in class_labels_dict.items()}\n",
    "\n",
    "    num_classes: int = 19\n",
    "    band_channels: int = 12\n",
    "    valid_pct: float = 0.1\n",
    "    img_size: int = 120\n",
    "\n",
    "    rgb_bands = [\"B04\", \"B03\", \"B02\"]\n",
    "    rgb_nir_bands = [\"B04\", \"B03\", \"B02\", \"B08\"]\n",
    "    rgb_swir_bands = [\"B04\", \"B03\", \"B02\", \"B11\", \"B12\"]\n",
    "    rgb_nir_swir_bands = [\"B04\", \"B03\", \"B02\", \"B08\", \"B11\", \"B12\"]\n",
    "    all_imp_bands = [ \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"]\n",
    "    all_bands = [\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B09\", \"B11\", \"B12\"]\n",
    "    \n",
    "    band_stats = {\n",
    "        \"mean\": {\n",
    "            \"B01\": 359.93681858037576,\n",
    "            \"B02\": 437.7795146920668,\n",
    "            \"B03\": 626.9061237185847,\n",
    "            \"B04\": 605.0589129818594,\n",
    "            \"B05\": 971.6512098450492,\n",
    "            \"B06\": 1821.9817358749056,\n",
    "            \"B07\": 2108.096240315571,\n",
    "            \"B08\": 2256.3215618504346,\n",
    "            \"B8A\": 2310.6351913265307,\n",
    "            \"B09\": 2311.6085833217353,\n",
    "            \"B11\": 1608.6865167942176,\n",
    "            \"B12\": 1017.1259618291762\n",
    "        },\n",
    "        \"std\": {\n",
    "            \"B01\": 583.5085769396974,\n",
    "            \"B02\": 648.4384481402268,\n",
    "            \"B03\": 639.2669907766995,\n",
    "            \"B04\": 717.5748664544205,\n",
    "            \"B05\": 761.8971822905785,\n",
    "            \"B06\": 1090.758232889144,\n",
    "            \"B07\": 1256.5524552734478,\n",
    "            \"B08\": 1349.2050493390414,\n",
    "            \"B8A\": 1287.1124261320342,\n",
    "            \"B09\": 1297.654379610044,\n",
    "            \"B11\": 1057.3350765979644,\n",
    "            \"B12\": 802.1790763840752\n",
    "        }\n",
    "    }\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    num_epochs: int = 10\n",
    "    batch_size: int = 32\n",
    "    num_workers: int = os.cpu_count() // 2\n",
    "    learning_rate: float = 0.0001\n",
    "    momentum: float = 0.9\n",
    "    weight_decay: float = 1e-4\n",
    "    lr_step_size: int = 7\n",
    "    lr_factor: float = 0.1\n",
    "    patience: int = 5\n",
    "    lr_patience: int = 5\n",
    "    dropout: float = 0.5\n",
    "\n",
    "    model_names: list = field(default_factory=lambda: [\n",
    "        'resnet18', \n",
    "        'resnet34', \n",
    "        'resnet50', \n",
    "        'resnet101', \n",
    "        'resnet152', \n",
    "        'densenet121', \n",
    "        'densenet169', \n",
    "        'densenet201', \n",
    "        'densenet161',\n",
    "        'efficientnet-b0',\n",
    "        'vgg16',\n",
    "        'vgg19'\n",
    "    ])\n",
    "\n",
    "@dataclass\n",
    "class ModuleConfig:\n",
    "    reduction: int = 16\n",
    "    ratio: int = 8\n",
    "    kernel_size: int = 3\n",
    "    dropout_rt: float = 0.1\n",
    "    activation: type = nn.ReLU\n",
    "\n",
    "@dataclass\n",
    "class TransformsConfig:\n",
    "    train_transforms = transforms.Compose([\n",
    "        BandNormalisation(\n",
    "            mean=[DatasetConfig.band_stats[\"mean\"][band] for band in DatasetConfig.all_bands],\n",
    "            std=[DatasetConfig.band_stats[\"std\"][band] for band in DatasetConfig.all_bands]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.CenterCrop(120),\n",
    "        BandNormalisation(\n",
    "            mean=[DatasetConfig.band_stats[\"mean\"][band] for band in DatasetConfig.all_bands],\n",
    "            std=[DatasetConfig.band_stats[\"std\"][band] for band in DatasetConfig.all_bands]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.CenterCrop(120),\n",
    "        BandNormalisation(\n",
    "            mean=[DatasetConfig.band_stats[\"mean\"][band] for band in DatasetConfig.all_bands],\n",
    "            std=[DatasetConfig.band_stats[\"std\"][band] for band in DatasetConfig.all_bands]\n",
    "        )\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigEarthNetDatasetTIF(Dataset):\n",
    "    def __init__(self, *, df, root_dir, transforms=None, is_test=False, selected_bands=None, metadata_csv=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "        self.is_test = is_test\n",
    "        self.selected_bands = selected_bands if selected_bands is not None else DatasetConfig.rgb_bands\n",
    "        self.metadata = metadata_csv\n",
    "\n",
    "        self.image_paths = list(Path(root_dir).rglob(\"*.tif\"))\n",
    "        self.patch_to_labels = dict(zip(self.metadata['patch_id'], self.metadata['labels']))\n",
    "        self.image_paths = list(Path(root_dir).rglob(\"*.tif\"))\n",
    "\n",
    "        self.selected_band_indices = get_band_indices(self.selected_bands, DatasetConfig.all_bands)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "\n",
    "        with rasterio.open(image_path) as src:\n",
    "            image = src.read()  \n",
    "            image = image[self.selected_band_indices, :, :]\n",
    "        \n",
    "        # Image is convered to a tensor before applying transforms\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        label = self.get_label(image_path)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def get_label(self, img_path):\n",
    "        img_path = Path(img_path) \n",
    "        patch_id = img_path.stem\n",
    "        labels = self.patch_to_labels.get(patch_id, None)\n",
    "\n",
    "        if labels is None:\n",
    "            return torch.zeros(DatasetConfig.num_classes)  \n",
    "    \n",
    "        if isinstance(labels, str):\n",
    "            cleaned_labels = labels.replace(\" '\", \", '\").replace(\"[\", \"[\").replace(\"]\", \"]\")\n",
    "            labels =  ast.literal_eval(cleaned_labels)\n",
    "        \n",
    "        encoded = encode_label(labels)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data module for BigEarthNet dataset\n",
    "class BigEarthNetTIFDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, bands=None, dataset_dir=None, metadata_csv=None):\n",
    "        super().__init__()\n",
    "        self.bands = bands\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.metadata_csv = metadata_csv\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train_df = self.metadata_csv[self.metadata_csv['split'] == 'train']\n",
    "        val_df = self.metadata_csv[self.metadata_csv['split'] == 'validation']\n",
    "        test_df = self.metadata_csv[self.metadata_csv['split'] == 'test']\n",
    "\n",
    "        self.train_dataset = BigEarthNetDatasetTIF(df=train_df, root_dir=self.dataset_dir, transforms=TransformsConfig.train_transforms, selected_bands=self.bands, metadata_csv=self.metadata_csv)\n",
    "        self.val_dataset = BigEarthNetDatasetTIF(df=val_df, root_dir=self.dataset_dir, transforms=TransformsConfig.val_transforms, selected_bands=self.bands, metadata_csv=self.metadata_csv)\n",
    "        self.test_dataset = BigEarthNetDatasetTIF(df=test_df, root_dir=self.dataset_dir, transforms=TransformsConfig.test_transforms, selected_bands=self.bands, metadata_csv=self.metadata_csv)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        dataloader = DataLoader(self.train_dataset, batch_size=ModelConfig.batch_size, num_workers=ModelConfig.num_workers, pin_memory=True, shuffle=True, persistent_workers=True)\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataloader = DataLoader(self.val_dataset, batch_size=ModelConfig.batch_size,  num_workers=ModelConfig.num_workers, pin_memory=True,  persistent_workers=True)\n",
    "        return dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataloader = DataLoader(self.test_dataset, batch_size=ModelConfig.batch_size,  num_workers=ModelConfig.num_workers, pin_memory=True,  persistent_workers=True)\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class BigEarthNetResNet18ModelTIF(pl.LightningModule):\n",
    "    def __init__(self, class_weights, num_classes, in_channels, model_weights):\n",
    "        super(BigEarthNetResNet18ModelTIF, self).__init__()\n",
    "        self.model = models.resnet18(weights=model_weights)\n",
    "\n",
    "        original_conv1 = self.model.conv1\n",
    "        self.model.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,  \n",
    "            out_channels=original_conv1.out_channels,\n",
    "            kernel_size=original_conv1.kernel_size,\n",
    "            stride=original_conv1.stride,\n",
    "            padding=original_conv1.padding,\n",
    "            bias=original_conv1.bias,\n",
    "        )\n",
    "\n",
    "        # Initialize weights for the new channels (copy pretrained weights for 3 channels and random for the rest)\n",
    "        nn.init.kaiming_normal_(self.model.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "        # Modify the final layer to output 19 classes\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, DatasetConfig.num_classes)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.criterion = nn.BCEWithLogitsLoss(pos_weight=self.class_weights) # Define loss function\n",
    "        # Passing the model to the GPU\n",
    "        self.model.to(device)\n",
    "\n",
    "        # Accuracy metrics\n",
    "        self.train_acc = MultilabelAccuracy(num_labels=DatasetConfig.num_classes)\n",
    "        self.val_acc = MultilabelAccuracy(num_labels=DatasetConfig.num_classes)\n",
    "        self.test_acc = MultilabelAccuracy(num_labels=DatasetConfig.num_classes)\n",
    "\n",
    "        # Recall metrics\n",
    "        self.train_recall = MultilabelRecall(num_labels=DatasetConfig.num_classes)\n",
    "        self.val_recall = MultilabelRecall(num_labels=DatasetConfig.num_classes)\n",
    "        self.test_recall = MultilabelRecall(num_labels=DatasetConfig.num_classes)\n",
    "\n",
    "        # Precision metrics\n",
    "        self.train_precision = MultilabelPrecision(num_labels=DatasetConfig.num_classes)\n",
    "        self.val_precision = MultilabelPrecision(num_labels=DatasetConfig.num_classes)\n",
    "        self.test_precision = MultilabelPrecision(num_labels=DatasetConfig.num_classes)\n",
    "\n",
    "        # F1 Score metrics\n",
    "        self.train_f1 = MultilabelF1Score(num_labels=DatasetConfig.num_classes)\n",
    "        self.val_f1 = MultilabelF1Score(num_labels=DatasetConfig.num_classes)\n",
    "        self.test_f1 = MultilabelF1Score(num_labels=DatasetConfig.num_classes)\n",
    "\n",
    "        #torch.summary(self.model, (DatasetConfig.band_channels, ModelConfig.img_size, ModelConfig.img_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=ModelConfig.learning_rate)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=ModelConfig.lr_factor, patience=ModelConfig.lr_patience)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',  \n",
    "                'interval': 'epoch',\n",
    "                'frequency': 1\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return self.criterion(logits, labels)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, 'train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, 'test')\n",
    "\n",
    "    def _step(self, batch, batch_idx, phase):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        acc = getattr(self, f'{phase}_acc')(logits, y)\n",
    "        recall = getattr(self, f'{phase}_recall')(logits, y)\n",
    "        f1 = getattr(self, f'{phase}_f1')(logits, y)\n",
    "        precision = getattr(self, f'{phase}_precision')(logits, y)\n",
    "\n",
    "        self.log(f'{phase}_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(f'{phase}_acc', acc, on_epoch=True, prog_bar=True)\n",
    "        self.log(f'{phase}_recall', recall, on_epoch=True, prog_bar=True)\n",
    "        self.log(f'{phase}_f1', f1, on_epoch=True, prog_bar=True)\n",
    "        self.log(f'{phase}_precision', precision, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_epoch_end(self, phase):\n",
    "        self.log(f'{phase}_acc_epoch', getattr(self, f'{phase}_acc').compute())\n",
    "        self.log(f'{phase}_recall_epoch', getattr(self, f'{phase}_recall').compute())\n",
    "        self.log(f'{phase}_f1_epoch', getattr(self, f'{phase}_f1').compute())\n",
    "        self.log(f'{phase}_precision_epoch', getattr(self, f'{phase}_precision').compute())\n",
    "\n",
    "        # Reset metrics\n",
    "        getattr(self, f'{phase}_acc').reset()\n",
    "        getattr(self, f'{phase}_recall').reset()\n",
    "        getattr(self, f'{phase}_f1').reset()\n",
    "        getattr(self, f'{phase}_precision').reset()\n",
    "\n",
    "   \n",
    "    def print_summary(self, input_size, filename):\n",
    "        current_directory = os.getcwd()\n",
    "        save_dir = os.path.join(current_directory, 'FYPProjectMultiSpectral', 'models', 'Architecture', filename)\n",
    "        save_path = os.path.join(save_dir, f'{filename}_summary.txt)')\n",
    "        os.makedirs(save_dir, exist_ok=True)  \n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(device)\n",
    "\n",
    "        # Create a dummy input tensor with the specified input size\n",
    "        dummy_input = torch.zeros(1, *input_size).to(device)\n",
    "\n",
    "        # Redirect the summary output to a file\n",
    "        with open(save_path, 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                summary(self.model, input_size)\n",
    "\n",
    "    def visualize_model(self, input_size, model_name):\n",
    "        current_directory = os.getcwd()\n",
    "        save_path = os.path.join(current_directory, 'FYPProjectMultiSpectral', 'models', 'Architecture', model_name)\n",
    "        os.makedirs(save_path, exist_ok=True)  \n",
    "\n",
    "        # Move the model to the correct device\n",
    "        self.model.to(device)\n",
    "\n",
    "        # Create a random tensor input based on the input size\n",
    "        x = torch.randn(1, *input_size).to(device)  \n",
    "        # Pass the tensor through the model\n",
    "        y = self.model(x)\n",
    "\n",
    "        # Create the visualization and save it at the specified path\n",
    "        file_path = os.path.join(save_path, f'{model_name}')\n",
    "        make_dot(y, params=dict(self.model.named_parameters())).render(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = DatasetConfig.metadata_paths[\"0.5\"]\n",
    "metadata_csv = pd.read_csv(metadata_path)\n",
    "\n",
    "dataset_dir = DatasetConfig.dataset_paths[\"0.5\"]\n",
    "\n",
    "class_weights, class_weights_array = calculate_class_weights(metadata_csv)\n",
    "class_weights = class_weights_array\n",
    "\n",
    "bands = DatasetConfig.all_bands\n",
    "\n",
    "# Initialize the data module\n",
    "data_module = BigEarthNetTIFDataModule(bands=bands, dataset_dir=dataset_dir, metadata_csv=metadata_csv)\n",
    "data_module.setup(stage=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data_module.train_dataloader()\n",
    "print(f\"Number of training batches: {len(train_dataloader)}\")\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    x, y = batch\n",
    "    print(f\"Batch Shape: {x.shape}\")\n",
    "    print(f\"Labels Shape: {y.shape}\")\n",
    "    break\n",
    "\n",
    "# Print a few sample data points\n",
    "for batch_idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Labels: {labels}\")\n",
    "    break  \n",
    "\n",
    "# Verify the distribution of classes in the labels\n",
    "all_labels = []\n",
    "for batch_idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "    all_labels.extend(labels.numpy())\n",
    "\n",
    "# Convert to a numpy array and print the class distribution\n",
    "all_labels = np.array(all_labels)\n",
    "unique, counts = np.unique(all_labels, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(f\"Class distribution: {class_distribution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigEarthNetResNet18ModelTIF(class_weights=class_weights, num_classes=DatasetConfig.num_classes, in_channels=12, model_weights=ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "\n",
    "# Create a sample input tensor\n",
    "sample_input = torch.randn(1, 12, 120, 120)  \n",
    "\n",
    "# Perform a forward pass\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    sample_output = model(sample_input)\n",
    "\n",
    "# Print the output shape\n",
    "print(f\"Output shape: {sample_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register hooks to capture activations\n",
    "layer_names = []\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        layer.register_forward_hook(get_activation(name))\n",
    "        layer_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet18'\n",
    "weights = 'ResNet18_Weights.DEFAULT'\n",
    "selected_bands = 'all_bands'\n",
    "selected_dataset = '0.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = r'C:\\Users\\isaac\\Desktop\\experiments\\logs'\n",
    "logger = TensorBoardLogger(log_dir, name=f\"{model_name}_{weights}_{selected_bands}_experiment_{selected_dataset}\")\n",
    "\n",
    "\n",
    "checkpoint_dir = fr'C:\\Users\\isaac\\Desktop\\experiments\\checkpoints\\{model_name}_{weights}_{selected_bands}_{selected_dataset}'\n",
    "\n",
    "# Checkpoint callback for val_loss\n",
    "checkpoint_callback_loss = ModelCheckpoint(\n",
    "    dirpath=checkpoint_dir,\n",
    "    filename=f'{{epoch:02d}}-{{val_loss:.2f}}',\n",
    "    save_top_k=1,\n",
    "    verbose=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Checkpoint callback for val_acc\n",
    "checkpoint_callback_acc = ModelCheckpoint(\n",
    "    dirpath=checkpoint_dir,\n",
    "    filename=f'{{epoch:02d}}-{{val_acc:.2f}}',\n",
    "    save_top_k=1,\n",
    "    verbose=False,\n",
    "    monitor='val_acc',\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "final_checkpoint = ModelCheckpoint(\n",
    "    dirpath=checkpoint_dir,\n",
    "    filename=f'final',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=ModelConfig.patience,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Model Training with custom callbacks\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=checkpoint_dir,\n",
    "    max_epochs=ModelConfig.num_epochs,\n",
    "    logger=logger,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    "    precision='16-mixed',\n",
    "    log_every_n_steps=1,\n",
    "    accumulate_grad_batches=2,\n",
    "    callbacks=[checkpoint_callback_loss, checkpoint_callback_acc, final_checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize activations after each epoch\n",
    "visualize_activations(layer_names, activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = checkpoint_callback_loss.final_checkpoint\n",
    "model = BigEarthNetTIFDataModule.load_from_checkpoint(checkpoint_path, class_weights=class_weights, num_classes=num_classes, in_channels=in_channels, model_weights=model_weights)\n",
    "model.eval()\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    "    precision='16-mixed'  \n",
    ")\n",
    "# Run test\n",
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for batch in tqdm(data_module.test_dataloader(), desc=\"Processing Batches\"):\n",
    "    inputs, labels = batch\n",
    "    inputs = inputs.to(model.device)\n",
    "    labels = labels.to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs)  \n",
    "        #print(f\"Raw logits: {logits}\")  \n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        #print(f\"Sigmoid outputs: {torch.sigmoid(logits)}\")  \n",
    "\n",
    "    all_preds.extend(preds.cpu().numpy())\n",
    "    all_labels.extend(labels.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
