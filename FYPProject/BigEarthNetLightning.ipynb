{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Of Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Library modules\n",
    "import os  # Operating system interactions, such as reading and writing files.\n",
    "import shutil  # High-level file operations like copying and moving files.\n",
    "import random  # Random number generation for various tasks.\n",
    "import textwrap  # Formatting text into paragraphs of a specified width.\n",
    "import warnings  # Warning control context manager.\n",
    "import zipfile  # Work with ZIP archives.\n",
    "import platform  # Access to underlying platformâ€™s identifying data.\n",
    "import itertools  # Functions creating iterators for efficient looping.\n",
    "from dataclasses import dataclass  # Class decorator for adding special methods to classes.\n",
    "\n",
    "# PyTorch and Deep Learning Libaries\n",
    "import torch  # Core PyTorch library for tensor computations.\n",
    "import torch.nn as nn  # Neural network module for defining layers and architectures.\n",
    "from torch.nn import functional as F  # Functional module for defining functions and loss functions.\n",
    "import torch.optim as optim  # Optimizer module for training models (SGD, Adam, etc.).\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split  # Data handling and batching\n",
    "import torchvision  # PyTorch's computer vision library.\n",
    "from torchvision import datasets, transforms  # Image datasets and transformations.\n",
    "import torchvision.datasets as datasets  # Specific datasets for vision tasks.\n",
    "import torchvision.transforms as transforms  # Transformations for image preprocessing.\n",
    "from torchvision.utils import make_grid  # Grid for displaying images.\n",
    "import torchvision.models as models  # Pretrained models for transfer learning.\n",
    "from torchvision.datasets import MNIST, EuroSAT  # Standard datasets.\n",
    "import torchvision.transforms.functional as TF  # Functional transformations.\n",
    "from torchvision.models import ResNet18_Weights  # ResNet-18 model with pretrained weights.\n",
    "from torchsummary import summary  # Model summary.\n",
    "import torchsummary  # Model summaries.\n",
    "import torchmetrics  # Model evaluation metrics.\n",
    "from torchmetrics import MeanMetric, Accuracy  # Accuracy metrics.\n",
    "from torchmetrics.classification import (\n",
    "    MultilabelF1Score, MultilabelRecall, MultilabelPrecision, MultilabelAccuracy\n",
    ")  # Classification metrics.\n",
    "from torchviz import make_dot  # Model visualization.\n",
    "from torchvision.ops import sigmoid_focal_loss  # Focal loss for class imbalance.\n",
    "from torchcam.methods import GradCAM  # Grad-CAM for model interpretability.\n",
    "from torchcam.utils import overlay_mask  # Overlay mask for visualizations.\n",
    "import pytorch_lightning as pl  # Training management.\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping, Callback  # Callbacks.\n",
    "from pytorch_lightning.loggers import TensorBoardLogger  # Logger for TensorBoard.\n",
    "\n",
    "# Geospatial Data Processing Libraries\n",
    "import rasterio  # Reading and writing geospatial raster data.\n",
    "from rasterio.warp import calculate_default_transform, reproject  # Reprojection and transformation.\n",
    "from rasterio.enums import Resampling  # Resampling for raster resizing.\n",
    "from rasterio.plot import show  # Visualization of raster data.\n",
    "\n",
    "# Data Manipulation, Analysis and Visualization Libraries\n",
    "import pandas as pd  # Data analysis and manipulation.\n",
    "import numpy as np  # Array operations and computations.\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score  # Evaluation metrics.\n",
    "import matplotlib.pyplot as plt  # Static and interactive plotting.\n",
    "import seaborn as sns  # High-level interface for statistical graphics.\n",
    "\n",
    "# Utility Libraries\n",
    "from tqdm import tqdm  # Progress bar for loops.\n",
    "from PIL import Image  # Image handling and manipulation.\n",
    "import ast  # Parsing Python code.\n",
    "import requests  # HTTP requests.\n",
    "import zstandard as zstd  # Compression and decompression.\n",
    "from collections import Counter  # Counting hashable objects.\n",
    "import certifi  # Certificates for HTTPS.\n",
    "import ssl  # Secure connections.\n",
    "import urllib.request  # URL handling.\n",
    "import kaggle  # Kaggle API for datasets.\n",
    "from IPython.display import Image  # Display images in notebooks.\n",
    "from pathlib import Path # File system path handling.\n",
    "from typing import Dict, List, Tuple  # Type hints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Seed and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda (GPU: NVIDIA GeForce RTX 3050)\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42  \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device} {'(GPU: ' + torch.cuda.get_device_name(0) + ')' if device.type == 'cuda' else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Config Data Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    dataset_path: str = r'C:\\Users\\isaac\\Desktop\\BigEarthTests\\Subsets\\50%'\n",
    "    combined_path: str = r'C:\\Users\\isaac\\Desktop\\BigEarthTests\\Subsets\\50%\\CombinedRGBImages'\n",
    "    metadata_path: str =r'C:\\Users\\isaac\\Desktop\\BigEarthTests\\Subsets\\metadata_50_percent.csv'\n",
    "    metadata_csv = pd.read_csv(metadata_path)\n",
    "    img_size: int = 120\n",
    "    img_mean, img_std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "    num_classes: int = 19\n",
    "    band_channels: int = 13\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    batch_size: int = 32\n",
    "    num_epochs: int = 10\n",
    "    model_name: str = 'resnet18'\n",
    "    num_workers: int = os.cpu_count() // 2\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=DatasetConfig.img_mean, std=DatasetConfig.img_std)\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=DatasetConfig.img_mean, std=DatasetConfig.img_std)\n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=DatasetConfig.img_mean, std=DatasetConfig.img_std)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arable land': 0, 'Broad-leaved forest': 1, 'Land principally occupied by agriculture, with significant areas of natural vegetation': 2, 'Pastures': 3, 'Urban fabric': 4, 'Complex cultivation patterns': 5, 'Mixed forest': 6, 'Industrial or commercial units': 7, 'Coniferous forest': 8, 'Transitional woodland, shrub': 9, 'Natural grassland and sparsely vegetated areas': 10, 'Inland waters': 11, 'Marine waters': 12, 'Inland wetlands': 13, 'Moors, heathland and sclerophyllous vegetation': 14, 'Permanent crops': 15, 'Agro-forestry areas': 16, 'Beaches, dunes, sands': 17, 'Coastal wetlands': 18}\n",
      "{0: 'Arable land', 1: 'Broad-leaved forest', 2: 'Land principally occupied by agriculture, with significant areas of natural vegetation', 3: 'Pastures', 4: 'Urban fabric', 5: 'Complex cultivation patterns', 6: 'Mixed forest', 7: 'Industrial or commercial units', 8: 'Coniferous forest', 9: 'Transitional woodland, shrub', 10: 'Natural grassland and sparsely vegetated areas', 11: 'Inland waters', 12: 'Marine waters', 13: 'Inland wetlands', 14: 'Moors, heathland and sclerophyllous vegetation', 15: 'Permanent crops', 16: 'Agro-forestry areas', 17: 'Beaches, dunes, sands', 18: 'Coastal wetlands'}\n"
     ]
    }
   ],
   "source": [
    "# Check if the labels are strings and need to be converted\n",
    "if isinstance(DatasetConfig.metadata_csv['labels'].iloc[0], str):\n",
    "    DatasetConfig.metadata_csv['labels'] = DatasetConfig.metadata_csv['labels'].apply(ast.literal_eval)\n",
    "\n",
    "# Get unique class labels\n",
    "class_labels = DatasetConfig.metadata_csv['labels'].explode().unique()\n",
    "\n",
    "# Create a dictionary mapping class labels to indices\n",
    "class_labels_dict = {label: idx for idx, label in enumerate(class_labels)}\n",
    "\n",
    "# Create a reversed dictionary mapping indices to class labels\n",
    "reversed_class_labels_dict = {idx: label for label, idx in class_labels_dict.items()}\n",
    "\n",
    "print(class_labels_dict)\n",
    "print(reversed_class_labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigEarthNetSubset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = list(Path(root_dir).rglob(\"*.tif\"))\n",
    "        self.metadata = pd.read_csv(DatasetConfig.metadata_path)\n",
    "\n",
    "        # Create a mapping from patch_id to labels\n",
    "        self.patch_to_labels = dict(zip(self.metadata['patch_id'], self.metadata['labels']))\n",
    "        self.image_paths = list(Path(root_dir).rglob(\"*.tif\"))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        with rasterio.open(image_path) as src:\n",
    "            image = src.read() \n",
    "        \n",
    "        image = torch.from_numpy(image).float()\n",
    "        \n",
    "        label = self.get_label(image_path)  \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def get_label(self, image_path):\n",
    "        patch_id = image_path.stem\n",
    "        labels = self.patch_to_labels.get(patch_id, None)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 2352\n"
     ]
    }
   ],
   "source": [
    "dataset = BigEarthNetSubset(DatasetConfig.combined_path)\n",
    "print(f\"Dataset length: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.BigEarthNetSubset object at 0x000002ECA185F650>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: <built-in method size of Tensor object at 0x000002ECA048EFF0>, Label: ['Broad-leaved forest', 'Coniferous forest', 'Mixed forest', 'Transitional woodland, shrub']\n"
     ]
    }
   ],
   "source": [
    "image, label = dataset[5]\n",
    "print(f\"Image shape: {image.size}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[29., 31., 41.,  ..., 21., 21., 25.],\n",
       "         [28., 22., 23.,  ..., 19., 23., 28.],\n",
       "         [28., 21., 26.,  ..., 20., 25., 28.],\n",
       "         ...,\n",
       "         [14., 13., 13.,  ..., 11., 28., 39.],\n",
       "         [13., 13., 13.,  ..., 24., 43., 37.],\n",
       "         [11., 13., 14.,  ..., 35., 35., 33.]],\n",
       "\n",
       "        [[40., 44., 47.,  ..., 39., 40., 45.],\n",
       "         [40., 34., 36.,  ..., 37., 44., 52.],\n",
       "         [38., 36., 39.,  ..., 39., 50., 54.],\n",
       "         ...,\n",
       "         [27., 26., 31.,  ..., 27., 40., 54.],\n",
       "         [29., 28., 32.,  ..., 41., 53., 57.],\n",
       "         [26., 28., 32.,  ..., 49., 53., 54.]],\n",
       "\n",
       "        [[17., 21., 26.,  ..., 15., 15., 17.],\n",
       "         [16., 11., 14.,  ..., 15., 17., 19.],\n",
       "         [16., 12., 15.,  ..., 15., 19., 21.],\n",
       "         ...,\n",
       "         [11., 10., 12.,  ...,  8., 16., 24.],\n",
       "         [ 9., 11., 12.,  ..., 14., 24., 23.],\n",
       "         [ 9., 11., 13.,  ..., 19., 21., 23.]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Data Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigEarthNetSubsetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def setup(self, stage=None):\n",
    "        self.train_transform = ModelConfig.train_transforms\n",
    "        self.val_transform = ModelConfig.val_transforms\n",
    "        self.test_transform = ModelConfig.test_transforms\n",
    "\n",
    "        # Load the dataset\n",
    "        halfdataset = BigEarthNetSubset(DatasetConfig.combined_path)\n",
    "\n",
    "        # Split the dataset\n",
    "        train_size = int(0.8 * len(halfdataset))\n",
    "        test_size = (len(halfdataset) - train_size) // 2\n",
    "        val_size = len(halfdataset) - train_size - test_size\n",
    "        train_dataset, val_dataset, test_dataset = random_split(halfdataset, [train_size, val_size, test_size])\n",
    "\n",
    "        # Apply transforms to the specific splits\n",
    "        train_dataset.dataset.transform = self.train_transform\n",
    "        val_dataset.dataset.transform = self.val_transform\n",
    "        test_dataset.dataset.transform = self.test_transform\n",
    "\n",
    "        # Assign datasets to module attributes\n",
    "        self.bigearthnet_train = train_dataset\n",
    "        self.bigearthnet_val = val_dataset\n",
    "        self.bigearthnet_test = test_dataset\n",
    "\n",
    "        print(f\"Number of samples in train set: {len(self.bigearthnet_train)}, val set: {len(self.bigearthnet_val)}, test set: {len(self.bigearthnet_test)}\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.bigearthnet_train, batch_size=ModelConfig.batch_size, num_workers=ModelConfig.num_workers, pin_memory=True, shuffle=True, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.bigearthnet_val, batch_size=ModelConfig.batch_size, num_workers=ModelConfig.num_workers, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.bigearthnet_test, batch_size=ModelConfig.batch_size, num_workers=ModelConfig.num_workers, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigEarthNetSubsetModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(BigEarthNetSubsetModel, self).__init__()\n",
    "        # Load the ResNet-18 model\n",
    "        self.model = models.resnet18(weights=None)\n",
    "        # Modify the final layer to output 19 classes\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, DatasetConfig.num_classes)\n",
    "        # Addition of a sigmoid activation function for muylti-label classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # Passing the model to the GPU\n",
    "        self.model.to(device)\n",
    "\n",
    "        # Accuracy metrics\n",
    "        self.train_acc = MultilabelAccuracy(num_classes=DatasetConfig.num_classes)\n",
    "        self.val_acc = MultilabelAccuracy(num_classes=DatasetConfig.num_classes)\n",
    "        self.test_acc = MultilabelAccuracy(num_classes=DatasetConfig.num_classes)\n",
    "\n",
    "        # Recall metrics\n",
    "        self.train_recall = MultilabelRecall(num_classes=DatasetConfig.num_classes)\n",
    "        self.val_recall = MultilabelRecall(num_classes=DatasetConfig.num_classes)\n",
    "        self.test_recall = MultilabelRecall(num_classes=DatasetConfig.num_classes)\n",
    "\n",
    "        # Precision metrics\n",
    "        self.train_precision = MultilabelPrecision(num_classes=DatasetConfig.num_classes)\n",
    "        self.val_precision = MultilabelPrecision(num_classes=DatasetConfig.num_classes)\n",
    "        self.test_precision = MultilabelPrecision(num_classes=DatasetConfig.num_classes)\n",
    "\n",
    "        # F1 Score metrics\n",
    "        self.train_f1 = MultilabelF1Score(num_classes=DatasetConfig.num_classes)\n",
    "        self.val_f1 = MultilabelF1Score(num_classes=DatasetConfig.num_classes)\n",
    "        self.test_f1 = MultilabelF1Score(num_classes=DatasetConfig.num_classes)\n",
    "\n",
    "        torch.summary(self.model, (DatasetConfig.band_channels, ModelConfig.img_size, ModelConfig.img_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.binary_cross_entropy_with_logits(logits, labels)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        acc = self.train_acc(logits, y)\n",
    "        recall = self.train_recall(logits, y)\n",
    "        f1 = self.train_f1(logits, y)\n",
    "        precision = self.train_precision(logits, y)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_recall', recall, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_f1', f1, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_precision', precision, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        acc = self.val_acc(logits, y)\n",
    "        recall = self.val_recall(logits, y)\n",
    "        f1 = self.val_f1(logits, y)\n",
    "        precision = self.val_precision(logits, y)\n",
    "\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_recall', recall, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_f1', f1, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_precision', precision, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        acc = self.test_acc(logits, y)\n",
    "        recall = self.test_recall(logits, y)\n",
    "        f1 = self.test_f1(logits, y)\n",
    "        precision = self.test_precision(logits, y)\n",
    "\n",
    "        self.log('test_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_acc', acc, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_recall', recall, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_f1', f1, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_precision', precision, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        pass\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        pass\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigEarthNetSubsetCallback(Callback):\n",
    "    def __init__(self, checkpoint_path, model_name):\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        epoch = trainer.current_epoch\n",
    "        checkpoint_path = os.path.join(self.checkpoint_dir, f\"epoch={epoch}_{self.model_name}.ckpt\")\n",
    "        torch.save(pl_module.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved at: {checkpoint_path}\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        base_path = os.path.join(self.checkpoint_dir, f\"final_{self.model_name}\")\n",
    "        final_model_path = f\"{base_path}.ckpt\"\n",
    "        counter = 1\n",
    "        \n",
    "        # Check if the path exists and increment the counter until a unique path is found\n",
    "        while os.path.exists(final_model_path):\n",
    "            final_model_path = f\"{base_path}_{counter}.ckpt\"\n",
    "            counter += 1\n",
    "        \n",
    "        torch.save(pl_module.state_dict(), final_model_path)\n",
    "        print(f\"Final model saved at: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train set: 1881, val set: 236, test set: 235\n"
     ]
    }
   ],
   "source": [
    "data_module = BigEarthNetSubsetDataModule()\n",
    "data_module.setup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
