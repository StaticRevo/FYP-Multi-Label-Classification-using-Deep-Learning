digraph {
	graph [size="111.89999999999999,111.89999999999999"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2026824237328 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2026824234464 [label=AddmmBackward0]
	2026824234128 -> 2026824234464
	2026840476752 [label="1.4.bias
 (19)" fillcolor=lightblue]
	2026840476752 -> 2026824234128
	2026824234128 [label=AccumulateGrad]
	2026824233504 -> 2026824234464
	2026824233504 [label=NativeDropoutBackward0]
	2026824233024 -> 2026824233504
	2026824233024 [label=ViewBackward0]
	2026824232688 -> 2026824233024
	2026824232688 [label=MeanBackward1]
	2026824232208 -> 2026824232688
	2026824232208 [label=ReshapeAliasBackward0]
	2026824231728 -> 2026824232208
	2026824231728 [label=TransposeBackward0]
	2026824231248 -> 2026824231728
	2026824231248 [label=NativeLayerNormBackward0]
	2026824230768 -> 2026824231248
	2026824230768 [label=AddBackward0]
	2026824229808 -> 2026824230768
	2026824229808 [label=NativeLayerNormBackward0]
	2026824228704 -> 2026824229808
	2026824228704 [label=AddBackward0]
	2026824227744 -> 2026824228704
	2026824227744 [label=AddBackward0]
	2026824227408 -> 2026824227744
	2026824227408 [label=TransposeBackward0]
	2026824226928 -> 2026824227408
	2026824226928 [label=ViewBackward0]
	2026824226448 -> 2026824226928
	2026824226448 [label=MulBackward0]
	2026824225968 -> 2026824226448
	2026824225968 [label=MulBackward0]
	2026824224864 -> 2026824225968
	2026824224864 [label=ReluBackward0]
	2026824224528 -> 2026824224864
	2026824224528 [label=AddBackward0]
	2026824224048 -> 2026824224528
	2026824224048 [label=MulBackward0]
	2026824222944 -> 2026824224048
	2026824222944 [label=DivBackward0]
	2026824222464 -> 2026824222944
	2026824222464 [label=CudnnBatchNormBackward0]
	2026824221984 -> 2026824222464
	2026824221984 [label=ConvolutionBackward0]
	2026824221024 -> 2026824221984
	2026824221024 [label=NativeDropoutBackward0]
	2026824236576 -> 2026824221024
	2026824236576 [label=ReluBackward0]
	2026824236816 -> 2026824236576
	2026824236816 [label=CudnnBatchNormBackward0]
	2026824236720 -> 2026824236816
	2026824236720 [label=ConvolutionBackward0]
	2026824223904 -> 2026824236720
	2026824223904 [label=ReluBackward0]
	2026824236336 -> 2026824223904
	2026824236336 [label=CudnnBatchNormBackward0]
	2026824236240 -> 2026824236336
	2026824236240 [label=ConvolutionBackward0]
	2026824235616 -> 2026824236240
	2026824235616 [label=ConvolutionBackward0]
	2026824235664 -> 2026824235616
	2026824235664 [label=MulBackward0]
	2026824235472 -> 2026824235664
	2026824235472 [label=ReluBackward0]
	2026824235232 -> 2026824235472
	2026824235232 [label=AddBackward0]
	2026824235184 -> 2026824235232
	2026824235184 [label=MulBackward0]
	2026824234992 -> 2026824235184
	2026824234992 [label=DivBackward0]
	2026824234656 -> 2026824234992
	2026824234656 [label=CudnnBatchNormBackward0]
	2026824234896 -> 2026824234656
	2026824234896 [label=ConvolutionBackward0]
	2026824234512 -> 2026824234896
	2026824234512 [label=NativeDropoutBackward0]
	2026824234272 -> 2026824234512
	2026824234272 [label=ReluBackward0]
	2026824234224 -> 2026824234272
	2026824234224 [label=CudnnBatchNormBackward0]
	2026824234080 -> 2026824234224
	2026824234080 [label=ConvolutionBackward0]
	2026824235376 -> 2026824234080
	2026824235376 [label=ConvolutionBackward0]
	2026824233744 -> 2026824235376
	2026824233744 [label=CatBackward0]
	2026824233408 -> 2026824233744
	2026824233408 [label=ConvolutionBackward0]
	2026824233264 -> 2026824233408
	2026824233264 [label=ReluBackward0]
	2026824232928 -> 2026824233264
	2026824232928 [label=CudnnBatchNormBackward0]
	2026824232832 -> 2026824232928
	2026824232832 [label=ConvolutionBackward0]
	2026824232640 -> 2026824232832
	2026824232640 [label=ConvolutionBackward0]
	2026824232256 -> 2026824232640
	2026824232256 [label=MulBackward0]
	2026824232304 -> 2026824232256
	2026824232304 [label=ReluBackward0]
	2026824232112 -> 2026824232304
	2026824232112 [label=AddBackward0]
	2026824231776 -> 2026824232112
	2026824231776 [label=MulBackward0]
	2026824231824 -> 2026824231776
	2026824231824 [label=DivBackward0]
	2026824231680 -> 2026824231824
	2026824231680 [label=CudnnBatchNormBackward0]
	2026824231488 -> 2026824231680
	2026824231488 [label=ConvolutionBackward0]
	2026824231344 -> 2026824231488
	2026824231344 [label=NativeDropoutBackward0]
	2026824231152 -> 2026824231344
	2026824231152 [label=ReluBackward0]
	2026824230816 -> 2026824231152
	2026824230816 [label=CudnnBatchNormBackward0]
	2026824231056 -> 2026824230816
	2026824231056 [label=ConvolutionBackward0]
	2026824231968 -> 2026824231056
	2026824231968 [label=ConvolutionBackward0]
	2026824230336 -> 2026824231968
	2026824230336 [label=CatBackward0]
	2026824230480 -> 2026824230336
	2026824230480 [label=ConvolutionBackward0]
	2026824229856 -> 2026824230480
	2026824229856 [label=ReluBackward0]
	2026824230000 -> 2026824229856
	2026824230000 [label=CudnnBatchNormBackward0]
	2026824229712 -> 2026824230000
	2026824229712 [label=ConvolutionBackward0]
	2026824229616 -> 2026824229712
	2026824229616 [label=ConvolutionBackward0]
	2026824229280 -> 2026824229616
	2026824229280 [label=MulBackward0]
	2026824228896 -> 2026824229280
	2026824228896 [label=MulBackward0]
	2026824228944 -> 2026824228896
	2026824228944 [label=MulBackward0]
	2026824228752 -> 2026824228944
	2026824228752 [label=ReluBackward0]
	2026824228512 -> 2026824228752
	2026824228512 [label=AddBackward0]
	2026824228464 -> 2026824228512
	2026824228464 [label=MulBackward0]
	2026824228272 -> 2026824228464
	2026824228272 [label=DivBackward0]
	2026824227936 -> 2026824228272
	2026824227936 [label=CudnnBatchNormBackward0]
	2026824228176 -> 2026824227936
	2026824228176 [label=ConvolutionBackward0]
	2026824227792 -> 2026824228176
	2026824227792 [label=NativeDropoutBackward0]
	2026824227552 -> 2026824227792
	2026824227552 [label=ReluBackward0]
	2026824227504 -> 2026824227552
	2026824227504 [label=CudnnBatchNormBackward0]
	2026824227360 -> 2026824227504
	2026824227360 [label=ConvolutionBackward0]
	2026824228656 -> 2026824227360
	2026824228656 [label=ReluBackward0]
	2026824227024 -> 2026824228656
	2026824227024 [label=CudnnBatchNormBackward0]
	2026824226880 -> 2026824227024
	2026824226880 [label=ConvolutionBackward0]
	2026824226592 -> 2026824226880
	2026824226592 [label=ConvolutionBackward0]
	2026824226640 -> 2026824226592
	2026824226640 [label=MaxPool2DWithIndicesBackward0]
	2026824226208 -> 2026824226640
	2026824226208 [label=ReluBackward0]
	2026824226112 -> 2026824226208
	2026824226112 [label=CudnnBatchNormBackward0]
	2026824226064 -> 2026824226112
	2026824226064 [label=ConvolutionBackward0]
	2026824225728 -> 2026824226064
	2026681460656 [label="0.0.weight
 (32, 12, 1, 1)" fillcolor=lightblue]
	2026681460656 -> 2026824225728
	2026824225728 [label=AccumulateGrad]
	2026824226256 -> 2026824226112
	2026681461424 [label="0.1.weight
 (32)" fillcolor=lightblue]
	2026681461424 -> 2026824226256
	2026824226256 [label=AccumulateGrad]
	2026824226400 -> 2026824226112
	2026681460368 [label="0.1.bias
 (32)" fillcolor=lightblue]
	2026681460368 -> 2026824226400
	2026824226400 [label=AccumulateGrad]
	2026824226544 -> 2026824226592
	2026681460944 [label="0.4.depthwise.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	2026681460944 -> 2026824226544
	2026824226544 [label=AccumulateGrad]
	2026824226496 -> 2026824226880
	2026681461040 [label="0.4.pointwise.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	2026681461040 -> 2026824226496
	2026824226496 [label=AccumulateGrad]
	2026824227120 -> 2026824227024
	2026681460848 [label="0.5.weight
 (64)" fillcolor=lightblue]
	2026681460848 -> 2026824227120
	2026824227120 [label=AccumulateGrad]
	2026824227168 -> 2026824227024
	2026681461136 [label="0.5.bias
 (64)" fillcolor=lightblue]
	2026681461136 -> 2026824227168
	2026824227168 [label=AccumulateGrad]
	2026824227072 -> 2026824227360
	2026681459408 [label="0.7.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2026681459408 -> 2026824227072
	2026824227072 [label=AccumulateGrad]
	2026824227600 -> 2026824227504
	2026681460176 [label="0.7.bn1.weight
 (64)" fillcolor=lightblue]
	2026681460176 -> 2026824227600
	2026824227600 [label=AccumulateGrad]
	2026824227648 -> 2026824227504
	2026681459120 [label="0.7.bn1.bias
 (64)" fillcolor=lightblue]
	2026681459120 -> 2026824227648
	2026824227648 [label=AccumulateGrad]
	2026824227840 -> 2026824228176
	2026681459696 [label="0.7.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2026681459696 -> 2026824227840
	2026824227840 [label=AccumulateGrad]
	2026824228032 -> 2026824227936
	2026681459600 [label="0.7.bn2.weight
 (64)" fillcolor=lightblue]
	2026681459600 -> 2026824228032
	2026824228032 [label=AccumulateGrad]
	2026824228560 -> 2026824227936
	2026681459792 [label="0.7.bn2.bias
 (64)" fillcolor=lightblue]
	2026681459792 -> 2026824228560
	2026824228560 [label=AccumulateGrad]
	2026824228656 -> 2026824228512
	2026824228800 -> 2026824228944
	2026824228800 [label=ViewBackward0]
	2026824228320 -> 2026824228800
	2026824228320 [label=SigmoidBackward0]
	2026824227984 -> 2026824228320
	2026824227984 [label=AddmmBackward0]
	2026824227312 -> 2026824227984
	2026681457776 [label="0.8.fc2.bias
 (64)" fillcolor=lightblue]
	2026681457776 -> 2026824227312
	2026824227312 [label=AccumulateGrad]
	2026824228080 -> 2026824227984
	2026824228080 [label=ReluBackward0]
	2026824227456 -> 2026824228080
	2026824227456 [label=AddmmBackward0]
	2026824227216 -> 2026824227456
	2026681458928 [label="0.8.fc1.bias
 (4)" fillcolor=lightblue]
	2026681458928 -> 2026824227216
	2026824227216 [label=AccumulateGrad]
	2026824226832 -> 2026824227456
	2026824226832 [label=MeanBackward1]
	2026824226160 -> 2026824226832
	2026824226160 [label=ViewBackward0]
	2026824228752 -> 2026824226160
	2026824226688 -> 2026824227456
	2026824226688 [label=TBackward0]
	2026824225872 -> 2026824226688
	2026681459024 [label="0.8.fc1.weight
 (4, 64)" fillcolor=lightblue]
	2026681459024 -> 2026824225872
	2026824225872 [label=AccumulateGrad]
	2026824228416 -> 2026824227984
	2026824228416 [label=TBackward0]
	2026824225632 -> 2026824228416
	2026681458160 [label="0.8.fc2.weight
 (64, 4)" fillcolor=lightblue]
	2026681458160 -> 2026824225632
	2026824225632 [label=AccumulateGrad]
	2026824229136 -> 2026824228896
	2026824229136 [label=SigmoidBackward0]
	2026824228128 -> 2026824229136
	2026824228128 [label=ConvolutionBackward0]
	2026824226016 -> 2026824228128
	2026824226016 [label=SplitWithSizesBackward0]
	2026824226976 -> 2026824226016
	2026824226976 [label=ReluBackward0]
	2026824225920 -> 2026824226976
	2026824225920 [label=CudnnBatchNormBackward0]
	2026824225584 -> 2026824225920
	2026824225584 [label=ConvolutionBackward0]
	2026824225248 -> 2026824225584
	2026824225248 [label=CatBackward0]
	2026824225296 -> 2026824225248
	2026824225296 [label=AdaptiveAvgPool2DBackward0]
	2026824228944 -> 2026824225296
	2026824225152 -> 2026824225248
	2026824225152 [label=PermuteBackward0]
	2026824225104 -> 2026824225152
	2026824225104 [label=AdaptiveAvgPool2DBackward0]
	2026824228944 -> 2026824225104
	2026824225392 -> 2026824225584
	2026681456240 [label="0.9.conv1.weight
 (8, 64, 1, 1)" fillcolor=lightblue]
	2026681456240 -> 2026824225392
	2026824225392 [label=AccumulateGrad]
	2026824225776 -> 2026824225920
	2026681458640 [label="0.9.bn1.weight
 (8)" fillcolor=lightblue]
	2026681458640 -> 2026824225776
	2026824225776 [label=AccumulateGrad]
	2026824226352 -> 2026824225920
	2026681456432 [label="0.9.bn1.bias
 (8)" fillcolor=lightblue]
	2026681456432 -> 2026824226352
	2026824226352 [label=AccumulateGrad]
	2026824227696 -> 2026824228128
	2026681458832 [label="0.9.conv_h.weight
 (64, 8, 1, 1)" fillcolor=lightblue]
	2026681458832 -> 2026824227696
	2026824227696 [label=AccumulateGrad]
	2026824229088 -> 2026824229280
	2026824229088 [label=PermuteBackward0]
	2026824229040 -> 2026824229088
	2026824229040 [label=SigmoidBackward0]
	2026824226736 -> 2026824229040
	2026824226736 [label=ConvolutionBackward0]
	2026824226016 -> 2026824226736
	2026824225440 -> 2026824226736
	2026681458544 [label="0.9.conv_w.weight
 (64, 8, 1, 1)" fillcolor=lightblue]
	2026681458544 -> 2026824225440
	2026824225440 [label=AccumulateGrad]
	2026824229520 -> 2026824229616
	2026840828592 [label="0.10.depthwise.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	2026840828592 -> 2026824229520
	2026824229520 [label=AccumulateGrad]
	2026824229472 -> 2026824229712
	2026840828688 [label="0.10.pointwise.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2026840828688 -> 2026824229472
	2026824229472 [label=AccumulateGrad]
	2026824229760 -> 2026824230000
	2026681458736 [label="0.11.weight
 (128)" fillcolor=lightblue]
	2026681458736 -> 2026824229760
	2026824229760 [label=AccumulateGrad]
	2026824230096 -> 2026824230000
	2026840828784 [label="0.11.bias
 (128)" fillcolor=lightblue]
	2026840828784 -> 2026824230096
	2026824230096 [label=AccumulateGrad]
	2026824230048 -> 2026824230480
	2026840829264 [label="0.13.conv_dil1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2026840829264 -> 2026824230048
	2026824230048 [label=AccumulateGrad]
	2026824230192 -> 2026824230480
	2026840829360 [label="0.13.conv_dil1.bias
 (128)" fillcolor=lightblue]
	2026840829360 -> 2026824230192
	2026824230192 [label=AccumulateGrad]
	2026824230384 -> 2026824230336
	2026824230384 [label=ConvolutionBackward0]
	2026824229856 -> 2026824230384
	2026824229568 -> 2026824230384
	2026840829456 [label="0.13.conv_dil2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2026840829456 -> 2026824229568
	2026824229568 [label=AccumulateGrad]
	2026824229904 -> 2026824230384
	2026840829552 [label="0.13.conv_dil2.bias
 (128)" fillcolor=lightblue]
	2026840829552 -> 2026824229904
	2026824229904 [label=AccumulateGrad]
	2026824230576 -> 2026824230336
	2026824230576 [label=ConvolutionBackward0]
	2026824229856 -> 2026824230576
	2026824228608 -> 2026824230576
	2026840829648 [label="0.13.conv_dil3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2026840829648 -> 2026824228608
	2026824228608 [label=AccumulateGrad]
	2026824229376 -> 2026824230576
	2026840829744 [label="0.13.conv_dil3.bias
 (128)" fillcolor=lightblue]
	2026840829744 -> 2026824229376
	2026824229376 [label=AccumulateGrad]
	2026824230528 -> 2026824231968
	2026840829840 [label="0.13.fuse.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	2026840829840 -> 2026824230528
	2026824230528 [label=AccumulateGrad]
	2026824230960 -> 2026824231968
	2026840829936 [label="0.13.fuse.bias
 (128)" fillcolor=lightblue]
	2026840829936 -> 2026824230960
	2026824230960 [label=AccumulateGrad]
	2026824230672 -> 2026824231056
	2026840830032 [label="0.14.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2026840830032 -> 2026824230672
	2026824230672 [label=AccumulateGrad]
	2026824230912 -> 2026824230816
	2026840829168 [label="0.14.bn1.weight
 (128)" fillcolor=lightblue]
	2026840829168 -> 2026824230912
	2026824230912 [label=AccumulateGrad]
	2026824231440 -> 2026824230816
	2026840830128 [label="0.14.bn1.bias
 (128)" fillcolor=lightblue]
	2026840830128 -> 2026824231440
	2026824231440 [label=AccumulateGrad]
	2026824231536 -> 2026824231488
	2026840830608 [label="0.14.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2026840830608 -> 2026824231536
	2026824231536 [label=AccumulateGrad]
	2026824231632 -> 2026824231680
	2026840830512 [label="0.14.bn2.weight
 (128)" fillcolor=lightblue]
	2026840830512 -> 2026824231632
	2026824231632 [label=AccumulateGrad]
	2026824231872 -> 2026824231680
	2026840830704 [label="0.14.bn2.bias
 (128)" fillcolor=lightblue]
	2026840830704 -> 2026824231872
	2026824231872 [label=AccumulateGrad]
	2026824231968 -> 2026824232112
	2026824232496 -> 2026824232256
	2026824232496 [label=UnsqueezeBackward0]
	2026824232016 -> 2026824232496
	2026824232016 [label=UnsqueezeBackward0]
	2026824231296 -> 2026824232016
	2026824231296 [label=SigmoidBackward0]
	2026824230864 -> 2026824231296
	2026824230864 [label=SqueezeBackward1]
	2026824231200 -> 2026824230864
	2026824231200 [label=ConvolutionBackward0]
	2026824229952 -> 2026824231200
	2026824229952 [label=UnsqueezeBackward0]
	2026824225680 -> 2026824229952
	2026824225680 [label=SqueezeBackward1]
	2026824229232 -> 2026824225680
	2026824229232 [label=SqueezeBackward1]
	2026824225200 -> 2026824229232
	2026824225200 [label=MeanBackward1]
	2026824232304 -> 2026824225200
	2026824230720 -> 2026824231200
	2026840831184 [label="0.15.conv.weight
 (1, 1, 3)" fillcolor=lightblue]
	2026840831184 -> 2026824230720
	2026824230720 [label=AccumulateGrad]
	2026824232448 -> 2026824232640
	2026840831280 [label="0.16.depthwise.weight
 (128, 1, 3, 3)" fillcolor=lightblue]
	2026840831280 -> 2026824232448
	2026824232448 [label=AccumulateGrad]
	2026824232880 -> 2026824232832
	2026840831376 [label="0.16.pointwise.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2026840831376 -> 2026824232880
	2026824232880 [label=AccumulateGrad]
	2026824232736 -> 2026824232928
	2026840831088 [label="0.17.weight
 (256)" fillcolor=lightblue]
	2026840831088 -> 2026824232736
	2026824232736 [label=AccumulateGrad]
	2026824233120 -> 2026824232928
	2026840831472 [label="0.17.bias
 (256)" fillcolor=lightblue]
	2026840831472 -> 2026824233120
	2026824233120 [label=AccumulateGrad]
	2026824233456 -> 2026824233408
	2026840831952 [label="0.19.conv_dil1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2026840831952 -> 2026824233456
	2026824233456 [label=AccumulateGrad]
	2026824233312 -> 2026824233408
	2026840832048 [label="0.19.conv_dil1.bias
 (256)" fillcolor=lightblue]
	2026840832048 -> 2026824233312
	2026824233312 [label=AccumulateGrad]
	2026824233552 -> 2026824233744
	2026824233552 [label=ConvolutionBackward0]
	2026824233264 -> 2026824233552
	2026824232976 -> 2026824233552
	2026840832144 [label="0.19.conv_dil2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2026840832144 -> 2026824232976
	2026824232976 [label=AccumulateGrad]
	2026824233072 -> 2026824233552
	2026840832240 [label="0.19.conv_dil2.bias
 (256)" fillcolor=lightblue]
	2026840832240 -> 2026824233072
	2026824233072 [label=AccumulateGrad]
	2026824233600 -> 2026824233744
	2026824233600 [label=ConvolutionBackward0]
	2026824233264 -> 2026824233600
	2026824232400 -> 2026824233600
	2026840832336 [label="0.19.conv_dil3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2026840832336 -> 2026824232400
	2026824232400 [label=AccumulateGrad]
	2026824232784 -> 2026824233600
	2026840832432 [label="0.19.conv_dil3.bias
 (256)" fillcolor=lightblue]
	2026840832432 -> 2026824232784
	2026824232784 [label=AccumulateGrad]
	2026824233936 -> 2026824235376
	2026840832528 [label="0.19.fuse.weight
 (256, 768, 1, 1)" fillcolor=lightblue]
	2026840832528 -> 2026824233936
	2026824233936 [label=AccumulateGrad]
	2026824233888 -> 2026824235376
	2026840832624 [label="0.19.fuse.bias
 (256)" fillcolor=lightblue]
	2026840832624 -> 2026824233888
	2026824233888 [label=AccumulateGrad]
	2026824233792 -> 2026824234080
	2026840832720 [label="0.20.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2026840832720 -> 2026824233792
	2026824233792 [label=AccumulateGrad]
	2026824234320 -> 2026824234224
	2026840831856 [label="0.20.bn1.weight
 (256)" fillcolor=lightblue]
	2026840831856 -> 2026824234320
	2026824234320 [label=AccumulateGrad]
	2026824234368 -> 2026824234224
	2026840832816 [label="0.20.bn1.bias
 (256)" fillcolor=lightblue]
	2026840832816 -> 2026824234368
	2026824234368 [label=AccumulateGrad]
	2026824234560 -> 2026824234896
	2026840833296 [label="0.20.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2026840833296 -> 2026824234560
	2026824234560 [label=AccumulateGrad]
	2026824234752 -> 2026824234656
	2026840833200 [label="0.20.bn2.weight
 (256)" fillcolor=lightblue]
	2026840833200 -> 2026824234752
	2026824234752 [label=AccumulateGrad]
	2026824235280 -> 2026824234656
	2026840833392 [label="0.20.bn2.bias
 (256)" fillcolor=lightblue]
	2026840833392 -> 2026824235280
	2026824235280 [label=AccumulateGrad]
	2026824235376 -> 2026824235232
	2026824235520 -> 2026824235664
	2026824235520 [label=SigmoidBackward0]
	2026824235040 -> 2026824235520
	2026824235040 [label=ConvolutionBackward0]
	2026824234704 -> 2026824235040
	2026824234704 [label=NativeDropoutBackward0]
	2026824234416 -> 2026824234704
	2026824234416 [label=ReluBackward0]
	2026824233696 -> 2026824234416
	2026824233696 [label=ConvolutionBackward0]
	2026824233216 -> 2026824233696
	2026824233216 [label=MeanBackward1]
	2026824235472 -> 2026824233216
	2026824233360 -> 2026824233696
	2026840833872 [label="0.21.fc1.weight
 (16, 256, 1, 1)" fillcolor=lightblue]
	2026840833872 -> 2026824233360
	2026824233360 [label=AccumulateGrad]
	2026824234848 -> 2026824235040
	2026840833968 [label="0.21.fc2.weight
 (256, 16, 1, 1)" fillcolor=lightblue]
	2026840833968 -> 2026824234848
	2026824234848 [label=AccumulateGrad]
	2026824235856 -> 2026824235616
	2026840473680 [label="0.22.depthwise.weight
 (256, 1, 3, 3)" fillcolor=lightblue]
	2026840473680 -> 2026824235856
	2026824235856 [label=AccumulateGrad]
	2026824235808 -> 2026824236240
	2026840473776 [label="0.22.pointwise.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2026840473776 -> 2026824235808
	2026824235808 [label=AccumulateGrad]
	2026824236144 -> 2026824236336
	2026840833776 [label="0.23.weight
 (512)" fillcolor=lightblue]
	2026840833776 -> 2026824236144
	2026824236144 [label=AccumulateGrad]
	2026824236432 -> 2026824236336
	2026840473872 [label="0.23.bias
 (512)" fillcolor=lightblue]
	2026840473872 -> 2026824236432
	2026824236432 [label=AccumulateGrad]
	2026824236096 -> 2026824236720
	2026840474352 [label="0.25.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2026840474352 -> 2026824236096
	2026824236096 [label=AccumulateGrad]
	2026824236624 -> 2026824236816
	2026840474256 [label="0.25.bn1.weight
 (512)" fillcolor=lightblue]
	2026840474256 -> 2026824236624
	2026824236624 [label=AccumulateGrad]
	2026824221168 -> 2026824236816
	2026840474448 [label="0.25.bn1.bias
 (512)" fillcolor=lightblue]
	2026840474448 -> 2026824221168
	2026824221168 [label=AccumulateGrad]
	2026824221648 -> 2026824221984
	2026840474928 [label="0.25.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2026840474928 -> 2026824221648
	2026824221648 [label=AccumulateGrad]
	2026824222608 -> 2026824222464
	2026840474832 [label="0.25.bn2.weight
 (512)" fillcolor=lightblue]
	2026840474832 -> 2026824222608
	2026824222608 [label=AccumulateGrad]
	2026824223424 -> 2026824222464
	2026840475024 [label="0.25.bn2.bias
 (512)" fillcolor=lightblue]
	2026840475024 -> 2026824223424
	2026824223424 [label=AccumulateGrad]
	2026824223904 -> 2026824224528
	2026824225488 -> 2026824225968
	2026824225488 [label=ViewBackward0]
	2026824223568 -> 2026824225488
	2026824223568 [label=SigmoidBackward0]
	2026824222128 -> 2026824223568
	2026824222128 [label=AddmmBackward0]
	2026824236480 -> 2026824222128
	2026840475696 [label="0.26.channel_att.fc2.bias
 (512)" fillcolor=lightblue]
	2026840475696 -> 2026824236480
	2026824236480 [label=AccumulateGrad]
	2026824221504 -> 2026824222128
	2026824221504 [label=ReluBackward0]
	2026824236960 -> 2026824221504
	2026824236960 [label=AddmmBackward0]
	2026824236192 -> 2026824236960
	2026840475504 [label="0.26.channel_att.fc1.bias
 (32)" fillcolor=lightblue]
	2026840475504 -> 2026824236192
	2026824236192 [label=AccumulateGrad]
	2026824236000 -> 2026824236960
	2026824236000 [label=MeanBackward1]
	2026824235136 -> 2026824236000
	2026824235136 [label=ViewBackward0]
	2026824224864 -> 2026824235136
	2026824235952 -> 2026824236960
	2026824235952 [label=TBackward0]
	2026824234800 -> 2026824235952
	2026840475408 [label="0.26.channel_att.fc1.weight
 (32, 512)" fillcolor=lightblue]
	2026840475408 -> 2026824234800
	2026824234800 [label=AccumulateGrad]
	2026824224384 -> 2026824222128
	2026824224384 [label=TBackward0]
	2026824234176 -> 2026824224384
	2026840475600 [label="0.26.channel_att.fc2.weight
 (512, 32)" fillcolor=lightblue]
	2026840475600 -> 2026824234176
	2026824234176 [label=AccumulateGrad]
	2026824225824 -> 2026824226448
	2026824225824 [label=SigmoidBackward0]
	2026824223088 -> 2026824225824
	2026824223088 [label=ConvolutionBackward0]
	2026824235328 -> 2026824223088
	2026824235328 [label=CatBackward0]
	2026824236288 -> 2026824235328
	2026824236288 [label=MeanBackward1]
	2026824225968 -> 2026824236288
	2026824234032 -> 2026824235328
	2026824234032 [label=MaxBackward0]
	2026824225968 -> 2026824234032
	2026824236672 -> 2026824223088
	2026840475888 [label="0.26.spatial_att.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	2026840475888 -> 2026824236672
	2026824236672 [label=AccumulateGrad]
	2026824228368 -> 2026824228704
	2026824228368 [label=NativeDropoutBackward0]
	2026824226304 -> 2026824228368
	2026824226304 [label=ViewBackward0]
	2026824225008 -> 2026824226304
	2026824225008 [label=AddmmBackward0]
	2026824233840 -> 2026824225008
	2026840477520 [label="1.0.transformer_encoder.layers.0.self_attn.out_proj.bias
 (512)" fillcolor=lightblue]
	2026840477520 -> 2026824233840
	2026824233840 [label=AccumulateGrad]
	2026824225344 -> 2026824225008
	2026824225344 [label=ViewBackward0]
	2026824235760 -> 2026824225344
	2026824235760 [label=PermuteBackward0]
	2026824231392 -> 2026824235760
	2026824231392 [label=ScaledDotProductEfficientAttentionBackward0]
	2026824232160 -> 2026824231392
	2026824232160 [label=ViewBackward0]
	2026824228992 -> 2026824232160
	2026824228992 [label=TransposeBackward0]
	2026824230240 -> 2026824228992
	2026824230240 [label=ViewBackward0]
	2026824224912 -> 2026824230240
	2026824224912 [label=SelectBackward0]
	2026824224576 -> 2026824224912
	2026824224576 [label=CloneBackward0]
	2026824224816 -> 2026824224576
	2026824224816 [label=SqueezeBackward1]
	2026824224720 -> 2026824224816
	2026824224720 [label=TransposeBackward0]
	2026824224432 -> 2026824224720
	2026824224432 [label=UnsqueezeBackward0]
	2026824224096 -> 2026824224432
	2026824224096 [label=ViewBackward0]
	2026824224336 -> 2026824224096
	2026824224336 [label=AddBackward0]
	2026824224240 -> 2026824224336
	2026824224240 [label=UnsafeViewBackward0]
	2026824223808 -> 2026824224240
	2026824223808 [label=MmBackward0]
	2026824223712 -> 2026824223808
	2026824223712 [label=ReshapeAliasBackward0]
	2026824227744 -> 2026824223712
	2026824223616 -> 2026824223808
	2026824223616 [label=TBackward0]
	2026824223856 -> 2026824223616
	2026810831024 [label="1.0.transformer_encoder.layers.0.self_attn.in_proj_weight
 (1536, 512)" fillcolor=lightblue]
	2026810831024 -> 2026824223856
	2026824223856 [label=AccumulateGrad]
	2026824224144 -> 2026824224336
	2026840475312 [label="1.0.transformer_encoder.layers.0.self_attn.in_proj_bias
 (1536)" fillcolor=lightblue]
	2026840475312 -> 2026824224144
	2026824224144 [label=AccumulateGrad]
	2026824231008 -> 2026824231392
	2026824231008 [label=ViewBackward0]
	2026824225056 -> 2026824231008
	2026824225056 [label=TransposeBackward0]
	2026824224672 -> 2026824225056
	2026824224672 [label=ViewBackward0]
	2026824224480 -> 2026824224672
	2026824224480 [label=SelectBackward0]
	2026824224576 -> 2026824224480
	2026824232592 -> 2026824231392
	2026824232592 [label=ViewBackward0]
	2026824224624 -> 2026824232592
	2026824224624 [label=TransposeBackward0]
	2026824224288 -> 2026824224624
	2026824224288 [label=ViewBackward0]
	2026824229424 -> 2026824224288
	2026824229424 [label=SelectBackward0]
	2026824224576 -> 2026824229424
	2026824227264 -> 2026824225008
	2026824227264 [label=TBackward0]
	2026824225536 -> 2026824227264
	2026840477232 [label="1.0.transformer_encoder.layers.0.self_attn.out_proj.weight
 (512, 512)" fillcolor=lightblue]
	2026840477232 -> 2026824225536
	2026824225536 [label=AccumulateGrad]
	2026824229328 -> 2026824229808
	2026840478000 [label="1.0.transformer_encoder.layers.0.norm1.weight
 (512)" fillcolor=lightblue]
	2026840478000 -> 2026824229328
	2026824229328 [label=AccumulateGrad]
	2026824229184 -> 2026824229808
	2026840478096 [label="1.0.transformer_encoder.layers.0.norm1.bias
 (512)" fillcolor=lightblue]
	2026840478096 -> 2026824229184
	2026824229184 [label=AccumulateGrad]
	2026824229664 -> 2026824230768
	2026824229664 [label=NativeDropoutBackward0]
	2026824226784 -> 2026824229664
	2026824226784 [label=ViewBackward0]
	2026824235712 -> 2026824226784
	2026824235712 [label=AddmmBackward0]
	2026824224192 -> 2026824235712
	2026840477904 [label="1.0.transformer_encoder.layers.0.linear2.bias
 (512)" fillcolor=lightblue]
	2026840477904 -> 2026824224192
	2026824224192 [label=AccumulateGrad]
	2026824232352 -> 2026824235712
	2026824232352 [label=ViewBackward0]
	2026824231920 -> 2026824232352
	2026824231920 [label=NativeDropoutBackward0]
	2026824224768 -> 2026824231920
	2026824224768 [label=ReluBackward0]
	2026824223472 -> 2026824224768
	2026824223472 [label=ViewBackward0]
	2026824223760 -> 2026824223472
	2026824223760 [label=AddmmBackward0]
	2026824223136 -> 2026824223760
	2026840477712 [label="1.0.transformer_encoder.layers.0.linear1.bias
 (2048)" fillcolor=lightblue]
	2026840477712 -> 2026824223136
	2026824223136 [label=AccumulateGrad]
	2026824223328 -> 2026824223760
	2026824223328 [label=ViewBackward0]
	2026824229808 -> 2026824223328
	2026824224000 -> 2026824223760
	2026824224000 [label=TBackward0]
	2026824223280 -> 2026824224000
	2026840477616 [label="1.0.transformer_encoder.layers.0.linear1.weight
 (2048, 512)" fillcolor=lightblue]
	2026840477616 -> 2026824223280
	2026824223280 [label=AccumulateGrad]
	2026824228848 -> 2026824235712
	2026824228848 [label=TBackward0]
	2026824223952 -> 2026824228848
	2026840477808 [label="1.0.transformer_encoder.layers.0.linear2.weight
 (512, 2048)" fillcolor=lightblue]
	2026840477808 -> 2026824223952
	2026824223952 [label=AccumulateGrad]
	2026824230624 -> 2026824231248
	2026840478192 [label="1.0.transformer_encoder.layers.0.norm2.weight
 (512)" fillcolor=lightblue]
	2026840478192 -> 2026824230624
	2026824230624 [label=AccumulateGrad]
	2026824233168 -> 2026824231248
	2026840478288 [label="1.0.transformer_encoder.layers.0.norm2.bias
 (512)" fillcolor=lightblue]
	2026840478288 -> 2026824233168
	2026824233168 [label=AccumulateGrad]
	2026824233648 -> 2026824234464
	2026824233648 [label=TBackward0]
	2026824232064 -> 2026824233648
	2026840476848 [label="1.4.weight
 (19, 512)" fillcolor=lightblue]
	2026840476848 -> 2026824232064
	2026824232064 [label=AccumulateGrad]
	2026824234464 -> 2026824237328
}
