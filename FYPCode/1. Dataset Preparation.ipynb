{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2015e7-ecb5-4e6e-97c6-fc4f8cf47a95",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3769c69-aadb-489d-b731-047091b6771a",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f8034c-aa60-46a2-b0df-27bb7e468d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # For directory and file manipulation\n",
    "import shutil # For high-level file operations like copying and removal\n",
    "import pandas as pd # For data manipulation and analysis\n",
    "from tqdm import tqdm # For displaying a progress bar\n",
    "import rasterio # For working with raster data (e.g., satellite imagery)\n",
    "from rasterio.plot import show # For displaying raster data\n",
    "import numpy as np # For numerical operations on arrays\n",
    "import matplotlib.pyplot as plt # For plotting data and images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5825c039-4416-46c7-9a6e-d2ba1c695f7c",
   "metadata": {},
   "source": [
    "### Loading Metadata and Defining Base Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3dda24b-40dc-46e4-8003-f23aac20d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata\n",
    "# metadata_df = pd.read_parquet(r'C:\\Users\\isaac\\datasets\\2020-BigEarthNet-S2\\metadata.parquet')\n",
    "metadata_df = pd.read_parquet(r'C:\\Users\\isaac\\Desktop\\SampleBigEarth\\metadata.parquet')\n",
    "\n",
    "# Base directories\n",
    "source_base_dir = r'D:\\datasets\\2020-BigEarthNet-S2'\n",
    "destination_base_dir = r'D:\\datasets\\2020-BigEarthNet-S2\\BigEarthNetDataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbcfb5f-97e8-49ba-a012-a473631d9433",
   "metadata": {},
   "source": [
    "### Inspecting the Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42f4db4-8089-4be1-9451-3809bcfcbe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame contains 480038 rows.\n",
      "\n",
      "Column Names:\n",
      "Index(['patch_id', 'labels', 'split', 'country', 's1_name', 's2v1_name',\n",
      "       'contains_seasonal_snow', 'contains_cloud_or_shadow'],\n",
      "      dtype='object')\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "                                            patch_id  \\\n",
      "0  S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_2...   \n",
      "1  S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_2...   \n",
      "2  S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_2...   \n",
      "3  S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_2...   \n",
      "4  S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_2...   \n",
      "\n",
      "                                              labels split  country  \\\n",
      "0  [Arable land, Broad-leaved forest, Mixed fores...  test  Austria   \n",
      "1  [Arable land, Broad-leaved forest, Inland wate...  test  Austria   \n",
      "2  [Arable land, Broad-leaved forest, Coniferous ...  test  Austria   \n",
      "3  [Broad-leaved forest, Complex cultivation patt...  test  Austria   \n",
      "4  [Broad-leaved forest, Complex cultivation patt...  test  Austria   \n",
      "\n",
      "                                        s1_name  \\\n",
      "0  S1B_IW_GRDH_1SDV_20170612T165809_33UUP_26_57   \n",
      "1  S1B_IW_GRDH_1SDV_20170612T165809_33UUP_27_55   \n",
      "2  S1B_IW_GRDH_1SDV_20170612T165809_33UUP_27_56   \n",
      "3  S1B_IW_GRDH_1SDV_20170612T165809_33UUP_27_57   \n",
      "4  S1B_IW_GRDH_1SDV_20170612T165809_33UUP_27_58   \n",
      "\n",
      "                          s2v1_name  contains_seasonal_snow  \\\n",
      "0  S2A_MSIL2A_20170613T101031_26_57                   False   \n",
      "1  S2A_MSIL2A_20170613T101031_27_55                   False   \n",
      "2  S2A_MSIL2A_20170613T101031_27_56                   False   \n",
      "3  S2A_MSIL2A_20170613T101031_27_57                   False   \n",
      "4  S2A_MSIL2A_20170613T101031_27_58                   False   \n",
      "\n",
      "   contains_cloud_or_shadow  \n",
      "0                     False  \n",
      "1                     False  \n",
      "2                     False  \n",
      "3                     False  \n",
      "4                     False  \n"
     ]
    }
   ],
   "source": [
    "num_rows = metadata_df.shape[0]\n",
    "print(f\"The DataFrame contains {num_rows} rows.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Display the column names\n",
    "print(\"Column Names:\")\n",
    "print(metadata_df.columns)\n",
    "\n",
    "print()\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(metadata_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0071c84-e3ff-412b-ae65-7133069471de",
   "metadata": {},
   "source": [
    "### Extracting Unique Labels and Creating Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa16bf4d-a9c9-4b99-b72d-73bdc1793b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels:\n",
      "1. Arable land\n",
      "2. Broad-leaved forest\n",
      "3. Mixed forest\n",
      "4. Pastures\n",
      "5. Inland waters\n",
      "6. Coniferous forest\n",
      "7. Complex cultivation patterns\n",
      "8. Land principally occupied by agriculture, with significant areas of natural vegetation\n",
      "9. Urban fabric\n",
      "10. Industrial or commercial units\n",
      "11. Inland wetlands\n",
      "12. Transitional woodland, shrub\n",
      "13. Natural grassland and sparsely vegetated areas\n",
      "14. Moors, heathland and sclerophyllous vegetation\n",
      "15. Marine waters\n",
      "16. Coastal wetlands\n",
      "17. Permanent crops\n",
      "18. Beaches, dunes, sands\n",
      "19. Agro-forestry areas\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating directories: 100%|██████████| 19/19 [00:00<00:00, 1807.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All directories have been created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract unique labels from the metadata\n",
    "unique_labels = metadata_df['labels'].explode().unique()\n",
    "\n",
    "# Print the unique labels in a numbered table format\n",
    "print(\"Unique Labels:\")\n",
    "for i, label in enumerate(unique_labels, start=1):\n",
    "    print(f\"{i}. {label}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Create directories for each label with progress bar\n",
    "for label in tqdm(unique_labels, desc=\"Creating directories\"):\n",
    "    label_dir = os.path.join(destination_base_dir, label)\n",
    "    \n",
    "    # Create the directory if it does not exist\n",
    "    if not os.path.exists(label_dir):\n",
    "        os.makedirs(label_dir)\n",
    "\n",
    "print(\"All directories have been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17303c09-e0af-4faa-b652-ec2a78893840",
   "metadata": {},
   "source": [
    "### Converting Labels to Binary Vectors and Saving MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aabb40c-bb7c-4a07-8f9d-abdb37f9aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique labels from the metadata and sort\n",
    "unique_labels = metadata_df['labels'].explode().unique()\n",
    "all_labels = sorted(unique_labels)  # Ensure all_labels is sorted\n",
    "\n",
    "# Create a dictionary to map label names to indices\n",
    "label_to_index = {label: i for i, label in enumerate(all_labels)}\n",
    "\n",
    "# Function to convert label list to binary vector\n",
    "def labels_to_vector(label_list):\n",
    "    vector = [0] * len(all_labels)\n",
    "    for label in label_list:\n",
    "        index = label_to_index[label]\n",
    "        vector[index] = 1\n",
    "    return vector\n",
    "\n",
    "# Apply the conversion to the 'labels' column\n",
    "metadata_df['label_vector'] = metadata_df['labels'].apply(labels_to_vector)\n",
    "\n",
    "# Save the updated DataFrame with the label_vector to a Parquet file\n",
    "metadata_df.to_parquet('updated_metadata_with_vectors.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d5d0c4-660c-4fa0-8434-e60db27a9060",
   "metadata": {},
   "source": [
    "### Loading and Inspecting Updated Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ad7839-719b-4404-a370-597046393d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame contains 480038 rows.\n",
      "\n",
      "Column Names:\n",
      "Index(['patch_id', 'labels', 'split', 'country', 's1_name', 's2v1_name',\n",
      "       'contains_seasonal_snow', 'contains_cloud_or_shadow', 'label_vector'],\n",
      "      dtype='object')\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "                                            patch_id  \\\n",
      "0  S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_2...   \n",
      "1  S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_2...   \n",
      "2  S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_2...   \n",
      "3  S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_2...   \n",
      "4  S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_2...   \n",
      "\n",
      "                                              labels split  country  \\\n",
      "0  [Arable land, Broad-leaved forest, Mixed fores...  test  Austria   \n",
      "1  [Arable land, Broad-leaved forest, Inland wate...  test  Austria   \n",
      "2  [Arable land, Broad-leaved forest, Coniferous ...  test  Austria   \n",
      "3  [Broad-leaved forest, Complex cultivation patt...  test  Austria   \n",
      "4  [Broad-leaved forest, Complex cultivation patt...  test  Austria   \n",
      "\n",
      "                                        s1_name  \\\n",
      "0  S1B_IW_GRDH_1SDV_20170612T165809_33UUP_26_57   \n",
      "1  S1B_IW_GRDH_1SDV_20170612T165809_33UUP_27_55   \n",
      "2  S1B_IW_GRDH_1SDV_20170612T165809_33UUP_27_56   \n",
      "3  S1B_IW_GRDH_1SDV_20170612T165809_33UUP_27_57   \n",
      "4  S1B_IW_GRDH_1SDV_20170612T165809_33UUP_27_58   \n",
      "\n",
      "                          s2v1_name  contains_seasonal_snow  \\\n",
      "0  S2A_MSIL2A_20170613T101031_26_57                   False   \n",
      "1  S2A_MSIL2A_20170613T101031_27_55                   False   \n",
      "2  S2A_MSIL2A_20170613T101031_27_56                   False   \n",
      "3  S2A_MSIL2A_20170613T101031_27_57                   False   \n",
      "4  S2A_MSIL2A_20170613T101031_27_58                   False   \n",
      "\n",
      "   contains_cloud_or_shadow                                       label_vector  \n",
      "0                     False  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
      "1                     False  [0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...  \n",
      "2                     False  [0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, ...  \n",
      "3                     False  [0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, ...  \n",
      "4                     False  [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "metadata_df = pd.read_parquet(r'C:\\Users\\isaac\\FYPCode\\updated_metadata_with_vectors.parquet')\n",
    "\n",
    "num_rows = metadata_df.shape[0]\n",
    "print(f\"The DataFrame contains {num_rows} rows.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Display the column names\n",
    "print(\"Column Names:\")\n",
    "print(metadata_df.columns)\n",
    "\n",
    "print()\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(metadata_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "137f283f-04f1-4def-a96c-0752afbe1d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 422728/422728 [10:04:23<00:00, 11.66it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Function to process each image\n",
    "def process_image(image_folder_path, labels):\n",
    "    try:\n",
    "        # Process each label\n",
    "        for label in labels:\n",
    "            dest_dir = os.path.join(destination_base_dir, label)\n",
    "\n",
    "            # Create the directory if it does not exist\n",
    "            if not os.path.exists(dest_dir):\n",
    "                os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "            # Construct the destination path for each label\n",
    "            dest_folder_path = os.path.join(dest_dir, os.path.basename(image_folder_path))\n",
    "\n",
    "            # Check if the destination folder already exists\n",
    "            if not os.path.exists(dest_folder_path):\n",
    "                # Copy the folder\n",
    "                shutil.copytree(image_folder_path, dest_folder_path)\n",
    "\n",
    "        # Remove the source directory after copying all the labels\n",
    "        shutil.rmtree(image_folder_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing folder {image_folder_path}: {e}\")\n",
    "\n",
    "# Count total images to process, excluding 'BigEarthNetDataset'\n",
    "total_images = 0\n",
    "for date_folder in os.listdir(source_base_dir):\n",
    "    if date_folder == 'BigEarthNetDataset':\n",
    "        continue  # Skip this folder\n",
    "    date_folder_path = os.path.join(source_base_dir, date_folder)\n",
    "    if os.path.isdir(date_folder_path):\n",
    "        image_folders = [f for f in os.listdir(date_folder_path) if os.path.isdir(os.path.join(date_folder_path, f))]\n",
    "        num_images = len(image_folders)\n",
    "        total_images += num_images\n",
    "\n",
    "# Create a progress bar for processing images\n",
    "with tqdm(total=total_images, desc=\"Processing Images\") as pbar:\n",
    "    # Iterate through each date folder\n",
    "    for date_folder in os.listdir(source_base_dir):\n",
    "        if date_folder == 'BigEarthNetDataset':\n",
    "            continue  # Skip this folder\n",
    "        date_folder_path = os.path.join(source_base_dir, date_folder)\n",
    "        \n",
    "        if os.path.isdir(date_folder_path):\n",
    "            # Iterate through each image folder within the date folder\n",
    "            for image_folder in os.listdir(date_folder_path):\n",
    "                image_folder_path = os.path.join(date_folder_path, image_folder)\n",
    "                \n",
    "                if os.path.isdir(image_folder_path):\n",
    "                    # Find the corresponding metadata row\n",
    "                    patch_id = image_folder\n",
    "                    row = metadata_df[metadata_df['patch_id'] == patch_id]\n",
    "                    \n",
    "                    if not row.empty:\n",
    "                        labels = row.iloc[0]['labels']\n",
    "                        process_image(image_folder_path, labels)\n",
    "                    \n",
    "                    # Update progress bar after processing each image\n",
    "                    pbar.update(1)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f9797c-1b2e-4020-a9d2-01b8ec736a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders: 100%|██████████| 19/19 [05:44<00:00, 18.14s/folder]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Name                                                            Subfolder Count\n",
      "-------------------------------------------------------------------------------------\n",
      "Arable land                                                                     188025\n",
      "Mixed forest                                                                    165780\n",
      "Coniferous forest                                                               154941\n",
      "Transitional woodland, shrub                                                    141150\n",
      "Broad-leaved forest                                                             135928\n",
      "Land principally occupied by agriculture, with significant areas of natural vegetation          122709\n",
      "Complex cultivation patterns                                                     99598\n",
      "Pastures                                                                         95605\n",
      "Urban fabric                                                                     63758\n",
      "Inland waters                                                                    63212\n",
      "Marine waters                                                                    61832\n",
      "Agro-forestry areas                                                              33181\n",
      "Permanent crops                                                                  29588\n",
      "Inland wetlands                                                                  20919\n",
      "Moors, heathland and sclerophyllous vegetation                                   13894\n",
      "Natural grassland and sparsely vegetated areas                                   11882\n",
      "Industrial or commercial units                                                   11142\n",
      "Coastal wetlands                                                                  1397\n",
      "Beaches, dunes, sands                                                             1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to hold the count of subfolders in each folder\n",
    "folder_subfolder_counts = {}\n",
    "\n",
    "# Iterate through each item in the base directory with a progress bar\n",
    "for folder in tqdm(os.listdir(destination_base_dir), desc=\"Processing Folders\", unit=\"folder\"):\n",
    "    folder_path = os.path.join(destination_base_dir, folder)\n",
    "    \n",
    "    # Check if the path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # List all subdirectories within the current folder\n",
    "        subfolders = [subfolder for subfolder in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, subfolder))]\n",
    "        \n",
    "        # Count the number of subfolders\n",
    "        subfolder_count = len(subfolders)\n",
    "        \n",
    "        # Store the count in the dictionary\n",
    "        folder_subfolder_counts[folder] = subfolder_count\n",
    "\n",
    "# Sort the dictionary by subfolder count in descending order\n",
    "sorted_folder_counts = sorted(folder_subfolder_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print header\n",
    "print(f\"{'Folder Name':<70} {'Subfolder Count':>15}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "# Print the sorted number of subfolders in each folder in a formatted manner\n",
    "for folder, count in sorted_folder_counts:\n",
    "    print(f\"{folder:<70} {count:>15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85b21a-97d5-4f03-b7e6-f6acc1e92306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the classes further - perform data augmentation and upscaling of lower numbered classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66535c84-9e63-49c9-9bff-82efbac899bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder 'dataset_splits' and within this folder create 'test', 'valid' and 'train'. Each of these folders should have the 19 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ec404-42ef-4e80-895f-7d5a0e8f32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the data to the valid (15%), test(15%) and train(70%) folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d48c6a5-5687-4258-89b3-7232d8de5551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
