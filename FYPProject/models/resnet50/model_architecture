digraph {
	graph [size="152.25,152.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2811112710000 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2812838646240 [label=SigmoidBackward0]
	2812838654304 -> 2812838646240
	2812838654304 [label=AddmmBackward0]
	2812838645760 -> 2812838654304
	2811112291696 [label="model.fc.bias
 (19)" fillcolor=lightblue]
	2811112291696 -> 2812838645760
	2812838645760 [label=AccumulateGrad]
	2812838654256 -> 2812838654304
	2812838654256 [label=ViewBackward0]
	2812838645616 -> 2812838654256
	2812838645616 [label=MeanBackward1]
	2812838645328 -> 2812838645616
	2812838645328 [label=ReluBackward0]
	2812838645184 -> 2812838645328
	2812838645184 [label=AddBackward0]
	2812838653056 -> 2812838645184
	2812838653056 [label=CudnnBatchNormBackward0]
	2812838652960 -> 2812838653056
	2812838652960 [label=ConvolutionBackward0]
	2812838652816 -> 2812838652960
	2812838652816 [label=ReluBackward0]
	2812838644560 -> 2812838652816
	2812838644560 [label=CudnnBatchNormBackward0]
	2812838652624 -> 2812838644560
	2812838652624 [label=ConvolutionBackward0]
	2812838644320 -> 2812838652624
	2812838644320 [label=ReluBackward0]
	2812838652336 -> 2812838644320
	2812838652336 [label=CudnnBatchNormBackward0]
	2812838652288 -> 2812838652336
	2812838652288 [label=ConvolutionBackward0]
	2812838645136 -> 2812838652288
	2812838645136 [label=ReluBackward0]
	2812838652000 -> 2812838645136
	2812838652000 [label=AddBackward0]
	2812838651568 -> 2812838652000
	2812838651568 [label=CudnnBatchNormBackward0]
	2812838651424 -> 2812838651568
	2812838651424 [label=ConvolutionBackward0]
	2812838650320 -> 2812838651424
	2812838650320 [label=ReluBackward0]
	2812838650176 -> 2812838650320
	2812838650176 [label=CudnnBatchNormBackward0]
	2812838650080 -> 2812838650176
	2812838650080 [label=ConvolutionBackward0]
	2812838651232 -> 2812838650080
	2812838651232 [label=ReluBackward0]
	2812838653776 -> 2812838651232
	2812838653776 [label=CudnnBatchNormBackward0]
	2812838656176 -> 2812838653776
	2812838656176 [label=ConvolutionBackward0]
	2812838651952 -> 2812838656176
	2812838651952 [label=ReluBackward0]
	2812838657040 -> 2812838651952
	2812838657040 [label=AddBackward0]
	2812838649936 -> 2812838657040
	2812838649936 [label=CudnnBatchNormBackward0]
	2812838656656 -> 2812838649936
	2812838656656 [label=ConvolutionBackward0]
	2812838648544 -> 2812838656656
	2812838648544 [label=ReluBackward0]
	2812838644848 -> 2812838648544
	2812838644848 [label=CudnnBatchNormBackward0]
	2812838644464 -> 2812838644848
	2812838644464 [label=ConvolutionBackward0]
	2812838645280 -> 2812838644464
	2812838645280 [label=ReluBackward0]
	2812838645664 -> 2812838645280
	2812838645664 [label=CudnnBatchNormBackward0]
	2812838647056 -> 2812838645664
	2812838647056 [label=ConvolutionBackward0]
	2812838647008 -> 2812838647056
	2812838647008 [label=ReluBackward0]
	2812838648112 -> 2812838647008
	2812838648112 [label=AddBackward0]
	2812838647680 -> 2812838648112
	2812838647680 [label=CudnnBatchNormBackward0]
	2812838646624 -> 2812838647680
	2812838646624 [label=ConvolutionBackward0]
	2812838646672 -> 2812838646624
	2812838646672 [label=ReluBackward0]
	2811112800512 -> 2812838646672
	2811112800512 [label=CudnnBatchNormBackward0]
	2811112800608 -> 2811112800512
	2811112800608 [label=ConvolutionBackward0]
	2811112800800 -> 2811112800608
	2811112800800 [label=ReluBackward0]
	2811112800944 -> 2811112800800
	2811112800944 [label=CudnnBatchNormBackward0]
	2811112801040 -> 2811112800944
	2811112801040 [label=ConvolutionBackward0]
	2812838648160 -> 2811112801040
	2812838648160 [label=ReluBackward0]
	2811112801328 -> 2812838648160
	2811112801328 [label=AddBackward0]
	2811112801424 -> 2811112801328
	2811112801424 [label=CudnnBatchNormBackward0]
	2811112801568 -> 2811112801424
	2811112801568 [label=ConvolutionBackward0]
	2811112801760 -> 2811112801568
	2811112801760 [label=ReluBackward0]
	2811112801904 -> 2811112801760
	2811112801904 [label=CudnnBatchNormBackward0]
	2811112801952 -> 2811112801904
	2811112801952 [label=ConvolutionBackward0]
	2811112802240 -> 2811112801952
	2811112802240 [label=ReluBackward0]
	2811112802384 -> 2811112802240
	2811112802384 [label=CudnnBatchNormBackward0]
	2811112802432 -> 2811112802384
	2811112802432 [label=ConvolutionBackward0]
	2811112801376 -> 2811112802432
	2811112801376 [label=ReluBackward0]
	2811112802816 -> 2811112801376
	2811112802816 [label=AddBackward0]
	2811112802864 -> 2811112802816
	2811112802864 [label=CudnnBatchNormBackward0]
	2811112803104 -> 2811112802864
	2811112803104 [label=ConvolutionBackward0]
	2811112803296 -> 2811112803104
	2811112803296 [label=ReluBackward0]
	2811112803440 -> 2811112803296
	2811112803440 [label=CudnnBatchNormBackward0]
	2811112803488 -> 2811112803440
	2811112803488 [label=ConvolutionBackward0]
	2811112803776 -> 2811112803488
	2811112803776 [label=ReluBackward0]
	2811112803920 -> 2811112803776
	2811112803920 [label=CudnnBatchNormBackward0]
	2811112803968 -> 2811112803920
	2811112803968 [label=ConvolutionBackward0]
	2811112802624 -> 2811112803968
	2811112802624 [label=ReluBackward0]
	2811112804352 -> 2811112802624
	2811112804352 [label=AddBackward0]
	2811112804400 -> 2811112804352
	2811112804400 [label=CudnnBatchNormBackward0]
	2811112804640 -> 2811112804400
	2811112804640 [label=ConvolutionBackward0]
	2811112804832 -> 2811112804640
	2811112804832 [label=ReluBackward0]
	2811112804976 -> 2811112804832
	2811112804976 [label=CudnnBatchNormBackward0]
	2811112805024 -> 2811112804976
	2811112805024 [label=ConvolutionBackward0]
	2811112805312 -> 2811112805024
	2811112805312 [label=ReluBackward0]
	2811112805456 -> 2811112805312
	2811112805456 [label=CudnnBatchNormBackward0]
	2811112805504 -> 2811112805456
	2811112805504 [label=ConvolutionBackward0]
	2811112804160 -> 2811112805504
	2811112804160 [label=ReluBackward0]
	2811112805888 -> 2811112804160
	2811112805888 [label=AddBackward0]
	2811112805936 -> 2811112805888
	2811112805936 [label=CudnnBatchNormBackward0]
	2811112806176 -> 2811112805936
	2811112806176 [label=ConvolutionBackward0]
	2811112806368 -> 2811112806176
	2811112806368 [label=ReluBackward0]
	2811112806512 -> 2811112806368
	2811112806512 [label=CudnnBatchNormBackward0]
	2811112806560 -> 2811112806512
	2811112806560 [label=ConvolutionBackward0]
	2811112806848 -> 2811112806560
	2811112806848 [label=ReluBackward0]
	2811112806992 -> 2811112806848
	2811112806992 [label=CudnnBatchNormBackward0]
	2811112807040 -> 2811112806992
	2811112807040 [label=ConvolutionBackward0]
	2811112805696 -> 2811112807040
	2811112805696 [label=ReluBackward0]
	2811112807424 -> 2811112805696
	2811112807424 [label=AddBackward0]
	2811112807472 -> 2811112807424
	2811112807472 [label=CudnnBatchNormBackward0]
	2811112807712 -> 2811112807472
	2811112807712 [label=ConvolutionBackward0]
	2811112807904 -> 2811112807712
	2811112807904 [label=ReluBackward0]
	2811112808048 -> 2811112807904
	2811112808048 [label=CudnnBatchNormBackward0]
	2811112808096 -> 2811112808048
	2811112808096 [label=ConvolutionBackward0]
	2811112808384 -> 2811112808096
	2811112808384 [label=ReluBackward0]
	2811112808528 -> 2811112808384
	2811112808528 [label=CudnnBatchNormBackward0]
	2811112808576 -> 2811112808528
	2811112808576 [label=ConvolutionBackward0]
	2811112808864 -> 2811112808576
	2811112808864 [label=ReluBackward0]
	2811112809008 -> 2811112808864
	2811112809008 [label=AddBackward0]
	2811112809056 -> 2811112809008
	2811112809056 [label=CudnnBatchNormBackward0]
	2811112809296 -> 2811112809056
	2811112809296 [label=ConvolutionBackward0]
	2811112809488 -> 2811112809296
	2811112809488 [label=ReluBackward0]
	2811112809632 -> 2811112809488
	2811112809632 [label=CudnnBatchNormBackward0]
	2811112809680 -> 2811112809632
	2811112809680 [label=ConvolutionBackward0]
	2811112809968 -> 2811112809680
	2811112809968 [label=ReluBackward0]
	2811112810112 -> 2811112809968
	2811112810112 [label=CudnnBatchNormBackward0]
	2811112810160 -> 2811112810112
	2811112810160 [label=ConvolutionBackward0]
	2811112808912 -> 2811112810160
	2811112808912 [label=ReluBackward0]
	2811112810544 -> 2811112808912
	2811112810544 [label=AddBackward0]
	2811112810592 -> 2811112810544
	2811112810592 [label=CudnnBatchNormBackward0]
	2811112810832 -> 2811112810592
	2811112810832 [label=ConvolutionBackward0]
	2811112811024 -> 2811112810832
	2811112811024 [label=ReluBackward0]
	2811112811168 -> 2811112811024
	2811112811168 [label=CudnnBatchNormBackward0]
	2811112811216 -> 2811112811168
	2811112811216 [label=ConvolutionBackward0]
	2811112811504 -> 2811112811216
	2811112811504 [label=ReluBackward0]
	2811112811648 -> 2811112811504
	2811112811648 [label=CudnnBatchNormBackward0]
	2811112811696 -> 2811112811648
	2811112811696 [label=ConvolutionBackward0]
	2811112810352 -> 2811112811696
	2811112810352 [label=ReluBackward0]
	2811112812080 -> 2811112810352
	2811112812080 [label=AddBackward0]
	2811112812128 -> 2811112812080
	2811112812128 [label=CudnnBatchNormBackward0]
	2811112812368 -> 2811112812128
	2811112812368 [label=ConvolutionBackward0]
	2811112812560 -> 2811112812368
	2811112812560 [label=ReluBackward0]
	2811112812704 -> 2811112812560
	2811112812704 [label=CudnnBatchNormBackward0]
	2811112812752 -> 2811112812704
	2811112812752 [label=ConvolutionBackward0]
	2811112813040 -> 2811112812752
	2811112813040 [label=ReluBackward0]
	2811112813184 -> 2811112813040
	2811112813184 [label=CudnnBatchNormBackward0]
	2811112813232 -> 2811112813184
	2811112813232 [label=ConvolutionBackward0]
	2811112811888 -> 2811112813232
	2811112811888 [label=ReluBackward0]
	2811112813616 -> 2811112811888
	2811112813616 [label=AddBackward0]
	2811112813664 -> 2811112813616
	2811112813664 [label=CudnnBatchNormBackward0]
	2811112813904 -> 2811112813664
	2811112813904 [label=ConvolutionBackward0]
	2811112814096 -> 2811112813904
	2811112814096 [label=ReluBackward0]
	2811112814240 -> 2811112814096
	2811112814240 [label=CudnnBatchNormBackward0]
	2811112814288 -> 2811112814240
	2811112814288 [label=ConvolutionBackward0]
	2811112814576 -> 2811112814288
	2811112814576 [label=ReluBackward0]
	2811112814720 -> 2811112814576
	2811112814720 [label=CudnnBatchNormBackward0]
	2811112814768 -> 2811112814720
	2811112814768 [label=ConvolutionBackward0]
	2811112815056 -> 2811112814768
	2811112815056 [label=ReluBackward0]
	2811112815200 -> 2811112815056
	2811112815200 [label=AddBackward0]
	2811112815248 -> 2811112815200
	2811112815248 [label=CudnnBatchNormBackward0]
	2811112815488 -> 2811112815248
	2811112815488 [label=ConvolutionBackward0]
	2811112815680 -> 2811112815488
	2811112815680 [label=ReluBackward0]
	2811112815824 -> 2811112815680
	2811112815824 [label=CudnnBatchNormBackward0]
	2811112815872 -> 2811112815824
	2811112815872 [label=ConvolutionBackward0]
	2811112816160 -> 2811112815872
	2811112816160 [label=ReluBackward0]
	2811112816304 -> 2811112816160
	2811112816304 [label=CudnnBatchNormBackward0]
	2811112816352 -> 2811112816304
	2811112816352 [label=ConvolutionBackward0]
	2811112815104 -> 2811112816352
	2811112815104 [label=ReluBackward0]
	2811112751264 -> 2811112815104
	2811112751264 [label=AddBackward0]
	2811112751312 -> 2811112751264
	2811112751312 [label=CudnnBatchNormBackward0]
	2811112751552 -> 2811112751312
	2811112751552 [label=ConvolutionBackward0]
	2811112751744 -> 2811112751552
	2811112751744 [label=ReluBackward0]
	2811112751888 -> 2811112751744
	2811112751888 [label=CudnnBatchNormBackward0]
	2811112751936 -> 2811112751888
	2811112751936 [label=ConvolutionBackward0]
	2811112752224 -> 2811112751936
	2811112752224 [label=ReluBackward0]
	2811112752368 -> 2811112752224
	2811112752368 [label=CudnnBatchNormBackward0]
	2811112752416 -> 2811112752368
	2811112752416 [label=ConvolutionBackward0]
	2811112751168 -> 2811112752416
	2811112751168 [label=ReluBackward0]
	2811112752800 -> 2811112751168
	2811112752800 [label=AddBackward0]
	2811112752848 -> 2811112752800
	2811112752848 [label=CudnnBatchNormBackward0]
	2811112753088 -> 2811112752848
	2811112753088 [label=ConvolutionBackward0]
	2811112753280 -> 2811112753088
	2811112753280 [label=ReluBackward0]
	2811112753424 -> 2811112753280
	2811112753424 [label=CudnnBatchNormBackward0]
	2811112753472 -> 2811112753424
	2811112753472 [label=ConvolutionBackward0]
	2811112753760 -> 2811112753472
	2811112753760 [label=ReluBackward0]
	2811112753904 -> 2811112753760
	2811112753904 [label=CudnnBatchNormBackward0]
	2811112753952 -> 2811112753904
	2811112753952 [label=ConvolutionBackward0]
	2811112754240 -> 2811112753952
	2811112754240 [label=MaxPool2DWithIndicesBackward0]
	2811112754384 -> 2811112754240
	2811112754384 [label=ReluBackward0]
	2811112754432 -> 2811112754384
	2811112754432 [label=CudnnBatchNormBackward0]
	2811112754576 -> 2811112754432
	2811112754576 [label=ConvolutionBackward0]
	2811112754864 -> 2811112754576
	2812875540528 [label="model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2812875540528 -> 2811112754864
	2811112754864 [label=AccumulateGrad]
	2811112754528 -> 2811112754432
	2812875540624 [label="model.bn1.weight
 (64)" fillcolor=lightblue]
	2812875540624 -> 2811112754528
	2811112754528 [label=AccumulateGrad]
	2811112754672 -> 2811112754432
	2812875540720 [label="model.bn1.bias
 (64)" fillcolor=lightblue]
	2812875540720 -> 2811112754672
	2811112754672 [label=AccumulateGrad]
	2811112754192 -> 2811112753952
	2812875541680 [label="model.layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2812875541680 -> 2811112754192
	2811112754192 [label=AccumulateGrad]
	2811112753808 -> 2811112753904
	2812875541776 [label="model.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2812875541776 -> 2811112753808
	2811112753808 [label=AccumulateGrad]
	2811112754048 -> 2811112753904
	2812875541872 [label="model.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2812875541872 -> 2811112754048
	2811112754048 [label=AccumulateGrad]
	2811112753712 -> 2811112753472
	2812875542256 [label="model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2812875542256 -> 2811112753712
	2811112753712 [label=AccumulateGrad]
	2811112753328 -> 2811112753424
	2812875542352 [label="model.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2812875542352 -> 2811112753328
	2811112753328 [label=AccumulateGrad]
	2811112753568 -> 2811112753424
	2812875542448 [label="model.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2812875542448 -> 2811112753568
	2811112753568 [label=AccumulateGrad]
	2811112753232 -> 2811112753088
	2812875542832 [label="model.layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2812875542832 -> 2811112753232
	2811112753232 [label=AccumulateGrad]
	2811112753040 -> 2811112752848
	2812875542928 [label="model.layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	2812875542928 -> 2811112753040
	2811112753040 [label=AccumulateGrad]
	2811112752992 -> 2811112752848
	2812875543024 [label="model.layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	2812875543024 -> 2811112752992
	2811112752992 [label=AccumulateGrad]
	2811112752608 -> 2811112752800
	2811112752608 [label=CudnnBatchNormBackward0]
	2811112753664 -> 2811112752608
	2811112753664 [label=ConvolutionBackward0]
	2811112754240 -> 2811112753664
	2811112754096 -> 2811112753664
	2812875541104 [label="model.layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2812875541104 -> 2811112754096
	2811112754096 [label=AccumulateGrad]
	2811112753184 -> 2811112752608
	2812875541200 [label="model.layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2812875541200 -> 2811112753184
	2811112753184 [label=AccumulateGrad]
	2811112753136 -> 2811112752608
	2812875541296 [label="model.layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2812875541296 -> 2811112753136
	2811112753136 [label=AccumulateGrad]
	2811112752704 -> 2811112752416
	2812875543408 [label="model.layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2812875543408 -> 2811112752704
	2811112752704 [label=AccumulateGrad]
	2811112752272 -> 2811112752368
	2812875543504 [label="model.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2812875543504 -> 2811112752272
	2811112752272 [label=AccumulateGrad]
	2811112752512 -> 2811112752368
	2812875543600 [label="model.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2812875543600 -> 2811112752512
	2811112752512 [label=AccumulateGrad]
	2811112752176 -> 2811112751936
	2812875543984 [label="model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2812875543984 -> 2811112752176
	2811112752176 [label=AccumulateGrad]
	2811112751792 -> 2811112751888
	2812875475280 [label="model.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2812875475280 -> 2811112751792
	2811112751792 [label=AccumulateGrad]
	2811112752032 -> 2811112751888
	2812875475568 [label="model.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2812875475568 -> 2811112752032
	2811112752032 [label=AccumulateGrad]
	2811112751696 -> 2811112751552
	2812875476336 [label="model.layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2812875476336 -> 2811112751696
	2811112751696 [label=AccumulateGrad]
	2811112751504 -> 2811112751312
	2812875476432 [label="model.layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	2812875476432 -> 2811112751504
	2811112751504 [label=AccumulateGrad]
	2811112751456 -> 2811112751312
	2812875476720 [label="model.layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	2812875476720 -> 2811112751456
	2811112751456 [label=AccumulateGrad]
	2811112751168 -> 2811112751264
	2811112816592 -> 2811112816352
	2812875544272 [label="model.layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2812875544272 -> 2811112816592
	2811112816592 [label=AccumulateGrad]
	2811112816208 -> 2811112816304
	2812875544368 [label="model.layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	2812875544368 -> 2811112816208
	2811112816208 [label=AccumulateGrad]
	2811112816448 -> 2811112816304
	2812875544464 [label="model.layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	2812875544464 -> 2811112816448
	2811112816448 [label=AccumulateGrad]
	2811112816112 -> 2811112815872
	2812875544848 [label="model.layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2812875544848 -> 2811112816112
	2811112816112 [label=AccumulateGrad]
	2811112815728 -> 2811112815824
	2812875544944 [label="model.layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	2812875544944 -> 2811112815728
	2811112815728 [label=AccumulateGrad]
	2811112815968 -> 2811112815824
	2812875545040 [label="model.layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	2812875545040 -> 2811112815968
	2811112815968 [label=AccumulateGrad]
	2811112815632 -> 2811112815488
	2812875545424 [label="model.layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2812875545424 -> 2811112815632
	2811112815632 [label=AccumulateGrad]
	2811112815440 -> 2811112815248
	2812875545520 [label="model.layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	2812875545520 -> 2811112815440
	2811112815440 [label=AccumulateGrad]
	2811112815392 -> 2811112815248
	2812875545616 [label="model.layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	2812875545616 -> 2811112815392
	2811112815392 [label=AccumulateGrad]
	2811112815104 -> 2811112815200
	2811112815008 -> 2811112814768
	2812875546576 [label="model.layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2812875546576 -> 2811112815008
	2811112815008 [label=AccumulateGrad]
	2811112814624 -> 2811112814720
	2812875546672 [label="model.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2812875546672 -> 2811112814624
	2811112814624 [label=AccumulateGrad]
	2811112814864 -> 2811112814720
	2812875546768 [label="model.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2812875546768 -> 2811112814864
	2811112814864 [label=AccumulateGrad]
	2811112814528 -> 2811112814288
	2812875547152 [label="model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2812875547152 -> 2811112814528
	2811112814528 [label=AccumulateGrad]
	2811112814144 -> 2811112814240
	2812875547248 [label="model.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2812875547248 -> 2811112814144
	2811112814144 [label=AccumulateGrad]
	2811112814384 -> 2811112814240
	2812875547344 [label="model.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2812875547344 -> 2811112814384
	2811112814384 [label=AccumulateGrad]
	2811112814048 -> 2811112813904
	2812875547728 [label="model.layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2812875547728 -> 2811112814048
	2811112814048 [label=AccumulateGrad]
	2811112813856 -> 2811112813664
	2812875547824 [label="model.layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	2812875547824 -> 2811112813856
	2811112813856 [label=AccumulateGrad]
	2811112813808 -> 2811112813664
	2812875547920 [label="model.layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	2812875547920 -> 2811112813808
	2811112813808 [label=AccumulateGrad]
	2811112813424 -> 2811112813616
	2811112813424 [label=CudnnBatchNormBackward0]
	2811112814480 -> 2811112813424
	2811112814480 [label=ConvolutionBackward0]
	2811112815056 -> 2811112814480
	2811112814912 -> 2811112814480
	2812875546000 [label="model.layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2812875546000 -> 2811112814912
	2811112814912 [label=AccumulateGrad]
	2811112814000 -> 2811112813424
	2812875546096 [label="model.layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2812875546096 -> 2811112814000
	2811112814000 [label=AccumulateGrad]
	2811112813952 -> 2811112813424
	2812875546192 [label="model.layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2812875546192 -> 2811112813952
	2811112813952 [label=AccumulateGrad]
	2811112813520 -> 2811112813232
	2812875548304 [label="model.layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2812875548304 -> 2811112813520
	2811112813520 [label=AccumulateGrad]
	2811112813088 -> 2811112813184
	2812875548400 [label="model.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2812875548400 -> 2811112813088
	2811112813088 [label=AccumulateGrad]
	2811112813328 -> 2811112813184
	2812875548496 [label="model.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2812875548496 -> 2811112813328
	2811112813328 [label=AccumulateGrad]
	2811112812992 -> 2811112812752
	2812875548880 [label="model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2812875548880 -> 2811112812992
	2811112812992 [label=AccumulateGrad]
	2811112812608 -> 2811112812704
	2812875548976 [label="model.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2812875548976 -> 2811112812608
	2811112812608 [label=AccumulateGrad]
	2811112812848 -> 2811112812704
	2812875549072 [label="model.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2812875549072 -> 2811112812848
	2811112812848 [label=AccumulateGrad]
	2811112812512 -> 2811112812368
	2812875549456 [label="model.layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2812875549456 -> 2811112812512
	2811112812512 [label=AccumulateGrad]
	2811112812320 -> 2811112812128
	2812875549552 [label="model.layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	2812875549552 -> 2811112812320
	2811112812320 [label=AccumulateGrad]
	2811112812272 -> 2811112812128
	2812875549648 [label="model.layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	2812875549648 -> 2811112812272
	2811112812272 [label=AccumulateGrad]
	2811112811888 -> 2811112812080
	2811112811984 -> 2811112811696
	2812875550032 [label="model.layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2812875550032 -> 2811112811984
	2811112811984 [label=AccumulateGrad]
	2811112811552 -> 2811112811648
	2812875550128 [label="model.layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	2812875550128 -> 2811112811552
	2811112811552 [label=AccumulateGrad]
	2811112811792 -> 2811112811648
	2812875550224 [label="model.layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	2812875550224 -> 2811112811792
	2811112811792 [label=AccumulateGrad]
	2811112811456 -> 2811112811216
	2812875550608 [label="model.layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2812875550608 -> 2811112811456
	2811112811456 [label=AccumulateGrad]
	2811112811072 -> 2811112811168
	2812875550704 [label="model.layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	2812875550704 -> 2811112811072
	2811112811072 [label=AccumulateGrad]
	2811112811312 -> 2811112811168
	2812875550800 [label="model.layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	2812875550800 -> 2811112811312
	2811112811312 [label=AccumulateGrad]
	2811112810976 -> 2811112810832
	2812875551184 [label="model.layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2812875551184 -> 2811112810976
	2811112810976 [label=AccumulateGrad]
	2811112810784 -> 2811112810592
	2812875551280 [label="model.layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	2812875551280 -> 2811112810784
	2811112810784 [label=AccumulateGrad]
	2811112810736 -> 2811112810592
	2812875551376 [label="model.layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	2812875551376 -> 2811112810736
	2811112810736 [label=AccumulateGrad]
	2811112810352 -> 2811112810544
	2811112810448 -> 2811112810160
	2812875551760 [label="model.layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2812875551760 -> 2811112810448
	2811112810448 [label=AccumulateGrad]
	2811112810016 -> 2811112810112
	2812875551856 [label="model.layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	2812875551856 -> 2811112810016
	2811112810016 [label=AccumulateGrad]
	2811112810256 -> 2811112810112
	2812875551952 [label="model.layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	2812875551952 -> 2811112810256
	2811112810256 [label=AccumulateGrad]
	2811112809920 -> 2811112809680
	2812875552336 [label="model.layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2812875552336 -> 2811112809920
	2811112809920 [label=AccumulateGrad]
	2811112809536 -> 2811112809632
	2812875552432 [label="model.layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	2812875552432 -> 2811112809536
	2811112809536 [label=AccumulateGrad]
	2811112809776 -> 2811112809632
	2812875552528 [label="model.layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	2812875552528 -> 2811112809776
	2811112809776 [label=AccumulateGrad]
	2811112809440 -> 2811112809296
	2812875552912 [label="model.layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2812875552912 -> 2811112809440
	2811112809440 [label=AccumulateGrad]
	2811112809248 -> 2811112809056
	2812875553008 [label="model.layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	2812875553008 -> 2811112809248
	2811112809248 [label=AccumulateGrad]
	2811112809200 -> 2811112809056
	2812875553104 [label="model.layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	2812875553104 -> 2811112809200
	2811112809200 [label=AccumulateGrad]
	2811112808912 -> 2811112809008
	2811112808816 -> 2811112808576
	2812875554064 [label="model.layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2812875554064 -> 2811112808816
	2811112808816 [label=AccumulateGrad]
	2811112808432 -> 2811112808528
	2812875554160 [label="model.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2812875554160 -> 2811112808432
	2811112808432 [label=AccumulateGrad]
	2811112808672 -> 2811112808528
	2812875554256 [label="model.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2812875554256 -> 2811112808672
	2811112808672 [label=AccumulateGrad]
	2811112808336 -> 2811112808096
	2812875554640 [label="model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2812875554640 -> 2811112808336
	2811112808336 [label=AccumulateGrad]
	2811112807952 -> 2811112808048
	2812875554736 [label="model.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2812875554736 -> 2811112807952
	2811112807952 [label=AccumulateGrad]
	2811112808192 -> 2811112808048
	2811112276048 [label="model.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2811112276048 -> 2811112808192
	2811112808192 [label=AccumulateGrad]
	2811112807856 -> 2811112807712
	2811112276432 [label="model.layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2811112276432 -> 2811112807856
	2811112807856 [label=AccumulateGrad]
	2811112807664 -> 2811112807472
	2811112276528 [label="model.layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	2811112276528 -> 2811112807664
	2811112807664 [label=AccumulateGrad]
	2811112807616 -> 2811112807472
	2811112276624 [label="model.layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	2811112276624 -> 2811112807616
	2811112807616 [label=AccumulateGrad]
	2811112807232 -> 2811112807424
	2811112807232 [label=CudnnBatchNormBackward0]
	2811112808288 -> 2811112807232
	2811112808288 [label=ConvolutionBackward0]
	2811112808864 -> 2811112808288
	2811112808720 -> 2811112808288
	2812875553488 [label="model.layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2812875553488 -> 2811112808720
	2811112808720 [label=AccumulateGrad]
	2811112807808 -> 2811112807232
	2812875553584 [label="model.layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	2812875553584 -> 2811112807808
	2811112807808 [label=AccumulateGrad]
	2811112807760 -> 2811112807232
	2812875553680 [label="model.layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	2812875553680 -> 2811112807760
	2811112807760 [label=AccumulateGrad]
	2811112807328 -> 2811112807040
	2811112277008 [label="model.layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2811112277008 -> 2811112807328
	2811112807328 [label=AccumulateGrad]
	2811112806896 -> 2811112806992
	2811112277104 [label="model.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2811112277104 -> 2811112806896
	2811112806896 [label=AccumulateGrad]
	2811112807136 -> 2811112806992
	2811112277200 [label="model.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2811112277200 -> 2811112807136
	2811112807136 [label=AccumulateGrad]
	2811112806800 -> 2811112806560
	2811112277584 [label="model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2811112277584 -> 2811112806800
	2811112806800 [label=AccumulateGrad]
	2811112806416 -> 2811112806512
	2811112277680 [label="model.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2811112277680 -> 2811112806416
	2811112806416 [label=AccumulateGrad]
	2811112806656 -> 2811112806512
	2811112277776 [label="model.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2811112277776 -> 2811112806656
	2811112806656 [label=AccumulateGrad]
	2811112806320 -> 2811112806176
	2811112278160 [label="model.layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2811112278160 -> 2811112806320
	2811112806320 [label=AccumulateGrad]
	2811112806128 -> 2811112805936
	2811112278256 [label="model.layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	2811112278256 -> 2811112806128
	2811112806128 [label=AccumulateGrad]
	2811112806080 -> 2811112805936
	2811112278352 [label="model.layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	2811112278352 -> 2811112806080
	2811112806080 [label=AccumulateGrad]
	2811112805696 -> 2811112805888
	2811112805792 -> 2811112805504
	2811112278736 [label="model.layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2811112278736 -> 2811112805792
	2811112805792 [label=AccumulateGrad]
	2811112805360 -> 2811112805456
	2811112278832 [label="model.layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	2811112278832 -> 2811112805360
	2811112805360 [label=AccumulateGrad]
	2811112805600 -> 2811112805456
	2811112278928 [label="model.layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	2811112278928 -> 2811112805600
	2811112805600 [label=AccumulateGrad]
	2811112805264 -> 2811112805024
	2811112279312 [label="model.layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2811112279312 -> 2811112805264
	2811112805264 [label=AccumulateGrad]
	2811112804880 -> 2811112804976
	2811112279408 [label="model.layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	2811112279408 -> 2811112804880
	2811112804880 [label=AccumulateGrad]
	2811112805120 -> 2811112804976
	2811112279504 [label="model.layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	2811112279504 -> 2811112805120
	2811112805120 [label=AccumulateGrad]
	2811112804784 -> 2811112804640
	2811112279888 [label="model.layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2811112279888 -> 2811112804784
	2811112804784 [label=AccumulateGrad]
	2811112804592 -> 2811112804400
	2811112279984 [label="model.layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	2811112279984 -> 2811112804592
	2811112804592 [label=AccumulateGrad]
	2811112804544 -> 2811112804400
	2811112280080 [label="model.layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	2811112280080 -> 2811112804544
	2811112804544 [label=AccumulateGrad]
	2811112804160 -> 2811112804352
	2811112804256 -> 2811112803968
	2811112280464 [label="model.layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2811112280464 -> 2811112804256
	2811112804256 [label=AccumulateGrad]
	2811112803824 -> 2811112803920
	2811112280560 [label="model.layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	2811112280560 -> 2811112803824
	2811112803824 [label=AccumulateGrad]
	2811112804064 -> 2811112803920
	2811112280656 [label="model.layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	2811112280656 -> 2811112804064
	2811112804064 [label=AccumulateGrad]
	2811112803728 -> 2811112803488
	2811112281040 [label="model.layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2811112281040 -> 2811112803728
	2811112803728 [label=AccumulateGrad]
	2811112803344 -> 2811112803440
	2811112281136 [label="model.layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	2811112281136 -> 2811112803344
	2811112803344 [label=AccumulateGrad]
	2811112803584 -> 2811112803440
	2811112281232 [label="model.layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	2811112281232 -> 2811112803584
	2811112803584 [label=AccumulateGrad]
	2811112803248 -> 2811112803104
	2811112281616 [label="model.layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2811112281616 -> 2811112803248
	2811112803248 [label=AccumulateGrad]
	2811112803056 -> 2811112802864
	2811112281712 [label="model.layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	2811112281712 -> 2811112803056
	2811112803056 [label=AccumulateGrad]
	2811112803008 -> 2811112802864
	2811112281808 [label="model.layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	2811112281808 -> 2811112803008
	2811112803008 [label=AccumulateGrad]
	2811112802624 -> 2811112802816
	2811112802720 -> 2811112802432
	2811112282192 [label="model.layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2811112282192 -> 2811112802720
	2811112802720 [label=AccumulateGrad]
	2811112802288 -> 2811112802384
	2811112282288 [label="model.layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	2811112282288 -> 2811112802288
	2811112802288 [label=AccumulateGrad]
	2811112802528 -> 2811112802384
	2811112282384 [label="model.layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	2811112282384 -> 2811112802528
	2811112802528 [label=AccumulateGrad]
	2811112802192 -> 2811112801952
	2811112282768 [label="model.layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2811112282768 -> 2811112802192
	2811112802192 [label=AccumulateGrad]
	2811112801808 -> 2811112801904
	2811112282864 [label="model.layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	2811112282864 -> 2811112801808
	2811112801808 [label=AccumulateGrad]
	2811112802048 -> 2811112801904
	2811112282960 [label="model.layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	2811112282960 -> 2811112802048
	2811112802048 [label=AccumulateGrad]
	2811112801712 -> 2811112801568
	2811112283344 [label="model.layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2811112283344 -> 2811112801712
	2811112801712 [label=AccumulateGrad]
	2811112801520 -> 2811112801424
	2811112283440 [label="model.layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	2811112283440 -> 2811112801520
	2811112801520 [label=AccumulateGrad]
	2811112801472 -> 2811112801424
	2811112283536 [label="model.layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	2811112283536 -> 2811112801472
	2811112801472 [label=AccumulateGrad]
	2811112801376 -> 2811112801328
	2811112801232 -> 2811112801040
	2811112283920 [label="model.layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2811112283920 -> 2811112801232
	2811112801232 [label=AccumulateGrad]
	2811112800992 -> 2811112800944
	2811112284016 [label="model.layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	2811112284016 -> 2811112800992
	2811112800992 [label=AccumulateGrad]
	2811112800848 -> 2811112800944
	2811112284112 [label="model.layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	2811112284112 -> 2811112800848
	2811112800848 [label=AccumulateGrad]
	2811112800752 -> 2811112800608
	2811112284496 [label="model.layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2811112284496 -> 2811112800752
	2811112800752 [label=AccumulateGrad]
	2811112800560 -> 2811112800512
	2811112284592 [label="model.layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	2811112284592 -> 2811112800560
	2811112800560 [label=AccumulateGrad]
	2811112800416 -> 2811112800512
	2811112284688 [label="model.layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	2811112284688 -> 2811112800416
	2811112800416 [label=AccumulateGrad]
	2811112800368 -> 2812838646624
	2811112285072 [label="model.layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2811112285072 -> 2811112800368
	2811112800368 [label=AccumulateGrad]
	2812838647968 -> 2812838647680
	2811112285168 [label="model.layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	2811112285168 -> 2812838647968
	2812838647968 [label=AccumulateGrad]
	2812838648016 -> 2812838647680
	2811112285264 [label="model.layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	2811112285264 -> 2812838648016
	2812838648016 [label=AccumulateGrad]
	2812838648160 -> 2812838648112
	2812838647632 -> 2812838647056
	2811112286224 [label="model.layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2811112286224 -> 2812838647632
	2812838647632 [label=AccumulateGrad]
	2812838646528 -> 2812838645664
	2811112286320 [label="model.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2811112286320 -> 2812838646528
	2812838646528 [label=AccumulateGrad]
	2812838646480 -> 2812838645664
	2811112286416 [label="model.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2811112286416 -> 2812838646480
	2812838646480 [label=AccumulateGrad]
	2812838645472 -> 2812838644464
	2811112286800 [label="model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2811112286800 -> 2812838645472
	2812838645472 [label=AccumulateGrad]
	2812838644896 -> 2812838644848
	2811112286896 [label="model.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2811112286896 -> 2812838644896
	2812838644896 [label=AccumulateGrad]
	2812838649456 -> 2812838644848
	2811112286992 [label="model.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2811112286992 -> 2812838649456
	2812838649456 [label=AccumulateGrad]
	2812838649696 -> 2812838656656
	2811112287376 [label="model.layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2811112287376 -> 2812838649696
	2812838649696 [label=AccumulateGrad]
	2812838647248 -> 2812838649936
	2811112287472 [label="model.layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	2811112287472 -> 2812838647248
	2812838647248 [label=AccumulateGrad]
	2812838649888 -> 2812838649936
	2811112287568 [label="model.layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	2811112287568 -> 2812838649888
	2812838649888 [label=AccumulateGrad]
	2812838651856 -> 2812838657040
	2812838651856 [label=CudnnBatchNormBackward0]
	2812838645568 -> 2812838651856
	2812838645568 [label=ConvolutionBackward0]
	2812838647008 -> 2812838645568
	2812838646960 -> 2812838645568
	2811112285648 [label="model.layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	2811112285648 -> 2812838646960
	2812838646960 [label=AccumulateGrad]
	2812838649504 -> 2812838651856
	2811112285744 [label="model.layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	2811112285744 -> 2812838649504
	2812838649504 [label=AccumulateGrad]
	2812838649408 -> 2812838651856
	2811112285840 [label="model.layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	2811112285840 -> 2812838649408
	2812838649408 [label=AccumulateGrad]
	2812838652384 -> 2812838656176
	2811112287952 [label="model.layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2811112287952 -> 2812838652384
	2812838652384 [label=AccumulateGrad]
	2812838652192 -> 2812838653776
	2811112288048 [label="model.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2811112288048 -> 2812838652192
	2812838652192 [label=AccumulateGrad]
	2812838650464 -> 2812838653776
	2811112288144 [label="model.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2811112288144 -> 2812838650464
	2812838650464 [label=AccumulateGrad]
	2812838652864 -> 2812838650080
	2811112288528 [label="model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2811112288528 -> 2812838652864
	2812838652864 [label=AccumulateGrad]
	2812838650128 -> 2812838650176
	2811112288624 [label="model.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2811112288624 -> 2812838650128
	2812838650128 [label=AccumulateGrad]
	2812838650272 -> 2812838650176
	2811112288720 [label="model.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2811112288720 -> 2812838650272
	2812838650272 [label=AccumulateGrad]
	2812838650368 -> 2812838651424
	2811112289104 [label="model.layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2811112289104 -> 2812838650368
	2812838650368 [label=AccumulateGrad]
	2812838651472 -> 2812838651568
	2811112289200 [label="model.layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	2811112289200 -> 2812838651472
	2812838651472 [label=AccumulateGrad]
	2812838651520 -> 2812838651568
	2811112289296 [label="model.layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	2811112289296 -> 2812838651520
	2812838651520 [label=AccumulateGrad]
	2812838651952 -> 2812838652000
	2812838652096 -> 2812838652288
	2811112289680 [label="model.layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2811112289680 -> 2812838652096
	2812838652096 [label=AccumulateGrad]
	2812838644128 -> 2812838652336
	2811112289776 [label="model.layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	2811112289776 -> 2812838644128
	2812838644128 [label=AccumulateGrad]
	2812838652432 -> 2812838652336
	2811112289872 [label="model.layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	2811112289872 -> 2812838652432
	2812838652432 [label=AccumulateGrad]
	2812838644368 -> 2812838652624
	2811112290256 [label="model.layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2811112290256 -> 2812838644368
	2812838644368 [label=AccumulateGrad]
	2812838652720 -> 2812838644560
	2811112290352 [label="model.layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	2811112290352 -> 2812838652720
	2812838652720 [label=AccumulateGrad]
	2812838644608 -> 2812838644560
	2811112290448 [label="model.layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	2811112290448 -> 2812838644608
	2812838644608 [label=AccumulateGrad]
	2812838644656 -> 2812838652960
	2811112290832 [label="model.layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2811112290832 -> 2812838644656
	2812838644656 [label=AccumulateGrad]
	2812838644800 -> 2812838653056
	2811112290928 [label="model.layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	2811112290928 -> 2812838644800
	2812838644800 [label=AccumulateGrad]
	2812838653008 -> 2812838653056
	2811112291024 [label="model.layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	2811112291024 -> 2812838653008
	2812838653008 [label=AccumulateGrad]
	2812838645136 -> 2812838645184
	2812838654400 -> 2812838654304
	2812838654400 [label=TBackward0]
	2812838645232 -> 2812838654400
	2811112291600 [label="model.fc.weight
 (19, 2048)" fillcolor=lightblue]
	2811112291600 -> 2812838645232
	2812838645232 [label=AccumulateGrad]
	2812838646240 -> 2811112710000
}
