{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Of Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Library modules\n",
    "import os  # Operating system interactions, such as reading and writing files.\n",
    "import shutil  # High-level file operations like copying and moving files.\n",
    "import random  # Random number generation for various tasks.\n",
    "import textwrap  # Formatting text into paragraphs of a specified width.\n",
    "import warnings  # Warning control context manager.\n",
    "import zipfile  # Work with ZIP archives.\n",
    "import platform  # Access to underlying platformâ€™s identifying data.\n",
    "import itertools  # Functions creating iterators for efficient looping.\n",
    "from dataclasses import dataclass  # Class decorator for adding special methods to classes.\n",
    "\n",
    "# PyTorch and Deep Learning Libaries\n",
    "import torch  # Core PyTorch library for tensor computations.\n",
    "import torch.nn as nn  # Neural network module for defining layers and architectures.\n",
    "from torch.nn import functional as F  # Functional module for defining functions and loss functions.\n",
    "import torch.optim as optim  # Optimizer module for training models (SGD, Adam, etc.).\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split  # Data handling and batching\n",
    "import torchvision  # PyTorch's computer vision library.\n",
    "from torchvision import datasets, transforms  # Image datasets and transformations.\n",
    "import torchvision.datasets as datasets  # Specific datasets for vision tasks.\n",
    "import torchvision.transforms as transforms  # Transformations for image preprocessing.\n",
    "from torchvision.utils import make_grid  # Grid for displaying images.\n",
    "import torchvision.models as models  # Pretrained models for transfer learning.\n",
    "from torchvision.datasets import MNIST, EuroSAT  # Standard datasets.\n",
    "import torchvision.transforms.functional as TF  # Functional transformations.\n",
    "from torchvision.models import ResNet18_Weights  # ResNet-18 model with pretrained weights.\n",
    "from torchsummary import summary  # Model summary.\n",
    "import torchsummary  # Model summaries.\n",
    "import torchmetrics  # Model evaluation metrics.\n",
    "from torchmetrics import MeanMetric, Accuracy  # Accuracy metrics.\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassF1Score, MulticlassRecall, MulticlassPrecision, MulticlassAccuracy\n",
    ")  # Classification metrics.\n",
    "from torchviz import make_dot  # Model visualization.\n",
    "from torchvision.ops import sigmoid_focal_loss  # Focal loss for class imbalance.\n",
    "from torchcam.methods import GradCAM  # Grad-CAM for model interpretability.\n",
    "from torchcam.utils import overlay_mask  # Overlay mask for visualizations.\n",
    "import pytorch_lightning as pl  # Training management.\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping, Callback  # Callbacks.\n",
    "from pytorch_lightning.loggers import TensorBoardLogger  # Logger for TensorBoard.\n",
    "\n",
    "# Geospatial Data Processing Libraries\n",
    "import rasterio  # Reading and writing geospatial raster data.\n",
    "from rasterio.warp import calculate_default_transform, reproject  # Reprojection and transformation.\n",
    "from rasterio.enums import Resampling  # Resampling for raster resizing.\n",
    "from rasterio.plot import show  # Visualization of raster data.\n",
    "\n",
    "# Data Manipulation, Analysis and Visualization Libraries\n",
    "import pandas as pd  # Data analysis and manipulation.\n",
    "import numpy as np  # Array operations and computations.\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score  # Evaluation metrics.\n",
    "import matplotlib.pyplot as plt  # Static and interactive plotting.\n",
    "import seaborn as sns  # High-level interface for statistical graphics.\n",
    "\n",
    "# Utility Libraries\n",
    "from tqdm import tqdm  # Progress bar for loops.\n",
    "from PIL import Image  # Image handling and manipulation.\n",
    "import ast  # Parsing Python code.\n",
    "import requests  # HTTP requests.\n",
    "import zstandard as zstd  # Compression and decompression.\n",
    "from collections import Counter  # Counting hashable objects.\n",
    "import certifi  # Certificates for HTTPS.\n",
    "import ssl  # Secure connections.\n",
    "import urllib.request  # URL handling.\n",
    "import kaggle  # Kaggle API for datasets.\n",
    "from IPython.display import Image  # Display images in notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Seed and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda (GPU: NVIDIA GeForce RTX 3050)\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42  \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device} {'(GPU: ' + torch.cuda.get_device_name(0) + ')' if device.type == 'cuda' else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    dataset_path: str = r'C:\\Users\\isaac\\Desktop\\BigEarthTests\\OnePBigEarthNet'\n",
    "    img_size: int = 120\n",
    "    img_mean, img_std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "    num_classes: int = 19\n",
    "    band_channels: int = 3\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    batch_size: int = 32\n",
    "    num_epochs: int = 10\n",
    "    model_name: str = 'resnet18'\n",
    "    num_workers: int = os.cpu_count() // 2\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=DatasetConfig.img_mean, std=DatasetConfig.img_std)\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=DatasetConfig.img_mean, std=DatasetConfig.img_std)\n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=DatasetConfig.img_mean, std=DatasetConfig.img_std)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigEarthNetSubset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        pass\n",
    "\n",
    "    def __getitem(self, index):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
