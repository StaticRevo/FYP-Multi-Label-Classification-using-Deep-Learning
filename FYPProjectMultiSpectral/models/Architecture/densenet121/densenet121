digraph {
	graph [size="428.4,428.4"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1364430323792 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1364510946736 [label=AddmmBackward0]
	1364510945536 -> 1364510946736
	1364430127280 [label="classifier.bias
 (19)" fillcolor=lightblue]
	1364430127280 -> 1364510945536
	1364510945536 [label=AccumulateGrad]
	1364510945680 -> 1364510946736
	1364510945680 [label=ViewBackward0]
	1364510945152 -> 1364510945680
	1364510945152 [label=MeanBackward1]
	1364510943952 -> 1364510945152
	1364510943952 [label=ReluBackward0]
	1364510943424 -> 1364510943952
	1364510943424 [label=CudnnBatchNormBackward0]
	1364510942896 -> 1364510943424
	1364510942896 [label=CatBackward0]
	1364510941840 -> 1364510942896
	1364510941840 [label=AvgPool2DBackward0]
	1364510937088 -> 1364510941840
	1364510937088 [label=ConvolutionBackward0]
	1364510936560 -> 1364510937088
	1364510936560 [label=ReluBackward0]
	1364510936176 -> 1364510936560
	1364510936176 [label=CudnnBatchNormBackward0]
	1364510935648 -> 1364510936176
	1364510935648 [label=CatBackward0]
	1364510934592 -> 1364510935648
	1364510934592 [label=AvgPool2DBackward0]
	1364510944336 -> 1364510934592
	1364510944336 [label=ConvolutionBackward0]
	1364510944000 -> 1364510944336
	1364510944000 [label=ReluBackward0]
	1364510943760 -> 1364510944000
	1364510943760 [label=CudnnBatchNormBackward0]
	1364510943712 -> 1364510943760
	1364510943712 [label=CatBackward0]
	1364510943328 -> 1364510943712
	1364510943328 [label=AvgPool2DBackward0]
	1364510942464 -> 1364510943328
	1364510942464 [label=ConvolutionBackward0]
	1364510942272 -> 1364510942464
	1364510942272 [label=ReluBackward0]
	1364510942320 -> 1364510942272
	1364510942320 [label=CudnnBatchNormBackward0]
	1364510942224 -> 1364510942320
	1364510942224 [label=CatBackward0]
	1364510941552 -> 1364510942224
	1364510941552 [label=MaxPool2DWithIndicesBackward0]
	1364510941024 -> 1364510941552
	1364510941024 [label=ReluBackward0]
	1364510941264 -> 1364510941024
	1364510941264 [label=CudnnBatchNormBackward0]
	1364510941168 -> 1364510941264
	1364510941168 [label=ConvolutionBackward0]
	1364510940496 -> 1364510941168
	1364429881264 [label="features.conv0.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	1364429881264 -> 1364510940496
	1364510940496 [label=AccumulateGrad]
	1364510941072 -> 1364510941264
	1364439281072 [label="features.norm0.weight
 (64)" fillcolor=lightblue]
	1364439281072 -> 1364510941072
	1364510941072 [label=AccumulateGrad]
	1364510941360 -> 1364510941264
	1364439280784 [label="features.norm0.bias
 (64)" fillcolor=lightblue]
	1364439280784 -> 1364510941360
	1364510941360 [label=AccumulateGrad]
	1364510941744 -> 1364510942224
	1364510941744 [label=ConvolutionBackward0]
	1364510940880 -> 1364510941744
	1364510940880 [label=ReluBackward0]
	1364510940592 -> 1364510940880
	1364510940592 [label=CudnnBatchNormBackward0]
	1364510940544 -> 1364510940592
	1364510940544 [label=ConvolutionBackward0]
	1364510940160 -> 1364510940544
	1364510940160 [label=ReluBackward0]
	1364510940208 -> 1364510940160
	1364510940208 [label=CudnnBatchNormBackward0]
	1364510940112 -> 1364510940208
	1364510940112 [label=CatBackward0]
	1364510941552 -> 1364510940112
	1364510940016 -> 1364510940208
	1364439281264 [label="features.denseblock1.denselayer1.norm1.weight
 (64)" fillcolor=lightblue]
	1364439281264 -> 1364510940016
	1364510940016 [label=AccumulateGrad]
	1364510939968 -> 1364510940208
	1364439281360 [label="features.denseblock1.denselayer1.norm1.bias
 (64)" fillcolor=lightblue]
	1364439281360 -> 1364510939968
	1364510939968 [label=AccumulateGrad]
	1364510940304 -> 1364510940544
	1364439281648 [label="features.denseblock1.denselayer1.conv1.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1364439281648 -> 1364510940304
	1364510940304 [label=AccumulateGrad]
	1364510940832 -> 1364510940592
	1364439280688 [label="features.denseblock1.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	1364439280688 -> 1364510940832
	1364510940832 [label=AccumulateGrad]
	1364510940688 -> 1364510940592
	1364439280592 [label="features.denseblock1.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	1364439280592 -> 1364510940688
	1364510940688 [label=AccumulateGrad]
	1364510941120 -> 1364510941744
	1364439279728 [label="features.denseblock1.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364439279728 -> 1364510941120
	1364510941120 [label=AccumulateGrad]
	1364510941888 -> 1364510942224
	1364510941888 [label=ConvolutionBackward0]
	1364510940640 -> 1364510941888
	1364510940640 [label=ReluBackward0]
	1364510939824 -> 1364510940640
	1364510939824 [label=CudnnBatchNormBackward0]
	1364510939632 -> 1364510939824
	1364510939632 [label=ConvolutionBackward0]
	1364510939488 -> 1364510939632
	1364510939488 [label=ReluBackward0]
	1364510939248 -> 1364510939488
	1364510939248 [label=CudnnBatchNormBackward0]
	1364510938912 -> 1364510939248
	1364510938912 [label=CatBackward0]
	1364510941552 -> 1364510938912
	1364510941744 -> 1364510938912
	1364510939104 -> 1364510939248
	1364439279920 [label="features.denseblock1.denselayer2.norm1.weight
 (96)" fillcolor=lightblue]
	1364439279920 -> 1364510939104
	1364510939104 [label=AccumulateGrad]
	1364510939584 -> 1364510939248
	1364439280016 [label="features.denseblock1.denselayer2.norm1.bias
 (96)" fillcolor=lightblue]
	1364439280016 -> 1364510939584
	1364510939584 [label=AccumulateGrad]
	1364510939680 -> 1364510939632
	1364439280496 [label="features.denseblock1.denselayer2.conv1.weight
 (128, 96, 1, 1)" fillcolor=lightblue]
	1364439280496 -> 1364510939680
	1364510939680 [label=AccumulateGrad]
	1364510940064 -> 1364510939824
	1364439280400 [label="features.denseblock1.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	1364439280400 -> 1364510940064
	1364510940064 [label=AccumulateGrad]
	1364510940736 -> 1364510939824
	1364439279440 [label="features.denseblock1.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	1364439279440 -> 1364510940736
	1364510940736 [label=AccumulateGrad]
	1364510940352 -> 1364510941888
	1364439279056 [label="features.denseblock1.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364439279056 -> 1364510940352
	1364510940352 [label=AccumulateGrad]
	1364510941648 -> 1364510942224
	1364510941648 [label=ConvolutionBackward0]
	1364510939776 -> 1364510941648
	1364510939776 [label=ReluBackward0]
	1364510939008 -> 1364510939776
	1364510939008 [label=CudnnBatchNormBackward0]
	1364510938960 -> 1364510939008
	1364510938960 [label=ConvolutionBackward0]
	1364510938576 -> 1364510938960
	1364510938576 [label=ReluBackward0]
	1364510938624 -> 1364510938576
	1364510938624 [label=CudnnBatchNormBackward0]
	1364510938528 -> 1364510938624
	1364510938528 [label=CatBackward0]
	1364510941552 -> 1364510938528
	1364510941744 -> 1364510938528
	1364510941888 -> 1364510938528
	1364510938432 -> 1364510938624
	1364439276656 [label="features.denseblock1.denselayer3.norm1.weight
 (128)" fillcolor=lightblue]
	1364439276656 -> 1364510938432
	1364510938432 [label=AccumulateGrad]
	1364510938384 -> 1364510938624
	1364439276848 [label="features.denseblock1.denselayer3.norm1.bias
 (128)" fillcolor=lightblue]
	1364439276848 -> 1364510938384
	1364510938384 [label=AccumulateGrad]
	1364510938720 -> 1364510938960
	1364439278960 [label="features.denseblock1.denselayer3.conv1.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	1364439278960 -> 1364510938720
	1364510938720 [label=AccumulateGrad]
	1364510939296 -> 1364510939008
	1364439279248 [label="features.denseblock1.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	1364439279248 -> 1364510939296
	1364510939296 [label=AccumulateGrad]
	1364510939440 -> 1364510939008
	1364439279152 [label="features.denseblock1.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	1364439279152 -> 1364510939440
	1364510939440 [label=AccumulateGrad]
	1364510939536 -> 1364510941648
	1364428832112 [label="features.denseblock1.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428832112 -> 1364510939536
	1364510939536 [label=AccumulateGrad]
	1364510941792 -> 1364510942224
	1364510941792 [label=ConvolutionBackward0]
	1364510939152 -> 1364510941792
	1364510939152 [label=ReluBackward0]
	1364510938240 -> 1364510939152
	1364510938240 [label=CudnnBatchNormBackward0]
	1364510938048 -> 1364510938240
	1364510938048 [label=ConvolutionBackward0]
	1364510937904 -> 1364510938048
	1364510937904 [label=ReluBackward0]
	1364510937664 -> 1364510937904
	1364510937664 [label=CudnnBatchNormBackward0]
	1364510937328 -> 1364510937664
	1364510937328 [label=CatBackward0]
	1364510941552 -> 1364510937328
	1364510941744 -> 1364510937328
	1364510941888 -> 1364510937328
	1364510941648 -> 1364510937328
	1364510937520 -> 1364510937664
	1364428832208 [label="features.denseblock1.denselayer4.norm1.weight
 (160)" fillcolor=lightblue]
	1364428832208 -> 1364510937520
	1364510937520 [label=AccumulateGrad]
	1364510938000 -> 1364510937664
	1364428832304 [label="features.denseblock1.denselayer4.norm1.bias
 (160)" fillcolor=lightblue]
	1364428832304 -> 1364510938000
	1364510938000 [label=AccumulateGrad]
	1364510938096 -> 1364510938048
	1364428832688 [label="features.denseblock1.denselayer4.conv1.weight
 (128, 160, 1, 1)" fillcolor=lightblue]
	1364428832688 -> 1364510938096
	1364510938096 [label=AccumulateGrad]
	1364510938480 -> 1364510938240
	1364428947536 [label="features.denseblock1.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	1364428947536 -> 1364510938480
	1364510938480 [label=AccumulateGrad]
	1364510939056 -> 1364510938240
	1364428947632 [label="features.denseblock1.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	1364428947632 -> 1364510939056
	1364510939056 [label=AccumulateGrad]
	1364510938768 -> 1364510941792
	1364428948016 [label="features.denseblock1.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428948016 -> 1364510938768
	1364510938768 [label=AccumulateGrad]
	1364510941600 -> 1364510942224
	1364510941600 [label=ConvolutionBackward0]
	1364510938192 -> 1364510941600
	1364510938192 [label=ReluBackward0]
	1364510937424 -> 1364510938192
	1364510937424 [label=CudnnBatchNormBackward0]
	1364510937376 -> 1364510937424
	1364510937376 [label=ConvolutionBackward0]
	1364510936992 -> 1364510937376
	1364510936992 [label=ReluBackward0]
	1364510937040 -> 1364510936992
	1364510937040 [label=CudnnBatchNormBackward0]
	1364510936944 -> 1364510937040
	1364510936944 [label=CatBackward0]
	1364510941552 -> 1364510936944
	1364510941744 -> 1364510936944
	1364510941888 -> 1364510936944
	1364510941648 -> 1364510936944
	1364510941792 -> 1364510936944
	1364510936848 -> 1364510937040
	1364428948112 [label="features.denseblock1.denselayer5.norm1.weight
 (192)" fillcolor=lightblue]
	1364428948112 -> 1364510936848
	1364510936848 [label=AccumulateGrad]
	1364510936800 -> 1364510937040
	1364428948208 [label="features.denseblock1.denselayer5.norm1.bias
 (192)" fillcolor=lightblue]
	1364428948208 -> 1364510936800
	1364510936800 [label=AccumulateGrad]
	1364510937136 -> 1364510937376
	1364428948592 [label="features.denseblock1.denselayer5.conv1.weight
 (128, 192, 1, 1)" fillcolor=lightblue]
	1364428948592 -> 1364510937136
	1364510937136 [label=AccumulateGrad]
	1364510937712 -> 1364510937424
	1364428948688 [label="features.denseblock1.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	1364428948688 -> 1364510937712
	1364510937712 [label=AccumulateGrad]
	1364510937856 -> 1364510937424
	1364428948784 [label="features.denseblock1.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	1364428948784 -> 1364510937856
	1364510937856 [label=AccumulateGrad]
	1364510937952 -> 1364510941600
	1364428949168 [label="features.denseblock1.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428949168 -> 1364510937952
	1364510937952 [label=AccumulateGrad]
	1364510941696 -> 1364510942224
	1364510941696 [label=ConvolutionBackward0]
	1364510937568 -> 1364510941696
	1364510937568 [label=ReluBackward0]
	1364510936656 -> 1364510937568
	1364510936656 [label=CudnnBatchNormBackward0]
	1364510936464 -> 1364510936656
	1364510936464 [label=ConvolutionBackward0]
	1364510936320 -> 1364510936464
	1364510936320 [label=ReluBackward0]
	1364510936080 -> 1364510936320
	1364510936080 [label=CudnnBatchNormBackward0]
	1364510935744 -> 1364510936080
	1364510935744 [label=CatBackward0]
	1364510941552 -> 1364510935744
	1364510941744 -> 1364510935744
	1364510941888 -> 1364510935744
	1364510941648 -> 1364510935744
	1364510941792 -> 1364510935744
	1364510941600 -> 1364510935744
	1364510935936 -> 1364510936080
	1364428949264 [label="features.denseblock1.denselayer6.norm1.weight
 (224)" fillcolor=lightblue]
	1364428949264 -> 1364510935936
	1364510935936 [label=AccumulateGrad]
	1364510936416 -> 1364510936080
	1364428949360 [label="features.denseblock1.denselayer6.norm1.bias
 (224)" fillcolor=lightblue]
	1364428949360 -> 1364510936416
	1364510936416 [label=AccumulateGrad]
	1364510936512 -> 1364510936464
	1364428949744 [label="features.denseblock1.denselayer6.conv1.weight
 (128, 224, 1, 1)" fillcolor=lightblue]
	1364428949744 -> 1364510936512
	1364510936512 [label=AccumulateGrad]
	1364510936896 -> 1364510936656
	1364428949840 [label="features.denseblock1.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	1364428949840 -> 1364510936896
	1364510936896 [label=AccumulateGrad]
	1364510937472 -> 1364510936656
	1364428949936 [label="features.denseblock1.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	1364428949936 -> 1364510937472
	1364510937472 [label=AccumulateGrad]
	1364510937184 -> 1364510941696
	1364428950320 [label="features.denseblock1.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428950320 -> 1364510937184
	1364510937184 [label=AccumulateGrad]
	1364510942128 -> 1364510942320
	1364428950416 [label="features.transition1.norm.weight
 (256)" fillcolor=lightblue]
	1364428950416 -> 1364510942128
	1364510942128 [label=AccumulateGrad]
	1364510942080 -> 1364510942320
	1364428950512 [label="features.transition1.norm.bias
 (256)" fillcolor=lightblue]
	1364428950512 -> 1364510942080
	1364510942080 [label=AccumulateGrad]
	1364510942416 -> 1364510942464
	1364428950896 [label="features.transition1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	1364428950896 -> 1364510942416
	1364510942416 [label=AccumulateGrad]
	1364510943472 -> 1364510943712
	1364510943472 [label=ConvolutionBackward0]
	1364510941408 -> 1364510943472
	1364510941408 [label=ReluBackward0]
	1364510941216 -> 1364510941408
	1364510941216 [label=CudnnBatchNormBackward0]
	1364510936608 -> 1364510941216
	1364510936608 [label=ConvolutionBackward0]
	1364510936128 -> 1364510936608
	1364510936128 [label=ReluBackward0]
	1364510935600 -> 1364510936128
	1364510935600 [label=CudnnBatchNormBackward0]
	1364510935408 -> 1364510935600
	1364510935408 [label=CatBackward0]
	1364510943328 -> 1364510935408
	1364510935552 -> 1364510935600
	1364428950992 [label="features.denseblock2.denselayer1.norm1.weight
 (128)" fillcolor=lightblue]
	1364428950992 -> 1364510935552
	1364510935552 [label=AccumulateGrad]
	1364510935792 -> 1364510935600
	1364428951088 [label="features.denseblock2.denselayer1.norm1.bias
 (128)" fillcolor=lightblue]
	1364428951088 -> 1364510935792
	1364510935792 [label=AccumulateGrad]
	1364510935840 -> 1364510936608
	1364428951472 [label="features.denseblock2.denselayer1.conv1.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	1364428951472 -> 1364510935840
	1364510935840 [label=AccumulateGrad]
	1364510936368 -> 1364510941216
	1364428951568 [label="features.denseblock2.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	1364428951568 -> 1364510936368
	1364510936368 [label=AccumulateGrad]
	1364510941936 -> 1364510941216
	1364428951664 [label="features.denseblock2.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	1364428951664 -> 1364510941936
	1364510941936 [label=AccumulateGrad]
	1364510942656 -> 1364510943472
	1364428952048 [label="features.denseblock2.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428952048 -> 1364510942656
	1364510942656 [label=AccumulateGrad]
	1364510943520 -> 1364510943712
	1364510943520 [label=ConvolutionBackward0]
	1364510936272 -> 1364510943520
	1364510936272 [label=ReluBackward0]
	1364510935216 -> 1364510936272
	1364510935216 [label=CudnnBatchNormBackward0]
	1364510935456 -> 1364510935216
	1364510935456 [label=ConvolutionBackward0]
	1364510935024 -> 1364510935456
	1364510935024 [label=ReluBackward0]
	1364510934784 -> 1364510935024
	1364510934784 [label=CudnnBatchNormBackward0]
	1364510934736 -> 1364510934784
	1364510934736 [label=CatBackward0]
	1364510943328 -> 1364510934736
	1364510943472 -> 1364510934736
	1364510934928 -> 1364510934784
	1364428952144 [label="features.denseblock2.denselayer2.norm1.weight
 (160)" fillcolor=lightblue]
	1364428952144 -> 1364510934928
	1364510934928 [label=AccumulateGrad]
	1364510934880 -> 1364510934784
	1364428952240 [label="features.denseblock2.denselayer2.norm1.bias
 (160)" fillcolor=lightblue]
	1364428952240 -> 1364510934880
	1364510934880 [label=AccumulateGrad]
	1364510935072 -> 1364510935456
	1364428952624 [label="features.denseblock2.denselayer2.conv1.weight
 (128, 160, 1, 1)" fillcolor=lightblue]
	1364428952624 -> 1364510935072
	1364510935072 [label=AccumulateGrad]
	1364510935984 -> 1364510935216
	1364428952720 [label="features.denseblock2.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	1364428952720 -> 1364510935984
	1364510935984 [label=AccumulateGrad]
	1364510942176 -> 1364510935216
	1364428952816 [label="features.denseblock2.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	1364428952816 -> 1364510942176
	1364510942176 [label=AccumulateGrad]
	1364510935888 -> 1364510943520
	1364428953200 [label="features.denseblock2.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428953200 -> 1364510935888
	1364510935888 [label=AccumulateGrad]
	1364510943136 -> 1364510943712
	1364510943136 [label=ConvolutionBackward0]
	1364510935312 -> 1364510943136
	1364510935312 [label=ReluBackward0]
	1364510934832 -> 1364510935312
	1364510934832 [label=CudnnBatchNormBackward0]
	1364510934496 -> 1364510934832
	1364510934496 [label=ConvolutionBackward0]
	1364510934400 -> 1364510934496
	1364510934400 [label=ReluBackward0]
	1364510934016 -> 1364510934400
	1364510934016 [label=CudnnBatchNormBackward0]
	1364510933824 -> 1364510934016
	1364510933824 [label=CatBackward0]
	1364510943328 -> 1364510933824
	1364510943472 -> 1364510933824
	1364510943520 -> 1364510933824
	1364510933968 -> 1364510934016
	1364428953296 [label="features.denseblock2.denselayer3.norm1.weight
 (192)" fillcolor=lightblue]
	1364428953296 -> 1364510933968
	1364510933968 [label=AccumulateGrad]
	1364510934208 -> 1364510934016
	1364428953392 [label="features.denseblock2.denselayer3.norm1.bias
 (192)" fillcolor=lightblue]
	1364428953392 -> 1364510934208
	1364510934208 [label=AccumulateGrad]
	1364510934256 -> 1364510934496
	1364428953776 [label="features.denseblock2.denselayer3.conv1.weight
 (128, 192, 1, 1)" fillcolor=lightblue]
	1364428953776 -> 1364510934256
	1364510934256 [label=AccumulateGrad]
	1364510934688 -> 1364510934832
	1364428953872 [label="features.denseblock2.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	1364428953872 -> 1364510934688
	1364510934688 [label=AccumulateGrad]
	1364510935264 -> 1364510934832
	1364428953968 [label="features.denseblock2.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	1364428953968 -> 1364510935264
	1364510935264 [label=AccumulateGrad]
	1364510935360 -> 1364510943136
	1364428954352 [label="features.denseblock2.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428954352 -> 1364510935360
	1364510935360 [label=AccumulateGrad]
	1364510943232 -> 1364510943712
	1364510943232 [label=ConvolutionBackward0]
	1364510934544 -> 1364510943232
	1364510934544 [label=ReluBackward0]
	1364510933632 -> 1364510934544
	1364510933632 [label=CudnnBatchNormBackward0]
	1364510933872 -> 1364510933632
	1364510933872 [label=ConvolutionBackward0]
	1364510933440 -> 1364510933872
	1364510933440 [label=ReluBackward0]
	1364510933200 -> 1364510933440
	1364510933200 [label=CudnnBatchNormBackward0]
	1364510933152 -> 1364510933200
	1364510933152 [label=CatBackward0]
	1364510943328 -> 1364510933152
	1364510943472 -> 1364510933152
	1364510943520 -> 1364510933152
	1364510943136 -> 1364510933152
	1364510933344 -> 1364510933200
	1364428954448 [label="features.denseblock2.denselayer4.norm1.weight
 (224)" fillcolor=lightblue]
	1364428954448 -> 1364510933344
	1364510933344 [label=AccumulateGrad]
	1364510933296 -> 1364510933200
	1364428954544 [label="features.denseblock2.denselayer4.norm1.bias
 (224)" fillcolor=lightblue]
	1364428954544 -> 1364510933296
	1364510933296 [label=AccumulateGrad]
	1364510933488 -> 1364510933872
	1364428954928 [label="features.denseblock2.denselayer4.conv1.weight
 (128, 224, 1, 1)" fillcolor=lightblue]
	1364428954928 -> 1364510933488
	1364510933488 [label=AccumulateGrad]
	1364510934304 -> 1364510933632
	1364428955024 [label="features.denseblock2.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	1364428955024 -> 1364510934304
	1364510934304 [label=AccumulateGrad]
	1364510934352 -> 1364510933632
	1364428955120 [label="features.denseblock2.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	1364428955120 -> 1364510934352
	1364510934352 [label=AccumulateGrad]
	1364510934160 -> 1364510943232
	1364428955504 [label="features.denseblock2.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428955504 -> 1364510934160
	1364510934160 [label=AccumulateGrad]
	1364510943376 -> 1364510943712
	1364510943376 [label=ConvolutionBackward0]
	1364510933728 -> 1364510943376
	1364510933728 [label=ReluBackward0]
	1364510933104 -> 1364510933728
	1364510933104 [label=CudnnBatchNormBackward0]
	1364510933680 -> 1364510933104
	1364510933680 [label=ConvolutionBackward0]
	1364510866352 -> 1364510933680
	1364510866352 [label=ReluBackward0]
	1364510865152 -> 1364510866352
	1364510865152 [label=CudnnBatchNormBackward0]
	1364510864624 -> 1364510865152
	1364510864624 [label=CatBackward0]
	1364510943328 -> 1364510864624
	1364510943472 -> 1364510864624
	1364510943520 -> 1364510864624
	1364510943136 -> 1364510864624
	1364510943232 -> 1364510864624
	1364510865296 -> 1364510865152
	1364428955600 [label="features.denseblock2.denselayer5.norm1.weight
 (256)" fillcolor=lightblue]
	1364428955600 -> 1364510865296
	1364510865296 [label=AccumulateGrad]
	1364510865680 -> 1364510865152
	1364428955696 [label="features.denseblock2.denselayer5.norm1.bias
 (256)" fillcolor=lightblue]
	1364428955696 -> 1364510865680
	1364510865680 [label=AccumulateGrad]
	1364510866208 -> 1364510933680
	1364428956080 [label="features.denseblock2.denselayer5.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	1364428956080 -> 1364510866208
	1364510866208 [label=AccumulateGrad]
	1364510867408 -> 1364510933104
	1364428956176 [label="features.denseblock2.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	1364428956176 -> 1364510867408
	1364510867408 [label=AccumulateGrad]
	1364510866736 -> 1364510933104
	1364428956272 [label="features.denseblock2.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	1364428956272 -> 1364510866736
	1364510866736 [label=AccumulateGrad]
	1364510933776 -> 1364510943376
	1364428956656 [label="features.denseblock2.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428956656 -> 1364510933776
	1364510933776 [label=AccumulateGrad]
	1364510943184 -> 1364510943712
	1364510943184 [label=ConvolutionBackward0]
	1364510933248 -> 1364510943184
	1364510933248 [label=ReluBackward0]
	1364510864768 -> 1364510933248
	1364510864768 [label=CudnnBatchNormBackward0]
	1364510864240 -> 1364510864768
	1364510864240 [label=ConvolutionBackward0]
	1364510863184 -> 1364510864240
	1364510863184 [label=ReluBackward0]
	1364510861984 -> 1364510863184
	1364510861984 [label=CudnnBatchNormBackward0]
	1364510861456 -> 1364510861984
	1364510861456 [label=CatBackward0]
	1364510943328 -> 1364510861456
	1364510943472 -> 1364510861456
	1364510943520 -> 1364510861456
	1364510943136 -> 1364510861456
	1364510943232 -> 1364510861456
	1364510943376 -> 1364510861456
	1364510862128 -> 1364510861984
	1364428956752 [label="features.denseblock2.denselayer6.norm1.weight
 (288)" fillcolor=lightblue]
	1364428956752 -> 1364510862128
	1364510862128 [label=AccumulateGrad]
	1364510862512 -> 1364510861984
	1364428956848 [label="features.denseblock2.denselayer6.norm1.bias
 (288)" fillcolor=lightblue]
	1364428956848 -> 1364510862512
	1364510862512 [label=AccumulateGrad]
	1364510863040 -> 1364510864240
	1364428957232 [label="features.denseblock2.denselayer6.conv1.weight
 (128, 288, 1, 1)" fillcolor=lightblue]
	1364428957232 -> 1364510863040
	1364510863040 [label=AccumulateGrad]
	1364510865824 -> 1364510864768
	1364428957328 [label="features.denseblock2.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	1364428957328 -> 1364510865824
	1364510865824 [label=AccumulateGrad]
	1364510867264 -> 1364510864768
	1364428957424 [label="features.denseblock2.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	1364428957424 -> 1364510867264
	1364510867264 [label=AccumulateGrad]
	1364510942752 -> 1364510943184
	1364428957808 [label="features.denseblock2.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428957808 -> 1364510942752
	1364510942752 [label=AccumulateGrad]
	1364510943280 -> 1364510943712
	1364510943280 [label=ConvolutionBackward0]
	1364510864096 -> 1364510943280
	1364510864096 [label=ReluBackward0]
	1364510861600 -> 1364510864096
	1364510861600 [label=CudnnBatchNormBackward0]
	1364510861072 -> 1364510861600
	1364510861072 [label=ConvolutionBackward0]
	1364510860016 -> 1364510861072
	1364510860016 [label=ReluBackward0]
	1364510858816 -> 1364510860016
	1364510858816 [label=CudnnBatchNormBackward0]
	1364510858288 -> 1364510858816
	1364510858288 [label=CatBackward0]
	1364510943328 -> 1364510858288
	1364510943472 -> 1364510858288
	1364510943520 -> 1364510858288
	1364510943136 -> 1364510858288
	1364510943232 -> 1364510858288
	1364510943376 -> 1364510858288
	1364510943184 -> 1364510858288
	1364510858960 -> 1364510858816
	1364428957904 [label="features.denseblock2.denselayer7.norm1.weight
 (320)" fillcolor=lightblue]
	1364428957904 -> 1364510858960
	1364510858960 [label=AccumulateGrad]
	1364510859344 -> 1364510858816
	1364428958000 [label="features.denseblock2.denselayer7.norm1.bias
 (320)" fillcolor=lightblue]
	1364428958000 -> 1364510859344
	1364510859344 [label=AccumulateGrad]
	1364510859872 -> 1364510861072
	1364428958384 [label="features.denseblock2.denselayer7.conv1.weight
 (128, 320, 1, 1)" fillcolor=lightblue]
	1364428958384 -> 1364510859872
	1364510859872 [label=AccumulateGrad]
	1364510862656 -> 1364510861600
	1364428958480 [label="features.denseblock2.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	1364428958480 -> 1364510862656
	1364510862656 [label=AccumulateGrad]
	1364510863568 -> 1364510861600
	1364428958576 [label="features.denseblock2.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	1364428958576 -> 1364510863568
	1364510863568 [label=AccumulateGrad]
	1364510863712 -> 1364510943280
	1364428958960 [label="features.denseblock2.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428958960 -> 1364510863712
	1364510863712 [label=AccumulateGrad]
	1364510942992 -> 1364510943712
	1364510942992 [label=ConvolutionBackward0]
	1364510860928 -> 1364510942992
	1364510860928 [label=ReluBackward0]
	1364510858432 -> 1364510860928
	1364510858432 [label=CudnnBatchNormBackward0]
	1364510857904 -> 1364510858432
	1364510857904 [label=ConvolutionBackward0]
	1364510856848 -> 1364510857904
	1364510856848 [label=ReluBackward0]
	1364510855648 -> 1364510856848
	1364510855648 [label=CudnnBatchNormBackward0]
	1364510855120 -> 1364510855648
	1364510855120 [label=CatBackward0]
	1364510943328 -> 1364510855120
	1364510943472 -> 1364510855120
	1364510943520 -> 1364510855120
	1364510943136 -> 1364510855120
	1364510943232 -> 1364510855120
	1364510943376 -> 1364510855120
	1364510943184 -> 1364510855120
	1364510943280 -> 1364510855120
	1364510855792 -> 1364510855648
	1364428959056 [label="features.denseblock2.denselayer8.norm1.weight
 (352)" fillcolor=lightblue]
	1364428959056 -> 1364510855792
	1364510855792 [label=AccumulateGrad]
	1364510856176 -> 1364510855648
	1364428959152 [label="features.denseblock2.denselayer8.norm1.bias
 (352)" fillcolor=lightblue]
	1364428959152 -> 1364510856176
	1364510856176 [label=AccumulateGrad]
	1364510856704 -> 1364510857904
	1364428959536 [label="features.denseblock2.denselayer8.conv1.weight
 (128, 352, 1, 1)" fillcolor=lightblue]
	1364428959536 -> 1364510856704
	1364510856704 [label=AccumulateGrad]
	1364510859488 -> 1364510858432
	1364428959632 [label="features.denseblock2.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	1364428959632 -> 1364510859488
	1364510859488 [label=AccumulateGrad]
	1364510860400 -> 1364510858432
	1364428959728 [label="features.denseblock2.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	1364428959728 -> 1364510860400
	1364510860400 [label=AccumulateGrad]
	1364510860544 -> 1364510942992
	1364428960112 [label="features.denseblock2.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428960112 -> 1364510860544
	1364510860544 [label=AccumulateGrad]
	1364510942944 -> 1364510943712
	1364510942944 [label=ConvolutionBackward0]
	1364510857760 -> 1364510942944
	1364510857760 [label=ReluBackward0]
	1364510855264 -> 1364510857760
	1364510855264 [label=CudnnBatchNormBackward0]
	1364510854736 -> 1364510855264
	1364510854736 [label=ConvolutionBackward0]
	1364510853680 -> 1364510854736
	1364510853680 [label=ReluBackward0]
	1364510852480 -> 1364510853680
	1364510852480 [label=CudnnBatchNormBackward0]
	1364510851952 -> 1364510852480
	1364510851952 [label=CatBackward0]
	1364510943328 -> 1364510851952
	1364510943472 -> 1364510851952
	1364510943520 -> 1364510851952
	1364510943136 -> 1364510851952
	1364510943232 -> 1364510851952
	1364510943376 -> 1364510851952
	1364510943184 -> 1364510851952
	1364510943280 -> 1364510851952
	1364510942992 -> 1364510851952
	1364510852624 -> 1364510852480
	1364428960208 [label="features.denseblock2.denselayer9.norm1.weight
 (384)" fillcolor=lightblue]
	1364428960208 -> 1364510852624
	1364510852624 [label=AccumulateGrad]
	1364510853008 -> 1364510852480
	1364428960304 [label="features.denseblock2.denselayer9.norm1.bias
 (384)" fillcolor=lightblue]
	1364428960304 -> 1364510853008
	1364510853008 [label=AccumulateGrad]
	1364510853536 -> 1364510854736
	1364428960688 [label="features.denseblock2.denselayer9.conv1.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	1364428960688 -> 1364510853536
	1364510853536 [label=AccumulateGrad]
	1364510856320 -> 1364510855264
	1364428960784 [label="features.denseblock2.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	1364428960784 -> 1364510856320
	1364510856320 [label=AccumulateGrad]
	1364510857232 -> 1364510855264
	1364428960880 [label="features.denseblock2.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	1364428960880 -> 1364510857232
	1364510857232 [label=AccumulateGrad]
	1364510857376 -> 1364510942944
	1364428961264 [label="features.denseblock2.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428961264 -> 1364510857376
	1364510857376 [label=AccumulateGrad]
	1364510942800 -> 1364510943712
	1364510942800 [label=ConvolutionBackward0]
	1364510854592 -> 1364510942800
	1364510854592 [label=ReluBackward0]
	1364510852096 -> 1364510854592
	1364510852096 [label=CudnnBatchNormBackward0]
	1364510851568 -> 1364510852096
	1364510851568 [label=ConvolutionBackward0]
	1364510866976 -> 1364510851568
	1364510866976 [label=ReluBackward0]
	1364510867024 -> 1364510866976
	1364510867024 [label=CudnnBatchNormBackward0]
	1364510866832 -> 1364510867024
	1364510866832 [label=CatBackward0]
	1364510943328 -> 1364510866832
	1364510943472 -> 1364510866832
	1364510943520 -> 1364510866832
	1364510943136 -> 1364510866832
	1364510943232 -> 1364510866832
	1364510943376 -> 1364510866832
	1364510943184 -> 1364510866832
	1364510943280 -> 1364510866832
	1364510942992 -> 1364510866832
	1364510942944 -> 1364510866832
	1364510867120 -> 1364510867024
	1364428961360 [label="features.denseblock2.denselayer10.norm1.weight
 (416)" fillcolor=lightblue]
	1364428961360 -> 1364510867120
	1364510867120 [label=AccumulateGrad]
	1364510867072 -> 1364510867024
	1364428961456 [label="features.denseblock2.denselayer10.norm1.bias
 (416)" fillcolor=lightblue]
	1364428961456 -> 1364510867072
	1364510867072 [label=AccumulateGrad]
	1364510867168 -> 1364510851568
	1364428961840 [label="features.denseblock2.denselayer10.conv1.weight
 (128, 416, 1, 1)" fillcolor=lightblue]
	1364428961840 -> 1364510867168
	1364510867168 [label=AccumulateGrad]
	1364510853152 -> 1364510852096
	1364428961936 [label="features.denseblock2.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	1364428961936 -> 1364510853152
	1364510853152 [label=AccumulateGrad]
	1364510854064 -> 1364510852096
	1364428962032 [label="features.denseblock2.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	1364428962032 -> 1364510854064
	1364510854064 [label=AccumulateGrad]
	1364510854208 -> 1364510942800
	1364428962416 [label="features.denseblock2.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428962416 -> 1364510854208
	1364510854208 [label=AccumulateGrad]
	1364510942608 -> 1364510943712
	1364510942608 [label=ConvolutionBackward0]
	1364510851424 -> 1364510942608
	1364510851424 [label=ReluBackward0]
	1364510866784 -> 1364510851424
	1364510866784 [label=CudnnBatchNormBackward0]
	1364510866448 -> 1364510866784
	1364510866448 [label=ConvolutionBackward0]
	1364510866592 -> 1364510866448
	1364510866592 [label=ReluBackward0]
	1364510866112 -> 1364510866592
	1364510866112 [label=CudnnBatchNormBackward0]
	1364510866016 -> 1364510866112
	1364510866016 [label=CatBackward0]
	1364510943328 -> 1364510866016
	1364510943472 -> 1364510866016
	1364510943520 -> 1364510866016
	1364510943136 -> 1364510866016
	1364510943232 -> 1364510866016
	1364510943376 -> 1364510866016
	1364510943184 -> 1364510866016
	1364510943280 -> 1364510866016
	1364510942992 -> 1364510866016
	1364510942944 -> 1364510866016
	1364510942800 -> 1364510866016
	1364510865920 -> 1364510866112
	1364428962512 [label="features.denseblock2.denselayer11.norm1.weight
 (448)" fillcolor=lightblue]
	1364428962512 -> 1364510865920
	1364510865920 [label=AccumulateGrad]
	1364510866304 -> 1364510866112
	1364428962608 [label="features.denseblock2.denselayer11.norm1.bias
 (448)" fillcolor=lightblue]
	1364428962608 -> 1364510866304
	1364510866304 [label=AccumulateGrad]
	1364510866496 -> 1364510866448
	1364428962992 [label="features.denseblock2.denselayer11.conv1.weight
 (128, 448, 1, 1)" fillcolor=lightblue]
	1364428962992 -> 1364510866496
	1364510866496 [label=AccumulateGrad]
	1364510867216 -> 1364510866784
	1364428963088 [label="features.denseblock2.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	1364428963088 -> 1364510867216
	1364510867216 [label=AccumulateGrad]
	1364510867360 -> 1364510866784
	1364428963184 [label="features.denseblock2.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	1364428963184 -> 1364510867360
	1364510867360 [label=AccumulateGrad]
	1364510867312 -> 1364510942608
	1364428963568 [label="features.denseblock2.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364428963568 -> 1364510867312
	1364510867312 [label=AccumulateGrad]
	1364510942704 -> 1364510943712
	1364510942704 [label=ConvolutionBackward0]
	1364510866640 -> 1364510942704
	1364510866640 [label=ReluBackward0]
	1364510866160 -> 1364510866640
	1364510866160 [label=CudnnBatchNormBackward0]
	1364510866064 -> 1364510866160
	1364510866064 [label=ConvolutionBackward0]
	1364510865392 -> 1364510866064
	1364510865392 [label=ReluBackward0]
	1364510865440 -> 1364510865392
	1364510865440 [label=CudnnBatchNormBackward0]
	1364510865248 -> 1364510865440
	1364510865248 [label=CatBackward0]
	1364510943328 -> 1364510865248
	1364510943472 -> 1364510865248
	1364510943520 -> 1364510865248
	1364510943136 -> 1364510865248
	1364510943232 -> 1364510865248
	1364510943376 -> 1364510865248
	1364510943184 -> 1364510865248
	1364510943280 -> 1364510865248
	1364510942992 -> 1364510865248
	1364510942944 -> 1364510865248
	1364510942800 -> 1364510865248
	1364510942608 -> 1364510865248
	1364510865536 -> 1364510865440
	1364428963664 [label="features.denseblock2.denselayer12.norm1.weight
 (480)" fillcolor=lightblue]
	1364428963664 -> 1364510865536
	1364510865536 [label=AccumulateGrad]
	1364510865488 -> 1364510865440
	1364428963760 [label="features.denseblock2.denselayer12.norm1.bias
 (480)" fillcolor=lightblue]
	1364428963760 -> 1364510865488
	1364510865488 [label=AccumulateGrad]
	1364510865584 -> 1364510866064
	1364429259120 [label="features.denseblock2.denselayer12.conv1.weight
 (128, 480, 1, 1)" fillcolor=lightblue]
	1364429259120 -> 1364510865584
	1364510865584 [label=AccumulateGrad]
	1364510866256 -> 1364510866160
	1364429259216 [label="features.denseblock2.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	1364429259216 -> 1364510866256
	1364510866256 [label=AccumulateGrad]
	1364510866544 -> 1364510866160
	1364429259312 [label="features.denseblock2.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	1364429259312 -> 1364510866544
	1364510866544 [label=AccumulateGrad]
	1364510866688 -> 1364510942704
	1364429259696 [label="features.denseblock2.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429259696 -> 1364510866688
	1364510866688 [label=AccumulateGrad]
	1364510943904 -> 1364510943760
	1364429259792 [label="features.transition2.norm.weight
 (512)" fillcolor=lightblue]
	1364429259792 -> 1364510943904
	1364510943904 [label=AccumulateGrad]
	1364510943856 -> 1364510943760
	1364429259888 [label="features.transition2.norm.bias
 (512)" fillcolor=lightblue]
	1364429259888 -> 1364510943856
	1364510943856 [label=AccumulateGrad]
	1364510944048 -> 1364510944336
	1364429260272 [label="features.transition2.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	1364429260272 -> 1364510944048
	1364510944048 [label=AccumulateGrad]
	1364510934448 -> 1364510935648
	1364510934448 [label=ConvolutionBackward0]
	1364510942848 -> 1364510934448
	1364510942848 [label=ReluBackward0]
	1364510943664 -> 1364510942848
	1364510943664 [label=CudnnBatchNormBackward0]
	1364510865968 -> 1364510943664
	1364510865968 [label=ConvolutionBackward0]
	1364510865632 -> 1364510865968
	1364510865632 [label=ReluBackward0]
	1364510865104 -> 1364510865632
	1364510865104 [label=CudnnBatchNormBackward0]
	1364510865008 -> 1364510865104
	1364510865008 [label=CatBackward0]
	1364510934592 -> 1364510865008
	1364510864912 -> 1364510865104
	1364429260368 [label="features.denseblock3.denselayer1.norm1.weight
 (256)" fillcolor=lightblue]
	1364429260368 -> 1364510864912
	1364510864912 [label=AccumulateGrad]
	1364510864864 -> 1364510865104
	1364429260464 [label="features.denseblock3.denselayer1.norm1.bias
 (256)" fillcolor=lightblue]
	1364429260464 -> 1364510864864
	1364510864864 [label=AccumulateGrad]
	1364510865200 -> 1364510865968
	1364429260848 [label="features.denseblock3.denselayer1.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	1364429260848 -> 1364510865200
	1364510865200 [label=AccumulateGrad]
	1364510865728 -> 1364510943664
	1364429260944 [label="features.denseblock3.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	1364429260944 -> 1364510865728
	1364510865728 [label=AccumulateGrad]
	1364510866880 -> 1364510943664
	1364429261040 [label="features.denseblock3.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	1364429261040 -> 1364510866880
	1364510866880 [label=AccumulateGrad]
	1364510944432 -> 1364510934448
	1364429261424 [label="features.denseblock3.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429261424 -> 1364510944432
	1364510944432 [label=AccumulateGrad]
	1364510935120 -> 1364510935648
	1364510935120 [label=ConvolutionBackward0]
	1364510943808 -> 1364510935120
	1364510943808 [label=ReluBackward0]
	1364510864720 -> 1364510943808
	1364510864720 [label=CudnnBatchNormBackward0]
	1364510864528 -> 1364510864720
	1364510864528 [label=ConvolutionBackward0]
	1364510864384 -> 1364510864528
	1364510864384 [label=ReluBackward0]
	1364510864144 -> 1364510864384
	1364510864144 [label=CudnnBatchNormBackward0]
	1364510863808 -> 1364510864144
	1364510863808 [label=CatBackward0]
	1364510934592 -> 1364510863808
	1364510934448 -> 1364510863808
	1364510864000 -> 1364510864144
	1364429261520 [label="features.denseblock3.denselayer2.norm1.weight
 (288)" fillcolor=lightblue]
	1364429261520 -> 1364510864000
	1364510864000 [label=AccumulateGrad]
	1364510864480 -> 1364510864144
	1364429261616 [label="features.denseblock3.denselayer2.norm1.bias
 (288)" fillcolor=lightblue]
	1364429261616 -> 1364510864480
	1364510864480 [label=AccumulateGrad]
	1364510864576 -> 1364510864528
	1364429262000 [label="features.denseblock3.denselayer2.conv1.weight
 (128, 288, 1, 1)" fillcolor=lightblue]
	1364429262000 -> 1364510864576
	1364510864576 [label=AccumulateGrad]
	1364510865056 -> 1364510864720
	1364429262096 [label="features.denseblock3.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	1364429262096 -> 1364510865056
	1364510865056 [label=AccumulateGrad]
	1364510865776 -> 1364510864720
	1364429262192 [label="features.denseblock3.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	1364429262192 -> 1364510865776
	1364510865776 [label=AccumulateGrad]
	1364510944240 -> 1364510935120
	1364429262576 [label="features.denseblock3.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429262576 -> 1364510944240
	1364510944240 [label=AccumulateGrad]
	1364510933920 -> 1364510935648
	1364510933920 [label=ConvolutionBackward0]
	1364510864672 -> 1364510933920
	1364510864672 [label=ReluBackward0]
	1364510863904 -> 1364510864672
	1364510863904 [label=CudnnBatchNormBackward0]
	1364510863856 -> 1364510863904
	1364510863856 [label=ConvolutionBackward0]
	1364510863472 -> 1364510863856
	1364510863472 [label=ReluBackward0]
	1364510863520 -> 1364510863472
	1364510863520 [label=CudnnBatchNormBackward0]
	1364510863424 -> 1364510863520
	1364510863424 [label=CatBackward0]
	1364510934592 -> 1364510863424
	1364510934448 -> 1364510863424
	1364510935120 -> 1364510863424
	1364510863328 -> 1364510863520
	1364429262672 [label="features.denseblock3.denselayer3.norm1.weight
 (320)" fillcolor=lightblue]
	1364429262672 -> 1364510863328
	1364510863328 [label=AccumulateGrad]
	1364510863280 -> 1364510863520
	1364429262768 [label="features.denseblock3.denselayer3.norm1.bias
 (320)" fillcolor=lightblue]
	1364429262768 -> 1364510863280
	1364510863280 [label=AccumulateGrad]
	1364510863616 -> 1364510863856
	1364429263152 [label="features.denseblock3.denselayer3.conv1.weight
 (128, 320, 1, 1)" fillcolor=lightblue]
	1364429263152 -> 1364510863616
	1364510863616 [label=AccumulateGrad]
	1364510864192 -> 1364510863904
	1364429263248 [label="features.denseblock3.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	1364429263248 -> 1364510864192
	1364510864192 [label=AccumulateGrad]
	1364510864336 -> 1364510863904
	1364429263344 [label="features.denseblock3.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	1364429263344 -> 1364510864336
	1364510864336 [label=AccumulateGrad]
	1364510864432 -> 1364510933920
	1364429263728 [label="features.denseblock3.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429263728 -> 1364510864432
	1364510864432 [label=AccumulateGrad]
	1364510934064 -> 1364510935648
	1364510934064 [label=ConvolutionBackward0]
	1364510864048 -> 1364510934064
	1364510864048 [label=ReluBackward0]
	1364510863136 -> 1364510864048
	1364510863136 [label=CudnnBatchNormBackward0]
	1364510862944 -> 1364510863136
	1364510862944 [label=ConvolutionBackward0]
	1364510862800 -> 1364510862944
	1364510862800 [label=ReluBackward0]
	1364510862560 -> 1364510862800
	1364510862560 [label=CudnnBatchNormBackward0]
	1364510862224 -> 1364510862560
	1364510862224 [label=CatBackward0]
	1364510934592 -> 1364510862224
	1364510934448 -> 1364510862224
	1364510935120 -> 1364510862224
	1364510933920 -> 1364510862224
	1364510862416 -> 1364510862560
	1364429263824 [label="features.denseblock3.denselayer4.norm1.weight
 (352)" fillcolor=lightblue]
	1364429263824 -> 1364510862416
	1364510862416 [label=AccumulateGrad]
	1364510862896 -> 1364510862560
	1364429263920 [label="features.denseblock3.denselayer4.norm1.bias
 (352)" fillcolor=lightblue]
	1364429263920 -> 1364510862896
	1364510862896 [label=AccumulateGrad]
	1364510862992 -> 1364510862944
	1364429264304 [label="features.denseblock3.denselayer4.conv1.weight
 (128, 352, 1, 1)" fillcolor=lightblue]
	1364429264304 -> 1364510862992
	1364510862992 [label=AccumulateGrad]
	1364510863376 -> 1364510863136
	1364429264400 [label="features.denseblock3.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	1364429264400 -> 1364510863376
	1364510863376 [label=AccumulateGrad]
	1364510863952 -> 1364510863136
	1364429264496 [label="features.denseblock3.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	1364429264496 -> 1364510863952
	1364510863952 [label=AccumulateGrad]
	1364510863664 -> 1364510934064
	1364429264880 [label="features.denseblock3.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429264880 -> 1364510863664
	1364510863664 [label=AccumulateGrad]
	1364510933392 -> 1364510935648
	1364510933392 [label=ConvolutionBackward0]
	1364510863088 -> 1364510933392
	1364510863088 [label=ReluBackward0]
	1364510862320 -> 1364510863088
	1364510862320 [label=CudnnBatchNormBackward0]
	1364510862272 -> 1364510862320
	1364510862272 [label=ConvolutionBackward0]
	1364510861888 -> 1364510862272
	1364510861888 [label=ReluBackward0]
	1364510861936 -> 1364510861888
	1364510861936 [label=CudnnBatchNormBackward0]
	1364510861840 -> 1364510861936
	1364510861840 [label=CatBackward0]
	1364510934592 -> 1364510861840
	1364510934448 -> 1364510861840
	1364510935120 -> 1364510861840
	1364510933920 -> 1364510861840
	1364510934064 -> 1364510861840
	1364510861744 -> 1364510861936
	1364429264976 [label="features.denseblock3.denselayer5.norm1.weight
 (384)" fillcolor=lightblue]
	1364429264976 -> 1364510861744
	1364510861744 [label=AccumulateGrad]
	1364510861696 -> 1364510861936
	1364429265072 [label="features.denseblock3.denselayer5.norm1.bias
 (384)" fillcolor=lightblue]
	1364429265072 -> 1364510861696
	1364510861696 [label=AccumulateGrad]
	1364510862032 -> 1364510862272
	1364429265456 [label="features.denseblock3.denselayer5.conv1.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	1364429265456 -> 1364510862032
	1364510862032 [label=AccumulateGrad]
	1364510862608 -> 1364510862320
	1364429265552 [label="features.denseblock3.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	1364429265552 -> 1364510862608
	1364510862608 [label=AccumulateGrad]
	1364510862752 -> 1364510862320
	1364429265648 [label="features.denseblock3.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	1364429265648 -> 1364510862752
	1364510862752 [label=AccumulateGrad]
	1364510862848 -> 1364510933392
	1364429266032 [label="features.denseblock3.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429266032 -> 1364510862848
	1364510862848 [label=AccumulateGrad]
	1364510933536 -> 1364510935648
	1364510933536 [label=ConvolutionBackward0]
	1364510862464 -> 1364510933536
	1364510862464 [label=ReluBackward0]
	1364510861552 -> 1364510862464
	1364510861552 [label=CudnnBatchNormBackward0]
	1364510861360 -> 1364510861552
	1364510861360 [label=ConvolutionBackward0]
	1364510861216 -> 1364510861360
	1364510861216 [label=ReluBackward0]
	1364510860976 -> 1364510861216
	1364510860976 [label=CudnnBatchNormBackward0]
	1364510860640 -> 1364510860976
	1364510860640 [label=CatBackward0]
	1364510934592 -> 1364510860640
	1364510934448 -> 1364510860640
	1364510935120 -> 1364510860640
	1364510933920 -> 1364510860640
	1364510934064 -> 1364510860640
	1364510933392 -> 1364510860640
	1364510860832 -> 1364510860976
	1364429266128 [label="features.denseblock3.denselayer6.norm1.weight
 (416)" fillcolor=lightblue]
	1364429266128 -> 1364510860832
	1364510860832 [label=AccumulateGrad]
	1364510861312 -> 1364510860976
	1364429266224 [label="features.denseblock3.denselayer6.norm1.bias
 (416)" fillcolor=lightblue]
	1364429266224 -> 1364510861312
	1364510861312 [label=AccumulateGrad]
	1364510861408 -> 1364510861360
	1364429266608 [label="features.denseblock3.denselayer6.conv1.weight
 (128, 416, 1, 1)" fillcolor=lightblue]
	1364429266608 -> 1364510861408
	1364510861408 [label=AccumulateGrad]
	1364510861792 -> 1364510861552
	1364429266704 [label="features.denseblock3.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	1364429266704 -> 1364510861792
	1364510861792 [label=AccumulateGrad]
	1364510862368 -> 1364510861552
	1364429266800 [label="features.denseblock3.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	1364429266800 -> 1364510862368
	1364510862368 [label=AccumulateGrad]
	1364510862080 -> 1364510933536
	1364429267184 [label="features.denseblock3.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429267184 -> 1364510862080
	1364510862080 [label=AccumulateGrad]
	1364510949328 -> 1364510935648
	1364510949328 [label=ConvolutionBackward0]
	1364510861504 -> 1364510949328
	1364510861504 [label=ReluBackward0]
	1364510860736 -> 1364510861504
	1364510860736 [label=CudnnBatchNormBackward0]
	1364510860688 -> 1364510860736
	1364510860688 [label=ConvolutionBackward0]
	1364510860304 -> 1364510860688
	1364510860304 [label=ReluBackward0]
	1364510860352 -> 1364510860304
	1364510860352 [label=CudnnBatchNormBackward0]
	1364510860256 -> 1364510860352
	1364510860256 [label=CatBackward0]
	1364510934592 -> 1364510860256
	1364510934448 -> 1364510860256
	1364510935120 -> 1364510860256
	1364510933920 -> 1364510860256
	1364510934064 -> 1364510860256
	1364510933392 -> 1364510860256
	1364510933536 -> 1364510860256
	1364510860160 -> 1364510860352
	1364429267280 [label="features.denseblock3.denselayer7.norm1.weight
 (448)" fillcolor=lightblue]
	1364429267280 -> 1364510860160
	1364510860160 [label=AccumulateGrad]
	1364510860112 -> 1364510860352
	1364429267376 [label="features.denseblock3.denselayer7.norm1.bias
 (448)" fillcolor=lightblue]
	1364429267376 -> 1364510860112
	1364510860112 [label=AccumulateGrad]
	1364510860448 -> 1364510860688
	1364429267760 [label="features.denseblock3.denselayer7.conv1.weight
 (128, 448, 1, 1)" fillcolor=lightblue]
	1364429267760 -> 1364510860448
	1364510860448 [label=AccumulateGrad]
	1364510861024 -> 1364510860736
	1364429267856 [label="features.denseblock3.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	1364429267856 -> 1364510861024
	1364510861024 [label=AccumulateGrad]
	1364510861168 -> 1364510860736
	1364429267952 [label="features.denseblock3.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	1364429267952 -> 1364510861168
	1364510861168 [label=AccumulateGrad]
	1364510861264 -> 1364510949328
	1364429268336 [label="features.denseblock3.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429268336 -> 1364510861264
	1364510861264 [label=AccumulateGrad]
	1364510945248 -> 1364510935648
	1364510945248 [label=ConvolutionBackward0]
	1364510860880 -> 1364510945248
	1364510860880 [label=ReluBackward0]
	1364510859968 -> 1364510860880
	1364510859968 [label=CudnnBatchNormBackward0]
	1364510859776 -> 1364510859968
	1364510859776 [label=ConvolutionBackward0]
	1364510859632 -> 1364510859776
	1364510859632 [label=ReluBackward0]
	1364510859392 -> 1364510859632
	1364510859392 [label=CudnnBatchNormBackward0]
	1364510859056 -> 1364510859392
	1364510859056 [label=CatBackward0]
	1364510934592 -> 1364510859056
	1364510934448 -> 1364510859056
	1364510935120 -> 1364510859056
	1364510933920 -> 1364510859056
	1364510934064 -> 1364510859056
	1364510933392 -> 1364510859056
	1364510933536 -> 1364510859056
	1364510949328 -> 1364510859056
	1364510859248 -> 1364510859392
	1364429268432 [label="features.denseblock3.denselayer8.norm1.weight
 (480)" fillcolor=lightblue]
	1364429268432 -> 1364510859248
	1364510859248 [label=AccumulateGrad]
	1364510859728 -> 1364510859392
	1364429268528 [label="features.denseblock3.denselayer8.norm1.bias
 (480)" fillcolor=lightblue]
	1364429268528 -> 1364510859728
	1364510859728 [label=AccumulateGrad]
	1364510859824 -> 1364510859776
	1364429268912 [label="features.denseblock3.denselayer8.conv1.weight
 (128, 480, 1, 1)" fillcolor=lightblue]
	1364429268912 -> 1364510859824
	1364510859824 [label=AccumulateGrad]
	1364510860208 -> 1364510859968
	1364429269008 [label="features.denseblock3.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	1364429269008 -> 1364510860208
	1364510860208 [label=AccumulateGrad]
	1364510860784 -> 1364510859968
	1364429269104 [label="features.denseblock3.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	1364429269104 -> 1364510860784
	1364510860784 [label=AccumulateGrad]
	1364510860496 -> 1364510945248
	1364429269488 [label="features.denseblock3.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429269488 -> 1364510860496
	1364510860496 [label=AccumulateGrad]
	1364510945344 -> 1364510935648
	1364510945344 [label=ConvolutionBackward0]
	1364510859920 -> 1364510945344
	1364510859920 [label=ReluBackward0]
	1364510859152 -> 1364510859920
	1364510859152 [label=CudnnBatchNormBackward0]
	1364510859104 -> 1364510859152
	1364510859104 [label=ConvolutionBackward0]
	1364510858720 -> 1364510859104
	1364510858720 [label=ReluBackward0]
	1364510858768 -> 1364510858720
	1364510858768 [label=CudnnBatchNormBackward0]
	1364510858672 -> 1364510858768
	1364510858672 [label=CatBackward0]
	1364510934592 -> 1364510858672
	1364510934448 -> 1364510858672
	1364510935120 -> 1364510858672
	1364510933920 -> 1364510858672
	1364510934064 -> 1364510858672
	1364510933392 -> 1364510858672
	1364510933536 -> 1364510858672
	1364510949328 -> 1364510858672
	1364510945248 -> 1364510858672
	1364510858576 -> 1364510858768
	1364429269584 [label="features.denseblock3.denselayer9.norm1.weight
 (512)" fillcolor=lightblue]
	1364429269584 -> 1364510858576
	1364510858576 [label=AccumulateGrad]
	1364510858528 -> 1364510858768
	1364429269680 [label="features.denseblock3.denselayer9.norm1.bias
 (512)" fillcolor=lightblue]
	1364429269680 -> 1364510858528
	1364510858528 [label=AccumulateGrad]
	1364510858864 -> 1364510859104
	1364429270064 [label="features.denseblock3.denselayer9.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1364429270064 -> 1364510858864
	1364510858864 [label=AccumulateGrad]
	1364510859440 -> 1364510859152
	1364429270160 [label="features.denseblock3.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	1364429270160 -> 1364510859440
	1364510859440 [label=AccumulateGrad]
	1364510859584 -> 1364510859152
	1364429270256 [label="features.denseblock3.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	1364429270256 -> 1364510859584
	1364510859584 [label=AccumulateGrad]
	1364510859680 -> 1364510945344
	1364429270640 [label="features.denseblock3.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429270640 -> 1364510859680
	1364510859680 [label=AccumulateGrad]
	1364510945488 -> 1364510935648
	1364510945488 [label=ConvolutionBackward0]
	1364510859296 -> 1364510945488
	1364510859296 [label=ReluBackward0]
	1364510858384 -> 1364510859296
	1364510858384 [label=CudnnBatchNormBackward0]
	1364510858192 -> 1364510858384
	1364510858192 [label=ConvolutionBackward0]
	1364510858048 -> 1364510858192
	1364510858048 [label=ReluBackward0]
	1364510857808 -> 1364510858048
	1364510857808 [label=CudnnBatchNormBackward0]
	1364510857472 -> 1364510857808
	1364510857472 [label=CatBackward0]
	1364510934592 -> 1364510857472
	1364510934448 -> 1364510857472
	1364510935120 -> 1364510857472
	1364510933920 -> 1364510857472
	1364510934064 -> 1364510857472
	1364510933392 -> 1364510857472
	1364510933536 -> 1364510857472
	1364510949328 -> 1364510857472
	1364510945248 -> 1364510857472
	1364510945344 -> 1364510857472
	1364510857664 -> 1364510857808
	1364429270736 [label="features.denseblock3.denselayer10.norm1.weight
 (544)" fillcolor=lightblue]
	1364429270736 -> 1364510857664
	1364510857664 [label=AccumulateGrad]
	1364510858144 -> 1364510857808
	1364429270832 [label="features.denseblock3.denselayer10.norm1.bias
 (544)" fillcolor=lightblue]
	1364429270832 -> 1364510858144
	1364510858144 [label=AccumulateGrad]
	1364510858240 -> 1364510858192
	1364429271216 [label="features.denseblock3.denselayer10.conv1.weight
 (128, 544, 1, 1)" fillcolor=lightblue]
	1364429271216 -> 1364510858240
	1364510858240 [label=AccumulateGrad]
	1364510858624 -> 1364510858384
	1364429271312 [label="features.denseblock3.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	1364429271312 -> 1364510858624
	1364510858624 [label=AccumulateGrad]
	1364510859200 -> 1364510858384
	1364429271408 [label="features.denseblock3.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	1364429271408 -> 1364510859200
	1364510859200 [label=AccumulateGrad]
	1364510858912 -> 1364510945488
	1364429271792 [label="features.denseblock3.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429271792 -> 1364510858912
	1364510858912 [label=AccumulateGrad]
	1364510945296 -> 1364510935648
	1364510945296 [label=ConvolutionBackward0]
	1364510858336 -> 1364510945296
	1364510858336 [label=ReluBackward0]
	1364510857568 -> 1364510858336
	1364510857568 [label=CudnnBatchNormBackward0]
	1364510857520 -> 1364510857568
	1364510857520 [label=ConvolutionBackward0]
	1364510857136 -> 1364510857520
	1364510857136 [label=ReluBackward0]
	1364510857184 -> 1364510857136
	1364510857184 [label=CudnnBatchNormBackward0]
	1364510857088 -> 1364510857184
	1364510857088 [label=CatBackward0]
	1364510934592 -> 1364510857088
	1364510934448 -> 1364510857088
	1364510935120 -> 1364510857088
	1364510933920 -> 1364510857088
	1364510934064 -> 1364510857088
	1364510933392 -> 1364510857088
	1364510933536 -> 1364510857088
	1364510949328 -> 1364510857088
	1364510945248 -> 1364510857088
	1364510945344 -> 1364510857088
	1364510945488 -> 1364510857088
	1364510856992 -> 1364510857184
	1364429271888 [label="features.denseblock3.denselayer11.norm1.weight
 (576)" fillcolor=lightblue]
	1364429271888 -> 1364510856992
	1364510856992 [label=AccumulateGrad]
	1364510856944 -> 1364510857184
	1364429271984 [label="features.denseblock3.denselayer11.norm1.bias
 (576)" fillcolor=lightblue]
	1364429271984 -> 1364510856944
	1364510856944 [label=AccumulateGrad]
	1364510857280 -> 1364510857520
	1364429272368 [label="features.denseblock3.denselayer11.conv1.weight
 (128, 576, 1, 1)" fillcolor=lightblue]
	1364429272368 -> 1364510857280
	1364510857280 [label=AccumulateGrad]
	1364510857856 -> 1364510857568
	1364429272464 [label="features.denseblock3.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	1364429272464 -> 1364510857856
	1364510857856 [label=AccumulateGrad]
	1364510858000 -> 1364510857568
	1364429272560 [label="features.denseblock3.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	1364429272560 -> 1364510858000
	1364510858000 [label=AccumulateGrad]
	1364510858096 -> 1364510945296
	1364429272944 [label="features.denseblock3.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429272944 -> 1364510858096
	1364510858096 [label=AccumulateGrad]
	1364510945392 -> 1364510935648
	1364510945392 [label=ConvolutionBackward0]
	1364510857712 -> 1364510945392
	1364510857712 [label=ReluBackward0]
	1364510856800 -> 1364510857712
	1364510856800 [label=CudnnBatchNormBackward0]
	1364510856608 -> 1364510856800
	1364510856608 [label=ConvolutionBackward0]
	1364510856464 -> 1364510856608
	1364510856464 [label=ReluBackward0]
	1364510856224 -> 1364510856464
	1364510856224 [label=CudnnBatchNormBackward0]
	1364510855888 -> 1364510856224
	1364510855888 [label=CatBackward0]
	1364510934592 -> 1364510855888
	1364510934448 -> 1364510855888
	1364510935120 -> 1364510855888
	1364510933920 -> 1364510855888
	1364510934064 -> 1364510855888
	1364510933392 -> 1364510855888
	1364510933536 -> 1364510855888
	1364510949328 -> 1364510855888
	1364510945248 -> 1364510855888
	1364510945344 -> 1364510855888
	1364510945488 -> 1364510855888
	1364510945296 -> 1364510855888
	1364510856080 -> 1364510856224
	1364429273040 [label="features.denseblock3.denselayer12.norm1.weight
 (608)" fillcolor=lightblue]
	1364429273040 -> 1364510856080
	1364510856080 [label=AccumulateGrad]
	1364510856560 -> 1364510856224
	1364429273136 [label="features.denseblock3.denselayer12.norm1.bias
 (608)" fillcolor=lightblue]
	1364429273136 -> 1364510856560
	1364510856560 [label=AccumulateGrad]
	1364510856656 -> 1364510856608
	1364429273520 [label="features.denseblock3.denselayer12.conv1.weight
 (128, 608, 1, 1)" fillcolor=lightblue]
	1364429273520 -> 1364510856656
	1364510856656 [label=AccumulateGrad]
	1364510857040 -> 1364510856800
	1364429273616 [label="features.denseblock3.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	1364429273616 -> 1364510857040
	1364510857040 [label=AccumulateGrad]
	1364510857616 -> 1364510856800
	1364429273712 [label="features.denseblock3.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	1364429273712 -> 1364510857616
	1364510857616 [label=AccumulateGrad]
	1364510857328 -> 1364510945392
	1364429274096 [label="features.denseblock3.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429274096 -> 1364510857328
	1364510857328 [label=AccumulateGrad]
	1364510945104 -> 1364510935648
	1364510945104 [label=ConvolutionBackward0]
	1364510856752 -> 1364510945104
	1364510856752 [label=ReluBackward0]
	1364510855984 -> 1364510856752
	1364510855984 [label=CudnnBatchNormBackward0]
	1364510855936 -> 1364510855984
	1364510855936 [label=ConvolutionBackward0]
	1364510855552 -> 1364510855936
	1364510855552 [label=ReluBackward0]
	1364510855600 -> 1364510855552
	1364510855600 [label=CudnnBatchNormBackward0]
	1364510855504 -> 1364510855600
	1364510855504 [label=CatBackward0]
	1364510934592 -> 1364510855504
	1364510934448 -> 1364510855504
	1364510935120 -> 1364510855504
	1364510933920 -> 1364510855504
	1364510934064 -> 1364510855504
	1364510933392 -> 1364510855504
	1364510933536 -> 1364510855504
	1364510949328 -> 1364510855504
	1364510945248 -> 1364510855504
	1364510945344 -> 1364510855504
	1364510945488 -> 1364510855504
	1364510945296 -> 1364510855504
	1364510945392 -> 1364510855504
	1364510855408 -> 1364510855600
	1364429274192 [label="features.denseblock3.denselayer13.norm1.weight
 (640)" fillcolor=lightblue]
	1364429274192 -> 1364510855408
	1364510855408 [label=AccumulateGrad]
	1364510855360 -> 1364510855600
	1364429274288 [label="features.denseblock3.denselayer13.norm1.bias
 (640)" fillcolor=lightblue]
	1364429274288 -> 1364510855360
	1364510855360 [label=AccumulateGrad]
	1364510855696 -> 1364510855936
	1364429274672 [label="features.denseblock3.denselayer13.conv1.weight
 (128, 640, 1, 1)" fillcolor=lightblue]
	1364429274672 -> 1364510855696
	1364510855696 [label=AccumulateGrad]
	1364510856272 -> 1364510855984
	1364429274768 [label="features.denseblock3.denselayer13.norm2.weight
 (128)" fillcolor=lightblue]
	1364429274768 -> 1364510856272
	1364510856272 [label=AccumulateGrad]
	1364510856416 -> 1364510855984
	1364429274864 [label="features.denseblock3.denselayer13.norm2.bias
 (128)" fillcolor=lightblue]
	1364429274864 -> 1364510856416
	1364510856416 [label=AccumulateGrad]
	1364510856512 -> 1364510945104
	1364429570224 [label="features.denseblock3.denselayer13.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429570224 -> 1364510856512
	1364510856512 [label=AccumulateGrad]
	1364510945056 -> 1364510935648
	1364510945056 [label=ConvolutionBackward0]
	1364510856128 -> 1364510945056
	1364510856128 [label=ReluBackward0]
	1364510855216 -> 1364510856128
	1364510855216 [label=CudnnBatchNormBackward0]
	1364510855024 -> 1364510855216
	1364510855024 [label=ConvolutionBackward0]
	1364510854880 -> 1364510855024
	1364510854880 [label=ReluBackward0]
	1364510854640 -> 1364510854880
	1364510854640 [label=CudnnBatchNormBackward0]
	1364510854304 -> 1364510854640
	1364510854304 [label=CatBackward0]
	1364510934592 -> 1364510854304
	1364510934448 -> 1364510854304
	1364510935120 -> 1364510854304
	1364510933920 -> 1364510854304
	1364510934064 -> 1364510854304
	1364510933392 -> 1364510854304
	1364510933536 -> 1364510854304
	1364510949328 -> 1364510854304
	1364510945248 -> 1364510854304
	1364510945344 -> 1364510854304
	1364510945488 -> 1364510854304
	1364510945296 -> 1364510854304
	1364510945392 -> 1364510854304
	1364510945104 -> 1364510854304
	1364510854496 -> 1364510854640
	1364429570320 [label="features.denseblock3.denselayer14.norm1.weight
 (672)" fillcolor=lightblue]
	1364429570320 -> 1364510854496
	1364510854496 [label=AccumulateGrad]
	1364510854976 -> 1364510854640
	1364429570416 [label="features.denseblock3.denselayer14.norm1.bias
 (672)" fillcolor=lightblue]
	1364429570416 -> 1364510854976
	1364510854976 [label=AccumulateGrad]
	1364510855072 -> 1364510855024
	1364429570800 [label="features.denseblock3.denselayer14.conv1.weight
 (128, 672, 1, 1)" fillcolor=lightblue]
	1364429570800 -> 1364510855072
	1364510855072 [label=AccumulateGrad]
	1364510855456 -> 1364510855216
	1364429570896 [label="features.denseblock3.denselayer14.norm2.weight
 (128)" fillcolor=lightblue]
	1364429570896 -> 1364510855456
	1364510855456 [label=AccumulateGrad]
	1364510856032 -> 1364510855216
	1364429570992 [label="features.denseblock3.denselayer14.norm2.bias
 (128)" fillcolor=lightblue]
	1364429570992 -> 1364510856032
	1364510856032 [label=AccumulateGrad]
	1364510855744 -> 1364510945056
	1364429571376 [label="features.denseblock3.denselayer14.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429571376 -> 1364510855744
	1364510855744 [label=AccumulateGrad]
	1364510944912 -> 1364510935648
	1364510944912 [label=ConvolutionBackward0]
	1364510855168 -> 1364510944912
	1364510855168 [label=ReluBackward0]
	1364510854400 -> 1364510855168
	1364510854400 [label=CudnnBatchNormBackward0]
	1364510854352 -> 1364510854400
	1364510854352 [label=ConvolutionBackward0]
	1364510853968 -> 1364510854352
	1364510853968 [label=ReluBackward0]
	1364510854016 -> 1364510853968
	1364510854016 [label=CudnnBatchNormBackward0]
	1364510853920 -> 1364510854016
	1364510853920 [label=CatBackward0]
	1364510934592 -> 1364510853920
	1364510934448 -> 1364510853920
	1364510935120 -> 1364510853920
	1364510933920 -> 1364510853920
	1364510934064 -> 1364510853920
	1364510933392 -> 1364510853920
	1364510933536 -> 1364510853920
	1364510949328 -> 1364510853920
	1364510945248 -> 1364510853920
	1364510945344 -> 1364510853920
	1364510945488 -> 1364510853920
	1364510945296 -> 1364510853920
	1364510945392 -> 1364510853920
	1364510945104 -> 1364510853920
	1364510945056 -> 1364510853920
	1364510853824 -> 1364510854016
	1364429571472 [label="features.denseblock3.denselayer15.norm1.weight
 (704)" fillcolor=lightblue]
	1364429571472 -> 1364510853824
	1364510853824 [label=AccumulateGrad]
	1364510853776 -> 1364510854016
	1364429571568 [label="features.denseblock3.denselayer15.norm1.bias
 (704)" fillcolor=lightblue]
	1364429571568 -> 1364510853776
	1364510853776 [label=AccumulateGrad]
	1364510854112 -> 1364510854352
	1364429571952 [label="features.denseblock3.denselayer15.conv1.weight
 (128, 704, 1, 1)" fillcolor=lightblue]
	1364429571952 -> 1364510854112
	1364510854112 [label=AccumulateGrad]
	1364510854688 -> 1364510854400
	1364429572048 [label="features.denseblock3.denselayer15.norm2.weight
 (128)" fillcolor=lightblue]
	1364429572048 -> 1364510854688
	1364510854688 [label=AccumulateGrad]
	1364510854832 -> 1364510854400
	1364429572144 [label="features.denseblock3.denselayer15.norm2.bias
 (128)" fillcolor=lightblue]
	1364429572144 -> 1364510854832
	1364510854832 [label=AccumulateGrad]
	1364510854928 -> 1364510944912
	1364429572528 [label="features.denseblock3.denselayer15.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429572528 -> 1364510854928
	1364510854928 [label=AccumulateGrad]
	1364510944720 -> 1364510935648
	1364510944720 [label=ConvolutionBackward0]
	1364510854544 -> 1364510944720
	1364510854544 [label=ReluBackward0]
	1364510853632 -> 1364510854544
	1364510853632 [label=CudnnBatchNormBackward0]
	1364510853440 -> 1364510853632
	1364510853440 [label=ConvolutionBackward0]
	1364510853296 -> 1364510853440
	1364510853296 [label=ReluBackward0]
	1364510853056 -> 1364510853296
	1364510853056 [label=CudnnBatchNormBackward0]
	1364510852720 -> 1364510853056
	1364510852720 [label=CatBackward0]
	1364510934592 -> 1364510852720
	1364510934448 -> 1364510852720
	1364510935120 -> 1364510852720
	1364510933920 -> 1364510852720
	1364510934064 -> 1364510852720
	1364510933392 -> 1364510852720
	1364510933536 -> 1364510852720
	1364510949328 -> 1364510852720
	1364510945248 -> 1364510852720
	1364510945344 -> 1364510852720
	1364510945488 -> 1364510852720
	1364510945296 -> 1364510852720
	1364510945392 -> 1364510852720
	1364510945104 -> 1364510852720
	1364510945056 -> 1364510852720
	1364510944912 -> 1364510852720
	1364510852912 -> 1364510853056
	1364429572624 [label="features.denseblock3.denselayer16.norm1.weight
 (736)" fillcolor=lightblue]
	1364429572624 -> 1364510852912
	1364510852912 [label=AccumulateGrad]
	1364510853392 -> 1364510853056
	1364429572720 [label="features.denseblock3.denselayer16.norm1.bias
 (736)" fillcolor=lightblue]
	1364429572720 -> 1364510853392
	1364510853392 [label=AccumulateGrad]
	1364510853488 -> 1364510853440
	1364429573104 [label="features.denseblock3.denselayer16.conv1.weight
 (128, 736, 1, 1)" fillcolor=lightblue]
	1364429573104 -> 1364510853488
	1364510853488 [label=AccumulateGrad]
	1364510853872 -> 1364510853632
	1364429573200 [label="features.denseblock3.denselayer16.norm2.weight
 (128)" fillcolor=lightblue]
	1364429573200 -> 1364510853872
	1364510853872 [label=AccumulateGrad]
	1364510854448 -> 1364510853632
	1364429573296 [label="features.denseblock3.denselayer16.norm2.bias
 (128)" fillcolor=lightblue]
	1364429573296 -> 1364510854448
	1364510854448 [label=AccumulateGrad]
	1364510854160 -> 1364510944720
	1364429573680 [label="features.denseblock3.denselayer16.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429573680 -> 1364510854160
	1364510854160 [label=AccumulateGrad]
	1364510944816 -> 1364510935648
	1364510944816 [label=ConvolutionBackward0]
	1364510853584 -> 1364510944816
	1364510853584 [label=ReluBackward0]
	1364510852816 -> 1364510853584
	1364510852816 [label=CudnnBatchNormBackward0]
	1364510852768 -> 1364510852816
	1364510852768 [label=ConvolutionBackward0]
	1364510852384 -> 1364510852768
	1364510852384 [label=ReluBackward0]
	1364510852432 -> 1364510852384
	1364510852432 [label=CudnnBatchNormBackward0]
	1364510852336 -> 1364510852432
	1364510852336 [label=CatBackward0]
	1364510934592 -> 1364510852336
	1364510934448 -> 1364510852336
	1364510935120 -> 1364510852336
	1364510933920 -> 1364510852336
	1364510934064 -> 1364510852336
	1364510933392 -> 1364510852336
	1364510933536 -> 1364510852336
	1364510949328 -> 1364510852336
	1364510945248 -> 1364510852336
	1364510945344 -> 1364510852336
	1364510945488 -> 1364510852336
	1364510945296 -> 1364510852336
	1364510945392 -> 1364510852336
	1364510945104 -> 1364510852336
	1364510945056 -> 1364510852336
	1364510944912 -> 1364510852336
	1364510944720 -> 1364510852336
	1364510852240 -> 1364510852432
	1364429573776 [label="features.denseblock3.denselayer17.norm1.weight
 (768)" fillcolor=lightblue]
	1364429573776 -> 1364510852240
	1364510852240 [label=AccumulateGrad]
	1364510852192 -> 1364510852432
	1364429573872 [label="features.denseblock3.denselayer17.norm1.bias
 (768)" fillcolor=lightblue]
	1364429573872 -> 1364510852192
	1364510852192 [label=AccumulateGrad]
	1364510852528 -> 1364510852768
	1364429574256 [label="features.denseblock3.denselayer17.conv1.weight
 (128, 768, 1, 1)" fillcolor=lightblue]
	1364429574256 -> 1364510852528
	1364510852528 [label=AccumulateGrad]
	1364510853104 -> 1364510852816
	1364429574352 [label="features.denseblock3.denselayer17.norm2.weight
 (128)" fillcolor=lightblue]
	1364429574352 -> 1364510853104
	1364510853104 [label=AccumulateGrad]
	1364510853248 -> 1364510852816
	1364429574448 [label="features.denseblock3.denselayer17.norm2.bias
 (128)" fillcolor=lightblue]
	1364429574448 -> 1364510853248
	1364510853248 [label=AccumulateGrad]
	1364510853344 -> 1364510944816
	1364429574832 [label="features.denseblock3.denselayer17.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429574832 -> 1364510853344
	1364510853344 [label=AccumulateGrad]
	1364510944960 -> 1364510935648
	1364510944960 [label=ConvolutionBackward0]
	1364510852960 -> 1364510944960
	1364510852960 [label=ReluBackward0]
	1364510852048 -> 1364510852960
	1364510852048 [label=CudnnBatchNormBackward0]
	1364510851856 -> 1364510852048
	1364510851856 [label=ConvolutionBackward0]
	1364510851712 -> 1364510851856
	1364510851712 [label=ReluBackward0]
	1364510851472 -> 1364510851712
	1364510851472 [label=CudnnBatchNormBackward0]
	1364510851136 -> 1364510851472
	1364510851136 [label=CatBackward0]
	1364510934592 -> 1364510851136
	1364510934448 -> 1364510851136
	1364510935120 -> 1364510851136
	1364510933920 -> 1364510851136
	1364510934064 -> 1364510851136
	1364510933392 -> 1364510851136
	1364510933536 -> 1364510851136
	1364510949328 -> 1364510851136
	1364510945248 -> 1364510851136
	1364510945344 -> 1364510851136
	1364510945488 -> 1364510851136
	1364510945296 -> 1364510851136
	1364510945392 -> 1364510851136
	1364510945104 -> 1364510851136
	1364510945056 -> 1364510851136
	1364510944912 -> 1364510851136
	1364510944720 -> 1364510851136
	1364510944816 -> 1364510851136
	1364510851328 -> 1364510851472
	1364429574928 [label="features.denseblock3.denselayer18.norm1.weight
 (800)" fillcolor=lightblue]
	1364429574928 -> 1364510851328
	1364510851328 [label=AccumulateGrad]
	1364510851808 -> 1364510851472
	1364429575024 [label="features.denseblock3.denselayer18.norm1.bias
 (800)" fillcolor=lightblue]
	1364429575024 -> 1364510851808
	1364510851808 [label=AccumulateGrad]
	1364510851904 -> 1364510851856
	1364429575408 [label="features.denseblock3.denselayer18.conv1.weight
 (128, 800, 1, 1)" fillcolor=lightblue]
	1364429575408 -> 1364510851904
	1364510851904 [label=AccumulateGrad]
	1364510852288 -> 1364510852048
	1364429575504 [label="features.denseblock3.denselayer18.norm2.weight
 (128)" fillcolor=lightblue]
	1364429575504 -> 1364510852288
	1364510852288 [label=AccumulateGrad]
	1364510852864 -> 1364510852048
	1364429575600 [label="features.denseblock3.denselayer18.norm2.bias
 (128)" fillcolor=lightblue]
	1364429575600 -> 1364510852864
	1364510852864 [label=AccumulateGrad]
	1364510852576 -> 1364510944960
	1364429575984 [label="features.denseblock3.denselayer18.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429575984 -> 1364510852576
	1364510852576 [label=AccumulateGrad]
	1364510944768 -> 1364510935648
	1364510944768 [label=ConvolutionBackward0]
	1364510852000 -> 1364510944768
	1364510852000 [label=ReluBackward0]
	1364510851232 -> 1364510852000
	1364510851232 [label=CudnnBatchNormBackward0]
	1364510851184 -> 1364510851232
	1364510851184 [label=ConvolutionBackward0]
	1364510784768 -> 1364510851184
	1364510784768 [label=ReluBackward0]
	1364510784384 -> 1364510784768
	1364510784384 [label=CudnnBatchNormBackward0]
	1364510783856 -> 1364510784384
	1364510783856 [label=CatBackward0]
	1364510934592 -> 1364510783856
	1364510934448 -> 1364510783856
	1364510935120 -> 1364510783856
	1364510933920 -> 1364510783856
	1364510934064 -> 1364510783856
	1364510933392 -> 1364510783856
	1364510933536 -> 1364510783856
	1364510949328 -> 1364510783856
	1364510945248 -> 1364510783856
	1364510945344 -> 1364510783856
	1364510945488 -> 1364510783856
	1364510945296 -> 1364510783856
	1364510945392 -> 1364510783856
	1364510945104 -> 1364510783856
	1364510945056 -> 1364510783856
	1364510944912 -> 1364510783856
	1364510944720 -> 1364510783856
	1364510944816 -> 1364510783856
	1364510944960 -> 1364510783856
	1364510783712 -> 1364510784384
	1364429576080 [label="features.denseblock3.denselayer19.norm1.weight
 (832)" fillcolor=lightblue]
	1364429576080 -> 1364510783712
	1364510783712 [label=AccumulateGrad]
	1364510784912 -> 1364510784384
	1364429576176 [label="features.denseblock3.denselayer19.norm1.bias
 (832)" fillcolor=lightblue]
	1364429576176 -> 1364510784912
	1364510784912 [label=AccumulateGrad]
	1364510785440 -> 1364510851184
	1364429576560 [label="features.denseblock3.denselayer19.conv1.weight
 (128, 832, 1, 1)" fillcolor=lightblue]
	1364429576560 -> 1364510785440
	1364510785440 [label=AccumulateGrad]
	1364510851520 -> 1364510851232
	1364429576656 [label="features.denseblock3.denselayer19.norm2.weight
 (128)" fillcolor=lightblue]
	1364429576656 -> 1364510851520
	1364510851520 [label=AccumulateGrad]
	1364510851664 -> 1364510851232
	1364429576752 [label="features.denseblock3.denselayer19.norm2.bias
 (128)" fillcolor=lightblue]
	1364429576752 -> 1364510851664
	1364510851664 [label=AccumulateGrad]
	1364510851760 -> 1364510944768
	1364429577136 [label="features.denseblock3.denselayer19.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429577136 -> 1364510851760
	1364510851760 [label=AccumulateGrad]
	1364510944864 -> 1364510935648
	1364510944864 [label=ConvolutionBackward0]
	1364510851280 -> 1364510944864
	1364510851280 [label=ReluBackward0]
	1364510783184 -> 1364510851280
	1364510783184 [label=CudnnBatchNormBackward0]
	1364510782656 -> 1364510783184
	1364510782656 [label=ConvolutionBackward0]
	1364510781600 -> 1364510782656
	1364510781600 [label=ReluBackward0]
	1364510781216 -> 1364510781600
	1364510781216 [label=CudnnBatchNormBackward0]
	1364510780688 -> 1364510781216
	1364510780688 [label=CatBackward0]
	1364510934592 -> 1364510780688
	1364510934448 -> 1364510780688
	1364510935120 -> 1364510780688
	1364510933920 -> 1364510780688
	1364510934064 -> 1364510780688
	1364510933392 -> 1364510780688
	1364510933536 -> 1364510780688
	1364510949328 -> 1364510780688
	1364510945248 -> 1364510780688
	1364510945344 -> 1364510780688
	1364510945488 -> 1364510780688
	1364510945296 -> 1364510780688
	1364510945392 -> 1364510780688
	1364510945104 -> 1364510780688
	1364510945056 -> 1364510780688
	1364510944912 -> 1364510780688
	1364510944720 -> 1364510780688
	1364510944816 -> 1364510780688
	1364510944960 -> 1364510780688
	1364510944768 -> 1364510780688
	1364510780544 -> 1364510781216
	1364429577232 [label="features.denseblock3.denselayer20.norm1.weight
 (864)" fillcolor=lightblue]
	1364429577232 -> 1364510780544
	1364510780544 [label=AccumulateGrad]
	1364510781744 -> 1364510781216
	1364429577328 [label="features.denseblock3.denselayer20.norm1.bias
 (864)" fillcolor=lightblue]
	1364429577328 -> 1364510781744
	1364510781744 [label=AccumulateGrad]
	1364510782272 -> 1364510782656
	1364429577712 [label="features.denseblock3.denselayer20.conv1.weight
 (128, 864, 1, 1)" fillcolor=lightblue]
	1364429577712 -> 1364510782272
	1364510782272 [label=AccumulateGrad]
	1364510784240 -> 1364510783184
	1364429577808 [label="features.denseblock3.denselayer20.norm2.weight
 (128)" fillcolor=lightblue]
	1364429577808 -> 1364510784240
	1364510784240 [label=AccumulateGrad]
	1364510785296 -> 1364510783184
	1364429577904 [label="features.denseblock3.denselayer20.norm2.bias
 (128)" fillcolor=lightblue]
	1364429577904 -> 1364510785296
	1364510785296 [label=AccumulateGrad]
	1364510851376 -> 1364510944864
	1364429578288 [label="features.denseblock3.denselayer20.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429578288 -> 1364510851376
	1364510851376 [label=AccumulateGrad]
	1364510944576 -> 1364510935648
	1364510944576 [label=ConvolutionBackward0]
	1364510864960 -> 1364510944576
	1364510864960 [label=ReluBackward0]
	1364510780016 -> 1364510864960
	1364510780016 [label=CudnnBatchNormBackward0]
	1364510779488 -> 1364510780016
	1364510779488 [label=ConvolutionBackward0]
	1364510778432 -> 1364510779488
	1364510778432 [label=ReluBackward0]
	1364510778048 -> 1364510778432
	1364510778048 [label=CudnnBatchNormBackward0]
	1364510777520 -> 1364510778048
	1364510777520 [label=CatBackward0]
	1364510934592 -> 1364510777520
	1364510934448 -> 1364510777520
	1364510935120 -> 1364510777520
	1364510933920 -> 1364510777520
	1364510934064 -> 1364510777520
	1364510933392 -> 1364510777520
	1364510933536 -> 1364510777520
	1364510949328 -> 1364510777520
	1364510945248 -> 1364510777520
	1364510945344 -> 1364510777520
	1364510945488 -> 1364510777520
	1364510945296 -> 1364510777520
	1364510945392 -> 1364510777520
	1364510945104 -> 1364510777520
	1364510945056 -> 1364510777520
	1364510944912 -> 1364510777520
	1364510944720 -> 1364510777520
	1364510944816 -> 1364510777520
	1364510944960 -> 1364510777520
	1364510944768 -> 1364510777520
	1364510944864 -> 1364510777520
	1364510777376 -> 1364510778048
	1364429578384 [label="features.denseblock3.denselayer21.norm1.weight
 (896)" fillcolor=lightblue]
	1364429578384 -> 1364510777376
	1364510777376 [label=AccumulateGrad]
	1364510778576 -> 1364510778048
	1364429578480 [label="features.denseblock3.denselayer21.norm1.bias
 (896)" fillcolor=lightblue]
	1364429578480 -> 1364510778576
	1364510778576 [label=AccumulateGrad]
	1364510779104 -> 1364510779488
	1364429578864 [label="features.denseblock3.denselayer21.conv1.weight
 (128, 896, 1, 1)" fillcolor=lightblue]
	1364429578864 -> 1364510779104
	1364510779104 [label=AccumulateGrad]
	1364510781072 -> 1364510780016
	1364429578960 [label="features.denseblock3.denselayer21.norm2.weight
 (128)" fillcolor=lightblue]
	1364429578960 -> 1364510781072
	1364510781072 [label=AccumulateGrad]
	1364510782800 -> 1364510780016
	1364429579056 [label="features.denseblock3.denselayer21.norm2.bias
 (128)" fillcolor=lightblue]
	1364429579056 -> 1364510782800
	1364510782800 [label=AccumulateGrad]
	1364510783328 -> 1364510944576
	1364429579440 [label="features.denseblock3.denselayer21.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429579440 -> 1364510783328
	1364510783328 [label=AccumulateGrad]
	1364510944528 -> 1364510935648
	1364510944528 [label=ConvolutionBackward0]
	1364510780160 -> 1364510944528
	1364510780160 [label=ReluBackward0]
	1364510776848 -> 1364510780160
	1364510776848 [label=CudnnBatchNormBackward0]
	1364510776320 -> 1364510776848
	1364510776320 [label=ConvolutionBackward0]
	1364510775264 -> 1364510776320
	1364510775264 [label=ReluBackward0]
	1364510774880 -> 1364510775264
	1364510774880 [label=CudnnBatchNormBackward0]
	1364510774352 -> 1364510774880
	1364510774352 [label=CatBackward0]
	1364510934592 -> 1364510774352
	1364510934448 -> 1364510774352
	1364510935120 -> 1364510774352
	1364510933920 -> 1364510774352
	1364510934064 -> 1364510774352
	1364510933392 -> 1364510774352
	1364510933536 -> 1364510774352
	1364510949328 -> 1364510774352
	1364510945248 -> 1364510774352
	1364510945344 -> 1364510774352
	1364510945488 -> 1364510774352
	1364510945296 -> 1364510774352
	1364510945392 -> 1364510774352
	1364510945104 -> 1364510774352
	1364510945056 -> 1364510774352
	1364510944912 -> 1364510774352
	1364510944720 -> 1364510774352
	1364510944816 -> 1364510774352
	1364510944960 -> 1364510774352
	1364510944768 -> 1364510774352
	1364510944864 -> 1364510774352
	1364510944576 -> 1364510774352
	1364510774208 -> 1364510774880
	1364429579536 [label="features.denseblock3.denselayer22.norm1.weight
 (928)" fillcolor=lightblue]
	1364429579536 -> 1364510774208
	1364510774208 [label=AccumulateGrad]
	1364510775408 -> 1364510774880
	1364429579632 [label="features.denseblock3.denselayer22.norm1.bias
 (928)" fillcolor=lightblue]
	1364429579632 -> 1364510775408
	1364510775408 [label=AccumulateGrad]
	1364510775936 -> 1364510776320
	1364429580016 [label="features.denseblock3.denselayer22.conv1.weight
 (128, 928, 1, 1)" fillcolor=lightblue]
	1364429580016 -> 1364510775936
	1364510775936 [label=AccumulateGrad]
	1364510777904 -> 1364510776848
	1364429580112 [label="features.denseblock3.denselayer22.norm2.weight
 (128)" fillcolor=lightblue]
	1364429580112 -> 1364510777904
	1364510777904 [label=AccumulateGrad]
	1364510779632 -> 1364510776848
	1364429580208 [label="features.denseblock3.denselayer22.norm2.bias
 (128)" fillcolor=lightblue]
	1364429580208 -> 1364510779632
	1364510779632 [label=AccumulateGrad]
	1364510778960 -> 1364510944528
	1364429580592 [label="features.denseblock3.denselayer22.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429580592 -> 1364510778960
	1364510778960 [label=AccumulateGrad]
	1364510944384 -> 1364510935648
	1364510944384 [label=ConvolutionBackward0]
	1364510776992 -> 1364510944384
	1364510776992 [label=ReluBackward0]
	1364510773680 -> 1364510776992
	1364510773680 [label=CudnnBatchNormBackward0]
	1364510773152 -> 1364510773680
	1364510773152 [label=ConvolutionBackward0]
	1364510772096 -> 1364510773152
	1364510772096 [label=ReluBackward0]
	1364510771712 -> 1364510772096
	1364510771712 [label=CudnnBatchNormBackward0]
	1364510771184 -> 1364510771712
	1364510771184 [label=CatBackward0]
	1364510934592 -> 1364510771184
	1364510934448 -> 1364510771184
	1364510935120 -> 1364510771184
	1364510933920 -> 1364510771184
	1364510934064 -> 1364510771184
	1364510933392 -> 1364510771184
	1364510933536 -> 1364510771184
	1364510949328 -> 1364510771184
	1364510945248 -> 1364510771184
	1364510945344 -> 1364510771184
	1364510945488 -> 1364510771184
	1364510945296 -> 1364510771184
	1364510945392 -> 1364510771184
	1364510945104 -> 1364510771184
	1364510945056 -> 1364510771184
	1364510944912 -> 1364510771184
	1364510944720 -> 1364510771184
	1364510944816 -> 1364510771184
	1364510944960 -> 1364510771184
	1364510944768 -> 1364510771184
	1364510944864 -> 1364510771184
	1364510944576 -> 1364510771184
	1364510944528 -> 1364510771184
	1364510771040 -> 1364510771712
	1364429580688 [label="features.denseblock3.denselayer23.norm1.weight
 (960)" fillcolor=lightblue]
	1364429580688 -> 1364510771040
	1364510771040 [label=AccumulateGrad]
	1364510772240 -> 1364510771712
	1364429580784 [label="features.denseblock3.denselayer23.norm1.bias
 (960)" fillcolor=lightblue]
	1364429580784 -> 1364510772240
	1364510772240 [label=AccumulateGrad]
	1364510772768 -> 1364510773152
	1364429581168 [label="features.denseblock3.denselayer23.conv1.weight
 (128, 960, 1, 1)" fillcolor=lightblue]
	1364429581168 -> 1364510772768
	1364510772768 [label=AccumulateGrad]
	1364510774736 -> 1364510773680
	1364429581264 [label="features.denseblock3.denselayer23.norm2.weight
 (128)" fillcolor=lightblue]
	1364429581264 -> 1364510774736
	1364510774736 [label=AccumulateGrad]
	1364510776464 -> 1364510773680
	1364429581360 [label="features.denseblock3.denselayer23.norm2.bias
 (128)" fillcolor=lightblue]
	1364429581360 -> 1364510776464
	1364510776464 [label=AccumulateGrad]
	1364510775792 -> 1364510944384
	1364429581744 [label="features.denseblock3.denselayer23.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429581744 -> 1364510775792
	1364510775792 [label=AccumulateGrad]
	1364510944192 -> 1364510935648
	1364510944192 [label=ConvolutionBackward0]
	1364510773824 -> 1364510944192
	1364510773824 [label=ReluBackward0]
	1364510770512 -> 1364510773824
	1364510770512 [label=CudnnBatchNormBackward0]
	1364510769984 -> 1364510770512
	1364510769984 [label=ConvolutionBackward0]
	1364510785392 -> 1364510769984
	1364510785392 [label=ReluBackward0]
	1364510785008 -> 1364510785392
	1364510785008 [label=CudnnBatchNormBackward0]
	1364510785248 -> 1364510785008
	1364510785248 [label=CatBackward0]
	1364510934592 -> 1364510785248
	1364510934448 -> 1364510785248
	1364510935120 -> 1364510785248
	1364510933920 -> 1364510785248
	1364510934064 -> 1364510785248
	1364510933392 -> 1364510785248
	1364510933536 -> 1364510785248
	1364510949328 -> 1364510785248
	1364510945248 -> 1364510785248
	1364510945344 -> 1364510785248
	1364510945488 -> 1364510785248
	1364510945296 -> 1364510785248
	1364510945392 -> 1364510785248
	1364510945104 -> 1364510785248
	1364510945056 -> 1364510785248
	1364510944912 -> 1364510785248
	1364510944720 -> 1364510785248
	1364510944816 -> 1364510785248
	1364510944960 -> 1364510785248
	1364510944768 -> 1364510785248
	1364510944864 -> 1364510785248
	1364510944576 -> 1364510785248
	1364510944528 -> 1364510785248
	1364510944384 -> 1364510785248
	1364510785104 -> 1364510785008
	1364429581840 [label="features.denseblock3.denselayer24.norm1.weight
 (992)" fillcolor=lightblue]
	1364429581840 -> 1364510785104
	1364510785104 [label=AccumulateGrad]
	1364510785344 -> 1364510785008
	1364429581936 [label="features.denseblock3.denselayer24.norm1.bias
 (992)" fillcolor=lightblue]
	1364429581936 -> 1364510785344
	1364510785344 [label=AccumulateGrad]
	1364510769600 -> 1364510769984
	1364429582320 [label="features.denseblock3.denselayer24.conv1.weight
 (128, 992, 1, 1)" fillcolor=lightblue]
	1364429582320 -> 1364510769600
	1364510769600 [label=AccumulateGrad]
	1364510771568 -> 1364510770512
	1364429582416 [label="features.denseblock3.denselayer24.norm2.weight
 (128)" fillcolor=lightblue]
	1364429582416 -> 1364510771568
	1364510771568 [label=AccumulateGrad]
	1364510773296 -> 1364510770512
	1364429582512 [label="features.denseblock3.denselayer24.norm2.bias
 (128)" fillcolor=lightblue]
	1364429582512 -> 1364510773296
	1364510773296 [label=AccumulateGrad]
	1364510772624 -> 1364510944192
	1364429582896 [label="features.denseblock3.denselayer24.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429582896 -> 1364510772624
	1364510772624 [label=AccumulateGrad]
	1364510935504 -> 1364510936176
	1364429582992 [label="features.transition3.norm.weight
 (1024)" fillcolor=lightblue]
	1364429582992 -> 1364510935504
	1364510935504 [label=AccumulateGrad]
	1364510936704 -> 1364510936176
	1364429583088 [label="features.transition3.norm.bias
 (1024)" fillcolor=lightblue]
	1364429583088 -> 1364510936704
	1364510936704 [label=AccumulateGrad]
	1364510937232 -> 1364510937088
	1364429583472 [label="features.transition3.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	1364429583472 -> 1364510937232
	1364510937232 [label=AccumulateGrad]
	1364510942512 -> 1364510942896
	1364510942512 [label=ConvolutionBackward0]
	1364510944288 -> 1364510942512
	1364510944288 [label=ReluBackward0]
	1364510936032 -> 1364510944288
	1364510936032 [label=CudnnBatchNormBackward0]
	1364510770656 -> 1364510936032
	1364510770656 [label=ConvolutionBackward0]
	1364510785200 -> 1364510770656
	1364510785200 [label=ReluBackward0]
	1364510784672 -> 1364510785200
	1364510784672 [label=CudnnBatchNormBackward0]
	1364510784576 -> 1364510784672
	1364510784576 [label=CatBackward0]
	1364510941840 -> 1364510784576
	1364510784480 -> 1364510784672
	1364429583568 [label="features.denseblock4.denselayer1.norm1.weight
 (512)" fillcolor=lightblue]
	1364429583568 -> 1364510784480
	1364510784480 [label=AccumulateGrad]
	1364510784864 -> 1364510784672
	1364429583664 [label="features.denseblock4.denselayer1.norm1.bias
 (512)" fillcolor=lightblue]
	1364429583664 -> 1364510784864
	1364510784864 [label=AccumulateGrad]
	1364510785056 -> 1364510770656
	1364429584048 [label="features.denseblock4.denselayer1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1364429584048 -> 1364510785056
	1364510785056 [label=AccumulateGrad]
	1364510769456 -> 1364510936032
	1364429584144 [label="features.denseblock4.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	1364429584144 -> 1364510769456
	1364510769456 [label=AccumulateGrad]
	1364510782128 -> 1364510936032
	1364429584240 [label="features.denseblock4.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	1364429584240 -> 1364510782128
	1364510782128 [label=AccumulateGrad]
	1364510937616 -> 1364510942512
	1364429584624 [label="features.denseblock4.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429584624 -> 1364510937616
	1364510937616 [label=AccumulateGrad]
	1364510942368 -> 1364510942896
	1364510942368 [label=ConvolutionBackward0]
	1364510934976 -> 1364510942368
	1364510934976 [label=ReluBackward0]
	1364510784720 -> 1364510934976
	1364510784720 [label=CudnnBatchNormBackward0]
	1364510784624 -> 1364510784720
	1364510784624 [label=ConvolutionBackward0]
	1364510783952 -> 1364510784624
	1364510783952 [label=ReluBackward0]
	1364510784000 -> 1364510783952
	1364510784000 [label=CudnnBatchNormBackward0]
	1364510783808 -> 1364510784000
	1364510783808 [label=CatBackward0]
	1364510941840 -> 1364510783808
	1364510942512 -> 1364510783808
	1364510784096 -> 1364510784000
	1364429584720 [label="features.denseblock4.denselayer2.norm1.weight
 (544)" fillcolor=lightblue]
	1364429584720 -> 1364510784096
	1364510784096 [label=AccumulateGrad]
	1364510784048 -> 1364510784000
	1364429584816 [label="features.denseblock4.denselayer2.norm1.bias
 (544)" fillcolor=lightblue]
	1364429584816 -> 1364510784048
	1364510784048 [label=AccumulateGrad]
	1364510784144 -> 1364510784624
	1364429585200 [label="features.denseblock4.denselayer2.conv1.weight
 (128, 544, 1, 1)" fillcolor=lightblue]
	1364429585200 -> 1364510784144
	1364510784144 [label=AccumulateGrad]
	1364510785152 -> 1364510784720
	1364429585296 [label="features.denseblock4.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	1364429585296 -> 1364510785152
	1364510785152 [label=AccumulateGrad]
	1364510770128 -> 1364510784720
	1364429585392 [label="features.denseblock4.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	1364429585392 -> 1364510770128
	1364510770128 [label=AccumulateGrad]
	1364510937760 -> 1364510942368
	1364429585776 [label="features.denseblock4.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429585776 -> 1364510937760
	1364510937760 [label=AccumulateGrad]
	1364510941984 -> 1364510942896
	1364510941984 [label=ConvolutionBackward0]
	1364510784528 -> 1364510941984
	1364510784528 [label=ReluBackward0]
	1364510783760 -> 1364510784528
	1364510783760 [label=CudnnBatchNormBackward0]
	1364510783424 -> 1364510783760
	1364510783424 [label=ConvolutionBackward0]
	1364510783568 -> 1364510783424
	1364510783568 [label=ReluBackward0]
	1364510783088 -> 1364510783568
	1364510783088 [label=CudnnBatchNormBackward0]
	1364510782992 -> 1364510783088
	1364510782992 [label=CatBackward0]
	1364510941840 -> 1364510782992
	1364510942512 -> 1364510782992
	1364510942368 -> 1364510782992
	1364510782896 -> 1364510783088
	1364429585872 [label="features.denseblock4.denselayer3.norm1.weight
 (576)" fillcolor=lightblue]
	1364429585872 -> 1364510782896
	1364510782896 [label=AccumulateGrad]
	1364510783280 -> 1364510783088
	1364429585968 [label="features.denseblock4.denselayer3.norm1.bias
 (576)" fillcolor=lightblue]
	1364429585968 -> 1364510783280
	1364510783280 [label=AccumulateGrad]
	1364510783472 -> 1364510783424
	1364429586352 [label="features.denseblock4.denselayer3.conv1.weight
 (128, 576, 1, 1)" fillcolor=lightblue]
	1364429586352 -> 1364510783472
	1364510783472 [label=AccumulateGrad]
	1364510784192 -> 1364510783760
	1364429865040 [label="features.denseblock4.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	1364429865040 -> 1364510784192
	1364510784192 [label=AccumulateGrad]
	1364510784336 -> 1364510783760
	1364429865136 [label="features.denseblock4.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	1364429865136 -> 1364510784336
	1364510784336 [label=AccumulateGrad]
	1364510784288 -> 1364510941984
	1364429865520 [label="features.denseblock4.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429865520 -> 1364510784288
	1364510784288 [label=AccumulateGrad]
	1364510941312 -> 1364510942896
	1364510941312 [label=ConvolutionBackward0]
	1364510783616 -> 1364510941312
	1364510783616 [label=ReluBackward0]
	1364510783136 -> 1364510783616
	1364510783136 [label=CudnnBatchNormBackward0]
	1364510783040 -> 1364510783136
	1364510783040 [label=ConvolutionBackward0]
	1364510782368 -> 1364510783040
	1364510782368 [label=ReluBackward0]
	1364510782416 -> 1364510782368
	1364510782416 [label=CudnnBatchNormBackward0]
	1364510782224 -> 1364510782416
	1364510782224 [label=CatBackward0]
	1364510941840 -> 1364510782224
	1364510942512 -> 1364510782224
	1364510942368 -> 1364510782224
	1364510941984 -> 1364510782224
	1364510782512 -> 1364510782416
	1364429865616 [label="features.denseblock4.denselayer4.norm1.weight
 (608)" fillcolor=lightblue]
	1364429865616 -> 1364510782512
	1364510782512 [label=AccumulateGrad]
	1364510782464 -> 1364510782416
	1364429865712 [label="features.denseblock4.denselayer4.norm1.bias
 (608)" fillcolor=lightblue]
	1364429865712 -> 1364510782464
	1364510782464 [label=AccumulateGrad]
	1364510782560 -> 1364510783040
	1364429866096 [label="features.denseblock4.denselayer4.conv1.weight
 (128, 608, 1, 1)" fillcolor=lightblue]
	1364429866096 -> 1364510782560
	1364510782560 [label=AccumulateGrad]
	1364510783232 -> 1364510783136
	1364429866192 [label="features.denseblock4.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	1364429866192 -> 1364510783232
	1364510783232 [label=AccumulateGrad]
	1364510783520 -> 1364510783136
	1364429866288 [label="features.denseblock4.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	1364429866288 -> 1364510783520
	1364510783520 [label=AccumulateGrad]
	1364510783664 -> 1364510941312
	1364429866672 [label="features.denseblock4.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429866672 -> 1364510783664
	1364510783664 [label=AccumulateGrad]
	1364510941456 -> 1364510942896
	1364510941456 [label=ConvolutionBackward0]
	1364510782944 -> 1364510941456
	1364510782944 [label=ReluBackward0]
	1364510782176 -> 1364510782944
	1364510782176 [label=CudnnBatchNormBackward0]
	1364510781840 -> 1364510782176
	1364510781840 [label=ConvolutionBackward0]
	1364510781984 -> 1364510781840
	1364510781984 [label=ReluBackward0]
	1364510781504 -> 1364510781984
	1364510781504 [label=CudnnBatchNormBackward0]
	1364510781408 -> 1364510781504
	1364510781408 [label=CatBackward0]
	1364510941840 -> 1364510781408
	1364510942512 -> 1364510781408
	1364510942368 -> 1364510781408
	1364510941984 -> 1364510781408
	1364510941312 -> 1364510781408
	1364510781312 -> 1364510781504
	1364429866768 [label="features.denseblock4.denselayer5.norm1.weight
 (640)" fillcolor=lightblue]
	1364429866768 -> 1364510781312
	1364510781312 [label=AccumulateGrad]
	1364510781696 -> 1364510781504
	1364429866864 [label="features.denseblock4.denselayer5.norm1.bias
 (640)" fillcolor=lightblue]
	1364429866864 -> 1364510781696
	1364510781696 [label=AccumulateGrad]
	1364510781888 -> 1364510781840
	1364429867248 [label="features.denseblock4.denselayer5.conv1.weight
 (128, 640, 1, 1)" fillcolor=lightblue]
	1364429867248 -> 1364510781888
	1364510781888 [label=AccumulateGrad]
	1364510782608 -> 1364510782176
	1364429867344 [label="features.denseblock4.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	1364429867344 -> 1364510782608
	1364510782608 [label=AccumulateGrad]
	1364510782752 -> 1364510782176
	1364429867440 [label="features.denseblock4.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	1364429867440 -> 1364510782752
	1364510782752 [label=AccumulateGrad]
	1364510782704 -> 1364510941456
	1364429867824 [label="features.denseblock4.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429867824 -> 1364510782704
	1364510782704 [label=AccumulateGrad]
	1364510940784 -> 1364510942896
	1364510940784 [label=ConvolutionBackward0]
	1364510782032 -> 1364510940784
	1364510782032 [label=ReluBackward0]
	1364510781552 -> 1364510782032
	1364510781552 [label=CudnnBatchNormBackward0]
	1364510781456 -> 1364510781552
	1364510781456 [label=ConvolutionBackward0]
	1364510780784 -> 1364510781456
	1364510780784 [label=ReluBackward0]
	1364510780832 -> 1364510780784
	1364510780832 [label=CudnnBatchNormBackward0]
	1364510780640 -> 1364510780832
	1364510780640 [label=CatBackward0]
	1364510941840 -> 1364510780640
	1364510942512 -> 1364510780640
	1364510942368 -> 1364510780640
	1364510941984 -> 1364510780640
	1364510941312 -> 1364510780640
	1364510941456 -> 1364510780640
	1364510780928 -> 1364510780832
	1364429867920 [label="features.denseblock4.denselayer6.norm1.weight
 (672)" fillcolor=lightblue]
	1364429867920 -> 1364510780928
	1364510780928 [label=AccumulateGrad]
	1364510780880 -> 1364510780832
	1364429868016 [label="features.denseblock4.denselayer6.norm1.bias
 (672)" fillcolor=lightblue]
	1364429868016 -> 1364510780880
	1364510780880 [label=AccumulateGrad]
	1364510780976 -> 1364510781456
	1364429868400 [label="features.denseblock4.denselayer6.conv1.weight
 (128, 672, 1, 1)" fillcolor=lightblue]
	1364429868400 -> 1364510780976
	1364510780976 [label=AccumulateGrad]
	1364510781648 -> 1364510781552
	1364429868496 [label="features.denseblock4.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	1364429868496 -> 1364510781648
	1364510781648 [label=AccumulateGrad]
	1364510781936 -> 1364510781552
	1364429868592 [label="features.denseblock4.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	1364429868592 -> 1364510781936
	1364510781936 [label=AccumulateGrad]
	1364510782080 -> 1364510940784
	1364429868976 [label="features.denseblock4.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429868976 -> 1364510782080
	1364510782080 [label=AccumulateGrad]
	1364510940928 -> 1364510942896
	1364510940928 [label=ConvolutionBackward0]
	1364510781360 -> 1364510940928
	1364510781360 [label=ReluBackward0]
	1364510780592 -> 1364510781360
	1364510780592 [label=CudnnBatchNormBackward0]
	1364510780256 -> 1364510780592
	1364510780256 [label=ConvolutionBackward0]
	1364510780400 -> 1364510780256
	1364510780400 [label=ReluBackward0]
	1364510779920 -> 1364510780400
	1364510779920 [label=CudnnBatchNormBackward0]
	1364510779824 -> 1364510779920
	1364510779824 [label=CatBackward0]
	1364510941840 -> 1364510779824
	1364510942512 -> 1364510779824
	1364510942368 -> 1364510779824
	1364510941984 -> 1364510779824
	1364510941312 -> 1364510779824
	1364510941456 -> 1364510779824
	1364510940784 -> 1364510779824
	1364510779728 -> 1364510779920
	1364429869072 [label="features.denseblock4.denselayer7.norm1.weight
 (704)" fillcolor=lightblue]
	1364429869072 -> 1364510779728
	1364510779728 [label=AccumulateGrad]
	1364510780112 -> 1364510779920
	1364429869168 [label="features.denseblock4.denselayer7.norm1.bias
 (704)" fillcolor=lightblue]
	1364429869168 -> 1364510780112
	1364510780112 [label=AccumulateGrad]
	1364510780304 -> 1364510780256
	1364429869552 [label="features.denseblock4.denselayer7.conv1.weight
 (128, 704, 1, 1)" fillcolor=lightblue]
	1364429869552 -> 1364510780304
	1364510780304 [label=AccumulateGrad]
	1364510781024 -> 1364510780592
	1364429869648 [label="features.denseblock4.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	1364429869648 -> 1364510781024
	1364510781024 [label=AccumulateGrad]
	1364510781168 -> 1364510780592
	1364429869744 [label="features.denseblock4.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	1364429869744 -> 1364510781168
	1364510781168 [label=AccumulateGrad]
	1364510781120 -> 1364510940928
	1364429870128 [label="features.denseblock4.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429870128 -> 1364510781120
	1364510781120 [label=AccumulateGrad]
	1364510940256 -> 1364510942896
	1364510940256 [label=ConvolutionBackward0]
	1364510780448 -> 1364510940256
	1364510780448 [label=ReluBackward0]
	1364510779968 -> 1364510780448
	1364510779968 [label=CudnnBatchNormBackward0]
	1364510779872 -> 1364510779968
	1364510779872 [label=ConvolutionBackward0]
	1364510779200 -> 1364510779872
	1364510779200 [label=ReluBackward0]
	1364510779248 -> 1364510779200
	1364510779248 [label=CudnnBatchNormBackward0]
	1364510779056 -> 1364510779248
	1364510779056 [label=CatBackward0]
	1364510941840 -> 1364510779056
	1364510942512 -> 1364510779056
	1364510942368 -> 1364510779056
	1364510941984 -> 1364510779056
	1364510941312 -> 1364510779056
	1364510941456 -> 1364510779056
	1364510940784 -> 1364510779056
	1364510940928 -> 1364510779056
	1364510779344 -> 1364510779248
	1364429870224 [label="features.denseblock4.denselayer8.norm1.weight
 (736)" fillcolor=lightblue]
	1364429870224 -> 1364510779344
	1364510779344 [label=AccumulateGrad]
	1364510779296 -> 1364510779248
	1364429870320 [label="features.denseblock4.denselayer8.norm1.bias
 (736)" fillcolor=lightblue]
	1364429870320 -> 1364510779296
	1364510779296 [label=AccumulateGrad]
	1364510779392 -> 1364510779872
	1364429870704 [label="features.denseblock4.denselayer8.conv1.weight
 (128, 736, 1, 1)" fillcolor=lightblue]
	1364429870704 -> 1364510779392
	1364510779392 [label=AccumulateGrad]
	1364510780064 -> 1364510779968
	1364429870800 [label="features.denseblock4.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	1364429870800 -> 1364510780064
	1364510780064 [label=AccumulateGrad]
	1364510780352 -> 1364510779968
	1364429870896 [label="features.denseblock4.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	1364429870896 -> 1364510780352
	1364510780352 [label=AccumulateGrad]
	1364510780496 -> 1364510940256
	1364429871280 [label="features.denseblock4.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429871280 -> 1364510780496
	1364510780496 [label=AccumulateGrad]
	1364510940400 -> 1364510942896
	1364510940400 [label=ConvolutionBackward0]
	1364510779776 -> 1364510940400
	1364510779776 [label=ReluBackward0]
	1364510779008 -> 1364510779776
	1364510779008 [label=CudnnBatchNormBackward0]
	1364510778672 -> 1364510779008
	1364510778672 [label=ConvolutionBackward0]
	1364510778816 -> 1364510778672
	1364510778816 [label=ReluBackward0]
	1364510778336 -> 1364510778816
	1364510778336 [label=CudnnBatchNormBackward0]
	1364510778240 -> 1364510778336
	1364510778240 [label=CatBackward0]
	1364510941840 -> 1364510778240
	1364510942512 -> 1364510778240
	1364510942368 -> 1364510778240
	1364510941984 -> 1364510778240
	1364510941312 -> 1364510778240
	1364510941456 -> 1364510778240
	1364510940784 -> 1364510778240
	1364510940928 -> 1364510778240
	1364510940256 -> 1364510778240
	1364510778144 -> 1364510778336
	1364429871376 [label="features.denseblock4.denselayer9.norm1.weight
 (768)" fillcolor=lightblue]
	1364429871376 -> 1364510778144
	1364510778144 [label=AccumulateGrad]
	1364510778528 -> 1364510778336
	1364429871472 [label="features.denseblock4.denselayer9.norm1.bias
 (768)" fillcolor=lightblue]
	1364429871472 -> 1364510778528
	1364510778528 [label=AccumulateGrad]
	1364510778720 -> 1364510778672
	1364429871856 [label="features.denseblock4.denselayer9.conv1.weight
 (128, 768, 1, 1)" fillcolor=lightblue]
	1364429871856 -> 1364510778720
	1364510778720 [label=AccumulateGrad]
	1364510779440 -> 1364510779008
	1364429871952 [label="features.denseblock4.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	1364429871952 -> 1364510779440
	1364510779440 [label=AccumulateGrad]
	1364510779584 -> 1364510779008
	1364429872048 [label="features.denseblock4.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	1364429872048 -> 1364510779584
	1364510779584 [label=AccumulateGrad]
	1364510779536 -> 1364510940400
	1364429872432 [label="features.denseblock4.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429872432 -> 1364510779536
	1364510779536 [label=AccumulateGrad]
	1364510939728 -> 1364510942896
	1364510939728 [label=ConvolutionBackward0]
	1364510778864 -> 1364510939728
	1364510778864 [label=ReluBackward0]
	1364510778384 -> 1364510778864
	1364510778384 [label=CudnnBatchNormBackward0]
	1364510778288 -> 1364510778384
	1364510778288 [label=ConvolutionBackward0]
	1364510777616 -> 1364510778288
	1364510777616 [label=ReluBackward0]
	1364510777664 -> 1364510777616
	1364510777664 [label=CudnnBatchNormBackward0]
	1364510777472 -> 1364510777664
	1364510777472 [label=CatBackward0]
	1364510941840 -> 1364510777472
	1364510942512 -> 1364510777472
	1364510942368 -> 1364510777472
	1364510941984 -> 1364510777472
	1364510941312 -> 1364510777472
	1364510941456 -> 1364510777472
	1364510940784 -> 1364510777472
	1364510940928 -> 1364510777472
	1364510940256 -> 1364510777472
	1364510940400 -> 1364510777472
	1364510777760 -> 1364510777664
	1364429872528 [label="features.denseblock4.denselayer10.norm1.weight
 (800)" fillcolor=lightblue]
	1364429872528 -> 1364510777760
	1364510777760 [label=AccumulateGrad]
	1364510777712 -> 1364510777664
	1364429872624 [label="features.denseblock4.denselayer10.norm1.bias
 (800)" fillcolor=lightblue]
	1364429872624 -> 1364510777712
	1364510777712 [label=AccumulateGrad]
	1364510777808 -> 1364510778288
	1364429873008 [label="features.denseblock4.denselayer10.conv1.weight
 (128, 800, 1, 1)" fillcolor=lightblue]
	1364429873008 -> 1364510777808
	1364510777808 [label=AccumulateGrad]
	1364510778480 -> 1364510778384
	1364429873104 [label="features.denseblock4.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	1364429873104 -> 1364510778480
	1364510778480 [label=AccumulateGrad]
	1364510778768 -> 1364510778384
	1364429873200 [label="features.denseblock4.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	1364429873200 -> 1364510778768
	1364510778768 [label=AccumulateGrad]
	1364510778912 -> 1364510939728
	1364429873584 [label="features.denseblock4.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429873584 -> 1364510778912
	1364510778912 [label=AccumulateGrad]
	1364510939872 -> 1364510942896
	1364510939872 [label=ConvolutionBackward0]
	1364510778192 -> 1364510939872
	1364510778192 [label=ReluBackward0]
	1364510777424 -> 1364510778192
	1364510777424 [label=CudnnBatchNormBackward0]
	1364510777088 -> 1364510777424
	1364510777088 [label=ConvolutionBackward0]
	1364510777232 -> 1364510777088
	1364510777232 [label=ReluBackward0]
	1364510776752 -> 1364510777232
	1364510776752 [label=CudnnBatchNormBackward0]
	1364510776656 -> 1364510776752
	1364510776656 [label=CatBackward0]
	1364510941840 -> 1364510776656
	1364510942512 -> 1364510776656
	1364510942368 -> 1364510776656
	1364510941984 -> 1364510776656
	1364510941312 -> 1364510776656
	1364510941456 -> 1364510776656
	1364510940784 -> 1364510776656
	1364510940928 -> 1364510776656
	1364510940256 -> 1364510776656
	1364510940400 -> 1364510776656
	1364510939728 -> 1364510776656
	1364510776560 -> 1364510776752
	1364429873680 [label="features.denseblock4.denselayer11.norm1.weight
 (832)" fillcolor=lightblue]
	1364429873680 -> 1364510776560
	1364510776560 [label=AccumulateGrad]
	1364510776944 -> 1364510776752
	1364429873776 [label="features.denseblock4.denselayer11.norm1.bias
 (832)" fillcolor=lightblue]
	1364429873776 -> 1364510776944
	1364510776944 [label=AccumulateGrad]
	1364510777136 -> 1364510777088
	1364429874160 [label="features.denseblock4.denselayer11.conv1.weight
 (128, 832, 1, 1)" fillcolor=lightblue]
	1364429874160 -> 1364510777136
	1364510777136 [label=AccumulateGrad]
	1364510777856 -> 1364510777424
	1364429874256 [label="features.denseblock4.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	1364429874256 -> 1364510777856
	1364510777856 [label=AccumulateGrad]
	1364510778000 -> 1364510777424
	1364429874352 [label="features.denseblock4.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	1364429874352 -> 1364510778000
	1364510778000 [label=AccumulateGrad]
	1364510777952 -> 1364510939872
	1364429874736 [label="features.denseblock4.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429874736 -> 1364510777952
	1364510777952 [label=AccumulateGrad]
	1364510939200 -> 1364510942896
	1364510939200 [label=ConvolutionBackward0]
	1364510777280 -> 1364510939200
	1364510777280 [label=ReluBackward0]
	1364510776800 -> 1364510777280
	1364510776800 [label=CudnnBatchNormBackward0]
	1364510776704 -> 1364510776800
	1364510776704 [label=ConvolutionBackward0]
	1364510776032 -> 1364510776704
	1364510776032 [label=ReluBackward0]
	1364510776080 -> 1364510776032
	1364510776080 [label=CudnnBatchNormBackward0]
	1364510775888 -> 1364510776080
	1364510775888 [label=CatBackward0]
	1364510941840 -> 1364510775888
	1364510942512 -> 1364510775888
	1364510942368 -> 1364510775888
	1364510941984 -> 1364510775888
	1364510941312 -> 1364510775888
	1364510941456 -> 1364510775888
	1364510940784 -> 1364510775888
	1364510940928 -> 1364510775888
	1364510940256 -> 1364510775888
	1364510940400 -> 1364510775888
	1364510939728 -> 1364510775888
	1364510939872 -> 1364510775888
	1364510776176 -> 1364510776080
	1364429874832 [label="features.denseblock4.denselayer12.norm1.weight
 (864)" fillcolor=lightblue]
	1364429874832 -> 1364510776176
	1364510776176 [label=AccumulateGrad]
	1364510776128 -> 1364510776080
	1364429874928 [label="features.denseblock4.denselayer12.norm1.bias
 (864)" fillcolor=lightblue]
	1364429874928 -> 1364510776128
	1364510776128 [label=AccumulateGrad]
	1364510776224 -> 1364510776704
	1364429875312 [label="features.denseblock4.denselayer12.conv1.weight
 (128, 864, 1, 1)" fillcolor=lightblue]
	1364429875312 -> 1364510776224
	1364510776224 [label=AccumulateGrad]
	1364510776896 -> 1364510776800
	1364429875408 [label="features.denseblock4.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	1364429875408 -> 1364510776896
	1364510776896 [label=AccumulateGrad]
	1364510777184 -> 1364510776800
	1364429875504 [label="features.denseblock4.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	1364429875504 -> 1364510777184
	1364510777184 [label=AccumulateGrad]
	1364510777328 -> 1364510939200
	1364429875888 [label="features.denseblock4.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429875888 -> 1364510777328
	1364510777328 [label=AccumulateGrad]
	1364510939344 -> 1364510942896
	1364510939344 [label=ConvolutionBackward0]
	1364510776608 -> 1364510939344
	1364510776608 [label=ReluBackward0]
	1364510775840 -> 1364510776608
	1364510775840 [label=CudnnBatchNormBackward0]
	1364510775504 -> 1364510775840
	1364510775504 [label=ConvolutionBackward0]
	1364510775648 -> 1364510775504
	1364510775648 [label=ReluBackward0]
	1364510775168 -> 1364510775648
	1364510775168 [label=CudnnBatchNormBackward0]
	1364510775072 -> 1364510775168
	1364510775072 [label=CatBackward0]
	1364510941840 -> 1364510775072
	1364510942512 -> 1364510775072
	1364510942368 -> 1364510775072
	1364510941984 -> 1364510775072
	1364510941312 -> 1364510775072
	1364510941456 -> 1364510775072
	1364510940784 -> 1364510775072
	1364510940928 -> 1364510775072
	1364510940256 -> 1364510775072
	1364510940400 -> 1364510775072
	1364510939728 -> 1364510775072
	1364510939872 -> 1364510775072
	1364510939200 -> 1364510775072
	1364510774976 -> 1364510775168
	1364429875984 [label="features.denseblock4.denselayer13.norm1.weight
 (896)" fillcolor=lightblue]
	1364429875984 -> 1364510774976
	1364510774976 [label=AccumulateGrad]
	1364510775360 -> 1364510775168
	1364429876080 [label="features.denseblock4.denselayer13.norm1.bias
 (896)" fillcolor=lightblue]
	1364429876080 -> 1364510775360
	1364510775360 [label=AccumulateGrad]
	1364510775552 -> 1364510775504
	1364429876464 [label="features.denseblock4.denselayer13.conv1.weight
 (128, 896, 1, 1)" fillcolor=lightblue]
	1364429876464 -> 1364510775552
	1364510775552 [label=AccumulateGrad]
	1364510776272 -> 1364510775840
	1364429876560 [label="features.denseblock4.denselayer13.norm2.weight
 (128)" fillcolor=lightblue]
	1364429876560 -> 1364510776272
	1364510776272 [label=AccumulateGrad]
	1364510776416 -> 1364510775840
	1364429876656 [label="features.denseblock4.denselayer13.norm2.bias
 (128)" fillcolor=lightblue]
	1364429876656 -> 1364510776416
	1364510776416 [label=AccumulateGrad]
	1364510776368 -> 1364510939344
	1364429877040 [label="features.denseblock4.denselayer13.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429877040 -> 1364510776368
	1364510776368 [label=AccumulateGrad]
	1364510938672 -> 1364510942896
	1364510938672 [label=ConvolutionBackward0]
	1364510775696 -> 1364510938672
	1364510775696 [label=ReluBackward0]
	1364510775216 -> 1364510775696
	1364510775216 [label=CudnnBatchNormBackward0]
	1364510775120 -> 1364510775216
	1364510775120 [label=ConvolutionBackward0]
	1364510774448 -> 1364510775120
	1364510774448 [label=ReluBackward0]
	1364510774496 -> 1364510774448
	1364510774496 [label=CudnnBatchNormBackward0]
	1364510774304 -> 1364510774496
	1364510774304 [label=CatBackward0]
	1364510941840 -> 1364510774304
	1364510942512 -> 1364510774304
	1364510942368 -> 1364510774304
	1364510941984 -> 1364510774304
	1364510941312 -> 1364510774304
	1364510941456 -> 1364510774304
	1364510940784 -> 1364510774304
	1364510940928 -> 1364510774304
	1364510940256 -> 1364510774304
	1364510940400 -> 1364510774304
	1364510939728 -> 1364510774304
	1364510939872 -> 1364510774304
	1364510939200 -> 1364510774304
	1364510939344 -> 1364510774304
	1364510774592 -> 1364510774496
	1364429877136 [label="features.denseblock4.denselayer14.norm1.weight
 (928)" fillcolor=lightblue]
	1364429877136 -> 1364510774592
	1364510774592 [label=AccumulateGrad]
	1364510774544 -> 1364510774496
	1364429877232 [label="features.denseblock4.denselayer14.norm1.bias
 (928)" fillcolor=lightblue]
	1364429877232 -> 1364510774544
	1364510774544 [label=AccumulateGrad]
	1364510774640 -> 1364510775120
	1364429877616 [label="features.denseblock4.denselayer14.conv1.weight
 (128, 928, 1, 1)" fillcolor=lightblue]
	1364429877616 -> 1364510774640
	1364510774640 [label=AccumulateGrad]
	1364510775312 -> 1364510775216
	1364429877712 [label="features.denseblock4.denselayer14.norm2.weight
 (128)" fillcolor=lightblue]
	1364429877712 -> 1364510775312
	1364510775312 [label=AccumulateGrad]
	1364510775600 -> 1364510775216
	1364429877808 [label="features.denseblock4.denselayer14.norm2.bias
 (128)" fillcolor=lightblue]
	1364429877808 -> 1364510775600
	1364510775600 [label=AccumulateGrad]
	1364510775744 -> 1364510938672
	1364429878192 [label="features.denseblock4.denselayer14.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429878192 -> 1364510775744
	1364510775744 [label=AccumulateGrad]
	1364510938816 -> 1364510942896
	1364510938816 [label=ConvolutionBackward0]
	1364510775024 -> 1364510938816
	1364510775024 [label=ReluBackward0]
	1364510774256 -> 1364510775024
	1364510774256 [label=CudnnBatchNormBackward0]
	1364510773920 -> 1364510774256
	1364510773920 [label=ConvolutionBackward0]
	1364510774064 -> 1364510773920
	1364510774064 [label=ReluBackward0]
	1364510773584 -> 1364510774064
	1364510773584 [label=CudnnBatchNormBackward0]
	1364510773488 -> 1364510773584
	1364510773488 [label=CatBackward0]
	1364510941840 -> 1364510773488
	1364510942512 -> 1364510773488
	1364510942368 -> 1364510773488
	1364510941984 -> 1364510773488
	1364510941312 -> 1364510773488
	1364510941456 -> 1364510773488
	1364510940784 -> 1364510773488
	1364510940928 -> 1364510773488
	1364510940256 -> 1364510773488
	1364510940400 -> 1364510773488
	1364510939728 -> 1364510773488
	1364510939872 -> 1364510773488
	1364510939200 -> 1364510773488
	1364510939344 -> 1364510773488
	1364510938672 -> 1364510773488
	1364510773392 -> 1364510773584
	1364429878288 [label="features.denseblock4.denselayer15.norm1.weight
 (960)" fillcolor=lightblue]
	1364429878288 -> 1364510773392
	1364510773392 [label=AccumulateGrad]
	1364510773776 -> 1364510773584
	1364429878384 [label="features.denseblock4.denselayer15.norm1.bias
 (960)" fillcolor=lightblue]
	1364429878384 -> 1364510773776
	1364510773776 [label=AccumulateGrad]
	1364510773968 -> 1364510773920
	1364429878768 [label="features.denseblock4.denselayer15.conv1.weight
 (128, 960, 1, 1)" fillcolor=lightblue]
	1364429878768 -> 1364510773968
	1364510773968 [label=AccumulateGrad]
	1364510774688 -> 1364510774256
	1364429878864 [label="features.denseblock4.denselayer15.norm2.weight
 (128)" fillcolor=lightblue]
	1364429878864 -> 1364510774688
	1364510774688 [label=AccumulateGrad]
	1364510774832 -> 1364510774256
	1364429878960 [label="features.denseblock4.denselayer15.norm2.bias
 (128)" fillcolor=lightblue]
	1364429878960 -> 1364510774832
	1364510774832 [label=AccumulateGrad]
	1364510774784 -> 1364510938816
	1364429879344 [label="features.denseblock4.denselayer15.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429879344 -> 1364510774784
	1364510774784 [label=AccumulateGrad]
	1364510938144 -> 1364510942896
	1364510938144 [label=ConvolutionBackward0]
	1364510774112 -> 1364510938144
	1364510774112 [label=ReluBackward0]
	1364510773632 -> 1364510774112
	1364510773632 [label=CudnnBatchNormBackward0]
	1364510773536 -> 1364510773632
	1364510773536 [label=ConvolutionBackward0]
	1364510772864 -> 1364510773536
	1364510772864 [label=ReluBackward0]
	1364510772912 -> 1364510772864
	1364510772912 [label=CudnnBatchNormBackward0]
	1364510772720 -> 1364510772912
	1364510772720 [label=CatBackward0]
	1364510941840 -> 1364510772720
	1364510942512 -> 1364510772720
	1364510942368 -> 1364510772720
	1364510941984 -> 1364510772720
	1364510941312 -> 1364510772720
	1364510941456 -> 1364510772720
	1364510940784 -> 1364510772720
	1364510940928 -> 1364510772720
	1364510940256 -> 1364510772720
	1364510940400 -> 1364510772720
	1364510939728 -> 1364510772720
	1364510939872 -> 1364510772720
	1364510939200 -> 1364510772720
	1364510939344 -> 1364510772720
	1364510938672 -> 1364510772720
	1364510938816 -> 1364510772720
	1364510773008 -> 1364510772912
	1364429879440 [label="features.denseblock4.denselayer16.norm1.weight
 (992)" fillcolor=lightblue]
	1364429879440 -> 1364510773008
	1364510773008 [label=AccumulateGrad]
	1364510772960 -> 1364510772912
	1364429879536 [label="features.denseblock4.denselayer16.norm1.bias
 (992)" fillcolor=lightblue]
	1364429879536 -> 1364510772960
	1364510772960 [label=AccumulateGrad]
	1364510773056 -> 1364510773536
	1364429879920 [label="features.denseblock4.denselayer16.conv1.weight
 (128, 992, 1, 1)" fillcolor=lightblue]
	1364429879920 -> 1364510773056
	1364510773056 [label=AccumulateGrad]
	1364510773728 -> 1364510773632
	1364429880016 [label="features.denseblock4.denselayer16.norm2.weight
 (128)" fillcolor=lightblue]
	1364429880016 -> 1364510773728
	1364510773728 [label=AccumulateGrad]
	1364510774016 -> 1364510773632
	1364429880112 [label="features.denseblock4.denselayer16.norm2.bias
 (128)" fillcolor=lightblue]
	1364429880112 -> 1364510774016
	1364510774016 [label=AccumulateGrad]
	1364510774160 -> 1364510938144
	1364429880496 [label="features.denseblock4.denselayer16.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	1364429880496 -> 1364510774160
	1364510774160 [label=AccumulateGrad]
	1364510943568 -> 1364510943424
	1364429880592 [label="features.norm5.weight
 (1024)" fillcolor=lightblue]
	1364429880592 -> 1364510943568
	1364510943568 [label=AccumulateGrad]
	1364510944480 -> 1364510943424
	1364429880688 [label="features.norm5.bias
 (1024)" fillcolor=lightblue]
	1364429880688 -> 1364510944480
	1364510944480 [label=AccumulateGrad]
	1364510945008 -> 1364510946736
	1364510945008 [label=TBackward0]
	1364510944096 -> 1364510945008
	1364430127184 [label="classifier.weight
 (19, 1024)" fillcolor=lightblue]
	1364430127184 -> 1364510944096
	1364510944096 [label=AccumulateGrad]
	1364510946736 -> 1364430323792
}
