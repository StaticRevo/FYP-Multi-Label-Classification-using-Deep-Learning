digraph {
	graph [size="151.95,151.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2097799916688 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2097799460272 [label=AddmmBackward0]
	2097799459072 -> 2097799460272
	2097544097392 [label="fc.bias
 (19)" fillcolor=lightblue]
	2097544097392 -> 2097799459072
	2097799459072 [label=AccumulateGrad]
	2097799459216 -> 2097799460272
	2097799459216 [label=ViewBackward0]
	2097799458688 -> 2097799459216
	2097799458688 [label=MeanBackward1]
	2097799457488 -> 2097799458688
	2097799457488 [label=ReluBackward0]
	2097799456960 -> 2097799457488
	2097799456960 [label=AddBackward0]
	2097799456432 -> 2097799456960
	2097799456432 [label=CudnnBatchNormBackward0]
	2097799456048 -> 2097799456432
	2097799456048 [label=ConvolutionBackward0]
	2097799454992 -> 2097799456048
	2097799454992 [label=ReluBackward0]
	2097799453792 -> 2097799454992
	2097799453792 [label=CudnnBatchNormBackward0]
	2097799453264 -> 2097799453792
	2097799453264 [label=ConvolutionBackward0]
	2097799452208 -> 2097799453264
	2097799452208 [label=ReluBackward0]
	2097799451824 -> 2097799452208
	2097799451824 [label=CudnnBatchNormBackward0]
	2097799451296 -> 2097799451824
	2097799451296 [label=ConvolutionBackward0]
	2097799457104 -> 2097799451296
	2097799457104 [label=ReluBackward0]
	2097799449712 -> 2097799457104
	2097799449712 [label=AddBackward0]
	2097799449184 -> 2097799449712
	2097799449184 [label=CudnnBatchNormBackward0]
	2097799447984 -> 2097799449184
	2097799447984 [label=ConvolutionBackward0]
	2097799446928 -> 2097799447984
	2097799446928 [label=ReluBackward0]
	2097799462816 -> 2097799446928
	2097799462816 [label=CudnnBatchNormBackward0]
	2097799462480 -> 2097799462816
	2097799462480 [label=ConvolutionBackward0]
	2097799462624 -> 2097799462480
	2097799462624 [label=ReluBackward0]
	2097799462144 -> 2097799462624
	2097799462144 [label=CudnnBatchNormBackward0]
	2097799462048 -> 2097799462144
	2097799462048 [label=ConvolutionBackward0]
	2097799449040 -> 2097799462048
	2097799449040 [label=ReluBackward0]
	2097799461616 -> 2097799449040
	2097799461616 [label=AddBackward0]
	2097799461520 -> 2097799461616
	2097799461520 [label=CudnnBatchNormBackward0]
	2097799461568 -> 2097799461520
	2097799461568 [label=ConvolutionBackward0]
	2097799460896 -> 2097799461568
	2097799460896 [label=ReluBackward0]
	2097799460944 -> 2097799460896
	2097799460944 [label=CudnnBatchNormBackward0]
	2097799460752 -> 2097799460944
	2097799460752 [label=ConvolutionBackward0]
	2097799460464 -> 2097799460752
	2097799460464 [label=ReluBackward0]
	2097799460512 -> 2097799460464
	2097799460512 [label=CudnnBatchNormBackward0]
	2097799460176 -> 2097799460512
	2097799460176 [label=ConvolutionBackward0]
	2097799460080 -> 2097799460176
	2097799460080 [label=ReluBackward0]
	2097799459696 -> 2097799460080
	2097799459696 [label=AddBackward0]
	2097799459504 -> 2097799459696
	2097799459504 [label=CudnnBatchNormBackward0]
	2097799459552 -> 2097799459504
	2097799459552 [label=ConvolutionBackward0]
	2097799459120 -> 2097799459552
	2097799459120 [label=ReluBackward0]
	2097799458880 -> 2097799459120
	2097799458880 [label=CudnnBatchNormBackward0]
	2097799458832 -> 2097799458880
	2097799458832 [label=ConvolutionBackward0]
	2097799458448 -> 2097799458832
	2097799458448 [label=ReluBackward0]
	2097799458496 -> 2097799458448
	2097799458496 [label=CudnnBatchNormBackward0]
	2097799458400 -> 2097799458496
	2097799458400 [label=ConvolutionBackward0]
	2097799459648 -> 2097799458400
	2097799459648 [label=ReluBackward0]
	2097799457968 -> 2097799459648
	2097799457968 [label=AddBackward0]
	2097799457872 -> 2097799457968
	2097799457872 [label=CudnnBatchNormBackward0]
	2097799457392 -> 2097799457872
	2097799457392 [label=ConvolutionBackward0]
	2097799457248 -> 2097799457392
	2097799457248 [label=ReluBackward0]
	2097799457008 -> 2097799457248
	2097799457008 [label=CudnnBatchNormBackward0]
	2097799456672 -> 2097799457008
	2097799456672 [label=ConvolutionBackward0]
	2097799456816 -> 2097799456672
	2097799456816 [label=ReluBackward0]
	2097799456336 -> 2097799456816
	2097799456336 [label=CudnnBatchNormBackward0]
	2097799456240 -> 2097799456336
	2097799456240 [label=ConvolutionBackward0]
	2097799457776 -> 2097799456240
	2097799457776 [label=ReluBackward0]
	2097799455808 -> 2097799457776
	2097799455808 [label=AddBackward0]
	2097799455712 -> 2097799455808
	2097799455712 [label=CudnnBatchNormBackward0]
	2097799455760 -> 2097799455712
	2097799455760 [label=ConvolutionBackward0]
	2097799455088 -> 2097799455760
	2097799455088 [label=ReluBackward0]
	2097799455136 -> 2097799455088
	2097799455136 [label=CudnnBatchNormBackward0]
	2097799454944 -> 2097799455136
	2097799454944 [label=ConvolutionBackward0]
	2097799454656 -> 2097799454944
	2097799454656 [label=ReluBackward0]
	2097799454704 -> 2097799454656
	2097799454704 [label=CudnnBatchNormBackward0]
	2097799454368 -> 2097799454704
	2097799454368 [label=ConvolutionBackward0]
	2097799455616 -> 2097799454368
	2097799455616 [label=ReluBackward0]
	2097799454176 -> 2097799455616
	2097799454176 [label=AddBackward0]
	2097799453840 -> 2097799454176
	2097799453840 [label=CudnnBatchNormBackward0]
	2097799453600 -> 2097799453840
	2097799453600 [label=ConvolutionBackward0]
	2097799453360 -> 2097799453600
	2097799453360 [label=ReluBackward0]
	2097799452976 -> 2097799453360
	2097799452976 [label=CudnnBatchNormBackward0]
	2097799453216 -> 2097799452976
	2097799453216 [label=ConvolutionBackward0]
	2097799452784 -> 2097799453216
	2097799452784 [label=ReluBackward0]
	2097799452544 -> 2097799452784
	2097799452544 [label=CudnnBatchNormBackward0]
	2097799452496 -> 2097799452544
	2097799452496 [label=ConvolutionBackward0]
	2097799453888 -> 2097799452496
	2097799453888 [label=ReluBackward0]
	2097799452016 -> 2097799453888
	2097799452016 [label=AddBackward0]
	2097799451968 -> 2097799452016
	2097799451968 [label=CudnnBatchNormBackward0]
	2097799451728 -> 2097799451968
	2097799451728 [label=ConvolutionBackward0]
	2097799451632 -> 2097799451728
	2097799451632 [label=ReluBackward0]
	2097799451248 -> 2097799451632
	2097799451248 [label=CudnnBatchNormBackward0]
	2097799451056 -> 2097799451248
	2097799451056 [label=ConvolutionBackward0]
	2097799450912 -> 2097799451056
	2097799450912 [label=ReluBackward0]
	2097799450672 -> 2097799450912
	2097799450672 [label=CudnnBatchNormBackward0]
	2097799450336 -> 2097799450672
	2097799450336 [label=ConvolutionBackward0]
	2097799452160 -> 2097799450336
	2097799452160 [label=ReluBackward0]
	2097799450144 -> 2097799452160
	2097799450144 [label=AddBackward0]
	2097799449808 -> 2097799450144
	2097799449808 [label=CudnnBatchNormBackward0]
	2097799449856 -> 2097799449808
	2097799449856 [label=ConvolutionBackward0]
	2097799449472 -> 2097799449856
	2097799449472 [label=ReluBackward0]
	2097799449520 -> 2097799449472
	2097799449520 [label=CudnnBatchNormBackward0]
	2097799449424 -> 2097799449520
	2097799449424 [label=ConvolutionBackward0]
	2097799448752 -> 2097799449424
	2097799448752 [label=ReluBackward0]
	2097799448800 -> 2097799448752
	2097799448800 [label=CudnnBatchNormBackward0]
	2097799448608 -> 2097799448800
	2097799448608 [label=ConvolutionBackward0]
	2097799448320 -> 2097799448608
	2097799448320 [label=ReluBackward0]
	2097799448368 -> 2097799448320
	2097799448368 [label=AddBackward0]
	2097799448032 -> 2097799448368
	2097799448032 [label=CudnnBatchNormBackward0]
	2097799447792 -> 2097799448032
	2097799447792 [label=ConvolutionBackward0]
	2097799447552 -> 2097799447792
	2097799447552 [label=ReluBackward0]
	2097799447168 -> 2097799447552
	2097799447168 [label=CudnnBatchNormBackward0]
	2097799447408 -> 2097799447168
	2097799447408 [label=ConvolutionBackward0]
	2097799446976 -> 2097799447408
	2097799446976 [label=ReluBackward0]
	2097799446736 -> 2097799446976
	2097799446736 [label=CudnnBatchNormBackward0]
	2097799446688 -> 2097799446736
	2097799446688 [label=ConvolutionBackward0]
	2097799448080 -> 2097799446688
	2097799448080 [label=ReluBackward0]
	2096904717024 -> 2097799448080
	2096904717024 [label=AddBackward0]
	2096904716592 -> 2096904717024
	2096904716592 [label=CudnnBatchNormBackward0]
	2096904721824 -> 2096904716592
	2096904721824 [label=ConvolutionBackward0]
	2096904717216 -> 2096904721824
	2096904717216 [label=ReluBackward0]
	2096904718656 -> 2096904717216
	2096904718656 [label=CudnnBatchNormBackward0]
	2096904721200 -> 2096904718656
	2096904721200 [label=ConvolutionBackward0]
	2096904726480 -> 2096904721200
	2096904726480 [label=ReluBackward0]
	2096904725760 -> 2096904726480
	2096904725760 [label=CudnnBatchNormBackward0]
	2096904723456 -> 2096904725760
	2096904723456 [label=ConvolutionBackward0]
	2096904731856 -> 2096904723456
	2096904731856 [label=ReluBackward0]
	2096904730032 -> 2096904731856
	2096904730032 [label=AddBackward0]
	2096904732432 -> 2096904730032
	2096904732432 [label=CudnnBatchNormBackward0]
	2096904717792 -> 2096904732432
	2096904717792 [label=ConvolutionBackward0]
	2096904723312 -> 2096904717792
	2096904723312 [label=ReluBackward0]
	2096904717936 -> 2096904723312
	2096904717936 [label=CudnnBatchNormBackward0]
	2096904717696 -> 2096904717936
	2096904717696 [label=ConvolutionBackward0]
	2096904716400 -> 2096904717696
	2096904716400 [label=ReluBackward0]
	2096904729840 -> 2096904716400
	2096904729840 [label=CudnnBatchNormBackward0]
	2096904720192 -> 2096904729840
	2096904720192 [label=ConvolutionBackward0]
	2096904723024 -> 2096904720192
	2096904723024 [label=ReluBackward0]
	2096904722448 -> 2096904723024
	2096904722448 [label=AddBackward0]
	2096904721440 -> 2096904722448
	2096904721440 [label=CudnnBatchNormBackward0]
	2096904726288 -> 2096904721440
	2096904726288 [label=ConvolutionBackward0]
	2096904722400 -> 2096904726288
	2096904722400 [label=ReluBackward0]
	2096904730368 -> 2096904722400
	2096904730368 [label=CudnnBatchNormBackward0]
	2096904732624 -> 2096904730368
	2096904732624 [label=ConvolutionBackward0]
	2096904729792 -> 2096904732624
	2096904729792 [label=ReluBackward0]
	2096904720672 -> 2096904729792
	2096904720672 [label=CudnnBatchNormBackward0]
	2096904729360 -> 2096904720672
	2096904729360 [label=ConvolutionBackward0]
	2096904718512 -> 2096904729360
	2096904718512 [label=ReluBackward0]
	2096904725040 -> 2096904718512
	2096904725040 [label=AddBackward0]
	2096904722832 -> 2096904725040
	2096904722832 [label=CudnnBatchNormBackward0]
	2096904720720 -> 2096904722832
	2096904720720 [label=ConvolutionBackward0]
	2096904722064 -> 2096904720720
	2096904722064 [label=ReluBackward0]
	2096904722880 -> 2096904722064
	2096904722880 [label=CudnnBatchNormBackward0]
	2096904718080 -> 2096904722880
	2096904718080 [label=ConvolutionBackward0]
	2096904728016 -> 2096904718080
	2096904728016 [label=ReluBackward0]
	2096904729984 -> 2096904728016
	2096904729984 [label=CudnnBatchNormBackward0]
	2096904719856 -> 2096904729984
	2096904719856 [label=ConvolutionBackward0]
	2096904732288 -> 2096904719856
	2096904732288 [label=ReluBackward0]
	2096904726864 -> 2096904732288
	2096904726864 [label=AddBackward0]
	2096904721920 -> 2096904726864
	2096904721920 [label=CudnnBatchNormBackward0]
	2096904721008 -> 2096904721920
	2096904721008 [label=ConvolutionBackward0]
	2096904718464 -> 2096904721008
	2096904718464 [label=ReluBackward0]
	2096904729120 -> 2096904718464
	2096904729120 [label=CudnnBatchNormBackward0]
	2096904726432 -> 2096904729120
	2096904726432 [label=ConvolutionBackward0]
	2096904729072 -> 2096904726432
	2096904729072 [label=ReluBackward0]
	2096904731424 -> 2096904729072
	2096904731424 [label=CudnnBatchNormBackward0]
	2096904716736 -> 2096904731424
	2096904716736 [label=ConvolutionBackward0]
	2096904730128 -> 2096904716736
	2096904730128 [label=ReluBackward0]
	2096904717600 -> 2096904730128
	2096904717600 [label=AddBackward0]
	2096904724032 -> 2096904717600
	2096904724032 [label=CudnnBatchNormBackward0]
	2096904717648 -> 2096904724032
	2096904717648 [label=ConvolutionBackward0]
	2096904723504 -> 2096904717648
	2096904723504 [label=ReluBackward0]
	2096904729456 -> 2096904723504
	2096904729456 [label=CudnnBatchNormBackward0]
	2096904725376 -> 2096904729456
	2096904725376 [label=ConvolutionBackward0]
	2096904725136 -> 2096904725376
	2096904725136 [label=ReluBackward0]
	2096904728736 -> 2096904725136
	2096904728736 [label=CudnnBatchNormBackward0]
	2096904719280 -> 2096904728736
	2096904719280 [label=ConvolutionBackward0]
	2096904724752 -> 2096904719280
	2096904724752 [label=MaxPool2DWithIndicesBackward0]
	2096904718176 -> 2096904724752
	2096904718176 [label=ReluBackward0]
	2096904732336 -> 2096904718176
	2096904732336 [label=CudnnBatchNormBackward0]
	2096904730992 -> 2096904732336
	2096904730992 [label=ConvolutionBackward0]
	2096904722928 -> 2096904730992
	2097544097200 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	2097544097200 -> 2096904722928
	2096904722928 [label=AccumulateGrad]
	2096904719760 -> 2096904732336
	2097280615824 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2097280615824 -> 2096904719760
	2096904719760 [label=AccumulateGrad]
	2096904731760 -> 2096904732336
	2097280615536 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2097280615536 -> 2096904731760
	2096904731760 [label=AccumulateGrad]
	2096904727584 -> 2096904719280
	2097280615440 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2097280615440 -> 2096904727584
	2096904727584 [label=AccumulateGrad]
	2096904726192 -> 2096904728736
	2097280615344 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2097280615344 -> 2096904726192
	2096904726192 [label=AccumulateGrad]
	2096904716448 -> 2096904728736
	2097280614480 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2097280614480 -> 2096904716448
	2096904716448 [label=AccumulateGrad]
	2096904726144 -> 2096904725376
	2097280614864 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2097280614864 -> 2096904726144
	2096904726144 [label=AccumulateGrad]
	2096904717168 -> 2096904729456
	2097280614960 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2097280614960 -> 2096904717168
	2096904717168 [label=AccumulateGrad]
	2096904719040 -> 2096904729456
	2097280615056 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2097280615056 -> 2096904719040
	2096904719040 [label=AccumulateGrad]
	2096904729696 -> 2096904717648
	2097268064176 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2097268064176 -> 2096904729696
	2096904729696 [label=AccumulateGrad]
	2096904730320 -> 2096904724032
	2097268063984 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	2097268063984 -> 2096904730320
	2096904730320 [label=AccumulateGrad]
	2096904720912 -> 2096904724032
	2097268063888 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	2097268063888 -> 2096904720912
	2096904720912 [label=AccumulateGrad]
	2096904725712 -> 2096904717600
	2096904725712 [label=CudnnBatchNormBackward0]
	2096904727008 -> 2096904725712
	2096904727008 [label=ConvolutionBackward0]
	2096904724752 -> 2096904727008
	2096904716880 -> 2096904727008
	2097280616016 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2097280616016 -> 2096904716880
	2096904716880 [label=AccumulateGrad]
	2096904720240 -> 2096904725712
	2097280616112 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2097280616112 -> 2096904720240
	2096904720240 [label=AccumulateGrad]
	2096904721152 -> 2096904725712
	2097280616208 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2097280616208 -> 2096904721152
	2096904721152 [label=AccumulateGrad]
	2096904720960 -> 2096904716736
	2097268063024 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2097268063024 -> 2096904720960
	2096904720960 [label=AccumulateGrad]
	2096904730704 -> 2096904731424
	2097268062928 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2097268062928 -> 2096904730704
	2096904730704 [label=AccumulateGrad]
	2096904732000 -> 2096904731424
	2097268063120 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2097268063120 -> 2096904732000
	2096904732000 [label=AccumulateGrad]
	2096904724128 -> 2096904726432
	2097268063792 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2097268063792 -> 2096904724128
	2096904724128 [label=AccumulateGrad]
	2096904716352 -> 2096904729120
	2097268063696 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2097268063696 -> 2096904716352
	2096904716352 [label=AccumulateGrad]
	2096904728976 -> 2096904729120
	2097543791440 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2097543791440 -> 2096904728976
	2096904728976 [label=AccumulateGrad]
	2096904728880 -> 2096904721008
	2097543791824 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2097543791824 -> 2096904728880
	2096904728880 [label=AccumulateGrad]
	2096904727296 -> 2096904721920
	2097543791920 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	2097543791920 -> 2096904727296
	2096904727296 [label=AccumulateGrad]
	2096904731520 -> 2096904721920
	2097543792016 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	2097543792016 -> 2096904731520
	2096904731520 [label=AccumulateGrad]
	2096904730128 -> 2096904726864
	2096904723984 -> 2096904719856
	2097543792400 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2097543792400 -> 2096904723984
	2096904723984 [label=AccumulateGrad]
	2096904722112 -> 2096904729984
	2097543792496 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	2097543792496 -> 2096904722112
	2096904722112 [label=AccumulateGrad]
	2096904719328 -> 2096904729984
	2097543792592 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	2097543792592 -> 2096904719328
	2096904719328 [label=AccumulateGrad]
	2096904720528 -> 2096904718080
	2097543792976 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2097543792976 -> 2096904720528
	2096904720528 [label=AccumulateGrad]
	2096904731232 -> 2096904722880
	2097543793072 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	2097543793072 -> 2096904731232
	2096904731232 [label=AccumulateGrad]
	2096904726576 -> 2096904722880
	2097543793168 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	2097543793168 -> 2096904726576
	2096904726576 [label=AccumulateGrad]
	2096904720432 -> 2096904720720
	2097543793552 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2097543793552 -> 2096904720432
	2096904720432 [label=AccumulateGrad]
	2096904732384 -> 2096904722832
	2097543793648 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	2097543793648 -> 2096904732384
	2096904732384 [label=AccumulateGrad]
	2096904728688 -> 2096904722832
	2097543793744 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	2097543793744 -> 2096904728688
	2096904728688 [label=AccumulateGrad]
	2096904732288 -> 2096904725040
	2096904724944 -> 2096904729360
	2097543794704 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2097543794704 -> 2096904724944
	2096904724944 [label=AccumulateGrad]
	2096904726912 -> 2096904720672
	2097543794800 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2097543794800 -> 2096904726912
	2096904726912 [label=AccumulateGrad]
	2096904732096 -> 2096904720672
	2097543794896 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2097543794896 -> 2096904732096
	2096904732096 [label=AccumulateGrad]
	2096904722736 -> 2096904732624
	2097543795280 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2097543795280 -> 2096904722736
	2096904722736 [label=AccumulateGrad]
	2096904729936 -> 2096904730368
	2097543795376 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2097543795376 -> 2096904729936
	2096904729936 [label=AccumulateGrad]
	2096904726960 -> 2096904730368
	2097543795472 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2097543795472 -> 2096904726960
	2096904726960 [label=AccumulateGrad]
	2096904719568 -> 2096904726288
	2097543795856 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2097543795856 -> 2096904719568
	2096904719568 [label=AccumulateGrad]
	2096904726336 -> 2096904721440
	2097543795952 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	2097543795952 -> 2096904726336
	2096904726336 [label=AccumulateGrad]
	2096904726672 -> 2096904721440
	2097543796048 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	2097543796048 -> 2096904726672
	2096904726672 [label=AccumulateGrad]
	2096904719520 -> 2096904722448
	2096904719520 [label=CudnnBatchNormBackward0]
	2096904724704 -> 2096904719520
	2096904724704 [label=ConvolutionBackward0]
	2096904718512 -> 2096904724704
	2096904731328 -> 2096904724704
	2097543794128 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2097543794128 -> 2096904731328
	2096904731328 [label=AccumulateGrad]
	2096904725232 -> 2096904719520
	2097543794224 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2097543794224 -> 2096904725232
	2096904725232 [label=AccumulateGrad]
	2096904728544 -> 2096904719520
	2097543794320 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2097543794320 -> 2096904728544
	2096904728544 [label=AccumulateGrad]
	2096904722976 -> 2096904720192
	2097543796432 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2097543796432 -> 2096904722976
	2096904722976 [label=AccumulateGrad]
	2096904729168 -> 2096904729840
	2097543796528 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2097543796528 -> 2096904729168
	2096904729168 [label=AccumulateGrad]
	2096904731952 -> 2096904729840
	2097543796624 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2097543796624 -> 2096904731952
	2096904731952 [label=AccumulateGrad]
	2096904729312 -> 2096904717696
	2097543797008 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2097543797008 -> 2096904729312
	2096904729312 [label=AccumulateGrad]
	2096904725520 -> 2096904717936
	2097543797104 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2097543797104 -> 2096904725520
	2096904725520 [label=AccumulateGrad]
	2096904720624 -> 2096904717936
	2097543797200 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2097543797200 -> 2096904720624
	2096904720624 [label=AccumulateGrad]
	2096904730896 -> 2096904717792
	2097543797584 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2097543797584 -> 2096904730896
	2096904730896 [label=AccumulateGrad]
	2096904723408 -> 2096904732432
	2097543797680 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	2097543797680 -> 2096904723408
	2096904723408 [label=AccumulateGrad]
	2096904725904 -> 2096904732432
	2097543797776 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	2097543797776 -> 2096904725904
	2096904725904 [label=AccumulateGrad]
	2096904723024 -> 2096904730032
	2096904729504 -> 2096904723456
	2097543798160 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2097543798160 -> 2096904729504
	2096904729504 [label=AccumulateGrad]
	2096904719808 -> 2096904725760
	2097543798256 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	2097543798256 -> 2096904719808
	2096904719808 [label=AccumulateGrad]
	2096904717264 -> 2096904725760
	2097543798352 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	2097543798352 -> 2096904717264
	2096904717264 [label=AccumulateGrad]
	2096904722784 -> 2096904721200
	2097543798736 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2097543798736 -> 2096904722784
	2096904722784 [label=AccumulateGrad]
	2096904725280 -> 2096904718656
	2097543798832 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	2097543798832 -> 2096904725280
	2096904725280 [label=AccumulateGrad]
	2096904725616 -> 2096904718656
	2097543798928 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	2097543798928 -> 2096904725616
	2096904725616 [label=AccumulateGrad]
	2096904721104 -> 2096904721824
	2097543799312 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2097543799312 -> 2096904721104
	2096904721104 [label=AccumulateGrad]
	2096904724992 -> 2096904716592
	2097543799408 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	2097543799408 -> 2096904724992
	2096904724992 [label=AccumulateGrad]
	2096904730800 -> 2096904716592
	2097543799504 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	2097543799504 -> 2096904730800
	2096904730800 [label=AccumulateGrad]
	2096904731856 -> 2096904717024
	2096904720336 -> 2097799446688
	2097543799888 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2097543799888 -> 2096904720336
	2096904720336 [label=AccumulateGrad]
	2097799446880 -> 2097799446736
	2097543799984 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	2097543799984 -> 2097799446880
	2097799446880 [label=AccumulateGrad]
	2097799446832 -> 2097799446736
	2097543800080 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	2097543800080 -> 2097799446832
	2097799446832 [label=AccumulateGrad]
	2097799447024 -> 2097799447408
	2097543800464 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2097543800464 -> 2097799447024
	2097799447024 [label=AccumulateGrad]
	2097799447264 -> 2097799447168
	2097543800560 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	2097543800560 -> 2097799447264
	2097799447264 [label=AccumulateGrad]
	2097799447504 -> 2097799447168
	2097543800656 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	2097543800656 -> 2097799447504
	2097799447504 [label=AccumulateGrad]
	2097799447840 -> 2097799447792
	2097543801040 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2097543801040 -> 2097799447840
	2097799447840 [label=AccumulateGrad]
	2097799447696 -> 2097799448032
	2097543801136 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	2097543801136 -> 2097799447696
	2097799447696 [label=AccumulateGrad]
	2097799447888 -> 2097799448032
	2097543801232 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	2097543801232 -> 2097799447888
	2097799447888 [label=AccumulateGrad]
	2097799448080 -> 2097799448368
	2097799448224 -> 2097799448608
	2097543802192 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2097543802192 -> 2097799448224
	2097799448224 [label=AccumulateGrad]
	2097799448896 -> 2097799448800
	2097543802288 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2097543802288 -> 2097799448896
	2097799448896 [label=AccumulateGrad]
	2097799448848 -> 2097799448800
	2097543802384 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2097543802384 -> 2097799448848
	2097799448848 [label=AccumulateGrad]
	2097799448944 -> 2097799449424
	2097543802768 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2097543802768 -> 2097799448944
	2097799448944 [label=AccumulateGrad]
	2097799449328 -> 2097799449520
	2097543802864 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2097543802864 -> 2097799449328
	2097799449328 [label=AccumulateGrad]
	2097799449280 -> 2097799449520
	2097543802960 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2097543802960 -> 2097799449280
	2097799449280 [label=AccumulateGrad]
	2097799449616 -> 2097799449856
	2097543803344 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2097543803344 -> 2097799449616
	2097799449616 [label=AccumulateGrad]
	2097799450048 -> 2097799449808
	2097543803440 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	2097543803440 -> 2097799450048
	2097799450048 [label=AccumulateGrad]
	2097799449904 -> 2097799449808
	2097543803536 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	2097543803536 -> 2097799449904
	2097799449904 [label=AccumulateGrad]
	2097799450000 -> 2097799450144
	2097799450000 [label=CudnnBatchNormBackward0]
	2097799449088 -> 2097799450000
	2097799449088 [label=ConvolutionBackward0]
	2097799448320 -> 2097799449088
	2097799448560 -> 2097799449088
	2097543801616 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2097543801616 -> 2097799448560
	2097799448560 [label=AccumulateGrad]
	2097799449664 -> 2097799450000
	2097543801712 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	2097543801712 -> 2097799449664
	2097799449664 [label=AccumulateGrad]
	2097799449952 -> 2097799450000
	2097543801808 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	2097543801808 -> 2097799449952
	2097799449952 [label=AccumulateGrad]
	2097799450480 -> 2097799450336
	2097543803920 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2097543803920 -> 2097799450480
	2097799450480 [label=AccumulateGrad]
	2097799450528 -> 2097799450672
	2097543804016 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2097543804016 -> 2097799450528
	2097799450528 [label=AccumulateGrad]
	2097799451008 -> 2097799450672
	2097543804112 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2097543804112 -> 2097799451008
	2097799451008 [label=AccumulateGrad]
	2097799451104 -> 2097799451056
	2097543804496 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2097543804496 -> 2097799451104
	2097799451104 [label=AccumulateGrad]
	2097799451200 -> 2097799451248
	2097543804592 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2097543804592 -> 2097799451200
	2097799451200 [label=AccumulateGrad]
	2097799451440 -> 2097799451248
	2097543804688 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2097543804688 -> 2097799451440
	2097799451440 [label=AccumulateGrad]
	2097799451488 -> 2097799451728
	2097543805072 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2097543805072 -> 2097799451488
	2097799451488 [label=AccumulateGrad]
	2097799451776 -> 2097799451968
	2097543805168 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	2097543805168 -> 2097799451776
	2097799451776 [label=AccumulateGrad]
	2097799452064 -> 2097799451968
	2097543805264 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	2097543805264 -> 2097799452064
	2097799452064 [label=AccumulateGrad]
	2097799452160 -> 2097799452016
	2097799452112 -> 2097799452496
	2097543805648 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2097543805648 -> 2097799452112
	2097799452112 [label=AccumulateGrad]
	2097799452688 -> 2097799452544
	2097543805744 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	2097543805744 -> 2097799452688
	2097799452688 [label=AccumulateGrad]
	2097799452640 -> 2097799452544
	2097543805840 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	2097543805840 -> 2097799452640
	2097799452640 [label=AccumulateGrad]
	2097799452832 -> 2097799453216
	2097543806224 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2097543806224 -> 2097799452832
	2097799452832 [label=AccumulateGrad]
	2097799453072 -> 2097799452976
	2097543806320 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	2097543806320 -> 2097799453072
	2097799453072 [label=AccumulateGrad]
	2097799453312 -> 2097799452976
	2097543806416 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	2097543806416 -> 2097799453312
	2097799453312 [label=AccumulateGrad]
	2097799453648 -> 2097799453600
	2097543806800 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2097543806800 -> 2097799453648
	2097799453648 [label=AccumulateGrad]
	2097799453504 -> 2097799453840
	2097543806896 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	2097543806896 -> 2097799453504
	2097799453504 [label=AccumulateGrad]
	2097799453696 -> 2097799453840
	2097544085584 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	2097544085584 -> 2097799453696
	2097799453696 [label=AccumulateGrad]
	2097799453888 -> 2097799454176
	2097799454272 -> 2097799454368
	2097544085968 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2097544085968 -> 2097799454272
	2097799454272 [label=AccumulateGrad]
	2097799454416 -> 2097799454704
	2097544086064 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	2097544086064 -> 2097799454416
	2097799454416 [label=AccumulateGrad]
	2097799454800 -> 2097799454704
	2097544086160 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	2097544086160 -> 2097799454800
	2097799454800 [label=AccumulateGrad]
	2097799454560 -> 2097799454944
	2097544086544 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2097544086544 -> 2097799454560
	2097799454560 [label=AccumulateGrad]
	2097799455232 -> 2097799455136
	2097544086640 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	2097544086640 -> 2097799455232
	2097799455232 [label=AccumulateGrad]
	2097799455184 -> 2097799455136
	2097544086736 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	2097544086736 -> 2097799455184
	2097799455184 [label=AccumulateGrad]
	2097799455280 -> 2097799455760
	2097544087120 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2097544087120 -> 2097799455280
	2097799455280 [label=AccumulateGrad]
	2097799455664 -> 2097799455712
	2097544087216 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	2097544087216 -> 2097799455664
	2097799455664 [label=AccumulateGrad]
	2097799455856 -> 2097799455712
	2097544087312 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	2097544087312 -> 2097799455856
	2097799455856 [label=AccumulateGrad]
	2097799455616 -> 2097799455808
	2097799456000 -> 2097799456240
	2097544087696 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2097544087696 -> 2097799456000
	2097799456000 [label=AccumulateGrad]
	2097799456144 -> 2097799456336
	2097544087792 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	2097544087792 -> 2097799456144
	2097799456144 [label=AccumulateGrad]
	2097799456528 -> 2097799456336
	2097544087888 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	2097544087888 -> 2097799456528
	2097799456528 [label=AccumulateGrad]
	2097799456720 -> 2097799456672
	2097544088272 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2097544088272 -> 2097799456720
	2097799456720 [label=AccumulateGrad]
	2097799456864 -> 2097799457008
	2097544088368 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	2097544088368 -> 2097799456864
	2097799456864 [label=AccumulateGrad]
	2097799457344 -> 2097799457008
	2097544088464 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	2097544088464 -> 2097799457344
	2097799457344 [label=AccumulateGrad]
	2097799457440 -> 2097799457392
	2097544088848 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2097544088848 -> 2097799457440
	2097799457440 [label=AccumulateGrad]
	2097799457536 -> 2097799457872
	2097544088944 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	2097544088944 -> 2097799457536
	2097799457536 [label=AccumulateGrad]
	2097799457584 -> 2097799457872
	2097544089040 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	2097544089040 -> 2097799457584
	2097799457584 [label=AccumulateGrad]
	2097799457776 -> 2097799457968
	2097799457728 -> 2097799458400
	2097544089424 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2097544089424 -> 2097799457728
	2097799457728 [label=AccumulateGrad]
	2097799458304 -> 2097799458496
	2097544089520 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	2097544089520 -> 2097799458304
	2097799458304 [label=AccumulateGrad]
	2097799458256 -> 2097799458496
	2097544089616 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	2097544089616 -> 2097799458256
	2097799458256 [label=AccumulateGrad]
	2097799458592 -> 2097799458832
	2097544090000 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2097544090000 -> 2097799458592
	2097799458592 [label=AccumulateGrad]
	2097799459024 -> 2097799458880
	2097544090096 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	2097544090096 -> 2097799459024
	2097799459024 [label=AccumulateGrad]
	2097799458976 -> 2097799458880
	2097544090192 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	2097544090192 -> 2097799458976
	2097799458976 [label=AccumulateGrad]
	2097799459168 -> 2097799459552
	2097544090576 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2097544090576 -> 2097799459168
	2097799459168 [label=AccumulateGrad]
	2097799459408 -> 2097799459504
	2097544090672 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	2097544090672 -> 2097799459408
	2097799459408 [label=AccumulateGrad]
	2097799459312 -> 2097799459504
	2097544090768 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	2097544090768 -> 2097799459312
	2097799459312 [label=AccumulateGrad]
	2097799459648 -> 2097799459696
	2097799459936 -> 2097799460176
	2097544091824 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2097544091824 -> 2097799459936
	2097799459936 [label=AccumulateGrad]
	2097799460224 -> 2097799460512
	2097544091920 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2097544091920 -> 2097799460224
	2097799460224 [label=AccumulateGrad]
	2097799460608 -> 2097799460512
	2097544092016 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2097544092016 -> 2097799460608
	2097799460608 [label=AccumulateGrad]
	2097799460368 -> 2097799460752
	2097544092400 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2097544092400 -> 2097799460368
	2097799460368 [label=AccumulateGrad]
	2097799461040 -> 2097799460944
	2097544092496 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2097544092496 -> 2097799461040
	2097799461040 [label=AccumulateGrad]
	2097799460992 -> 2097799460944
	2097544092592 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2097544092592 -> 2097799460992
	2097799460992 [label=AccumulateGrad]
	2097799461088 -> 2097799461568
	2097544092976 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2097544092976 -> 2097799461088
	2097799461088 [label=AccumulateGrad]
	2097799461472 -> 2097799461520
	2097544093072 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	2097544093072 -> 2097799461472
	2097799461472 [label=AccumulateGrad]
	2097799461664 -> 2097799461520
	2097544093168 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	2097544093168 -> 2097799461664
	2097799461664 [label=AccumulateGrad]
	2097799461424 -> 2097799461616
	2097799461424 [label=CudnnBatchNormBackward0]
	2097799460560 -> 2097799461424
	2097799460560 [label=ConvolutionBackward0]
	2097799460080 -> 2097799460560
	2097799460032 -> 2097799460560
	2097544091248 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	2097544091248 -> 2097799460032
	2097799460032 [label=AccumulateGrad]
	2097799461232 -> 2097799461424
	2097544091344 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	2097544091344 -> 2097799461232
	2097799461232 [label=AccumulateGrad]
	2097799461280 -> 2097799461424
	2097544091440 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	2097544091440 -> 2097799461280
	2097799461280 [label=AccumulateGrad]
	2097799461808 -> 2097799462048
	2097544093552 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2097544093552 -> 2097799461808
	2097799461808 [label=AccumulateGrad]
	2097799461952 -> 2097799462144
	2097544093648 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2097544093648 -> 2097799461952
	2097799461952 [label=AccumulateGrad]
	2097799462336 -> 2097799462144
	2097544093744 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2097544093744 -> 2097799462336
	2097799462336 [label=AccumulateGrad]
	2097799462528 -> 2097799462480
	2097544094128 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2097544094128 -> 2097799462528
	2097799462528 [label=AccumulateGrad]
	2097799462672 -> 2097799462816
	2097544094224 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2097544094224 -> 2097799462672
	2097799462672 [label=AccumulateGrad]
	2097799447072 -> 2097799462816
	2097544094320 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2097544094320 -> 2097799447072
	2097799447072 [label=AccumulateGrad]
	2097799447600 -> 2097799447984
	2097544094704 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2097544094704 -> 2097799447600
	2097799447600 [label=AccumulateGrad]
	2097799448656 -> 2097799449184
	2097544094800 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	2097544094800 -> 2097799448656
	2097799448656 [label=AccumulateGrad]
	2097799448512 -> 2097799449184
	2097544094896 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	2097544094896 -> 2097799448512
	2097799448512 [label=AccumulateGrad]
	2097799449040 -> 2097799449712
	2097799450240 -> 2097799451296
	2097544095280 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2097544095280 -> 2097799450240
	2097799450240 [label=AccumulateGrad]
	2097799451152 -> 2097799451824
	2097544095376 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	2097544095376 -> 2097799451152
	2097799451152 [label=AccumulateGrad]
	2097799452352 -> 2097799451824
	2097544095472 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	2097544095472 -> 2097799452352
	2097799452352 [label=AccumulateGrad]
	2097799452880 -> 2097799453264
	2097544095856 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2097544095856 -> 2097799452880
	2097799452880 [label=AccumulateGrad]
	2097799453936 -> 2097799453792
	2097544095952 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	2097544095952 -> 2097799453936
	2097799453936 [label=AccumulateGrad]
	2097799454320 -> 2097799453792
	2097544096048 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	2097544096048 -> 2097799454320
	2097799454320 [label=AccumulateGrad]
	2097799454848 -> 2097799456048
	2097544096432 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2097544096432 -> 2097799454848
	2097799454848 [label=AccumulateGrad]
	2097799455904 -> 2097799456432
	2097544096528 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	2097544096528 -> 2097799455904
	2097799455904 [label=AccumulateGrad]
	2097799456576 -> 2097799456432
	2097544096624 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	2097544096624 -> 2097799456576
	2097799456576 [label=AccumulateGrad]
	2097799457104 -> 2097799456960
	2097799458544 -> 2097799460272
	2097799458544 [label=TBackward0]
	2097799457632 -> 2097799458544
	2097544097296 [label="fc.weight
 (19, 2048)" fillcolor=lightblue]
	2097544097296 -> 2097799457632
	2097799457632 [label=AccumulateGrad]
	2097799460272 -> 2097799916688
}
