digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2805207759472 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	2805204586400 [label=AddmmBackward0]
	2805204591968 -> 2805204586400
	2805207588336 [label="fc.bias
 (10)" fillcolor=lightblue]
	2805207588336 -> 2805204591968
	2805204591968 [label=AccumulateGrad]
	2805204586112 -> 2805204586400
	2805204586112 [label=ViewBackward0]
	2805204584768 -> 2805204586112
	2805204584768 [label=MeanBackward1]
	2805204586496 -> 2805204584768
	2805204586496 [label=ReluBackward0]
	2805204593456 -> 2805204586496
	2805204593456 [label=AddBackward0]
	2805204593360 -> 2805204593456
	2805204593360 [label=NativeBatchNormBackward0]
	2805204587936 -> 2805204593360
	2805204587936 [label=ConvolutionBackward0]
	2805204585776 -> 2805204587936
	2805204585776 [label=ReluBackward0]
	2805204585920 -> 2805204585776
	2805204585920 [label=NativeBatchNormBackward0]
	2805204586016 -> 2805204585920
	2805204586016 [label=ConvolutionBackward0]
	2805204593408 -> 2805204586016
	2805204593408 [label=ReluBackward0]
	2805204589136 -> 2805204593408
	2805204589136 [label=AddBackward0]
	2805204587168 -> 2805204589136
	2805204587168 [label=NativeBatchNormBackward0]
	2805204598496 -> 2805204587168
	2805204598496 [label=ConvolutionBackward0]
	2805204591488 -> 2805204598496
	2805204591488 [label=ReluBackward0]
	2805204597440 -> 2805204591488
	2805204597440 [label=NativeBatchNormBackward0]
	2805204597872 -> 2805204597440
	2805204597872 [label=ConvolutionBackward0]
	2804861760032 -> 2805204597872
	2804861760032 [label=ReluBackward0]
	2804861760704 -> 2804861760032
	2804861760704 [label=AddBackward0]
	2804861759072 -> 2804861760704
	2804861759072 [label=NativeBatchNormBackward0]
	2804861758544 -> 2804861759072
	2804861758544 [label=ConvolutionBackward0]
	2804861759024 -> 2804861758544
	2804861759024 [label=ReluBackward0]
	2804861760656 -> 2804861759024
	2804861760656 [label=NativeBatchNormBackward0]
	2804861762720 -> 2804861760656
	2804861762720 [label=ConvolutionBackward0]
	2804861759216 -> 2804861762720
	2804861759216 [label=ReluBackward0]
	2804861759120 -> 2804861759216
	2804861759120 [label=AddBackward0]
	2804856849888 -> 2804861759120
	2804856849888 [label=NativeBatchNormBackward0]
	2804856857328 -> 2804856849888
	2804856857328 [label=ConvolutionBackward0]
	2804856849792 -> 2804856857328
	2804856849792 [label=ReluBackward0]
	2804856851952 -> 2804856849792
	2804856851952 [label=NativeBatchNormBackward0]
	2804856849216 -> 2804856851952
	2804856849216 [label=ConvolutionBackward0]
	2804856853968 -> 2804856849216
	2804856853968 [label=ReluBackward0]
	2804856859584 -> 2804856853968
	2804856859584 [label=AddBackward0]
	2804856853488 -> 2804856859584
	2804856853488 [label=NativeBatchNormBackward0]
	2804856855024 -> 2804856853488
	2804856855024 [label=ConvolutionBackward0]
	2804856849120 -> 2804856855024
	2804856849120 [label=ReluBackward0]
	2804856852528 -> 2804856849120
	2804856852528 [label=NativeBatchNormBackward0]
	2804856858048 -> 2804856852528
	2804856858048 [label=ConvolutionBackward0]
	2804856853104 -> 2804856858048
	2804856853104 [label=ReluBackward0]
	2804856849936 -> 2804856853104
	2804856849936 [label=AddBackward0]
	2805200973696 -> 2804856849936
	2805200973696 [label=NativeBatchNormBackward0]
	2805200969520 -> 2805200973696
	2805200969520 [label=ConvolutionBackward0]
	2805200972784 -> 2805200969520
	2805200972784 [label=ReluBackward0]
	2805200972736 -> 2805200972784
	2805200972736 [label=NativeBatchNormBackward0]
	2805200969088 -> 2805200972736
	2805200969088 [label=ConvolutionBackward0]
	2805200966880 -> 2805200969088
	2805200966880 [label=ReluBackward0]
	2805200970576 -> 2805200966880
	2805200970576 [label=AddBackward0]
	2805200972496 -> 2805200970576
	2805200972496 [label=NativeBatchNormBackward0]
	2805200972208 -> 2805200972496
	2805200972208 [label=ConvolutionBackward0]
	2805200973456 -> 2805200972208
	2805200973456 [label=ReluBackward0]
	2805200969328 -> 2805200973456
	2805200969328 [label=NativeBatchNormBackward0]
	2805200969376 -> 2805200969328
	2805200969376 [label=ConvolutionBackward0]
	2805200968272 -> 2805200969376
	2805200968272 [label=ReluBackward0]
	2805200973744 -> 2805200968272
	2805200973744 [label=AddBackward0]
	2805200966352 -> 2805200973744
	2805200966352 [label=NativeBatchNormBackward0]
	2805200971872 -> 2805200966352
	2805200971872 [label=ConvolutionBackward0]
	2805200972640 -> 2805200971872
	2805200972640 [label=ReluBackward0]
	2805200973888 -> 2805200972640
	2805200973888 [label=NativeBatchNormBackward0]
	2805200966688 -> 2805200973888
	2805200966688 [label=ConvolutionBackward0]
	2805200969184 -> 2805200966688
	2805200969184 [label=MaxPool2DWithIndicesBackward0]
	2805200972688 -> 2805200969184
	2805200972688 [label=ReluBackward0]
	2805200972352 -> 2805200972688
	2805200972352 [label=NativeBatchNormBackward0]
	2805200974080 -> 2805200972352
	2805200974080 [label=ConvolutionBackward0]
	2805200973984 -> 2805200974080
	2805207427952 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2805207427952 -> 2805200973984
	2805200973984 [label=AccumulateGrad]
	2805200972544 -> 2805200972352
	2805206605392 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2805206605392 -> 2805200972544
	2805200972544 [label=AccumulateGrad]
	2805200969232 -> 2805200972352
	2805207426896 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2805207426896 -> 2805200969232
	2805200969232 [label=AccumulateGrad]
	2805200968416 -> 2805200966688
	2805207428336 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2805207428336 -> 2805200968416
	2805200968416 [label=AccumulateGrad]
	2805200966304 -> 2805200973888
	2805207429584 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2805207429584 -> 2805200966304
	2805200966304 [label=AccumulateGrad]
	2805200971776 -> 2805200973888
	2805207429680 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2805207429680 -> 2805200971776
	2805200971776 [label=AccumulateGrad]
	2805200972880 -> 2805200971872
	2805207430064 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2805207430064 -> 2805200972880
	2805200972880 [label=AccumulateGrad]
	2805200966400 -> 2805200966352
	2805207430160 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2805207430160 -> 2805200966400
	2805200966400 [label=AccumulateGrad]
	2805200966640 -> 2805200966352
	2805207430256 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2805207430256 -> 2805200966640
	2805200966640 [label=AccumulateGrad]
	2805200969184 -> 2805200973744
	2805200973072 -> 2805200969376
	2805207430640 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2805207430640 -> 2805200973072
	2805200973072 [label=AccumulateGrad]
	2805200969280 -> 2805200969328
	2805207430736 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2805207430736 -> 2805200969280
	2805200969280 [label=AccumulateGrad]
	2805200973024 -> 2805200969328
	2805207430832 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2805207430832 -> 2805200973024
	2805200973024 [label=AccumulateGrad]
	2805200973840 -> 2805200972208
	2805207431216 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2805207431216 -> 2805200973840
	2805200973840 [label=AccumulateGrad]
	2805200972160 -> 2805200972496
	2805207431312 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2805207431312 -> 2805200972160
	2805200972160 [label=AccumulateGrad]
	2805200972448 -> 2805200972496
	2805207431408 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2805207431408 -> 2805200972448
	2805200972448 [label=AccumulateGrad]
	2805200968272 -> 2805200970576
	2805200973312 -> 2805200969088
	2805207432464 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2805207432464 -> 2805200973312
	2805200973312 [label=AccumulateGrad]
	2805200973120 -> 2805200972736
	2805207432560 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2805207432560 -> 2805200973120
	2805200973120 [label=AccumulateGrad]
	2805200972832 -> 2805200972736
	2805207432656 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2805207432656 -> 2805200972832
	2805200972832 [label=AccumulateGrad]
	2805200973168 -> 2805200969520
	2805207433040 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2805207433040 -> 2805200973168
	2805200973168 [label=AccumulateGrad]
	2805200969664 -> 2805200973696
	2805207433136 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2805207433136 -> 2805200969664
	2805200969664 [label=AccumulateGrad]
	2805200973264 -> 2805200973696
	2805207580752 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2805207580752 -> 2805200973264
	2805200973264 [label=AccumulateGrad]
	2805200969136 -> 2804856849936
	2805200969136 [label=NativeBatchNormBackward0]
	2805200973408 -> 2805200969136
	2805200973408 [label=ConvolutionBackward0]
	2805200966880 -> 2805200973408
	2805200966112 -> 2805200973408
	2805207431888 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2805207431888 -> 2805200966112
	2805200966112 [label=AccumulateGrad]
	2805200969808 -> 2805200969136
	2805207431984 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2805207431984 -> 2805200969808
	2805200969808 [label=AccumulateGrad]
	2805200969424 -> 2805200969136
	2805207432080 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2805207432080 -> 2805200969424
	2805200969424 [label=AccumulateGrad]
	2804856853248 -> 2804856858048
	2805207581136 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2805207581136 -> 2804856853248
	2804856853248 [label=AccumulateGrad]
	2804856852672 -> 2804856852528
	2805207581232 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2805207581232 -> 2804856852672
	2804856852672 [label=AccumulateGrad]
	2804856848496 -> 2804856852528
	2805207581328 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2805207581328 -> 2804856848496
	2804856848496 [label=AccumulateGrad]
	2804856850032 -> 2804856855024
	2805207581712 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2805207581712 -> 2804856850032
	2804856850032 [label=AccumulateGrad]
	2804856853344 -> 2804856853488
	2805207581808 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2805207581808 -> 2804856853344
	2804856853344 [label=AccumulateGrad]
	2804856853920 -> 2804856853488
	2805207581904 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2805207581904 -> 2804856853920
	2804856853920 [label=AccumulateGrad]
	2804856853104 -> 2804856859584
	2804856851616 -> 2804856849216
	2805207582864 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2805207582864 -> 2804856851616
	2804856851616 [label=AccumulateGrad]
	2804856850704 -> 2804856851952
	2805207582960 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2805207582960 -> 2804856850704
	2804856850704 [label=AccumulateGrad]
	2804856858288 -> 2804856851952
	2805207583056 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2805207583056 -> 2804856858288
	2804856858288 [label=AccumulateGrad]
	2804856854352 -> 2804856857328
	2805207583440 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2805207583440 -> 2804856854352
	2804856854352 [label=AccumulateGrad]
	2804856851376 -> 2804856849888
	2805207583536 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2805207583536 -> 2804856851376
	2804856851376 [label=AccumulateGrad]
	2804856849072 -> 2804856849888
	2805207583632 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2805207583632 -> 2804856849072
	2804856849072 [label=AccumulateGrad]
	2804856858816 -> 2804861759120
	2804856858816 [label=NativeBatchNormBackward0]
	2804856850080 -> 2804856858816
	2804856850080 [label=ConvolutionBackward0]
	2804856853968 -> 2804856850080
	2804856852432 -> 2804856850080
	2805207582288 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2805207582288 -> 2804856852432
	2804856852432 [label=AccumulateGrad]
	2804856852336 -> 2804856858816
	2805207582384 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2805207582384 -> 2804856852336
	2804856852336 [label=AccumulateGrad]
	2804856852576 -> 2804856858816
	2805207582480 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2805207582480 -> 2804856852576
	2804856852576 [label=AccumulateGrad]
	2804861760800 -> 2804861762720
	2805207584016 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2805207584016 -> 2804861760800
	2804861760800 [label=AccumulateGrad]
	2804861759888 -> 2804861760656
	2805207584112 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2805207584112 -> 2804861759888
	2804861759888 [label=AccumulateGrad]
	2804861760560 -> 2804861760656
	2805207584208 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2805207584208 -> 2804861760560
	2804861760560 [label=AccumulateGrad]
	2804861759312 -> 2804861758544
	2805207584592 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2805207584592 -> 2804861759312
	2804861759312 [label=AccumulateGrad]
	2804861760320 -> 2804861759072
	2805207584688 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2805207584688 -> 2804861760320
	2804861760320 [label=AccumulateGrad]
	2804861759936 -> 2804861759072
	2805207584784 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2805207584784 -> 2804861759936
	2804861759936 [label=AccumulateGrad]
	2804861759216 -> 2804861760704
	2804861759840 -> 2805204597872
	2805207585744 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2805207585744 -> 2804861759840
	2804861759840 [label=AccumulateGrad]
	2804861760416 -> 2805204597440
	2805207585840 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2805207585840 -> 2804861760416
	2804861760416 [label=AccumulateGrad]
	2804861760512 -> 2805204597440
	2805207585936 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2805207585936 -> 2804861760512
	2804861760512 [label=AccumulateGrad]
	2805204593888 -> 2805204598496
	2805207586320 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2805207586320 -> 2805204593888
	2805204593888 [label=AccumulateGrad]
	2805204587072 -> 2805204587168
	2805207586416 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2805207586416 -> 2805204587072
	2805204587072 [label=AccumulateGrad]
	2805204587120 -> 2805204587168
	2805207586512 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2805207586512 -> 2805204587120
	2805204587120 [label=AccumulateGrad]
	2805204587456 -> 2805204589136
	2805204587456 [label=NativeBatchNormBackward0]
	2805204598256 -> 2805204587456
	2805204598256 [label=ConvolutionBackward0]
	2804861760032 -> 2805204598256
	2804861759168 -> 2805204598256
	2805207585168 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2805207585168 -> 2804861759168
	2804861759168 [label=AccumulateGrad]
	2805204582704 -> 2805204587456
	2805207585264 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2805207585264 -> 2805204582704
	2805204582704 [label=AccumulateGrad]
	2805204583568 -> 2805204587456
	2805207585360 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2805207585360 -> 2805204583568
	2805204583568 [label=AccumulateGrad]
	2805204586688 -> 2805204586016
	2805207586896 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2805207586896 -> 2805204586688
	2805204586688 [label=AccumulateGrad]
	2805204585968 -> 2805204585920
	2805207586992 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2805207586992 -> 2805204585968
	2805204585968 [label=AccumulateGrad]
	2805204585824 -> 2805204585920
	2805207587088 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2805207587088 -> 2805204585824
	2805204585824 [label=AccumulateGrad]
	2805204591152 -> 2805204587936
	2805207587472 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2805207587472 -> 2805204591152
	2805204591152 [label=AccumulateGrad]
	2805204592256 -> 2805204593360
	2805207587568 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2805207587568 -> 2805204592256
	2805204592256 [label=AccumulateGrad]
	2805204593312 -> 2805204593360
	2805207587664 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2805207587664 -> 2805204593312
	2805204593312 [label=AccumulateGrad]
	2805204593408 -> 2805204593456
	2805204584144 -> 2805204586400
	2805204584144 [label=TBackward0]
	2805204593504 -> 2805204584144
	2805207588240 [label="fc.weight
 (10, 512)" fillcolor=lightblue]
	2805207588240 -> 2805204593504
	2805204593504 [label=AccumulateGrad]
	2805204586400 -> 2805207759472
}
