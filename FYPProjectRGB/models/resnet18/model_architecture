digraph {
	graph [size="59.849999999999994,59.849999999999994"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1804578898672 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1804543109888 [label=SigmoidBackward0]
	1804543109696 -> 1804543109888
	1804543109696 [label=AddmmBackward0]
	1804543109552 -> 1804543109696
	1804578725264 [label="model.fc.bias
 (19)" fillcolor=lightblue]
	1804578725264 -> 1804543109552
	1804543109552 [label=AccumulateGrad]
	1804543109744 -> 1804543109696
	1804543109744 [label=ViewBackward0]
	1804543109504 -> 1804543109744
	1804543109504 [label=MeanBackward1]
	1804543109312 -> 1804543109504
	1804543109312 [label=ReluBackward0]
	1804543109216 -> 1804543109312
	1804543109216 [label=AddBackward0]
	1804543109120 -> 1804543109216
	1804543109120 [label=CudnnBatchNormBackward0]
	1804543108880 -> 1804543109120
	1804543108880 [label=ConvolutionBackward0]
	1804543107056 -> 1804543108880
	1804543107056 [label=ReluBackward0]
	1804543106864 -> 1804543107056
	1804543106864 [label=CudnnBatchNormBackward0]
	1804543111088 -> 1804543106864
	1804543111088 [label=ConvolutionBackward0]
	1804543109168 -> 1804543111088
	1804543109168 [label=ReluBackward0]
	1804543111232 -> 1804543109168
	1804543111232 [label=AddBackward0]
	1804543112000 -> 1804543111232
	1804543112000 [label=CudnnBatchNormBackward0]
	1804543112144 -> 1804543112000
	1804543112144 [label=ConvolutionBackward0]
	1804543112336 -> 1804543112144
	1804543112336 [label=ReluBackward0]
	1804543112480 -> 1804543112336
	1804543112480 [label=CudnnBatchNormBackward0]
	1804543112576 -> 1804543112480
	1804543112576 [label=ConvolutionBackward0]
	1804543110416 -> 1804543112576
	1804543110416 [label=ReluBackward0]
	1804543113632 -> 1804543110416
	1804543113632 [label=AddBackward0]
	1804543114496 -> 1804543113632
	1804543114496 [label=CudnnBatchNormBackward0]
	1804543113008 -> 1804543114496
	1804543113008 [label=ConvolutionBackward0]
	1804543113824 -> 1804543113008
	1804543113824 [label=ReluBackward0]
	1804543113728 -> 1804543113824
	1804543113728 [label=CudnnBatchNormBackward0]
	1804543113920 -> 1804543113728
	1804543113920 [label=ConvolutionBackward0]
	1804543112768 -> 1804543113920
	1804543112768 [label=ReluBackward0]
	1804543112816 -> 1804543112768
	1804543112816 [label=AddBackward0]
	1804543110896 -> 1804543112816
	1804543110896 [label=CudnnBatchNormBackward0]
	1804543110992 -> 1804543110896
	1804543110992 [label=ConvolutionBackward0]
	1804543111040 -> 1804543110992
	1804543111040 [label=ReluBackward0]
	1804543113440 -> 1804543111040
	1804543113440 [label=CudnnBatchNormBackward0]
	1804543111760 -> 1804543113440
	1804543111760 [label=ConvolutionBackward0]
	1804578914512 -> 1804543111760
	1804578914512 [label=ReluBackward0]
	1804578914656 -> 1804578914512
	1804578914656 [label=AddBackward0]
	1804578914752 -> 1804578914656
	1804578914752 [label=CudnnBatchNormBackward0]
	1804578914896 -> 1804578914752
	1804578914896 [label=ConvolutionBackward0]
	1804578915088 -> 1804578914896
	1804578915088 [label=ReluBackward0]
	1804578915232 -> 1804578915088
	1804578915232 [label=CudnnBatchNormBackward0]
	1804578915328 -> 1804578915232
	1804578915328 [label=ConvolutionBackward0]
	1804578914704 -> 1804578915328
	1804578914704 [label=ReluBackward0]
	1804578915616 -> 1804578914704
	1804578915616 [label=AddBackward0]
	1804578915712 -> 1804578915616
	1804578915712 [label=CudnnBatchNormBackward0]
	1804578915856 -> 1804578915712
	1804578915856 [label=ConvolutionBackward0]
	1804578916048 -> 1804578915856
	1804578916048 [label=ReluBackward0]
	1804578916192 -> 1804578916048
	1804578916192 [label=CudnnBatchNormBackward0]
	1804578916288 -> 1804578916192
	1804578916288 [label=ConvolutionBackward0]
	1804578916480 -> 1804578916288
	1804578916480 [label=ReluBackward0]
	1804578916624 -> 1804578916480
	1804578916624 [label=AddBackward0]
	1804578916720 -> 1804578916624
	1804578916720 [label=CudnnBatchNormBackward0]
	1804578916864 -> 1804578916720
	1804578916864 [label=ConvolutionBackward0]
	1804578917056 -> 1804578916864
	1804578917056 [label=ReluBackward0]
	1804578917200 -> 1804578917056
	1804578917200 [label=CudnnBatchNormBackward0]
	1804578917296 -> 1804578917200
	1804578917296 [label=ConvolutionBackward0]
	1804578916672 -> 1804578917296
	1804578916672 [label=ReluBackward0]
	1804578917584 -> 1804578916672
	1804578917584 [label=AddBackward0]
	1804578917680 -> 1804578917584
	1804578917680 [label=CudnnBatchNormBackward0]
	1804578917824 -> 1804578917680
	1804578917824 [label=ConvolutionBackward0]
	1804578918016 -> 1804578917824
	1804578918016 [label=ReluBackward0]
	1804578918160 -> 1804578918016
	1804578918160 [label=CudnnBatchNormBackward0]
	1804578918256 -> 1804578918160
	1804578918256 [label=ConvolutionBackward0]
	1804578917632 -> 1804578918256
	1804578917632 [label=MaxPool2DWithIndicesBackward0]
	1804578918544 -> 1804578917632
	1804578918544 [label=ReluBackward0]
	1804578918592 -> 1804578918544
	1804578918592 [label=CudnnBatchNormBackward0]
	1804578918736 -> 1804578918592
	1804578918736 [label=ConvolutionBackward0]
	1804578919024 -> 1804578918736
	1804578581936 [label="model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	1804578581936 -> 1804578919024
	1804578919024 [label=AccumulateGrad]
	1804578918688 -> 1804578918592
	1804578582128 [label="model.bn1.weight
 (64)" fillcolor=lightblue]
	1804578582128 -> 1804578918688
	1804578918688 [label=AccumulateGrad]
	1804578918832 -> 1804578918592
	1804578582512 [label="model.bn1.bias
 (64)" fillcolor=lightblue]
	1804578582512 -> 1804578918832
	1804578918832 [label=AccumulateGrad]
	1804578918448 -> 1804578918256
	1804578582896 [label="model.layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1804578582896 -> 1804578918448
	1804578918448 [label=AccumulateGrad]
	1804578918208 -> 1804578918160
	1804578582992 [label="model.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1804578582992 -> 1804578918208
	1804578918208 [label=AccumulateGrad]
	1804578918064 -> 1804578918160
	1804578583088 [label="model.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1804578583088 -> 1804578918064
	1804578918064 [label=AccumulateGrad]
	1804578917968 -> 1804578917824
	1804578583472 [label="model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1804578583472 -> 1804578917968
	1804578917968 [label=AccumulateGrad]
	1804578917776 -> 1804578917680
	1804578583568 [label="model.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1804578583568 -> 1804578917776
	1804578917776 [label=AccumulateGrad]
	1804578917728 -> 1804578917680
	1804578583664 [label="model.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1804578583664 -> 1804578917728
	1804578917728 [label=AccumulateGrad]
	1804578917632 -> 1804578917584
	1804578917488 -> 1804578917296
	1804578584048 [label="model.layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1804578584048 -> 1804578917488
	1804578917488 [label=AccumulateGrad]
	1804578917248 -> 1804578917200
	1804578584144 [label="model.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1804578584144 -> 1804578917248
	1804578917248 [label=AccumulateGrad]
	1804578917104 -> 1804578917200
	1804578584240 [label="model.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1804578584240 -> 1804578917104
	1804578917104 [label=AccumulateGrad]
	1804578917008 -> 1804578916864
	1804578584624 [label="model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1804578584624 -> 1804578917008
	1804578917008 [label=AccumulateGrad]
	1804578916816 -> 1804578916720
	1804578584720 [label="model.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1804578584720 -> 1804578916816
	1804578916816 [label=AccumulateGrad]
	1804578916768 -> 1804578916720
	1804578584816 [label="model.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1804578584816 -> 1804578916768
	1804578916768 [label=AccumulateGrad]
	1804578916672 -> 1804578916624
	1804578916432 -> 1804578916288
	1804578585776 [label="model.layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1804578585776 -> 1804578916432
	1804578916432 [label=AccumulateGrad]
	1804578916240 -> 1804578916192
	1804578585872 [label="model.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1804578585872 -> 1804578916240
	1804578916240 [label=AccumulateGrad]
	1804578916096 -> 1804578916192
	1804578585968 [label="model.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1804578585968 -> 1804578916096
	1804578916096 [label=AccumulateGrad]
	1804578916000 -> 1804578915856
	1804578586352 [label="model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1804578586352 -> 1804578916000
	1804578916000 [label=AccumulateGrad]
	1804578915808 -> 1804578915712
	1804578586448 [label="model.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1804578586448 -> 1804578915808
	1804578915808 [label=AccumulateGrad]
	1804578915760 -> 1804578915712
	1804578586544 [label="model.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1804578586544 -> 1804578915760
	1804578915760 [label=AccumulateGrad]
	1804578915664 -> 1804578915616
	1804578915664 [label=CudnnBatchNormBackward0]
	1804578916384 -> 1804578915664
	1804578916384 [label=ConvolutionBackward0]
	1804578916480 -> 1804578916384
	1804578916528 -> 1804578916384
	1804578585200 [label="model.layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1804578585200 -> 1804578916528
	1804578916528 [label=AccumulateGrad]
	1804578915952 -> 1804578915664
	1804578585296 [label="model.layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	1804578585296 -> 1804578915952
	1804578915952 [label=AccumulateGrad]
	1804578915904 -> 1804578915664
	1804578585392 [label="model.layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	1804578585392 -> 1804578915904
	1804578915904 [label=AccumulateGrad]
	1804578915520 -> 1804578915328
	1804578718064 [label="model.layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1804578718064 -> 1804578915520
	1804578915520 [label=AccumulateGrad]
	1804578915280 -> 1804578915232
	1804578718160 [label="model.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1804578718160 -> 1804578915280
	1804578915280 [label=AccumulateGrad]
	1804578915136 -> 1804578915232
	1804578718256 [label="model.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1804578718256 -> 1804578915136
	1804578915136 [label=AccumulateGrad]
	1804578915040 -> 1804578914896
	1804578718640 [label="model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1804578718640 -> 1804578915040
	1804578915040 [label=AccumulateGrad]
	1804578914848 -> 1804578914752
	1804578718736 [label="model.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1804578718736 -> 1804578914848
	1804578914848 [label=AccumulateGrad]
	1804578914800 -> 1804578914752
	1804578718832 [label="model.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1804578718832 -> 1804578914800
	1804578914800 [label=AccumulateGrad]
	1804578914704 -> 1804578914656
	1804578914464 -> 1804543111760
	1804578719792 [label="model.layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1804578719792 -> 1804578914464
	1804578914464 [label=AccumulateGrad]
	1804543113296 -> 1804543113440
	1804578719888 [label="model.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1804578719888 -> 1804543113296
	1804543113296 [label=AccumulateGrad]
	1804543114688 -> 1804543113440
	1804578719984 [label="model.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1804578719984 -> 1804543114688
	1804543114688 [label=AccumulateGrad]
	1804543106480 -> 1804543110992
	1804578720368 [label="model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1804578720368 -> 1804543106480
	1804543106480 [label=AccumulateGrad]
	1804543108928 -> 1804543110896
	1804578720464 [label="model.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1804578720464 -> 1804543108928
	1804543108928 [label=AccumulateGrad]
	1804543112912 -> 1804543110896
	1804578720560 [label="model.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1804578720560 -> 1804543112912
	1804543112912 [label=AccumulateGrad]
	1804543112672 -> 1804543112816
	1804543112672 [label=CudnnBatchNormBackward0]
	1804543114736 -> 1804543112672
	1804543114736 [label=ConvolutionBackward0]
	1804578914512 -> 1804543114736
	1804578914560 -> 1804543114736
	1804578719216 [label="model.layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1804578719216 -> 1804578914560
	1804578914560 [label=AccumulateGrad]
	1804543106672 -> 1804543112672
	1804578719312 [label="model.layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1804578719312 -> 1804543106672
	1804543106672 [label=AccumulateGrad]
	1804543106576 -> 1804543112672
	1804578719408 [label="model.layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1804578719408 -> 1804543106576
	1804543106576 [label=AccumulateGrad]
	1804543115168 -> 1804543113920
	1804578720944 [label="model.layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1804578720944 -> 1804543115168
	1804543115168 [label=AccumulateGrad]
	1804543113872 -> 1804543113728
	1804578721040 [label="model.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1804578721040 -> 1804543113872
	1804543113872 [label=AccumulateGrad]
	1804543113680 -> 1804543113728
	1804578721136 [label="model.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1804578721136 -> 1804543113680
	1804543113680 [label=AccumulateGrad]
	1804543113392 -> 1804543113008
	1804578721520 [label="model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1804578721520 -> 1804543113392
	1804543113392 [label=AccumulateGrad]
	1804543113248 -> 1804543114496
	1804578721616 [label="model.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1804578721616 -> 1804543113248
	1804543113248 [label=AccumulateGrad]
	1804543107728 -> 1804543114496
	1804578721712 [label="model.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1804578721712 -> 1804543107728
	1804543107728 [label=AccumulateGrad]
	1804543112768 -> 1804543113632
	1804543113056 -> 1804543112576
	1804578722672 [label="model.layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1804578722672 -> 1804543113056
	1804543113056 [label=AccumulateGrad]
	1804543112528 -> 1804543112480
	1804578722768 [label="model.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1804578722768 -> 1804543112528
	1804543112528 [label=AccumulateGrad]
	1804543112384 -> 1804543112480
	1804578722864 [label="model.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1804578722864 -> 1804543112384
	1804543112384 [label=AccumulateGrad]
	1804543112288 -> 1804543112144
	1804578723248 [label="model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1804578723248 -> 1804543112288
	1804543112288 [label=AccumulateGrad]
	1804543112096 -> 1804543112000
	1804578723344 [label="model.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1804578723344 -> 1804543112096
	1804543112096 [label=AccumulateGrad]
	1804543112048 -> 1804543112000
	1804578723440 [label="model.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1804578723440 -> 1804543112048
	1804543112048 [label=AccumulateGrad]
	1804543111952 -> 1804543111232
	1804543111952 [label=CudnnBatchNormBackward0]
	1804543112864 -> 1804543111952
	1804543112864 [label=ConvolutionBackward0]
	1804543110416 -> 1804543112864
	1804543106624 -> 1804543112864
	1804578722096 [label="model.layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1804578722096 -> 1804543106624
	1804543106624 [label=AccumulateGrad]
	1804543112240 -> 1804543111952
	1804578722192 [label="model.layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1804578722192 -> 1804543112240
	1804543112240 [label=AccumulateGrad]
	1804543112192 -> 1804543111952
	1804578722288 [label="model.layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1804578722288 -> 1804543112192
	1804543112192 [label=AccumulateGrad]
	1804543111136 -> 1804543111088
	1804578723824 [label="model.layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1804578723824 -> 1804543111136
	1804543111136 [label=AccumulateGrad]
	1804543106816 -> 1804543106864
	1804578723920 [label="model.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1804578723920 -> 1804543106816
	1804543106816 [label=AccumulateGrad]
	1804543106960 -> 1804543106864
	1804578724016 [label="model.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1804578724016 -> 1804543106960
	1804543106960 [label=AccumulateGrad]
	1804543108736 -> 1804543108880
	1804578724400 [label="model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1804578724400 -> 1804543108736
	1804543108736 [label=AccumulateGrad]
	1804543109024 -> 1804543109120
	1804578724496 [label="model.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1804578724496 -> 1804543109024
	1804543109024 [label=AccumulateGrad]
	1804543109072 -> 1804543109120
	1804578724592 [label="model.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1804578724592 -> 1804543109072
	1804543109072 [label=AccumulateGrad]
	1804543109168 -> 1804543109216
	1804543109600 -> 1804543109696
	1804543109600 [label=TBackward0]
	1804543109264 -> 1804543109600
	1804578725168 [label="model.fc.weight
 (19, 512)" fillcolor=lightblue]
	1804578725168 -> 1804543109264
	1804543109264 [label=AccumulateGrad]
	1804543109888 -> 1804578898672
}
