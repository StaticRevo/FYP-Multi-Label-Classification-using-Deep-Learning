digraph {
	graph [size="206.7,206.7"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1677464035664 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1677458305328 [label=AddmmBackward0]
	1677458305184 -> 1677458305328
	1677463638800 [label="classifier.1.bias
 (19)" fillcolor=lightblue]
	1677463638800 -> 1677458305184
	1677458305184 [label=AccumulateGrad]
	1677458301248 -> 1677458305328
	1677458301248 [label=AsStridedBackward0]
	1677458308544 -> 1677458301248
	1677458308544 [label=CopySlices]
	1677458303168 -> 1677458308544
	1677458303168 [label=MeanBackward1]
	1677458306432 -> 1677458303168
	1677458306432 [label=SiluBackward0]
	1677458301104 -> 1677458306432
	1677458301104 [label=CudnnBatchNormBackward0]
	1677458300048 -> 1677458301104
	1677458300048 [label=ConvolutionBackward0]
	1677458300672 -> 1677458300048
	1677458300672 [label=CudnnBatchNormBackward0]
	1677458302640 -> 1677458300672
	1677458302640 [label=ConvolutionBackward0]
	1677458300576 -> 1677458302640
	1677458300576 [label=MulBackward0]
	1677458307728 -> 1677458300576
	1677458307728 [label=SigmoidBackward0]
	1677458304560 -> 1677458307728
	1677458304560 [label=ConvolutionBackward0]
	1677458302736 -> 1677458304560
	1677458302736 [label=SiluBackward0]
	1677458299664 -> 1677458302736
	1677458299664 [label=ConvolutionBackward0]
	1677458300480 -> 1677458299664
	1677458300480 [label=MeanBackward1]
	1677458303264 -> 1677458300480
	1677458303264 [label=SiluBackward0]
	1677458299616 -> 1677458303264
	1677458299616 [label=CudnnBatchNormBackward0]
	1677458303360 -> 1677458299616
	1677458303360 [label=ConvolutionBackward0]
	1677458305136 -> 1677458303360
	1677458305136 [label=SiluBackward0]
	1677458302112 -> 1677458305136
	1677458302112 [label=CudnnBatchNormBackward0]
	1677467478208 -> 1677458302112
	1677467478208 [label=ConvolutionBackward0]
	1677467478400 -> 1677467478208
	1677467478400 [label=AddBackward0]
	1677467478544 -> 1677467478400
	1677467478544 [label=MulBackward0]
	1677467478688 -> 1677467478544
	1677467478688 [label=CudnnBatchNormBackward0]
	1677467478784 -> 1677467478688
	1677467478784 [label=ConvolutionBackward0]
	1677467468992 -> 1677467478784
	1677467468992 [label=MulBackward0]
	1677467469136 -> 1677467468992
	1677467469136 [label=SigmoidBackward0]
	1677467469280 -> 1677467469136
	1677467469280 [label=ConvolutionBackward0]
	1677467469376 -> 1677467469280
	1677467469376 [label=SiluBackward0]
	1677467469568 -> 1677467469376
	1677467469568 [label=ConvolutionBackward0]
	1677467469664 -> 1677467469568
	1677467469664 [label=MeanBackward1]
	1677467469088 -> 1677467469664
	1677467469088 [label=SiluBackward0]
	1677467469904 -> 1677467469088
	1677467469904 [label=CudnnBatchNormBackward0]
	1677467470000 -> 1677467469904
	1677467470000 [label=ConvolutionBackward0]
	1677467470192 -> 1677467470000
	1677467470192 [label=SiluBackward0]
	1677467470336 -> 1677467470192
	1677467470336 [label=CudnnBatchNormBackward0]
	1677467470432 -> 1677467470336
	1677467470432 [label=ConvolutionBackward0]
	1677467478496 -> 1677467470432
	1677467478496 [label=AddBackward0]
	1677467470720 -> 1677467478496
	1677467470720 [label=MulBackward0]
	1677467470864 -> 1677467470720
	1677467470864 [label=CudnnBatchNormBackward0]
	1677467470960 -> 1677467470864
	1677467470960 [label=ConvolutionBackward0]
	1677467471152 -> 1677467470960
	1677467471152 [label=MulBackward0]
	1677467471296 -> 1677467471152
	1677467471296 [label=SigmoidBackward0]
	1677467471440 -> 1677467471296
	1677467471440 [label=ConvolutionBackward0]
	1677467471536 -> 1677467471440
	1677467471536 [label=SiluBackward0]
	1677467471728 -> 1677467471536
	1677467471728 [label=ConvolutionBackward0]
	1677467471824 -> 1677467471728
	1677467471824 [label=MeanBackward1]
	1677467471248 -> 1677467471824
	1677467471248 [label=SiluBackward0]
	1677467472064 -> 1677467471248
	1677467472064 [label=CudnnBatchNormBackward0]
	1677467472160 -> 1677467472064
	1677467472160 [label=ConvolutionBackward0]
	1677467472352 -> 1677467472160
	1677467472352 [label=SiluBackward0]
	1677467472496 -> 1677467472352
	1677467472496 [label=CudnnBatchNormBackward0]
	1677467472592 -> 1677467472496
	1677467472592 [label=ConvolutionBackward0]
	1677467470672 -> 1677467472592
	1677467470672 [label=AddBackward0]
	1677467472880 -> 1677467470672
	1677467472880 [label=MulBackward0]
	1677467473024 -> 1677467472880
	1677467473024 [label=CudnnBatchNormBackward0]
	1677467473120 -> 1677467473024
	1677467473120 [label=ConvolutionBackward0]
	1677467473312 -> 1677467473120
	1677467473312 [label=MulBackward0]
	1677467473456 -> 1677467473312
	1677467473456 [label=SigmoidBackward0]
	1677467473600 -> 1677467473456
	1677467473600 [label=ConvolutionBackward0]
	1677467473696 -> 1677467473600
	1677467473696 [label=SiluBackward0]
	1677467473888 -> 1677467473696
	1677467473888 [label=ConvolutionBackward0]
	1677467473984 -> 1677467473888
	1677467473984 [label=MeanBackward1]
	1677467473408 -> 1677467473984
	1677467473408 [label=SiluBackward0]
	1677467474224 -> 1677467473408
	1677467474224 [label=CudnnBatchNormBackward0]
	1677467474272 -> 1677467474224
	1677467474272 [label=ConvolutionBackward0]
	1677467474560 -> 1677467474272
	1677467474560 [label=SiluBackward0]
	1677467474704 -> 1677467474560
	1677467474704 [label=CudnnBatchNormBackward0]
	1677467474752 -> 1677467474704
	1677467474752 [label=ConvolutionBackward0]
	1677467472832 -> 1677467474752
	1677467472832 [label=CudnnBatchNormBackward0]
	1677467475136 -> 1677467472832
	1677467475136 [label=ConvolutionBackward0]
	1677467475328 -> 1677467475136
	1677467475328 [label=MulBackward0]
	1677467475472 -> 1677467475328
	1677467475472 [label=SigmoidBackward0]
	1677467475616 -> 1677467475472
	1677467475616 [label=ConvolutionBackward0]
	1677467475664 -> 1677467475616
	1677467475664 [label=SiluBackward0]
	1677467475952 -> 1677467475664
	1677467475952 [label=ConvolutionBackward0]
	1677467476000 -> 1677467475952
	1677467476000 [label=MeanBackward1]
	1677467475424 -> 1677467476000
	1677467475424 [label=SiluBackward0]
	1677467476192 -> 1677467475424
	1677467476192 [label=CudnnBatchNormBackward0]
	1677467476432 -> 1677467476192
	1677467476432 [label=ConvolutionBackward0]
	1677467476720 -> 1677467476432
	1677467476720 [label=SiluBackward0]
	1677467476864 -> 1677467476720
	1677467476864 [label=CudnnBatchNormBackward0]
	1677467476912 -> 1677467476864
	1677467476912 [label=ConvolutionBackward0]
	1677467477200 -> 1677467476912
	1677467477200 [label=AddBackward0]
	1677467477344 -> 1677467477200
	1677467477344 [label=MulBackward0]
	1677467477488 -> 1677467477344
	1677467477488 [label=CudnnBatchNormBackward0]
	1677467478928 -> 1677467477488
	1677467478928 [label=ConvolutionBackward0]
	1677467479120 -> 1677467478928
	1677467479120 [label=MulBackward0]
	1677467479264 -> 1677467479120
	1677467479264 [label=SigmoidBackward0]
	1677467479408 -> 1677467479264
	1677467479408 [label=ConvolutionBackward0]
	1677467479456 -> 1677467479408
	1677467479456 [label=SiluBackward0]
	1677467479744 -> 1677467479456
	1677467479744 [label=ConvolutionBackward0]
	1677467479792 -> 1677467479744
	1677467479792 [label=MeanBackward1]
	1677467479216 -> 1677467479792
	1677467479216 [label=SiluBackward0]
	1677467479984 -> 1677467479216
	1677467479984 [label=CudnnBatchNormBackward0]
	1677467480224 -> 1677467479984
	1677467480224 [label=ConvolutionBackward0]
	1677467480512 -> 1677467480224
	1677467480512 [label=SiluBackward0]
	1677467480656 -> 1677467480512
	1677467480656 [label=CudnnBatchNormBackward0]
	1677467480704 -> 1677467480656
	1677467480704 [label=ConvolutionBackward0]
	1677467477296 -> 1677467480704
	1677467477296 [label=AddBackward0]
	1677467481088 -> 1677467477296
	1677467481088 [label=MulBackward0]
	1677467481232 -> 1677467481088
	1677467481232 [label=CudnnBatchNormBackward0]
	1677467481328 -> 1677467481232
	1677467481328 [label=ConvolutionBackward0]
	1677467481520 -> 1677467481328
	1677467481520 [label=MulBackward0]
	1677467481664 -> 1677467481520
	1677467481664 [label=SigmoidBackward0]
	1677467481808 -> 1677467481664
	1677467481808 [label=ConvolutionBackward0]
	1677467481856 -> 1677467481808
	1677467481856 [label=SiluBackward0]
	1677467482144 -> 1677467481856
	1677467482144 [label=ConvolutionBackward0]
	1677467482192 -> 1677467482144
	1677467482192 [label=MeanBackward1]
	1677467481616 -> 1677467482192
	1677467481616 [label=SiluBackward0]
	1677467482384 -> 1677467481616
	1677467482384 [label=CudnnBatchNormBackward0]
	1677467482624 -> 1677467482384
	1677467482624 [label=ConvolutionBackward0]
	1677467482912 -> 1677467482624
	1677467482912 [label=SiluBackward0]
	1677467483056 -> 1677467482912
	1677467483056 [label=CudnnBatchNormBackward0]
	1677467483104 -> 1677467483056
	1677467483104 [label=ConvolutionBackward0]
	1677467481040 -> 1677467483104
	1677467481040 [label=CudnnBatchNormBackward0]
	1677467483488 -> 1677467481040
	1677467483488 [label=ConvolutionBackward0]
	1677467483680 -> 1677467483488
	1677467483680 [label=MulBackward0]
	1677467483824 -> 1677467483680
	1677467483824 [label=SigmoidBackward0]
	1677467483968 -> 1677467483824
	1677467483968 [label=ConvolutionBackward0]
	1677467484016 -> 1677467483968
	1677467484016 [label=SiluBackward0]
	1677464305872 -> 1677467484016
	1677464305872 [label=ConvolutionBackward0]
	1677464305920 -> 1677464305872
	1677464305920 [label=MeanBackward1]
	1677467483776 -> 1677464305920
	1677467483776 [label=SiluBackward0]
	1677464306112 -> 1677467483776
	1677464306112 [label=CudnnBatchNormBackward0]
	1677464306352 -> 1677464306112
	1677464306352 [label=ConvolutionBackward0]
	1677464306640 -> 1677464306352
	1677464306640 [label=SiluBackward0]
	1677464306736 -> 1677464306640
	1677464306736 [label=CudnnBatchNormBackward0]
	1677459490992 -> 1677464306736
	1677459490992 [label=ConvolutionBackward0]
	1677459501216 -> 1677459490992
	1677459501216 [label=AddBackward0]
	1677459498528 -> 1677459501216
	1677459498528 [label=MulBackward0]
	1677459491376 -> 1677459498528
	1677459491376 [label=CudnnBatchNormBackward0]
	1677459492672 -> 1677459491376
	1677459492672 [label=ConvolutionBackward0]
	1677459501648 -> 1677459492672
	1677459501648 [label=MulBackward0]
	1677459497232 -> 1677459501648
	1677459497232 [label=SigmoidBackward0]
	1677459497040 -> 1677459497232
	1677459497040 [label=ConvolutionBackward0]
	1677459496704 -> 1677459497040
	1677459496704 [label=SiluBackward0]
	1677459502176 -> 1677459496704
	1677459502176 [label=ConvolutionBackward0]
	1677459500160 -> 1677459502176
	1677459500160 [label=MeanBackward1]
	1677459498816 -> 1677459500160
	1677459498816 [label=SiluBackward0]
	1677459492144 -> 1677459498816
	1677459492144 [label=CudnnBatchNormBackward0]
	1677459499392 -> 1677459492144
	1677459499392 [label=ConvolutionBackward0]
	1677459494832 -> 1677459499392
	1677459494832 [label=SiluBackward0]
	1677459499968 -> 1677459494832
	1677459499968 [label=CudnnBatchNormBackward0]
	1677459488880 -> 1677459499968
	1677459488880 [label=ConvolutionBackward0]
	1677459494640 -> 1677459488880
	1677459494640 [label=AddBackward0]
	1677459493296 -> 1677459494640
	1677459493296 [label=MulBackward0]
	1677459497664 -> 1677459493296
	1677459497664 [label=CudnnBatchNormBackward0]
	1677459504240 -> 1677459497664
	1677459504240 [label=ConvolutionBackward0]
	1677459503904 -> 1677459504240
	1677459503904 [label=MulBackward0]
	1677459500976 -> 1677459503904
	1677459500976 [label=SigmoidBackward0]
	1677459501744 -> 1677459500976
	1677459501744 [label=ConvolutionBackward0]
	1677459499776 -> 1677459501744
	1677459499776 [label=SiluBackward0]
	1677459491424 -> 1677459499776
	1677459491424 [label=ConvolutionBackward0]
	1677459490896 -> 1677459491424
	1677459490896 [label=MeanBackward1]
	1677459501168 -> 1677459490896
	1677459501168 [label=SiluBackward0]
	1677459494160 -> 1677459501168
	1677459494160 [label=CudnnBatchNormBackward0]
	1677459500256 -> 1677459494160
	1677459500256 [label=ConvolutionBackward0]
	1677459489024 -> 1677459500256
	1677459489024 [label=SiluBackward0]
	1677459499248 -> 1677459489024
	1677459499248 [label=CudnnBatchNormBackward0]
	1677459500640 -> 1677459499248
	1677459500640 [label=ConvolutionBackward0]
	1677459490080 -> 1677459500640
	1677459490080 [label=CudnnBatchNormBackward0]
	1677459491472 -> 1677459490080
	1677459491472 [label=ConvolutionBackward0]
	1677459494112 -> 1677459491472
	1677459494112 [label=MulBackward0]
	1677459494400 -> 1677459494112
	1677459494400 [label=SigmoidBackward0]
	1677459501312 -> 1677459494400
	1677459501312 [label=ConvolutionBackward0]
	1677459492576 -> 1677459501312
	1677459492576 [label=SiluBackward0]
	1677459500016 -> 1677459492576
	1677459500016 [label=ConvolutionBackward0]
	1677459500736 -> 1677459500016
	1677459500736 [label=MeanBackward1]
	1677459488928 -> 1677459500736
	1677459488928 [label=SiluBackward0]
	1677459495840 -> 1677459488928
	1677459495840 [label=CudnnBatchNormBackward0]
	1677459493824 -> 1677459495840
	1677459493824 [label=ConvolutionBackward0]
	1677459495168 -> 1677459493824
	1677459495168 [label=SiluBackward0]
	1677459496128 -> 1677459495168
	1677459496128 [label=CudnnBatchNormBackward0]
	1677459499056 -> 1677459496128
	1677459499056 [label=ConvolutionBackward0]
	1677459495552 -> 1677459499056
	1677459495552 [label=AddBackward0]
	1677459495600 -> 1677459495552
	1677459495600 [label=MulBackward0]
	1677459500592 -> 1677459495600
	1677459500592 [label=CudnnBatchNormBackward0]
	1677459490176 -> 1677459500592
	1677459490176 [label=ConvolutionBackward0]
	1677459501936 -> 1677459490176
	1677459501936 [label=MulBackward0]
	1677459503712 -> 1677459501936
	1677459503712 [label=SigmoidBackward0]
	1677459489936 -> 1677459503712
	1677459489936 [label=ConvolutionBackward0]
	1677459503472 -> 1677459489936
	1677459503472 [label=SiluBackward0]
	1677459503328 -> 1677459503472
	1677459503328 [label=ConvolutionBackward0]
	1677459504288 -> 1677459503328
	1677459504288 [label=MeanBackward1]
	1677459497280 -> 1677459504288
	1677459497280 [label=SiluBackward0]
	1677459504336 -> 1677459497280
	1677459504336 [label=CudnnBatchNormBackward0]
	1677459504576 -> 1677459504336
	1677459504576 [label=ConvolutionBackward0]
	1677459504864 -> 1677459504576
	1677459504864 [label=SiluBackward0]
	1677459505008 -> 1677459504864
	1677459505008 [label=CudnnBatchNormBackward0]
	1677459505056 -> 1677459505008
	1677459505056 [label=ConvolutionBackward0]
	1677459498096 -> 1677459505056
	1677459498096 [label=CudnnBatchNormBackward0]
	1677459503424 -> 1677459498096
	1677459503424 [label=ConvolutionBackward0]
	1677459499488 -> 1677459503424
	1677459499488 [label=MulBackward0]
	1677470026000 -> 1677459499488
	1677470026000 [label=SigmoidBackward0]
	1677470026144 -> 1677470026000
	1677470026144 [label=ConvolutionBackward0]
	1677470026192 -> 1677470026144
	1677470026192 [label=SiluBackward0]
	1677470026480 -> 1677470026192
	1677470026480 [label=ConvolutionBackward0]
	1677470026528 -> 1677470026480
	1677470026528 [label=MeanBackward1]
	1677470025952 -> 1677470026528
	1677470025952 [label=SiluBackward0]
	1677470026720 -> 1677470025952
	1677470026720 [label=CudnnBatchNormBackward0]
	1677470026960 -> 1677470026720
	1677470026960 [label=ConvolutionBackward0]
	1677470027248 -> 1677470026960
	1677470027248 [label=SiluBackward0]
	1677470027392 -> 1677470027248
	1677470027392 [label=CudnnBatchNormBackward0]
	1677470027440 -> 1677470027392
	1677470027440 [label=ConvolutionBackward0]
	1677470027728 -> 1677470027440
	1677470027728 [label=AddBackward0]
	1677470027872 -> 1677470027728
	1677470027872 [label=MulBackward0]
	1677470028016 -> 1677470027872
	1677470028016 [label=CudnnBatchNormBackward0]
	1677470028112 -> 1677470028016
	1677470028112 [label=ConvolutionBackward0]
	1677470028304 -> 1677470028112
	1677470028304 [label=MulBackward0]
	1677470028448 -> 1677470028304
	1677470028448 [label=SigmoidBackward0]
	1677470028592 -> 1677470028448
	1677470028592 [label=ConvolutionBackward0]
	1677470028640 -> 1677470028592
	1677470028640 [label=SiluBackward0]
	1677470028928 -> 1677470028640
	1677470028928 [label=ConvolutionBackward0]
	1677470028976 -> 1677470028928
	1677470028976 [label=MeanBackward1]
	1677470028400 -> 1677470028976
	1677470028400 [label=SiluBackward0]
	1677470029168 -> 1677470028400
	1677470029168 [label=CudnnBatchNormBackward0]
	1677470029408 -> 1677470029168
	1677470029408 [label=ConvolutionBackward0]
	1677470029696 -> 1677470029408
	1677470029696 [label=SiluBackward0]
	1677470029840 -> 1677470029696
	1677470029840 [label=CudnnBatchNormBackward0]
	1677470029888 -> 1677470029840
	1677470029888 [label=ConvolutionBackward0]
	1677470027824 -> 1677470029888
	1677470027824 [label=CudnnBatchNormBackward0]
	1677470030272 -> 1677470027824
	1677470030272 [label=ConvolutionBackward0]
	1677470030464 -> 1677470030272
	1677470030464 [label=MulBackward0]
	1677470030608 -> 1677470030464
	1677470030608 [label=SigmoidBackward0]
	1677470030752 -> 1677470030608
	1677470030752 [label=ConvolutionBackward0]
	1677470030800 -> 1677470030752
	1677470030800 [label=SiluBackward0]
	1677470031088 -> 1677470030800
	1677470031088 [label=ConvolutionBackward0]
	1677470031136 -> 1677470031088
	1677470031136 [label=MeanBackward1]
	1677470030560 -> 1677470031136
	1677470030560 [label=SiluBackward0]
	1677470031328 -> 1677470030560
	1677470031328 [label=CudnnBatchNormBackward0]
	1677470031568 -> 1677470031328
	1677470031568 [label=ConvolutionBackward0]
	1677470031856 -> 1677470031568
	1677470031856 [label=SiluBackward0]
	1677470032000 -> 1677470031856
	1677470032000 [label=CudnnBatchNormBackward0]
	1677470032048 -> 1677470032000
	1677470032048 [label=ConvolutionBackward0]
	1677470032336 -> 1677470032048
	1677470032336 [label=CudnnBatchNormBackward0]
	1677470032480 -> 1677470032336
	1677470032480 [label=ConvolutionBackward0]
	1677470032672 -> 1677470032480
	1677470032672 [label=MulBackward0]
	1677470032816 -> 1677470032672
	1677470032816 [label=SigmoidBackward0]
	1677470032960 -> 1677470032816
	1677470032960 [label=ConvolutionBackward0]
	1677470033008 -> 1677470032960
	1677470033008 [label=SiluBackward0]
	1677470033296 -> 1677470033008
	1677470033296 [label=ConvolutionBackward0]
	1677470033344 -> 1677470033296
	1677470033344 [label=MeanBackward1]
	1677470032768 -> 1677470033344
	1677470032768 [label=SiluBackward0]
	1677470033536 -> 1677470032768
	1677470033536 [label=CudnnBatchNormBackward0]
	1677470033776 -> 1677470033536
	1677470033776 [label=ConvolutionBackward0]
	1677470034064 -> 1677470033776
	1677470034064 [label=SiluBackward0]
	1677470034208 -> 1677470034064
	1677470034208 [label=CudnnBatchNormBackward0]
	1677470034256 -> 1677470034208
	1677470034256 [label=ConvolutionBackward0]
	1677470034544 -> 1677470034256
	1677463638608 [label="features.0.0.weight
 (32, 12, 3, 3)" fillcolor=lightblue]
	1677463638608 -> 1677470034544
	1677470034544 [label=AccumulateGrad]
	1677470034112 -> 1677470034208
	1677513257616 [label="features.0.1.weight
 (32)" fillcolor=lightblue]
	1677513257616 -> 1677470034112
	1677470034112 [label=AccumulateGrad]
	1677470034352 -> 1677470034208
	1677467517296 [label="features.0.1.bias
 (32)" fillcolor=lightblue]
	1677467517296 -> 1677470034352
	1677470034352 [label=AccumulateGrad]
	1677470034016 -> 1677470033776
	1677467517776 [label="features.1.0.block.0.0.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	1677467517776 -> 1677470034016
	1677470034016 [label=AccumulateGrad]
	1677470033728 -> 1677470033536
	1677467517872 [label="features.1.0.block.0.1.weight
 (32)" fillcolor=lightblue]
	1677467517872 -> 1677470033728
	1677470033728 [label=AccumulateGrad]
	1677470033872 -> 1677470033536
	1677467517968 [label="features.1.0.block.0.1.bias
 (32)" fillcolor=lightblue]
	1677467517968 -> 1677470033872
	1677470033872 [label=AccumulateGrad]
	1677470033200 -> 1677470033296
	1677467518352 [label="features.1.0.block.1.fc1.weight
 (8, 32, 1, 1)" fillcolor=lightblue]
	1677467518352 -> 1677470033200
	1677470033200 [label=AccumulateGrad]
	1677470033440 -> 1677470033296
	1677467518448 [label="features.1.0.block.1.fc1.bias
 (8)" fillcolor=lightblue]
	1677467518448 -> 1677470033440
	1677470033440 [label=AccumulateGrad]
	1677470032864 -> 1677470032960
	1677467518544 [label="features.1.0.block.1.fc2.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	1677467518544 -> 1677470032864
	1677470032864 [label=AccumulateGrad]
	1677470033104 -> 1677470032960
	1677467518640 [label="features.1.0.block.1.fc2.bias
 (32)" fillcolor=lightblue]
	1677467518640 -> 1677470033104
	1677470033104 [label=AccumulateGrad]
	1677470032768 -> 1677470032672
	1677470032624 -> 1677470032480
	1677467518736 [label="features.1.0.block.2.0.weight
 (16, 32, 1, 1)" fillcolor=lightblue]
	1677467518736 -> 1677470032624
	1677470032624 [label=AccumulateGrad]
	1677470032432 -> 1677470032336
	1677467518832 [label="features.1.0.block.2.1.weight
 (16)" fillcolor=lightblue]
	1677467518832 -> 1677470032432
	1677470032432 [label=AccumulateGrad]
	1677470032384 -> 1677470032336
	1677467518928 [label="features.1.0.block.2.1.bias
 (16)" fillcolor=lightblue]
	1677467518928 -> 1677470032384
	1677470032384 [label=AccumulateGrad]
	1677470032288 -> 1677470032048
	1677467519312 [label="features.2.0.block.0.0.weight
 (96, 16, 1, 1)" fillcolor=lightblue]
	1677467519312 -> 1677470032288
	1677470032288 [label=AccumulateGrad]
	1677470031904 -> 1677470032000
	1677467519408 [label="features.2.0.block.0.1.weight
 (96)" fillcolor=lightblue]
	1677467519408 -> 1677470031904
	1677470031904 [label=AccumulateGrad]
	1677470032144 -> 1677470032000
	1677467519504 [label="features.2.0.block.0.1.bias
 (96)" fillcolor=lightblue]
	1677467519504 -> 1677470032144
	1677470032144 [label=AccumulateGrad]
	1677470031808 -> 1677470031568
	1677467519888 [label="features.2.0.block.1.0.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	1677467519888 -> 1677470031808
	1677470031808 [label=AccumulateGrad]
	1677470031520 -> 1677470031328
	1677467519984 [label="features.2.0.block.1.1.weight
 (96)" fillcolor=lightblue]
	1677467519984 -> 1677470031520
	1677470031520 [label=AccumulateGrad]
	1677470031664 -> 1677470031328
	1677467520080 [label="features.2.0.block.1.1.bias
 (96)" fillcolor=lightblue]
	1677467520080 -> 1677470031664
	1677470031664 [label=AccumulateGrad]
	1677470030992 -> 1677470031088
	1677467520464 [label="features.2.0.block.2.fc1.weight
 (4, 96, 1, 1)" fillcolor=lightblue]
	1677467520464 -> 1677470030992
	1677470030992 [label=AccumulateGrad]
	1677470031232 -> 1677470031088
	1677467520560 [label="features.2.0.block.2.fc1.bias
 (4)" fillcolor=lightblue]
	1677467520560 -> 1677470031232
	1677470031232 [label=AccumulateGrad]
	1677470030656 -> 1677470030752
	1677467520656 [label="features.2.0.block.2.fc2.weight
 (96, 4, 1, 1)" fillcolor=lightblue]
	1677467520656 -> 1677470030656
	1677470030656 [label=AccumulateGrad]
	1677470030896 -> 1677470030752
	1677467520752 [label="features.2.0.block.2.fc2.bias
 (96)" fillcolor=lightblue]
	1677467520752 -> 1677470030896
	1677470030896 [label=AccumulateGrad]
	1677470030560 -> 1677470030464
	1677470030416 -> 1677470030272
	1677467520848 [label="features.2.0.block.3.0.weight
 (24, 96, 1, 1)" fillcolor=lightblue]
	1677467520848 -> 1677470030416
	1677470030416 [label=AccumulateGrad]
	1677470030224 -> 1677470027824
	1677467520944 [label="features.2.0.block.3.1.weight
 (24)" fillcolor=lightblue]
	1677467520944 -> 1677470030224
	1677470030224 [label=AccumulateGrad]
	1677470030080 -> 1677470027824
	1677467521040 [label="features.2.0.block.3.1.bias
 (24)" fillcolor=lightblue]
	1677467521040 -> 1677470030080
	1677470030080 [label=AccumulateGrad]
	1677470030176 -> 1677470029888
	1677467521424 [label="features.2.1.block.0.0.weight
 (144, 24, 1, 1)" fillcolor=lightblue]
	1677467521424 -> 1677470030176
	1677470030176 [label=AccumulateGrad]
	1677470029744 -> 1677470029840
	1677467521520 [label="features.2.1.block.0.1.weight
 (144)" fillcolor=lightblue]
	1677467521520 -> 1677470029744
	1677470029744 [label=AccumulateGrad]
	1677470029984 -> 1677470029840
	1677467521616 [label="features.2.1.block.0.1.bias
 (144)" fillcolor=lightblue]
	1677467521616 -> 1677470029984
	1677470029984 [label=AccumulateGrad]
	1677470029648 -> 1677470029408
	1677467522000 [label="features.2.1.block.1.0.weight
 (144, 1, 3, 3)" fillcolor=lightblue]
	1677467522000 -> 1677470029648
	1677470029648 [label=AccumulateGrad]
	1677470029360 -> 1677470029168
	1677467522096 [label="features.2.1.block.1.1.weight
 (144)" fillcolor=lightblue]
	1677467522096 -> 1677470029360
	1677470029360 [label=AccumulateGrad]
	1677470029504 -> 1677470029168
	1677467522192 [label="features.2.1.block.1.1.bias
 (144)" fillcolor=lightblue]
	1677467522192 -> 1677470029504
	1677470029504 [label=AccumulateGrad]
	1677470028832 -> 1677470028928
	1677467522576 [label="features.2.1.block.2.fc1.weight
 (6, 144, 1, 1)" fillcolor=lightblue]
	1677467522576 -> 1677470028832
	1677470028832 [label=AccumulateGrad]
	1677470029072 -> 1677470028928
	1677467522672 [label="features.2.1.block.2.fc1.bias
 (6)" fillcolor=lightblue]
	1677467522672 -> 1677470029072
	1677470029072 [label=AccumulateGrad]
	1677470028496 -> 1677470028592
	1677467522768 [label="features.2.1.block.2.fc2.weight
 (144, 6, 1, 1)" fillcolor=lightblue]
	1677467522768 -> 1677470028496
	1677470028496 [label=AccumulateGrad]
	1677470028736 -> 1677470028592
	1677467522864 [label="features.2.1.block.2.fc2.bias
 (144)" fillcolor=lightblue]
	1677467522864 -> 1677470028736
	1677470028736 [label=AccumulateGrad]
	1677470028400 -> 1677470028304
	1677470028256 -> 1677470028112
	1677467522960 [label="features.2.1.block.3.0.weight
 (24, 144, 1, 1)" fillcolor=lightblue]
	1677467522960 -> 1677470028256
	1677470028256 [label=AccumulateGrad]
	1677470028064 -> 1677470028016
	1677467523056 [label="features.2.1.block.3.1.weight
 (24)" fillcolor=lightblue]
	1677467523056 -> 1677470028064
	1677470028064 [label=AccumulateGrad]
	1677470027920 -> 1677470028016
	1677467523152 [label="features.2.1.block.3.1.bias
 (24)" fillcolor=lightblue]
	1677467523152 -> 1677470027920
	1677470027920 [label=AccumulateGrad]
	1677470027824 -> 1677470027728
	1677470027680 -> 1677470027440
	1677467523536 [label="features.3.0.block.0.0.weight
 (144, 24, 1, 1)" fillcolor=lightblue]
	1677467523536 -> 1677470027680
	1677470027680 [label=AccumulateGrad]
	1677470027296 -> 1677470027392
	1677467523632 [label="features.3.0.block.0.1.weight
 (144)" fillcolor=lightblue]
	1677467523632 -> 1677470027296
	1677470027296 [label=AccumulateGrad]
	1677470027536 -> 1677470027392
	1677467523728 [label="features.3.0.block.0.1.bias
 (144)" fillcolor=lightblue]
	1677467523728 -> 1677470027536
	1677470027536 [label=AccumulateGrad]
	1677470027200 -> 1677470026960
	1677467524112 [label="features.3.0.block.1.0.weight
 (144, 1, 5, 5)" fillcolor=lightblue]
	1677467524112 -> 1677470027200
	1677470027200 [label=AccumulateGrad]
	1677470026912 -> 1677470026720
	1677467524208 [label="features.3.0.block.1.1.weight
 (144)" fillcolor=lightblue]
	1677467524208 -> 1677470026912
	1677470026912 [label=AccumulateGrad]
	1677470027056 -> 1677470026720
	1677467524304 [label="features.3.0.block.1.1.bias
 (144)" fillcolor=lightblue]
	1677467524304 -> 1677470027056
	1677470027056 [label=AccumulateGrad]
	1677470026384 -> 1677470026480
	1677467524688 [label="features.3.0.block.2.fc1.weight
 (6, 144, 1, 1)" fillcolor=lightblue]
	1677467524688 -> 1677470026384
	1677470026384 [label=AccumulateGrad]
	1677470026624 -> 1677470026480
	1677467524784 [label="features.3.0.block.2.fc1.bias
 (6)" fillcolor=lightblue]
	1677467524784 -> 1677470026624
	1677470026624 [label=AccumulateGrad]
	1677470026048 -> 1677470026144
	1677467524880 [label="features.3.0.block.2.fc2.weight
 (144, 6, 1, 1)" fillcolor=lightblue]
	1677467524880 -> 1677470026048
	1677470026048 [label=AccumulateGrad]
	1677470026288 -> 1677470026144
	1677467524976 [label="features.3.0.block.2.fc2.bias
 (144)" fillcolor=lightblue]
	1677467524976 -> 1677470026288
	1677470026288 [label=AccumulateGrad]
	1677470025952 -> 1677459499488
	1677470025856 -> 1677459503424
	1677467525072 [label="features.3.0.block.3.0.weight
 (40, 144, 1, 1)" fillcolor=lightblue]
	1677467525072 -> 1677470025856
	1677470025856 [label=AccumulateGrad]
	1677459493584 -> 1677459498096
	1677467525168 [label="features.3.0.block.3.1.weight
 (40)" fillcolor=lightblue]
	1677467525168 -> 1677459493584
	1677459493584 [label=AccumulateGrad]
	1677459499536 -> 1677459498096
	1677467525264 [label="features.3.0.block.3.1.bias
 (40)" fillcolor=lightblue]
	1677467525264 -> 1677459499536
	1677459499536 [label=AccumulateGrad]
	1677459500880 -> 1677459505056
	1677467525648 [label="features.3.1.block.0.0.weight
 (240, 40, 1, 1)" fillcolor=lightblue]
	1677467525648 -> 1677459500880
	1677459500880 [label=AccumulateGrad]
	1677459504912 -> 1677459505008
	1677467525744 [label="features.3.1.block.0.1.weight
 (240)" fillcolor=lightblue]
	1677467525744 -> 1677459504912
	1677459504912 [label=AccumulateGrad]
	1677459490368 -> 1677459505008
	1677467525840 [label="features.3.1.block.0.1.bias
 (240)" fillcolor=lightblue]
	1677467525840 -> 1677459490368
	1677459490368 [label=AccumulateGrad]
	1677459504816 -> 1677459504576
	1677467526224 [label="features.3.1.block.1.0.weight
 (240, 1, 5, 5)" fillcolor=lightblue]
	1677467526224 -> 1677459504816
	1677459504816 [label=AccumulateGrad]
	1677459504528 -> 1677459504336
	1677467526320 [label="features.3.1.block.1.1.weight
 (240)" fillcolor=lightblue]
	1677467526320 -> 1677459504528
	1677459504528 [label=AccumulateGrad]
	1677459504672 -> 1677459504336
	1677467526416 [label="features.3.1.block.1.1.bias
 (240)" fillcolor=lightblue]
	1677467526416 -> 1677459504672
	1677459504672 [label=AccumulateGrad]
	1677459489312 -> 1677459503328
	1677467526800 [label="features.3.1.block.2.fc1.weight
 (10, 240, 1, 1)" fillcolor=lightblue]
	1677467526800 -> 1677459489312
	1677459489312 [label=AccumulateGrad]
	1677459499344 -> 1677459503328
	1677467526896 [label="features.3.1.block.2.fc1.bias
 (10)" fillcolor=lightblue]
	1677467526896 -> 1677459499344
	1677459499344 [label=AccumulateGrad]
	1677459499584 -> 1677459489936
	1677467526992 [label="features.3.1.block.2.fc2.weight
 (240, 10, 1, 1)" fillcolor=lightblue]
	1677467526992 -> 1677459499584
	1677459499584 [label=AccumulateGrad]
	1677459503520 -> 1677459489936
	1677467527088 [label="features.3.1.block.2.fc2.bias
 (240)" fillcolor=lightblue]
	1677467527088 -> 1677459503520
	1677459503520 [label=AccumulateGrad]
	1677459497280 -> 1677459501936
	1677459502080 -> 1677459490176
	1677467527184 [label="features.3.1.block.3.0.weight
 (40, 240, 1, 1)" fillcolor=lightblue]
	1677467527184 -> 1677459502080
	1677459502080 [label=AccumulateGrad]
	1677459497952 -> 1677459500592
	1677467527280 [label="features.3.1.block.3.1.weight
 (40)" fillcolor=lightblue]
	1677467527280 -> 1677459497952
	1677459497952 [label=AccumulateGrad]
	1677459489744 -> 1677459500592
	1677467527376 [label="features.3.1.block.3.1.bias
 (40)" fillcolor=lightblue]
	1677467527376 -> 1677459489744
	1677459489744 [label=AccumulateGrad]
	1677459498096 -> 1677459495552
	1677459502752 -> 1677459499056
	1677467527760 [label="features.4.0.block.0.0.weight
 (240, 40, 1, 1)" fillcolor=lightblue]
	1677467527760 -> 1677459502752
	1677459502752 [label=AccumulateGrad]
	1677459495792 -> 1677459496128
	1677467527856 [label="features.4.0.block.0.1.weight
 (240)" fillcolor=lightblue]
	1677467527856 -> 1677459495792
	1677459495792 [label=AccumulateGrad]
	1677459501984 -> 1677459496128
	1677467527952 [label="features.4.0.block.0.1.bias
 (240)" fillcolor=lightblue]
	1677467527952 -> 1677459501984
	1677459501984 [label=AccumulateGrad]
	1677459502992 -> 1677459493824
	1677467528336 [label="features.4.0.block.1.0.weight
 (240, 1, 3, 3)" fillcolor=lightblue]
	1677467528336 -> 1677459502992
	1677459502992 [label=AccumulateGrad]
	1677459497520 -> 1677459495840
	1677467528432 [label="features.4.0.block.1.1.weight
 (240)" fillcolor=lightblue]
	1677467528432 -> 1677459497520
	1677459497520 [label=AccumulateGrad]
	1677459491664 -> 1677459495840
	1677467528528 [label="features.4.0.block.1.1.bias
 (240)" fillcolor=lightblue]
	1677467528528 -> 1677459491664
	1677459491664 [label=AccumulateGrad]
	1677459498576 -> 1677459500016
	1677467528912 [label="features.4.0.block.2.fc1.weight
 (10, 240, 1, 1)" fillcolor=lightblue]
	1677467528912 -> 1677459498576
	1677459498576 [label=AccumulateGrad]
	1677459496896 -> 1677459500016
	1677467529008 [label="features.4.0.block.2.fc1.bias
 (10)" fillcolor=lightblue]
	1677467529008 -> 1677459496896
	1677459496896 [label=AccumulateGrad]
	1677459491856 -> 1677459501312
	1677467529104 [label="features.4.0.block.2.fc2.weight
 (240, 10, 1, 1)" fillcolor=lightblue]
	1677467529104 -> 1677459491856
	1677459491856 [label=AccumulateGrad]
	1677459499296 -> 1677459501312
	1677467529200 [label="features.4.0.block.2.fc2.bias
 (240)" fillcolor=lightblue]
	1677467529200 -> 1677459499296
	1677459499296 [label=AccumulateGrad]
	1677459488928 -> 1677459494112
	1677459500208 -> 1677459491472
	1677467529296 [label="features.4.0.block.3.0.weight
 (80, 240, 1, 1)" fillcolor=lightblue]
	1677467529296 -> 1677459500208
	1677459500208 [label=AccumulateGrad]
	1677459494496 -> 1677459490080
	1677467529392 [label="features.4.0.block.3.1.weight
 (80)" fillcolor=lightblue]
	1677467529392 -> 1677459494496
	1677459494496 [label=AccumulateGrad]
	1677459502272 -> 1677459490080
	1677467529488 [label="features.4.0.block.3.1.bias
 (80)" fillcolor=lightblue]
	1677467529488 -> 1677459502272
	1677459502272 [label=AccumulateGrad]
	1677459499104 -> 1677459500640
	1677467529872 [label="features.4.1.block.0.0.weight
 (480, 80, 1, 1)" fillcolor=lightblue]
	1677467529872 -> 1677459499104
	1677459499104 [label=AccumulateGrad]
	1677459489168 -> 1677459499248
	1677467529968 [label="features.4.1.block.0.1.weight
 (480)" fillcolor=lightblue]
	1677467529968 -> 1677459489168
	1677459489168 [label=AccumulateGrad]
	1677459499920 -> 1677459499248
	1677467530064 [label="features.4.1.block.0.1.bias
 (480)" fillcolor=lightblue]
	1677467530064 -> 1677459499920
	1677459499920 [label=AccumulateGrad]
	1677459498672 -> 1677459500256
	1677467530448 [label="features.4.1.block.1.0.weight
 (480, 1, 3, 3)" fillcolor=lightblue]
	1677467530448 -> 1677459498672
	1677459498672 [label=AccumulateGrad]
	1677459497856 -> 1677459494160
	1677467530544 [label="features.4.1.block.1.1.weight
 (480)" fillcolor=lightblue]
	1677467530544 -> 1677459497856
	1677459497856 [label=AccumulateGrad]
	1677459494448 -> 1677459494160
	1677467530640 [label="features.4.1.block.1.1.bias
 (480)" fillcolor=lightblue]
	1677467530640 -> 1677459494448
	1677459494448 [label=AccumulateGrad]
	1677459491328 -> 1677459491424
	1677467531024 [label="features.4.1.block.2.fc1.weight
 (20, 480, 1, 1)" fillcolor=lightblue]
	1677467531024 -> 1677459491328
	1677459491328 [label=AccumulateGrad]
	1677459491136 -> 1677459491424
	1677467531120 [label="features.4.1.block.2.fc1.bias
 (20)" fillcolor=lightblue]
	1677467531120 -> 1677459491136
	1677459491136 [label=AccumulateGrad]
	1677459501072 -> 1677459501744
	1677467531216 [label="features.4.1.block.2.fc2.weight
 (480, 20, 1, 1)" fillcolor=lightblue]
	1677467531216 -> 1677459501072
	1677459501072 [label=AccumulateGrad]
	1677459502896 -> 1677459501744
	1677467531312 [label="features.4.1.block.2.fc2.bias
 (480)" fillcolor=lightblue]
	1677467531312 -> 1677459502896
	1677459502896 [label=AccumulateGrad]
	1677459501168 -> 1677459503904
	1677459492240 -> 1677459504240
	1677467531408 [label="features.4.1.block.3.0.weight
 (80, 480, 1, 1)" fillcolor=lightblue]
	1677467531408 -> 1677459492240
	1677459492240 [label=AccumulateGrad]
	1677459496176 -> 1677459497664
	1677467531504 [label="features.4.1.block.3.1.weight
 (80)" fillcolor=lightblue]
	1677467531504 -> 1677459496176
	1677459496176 [label=AccumulateGrad]
	1677459501888 -> 1677459497664
	1677467531600 [label="features.4.1.block.3.1.bias
 (80)" fillcolor=lightblue]
	1677467531600 -> 1677459501888
	1677459501888 [label=AccumulateGrad]
	1677459490080 -> 1677459494640
	1677459502224 -> 1677459488880
	1677467531984 [label="features.4.2.block.0.0.weight
 (480, 80, 1, 1)" fillcolor=lightblue]
	1677467531984 -> 1677459502224
	1677459502224 [label=AccumulateGrad]
	1677459500544 -> 1677459499968
	1677467532080 [label="features.4.2.block.0.1.weight
 (480)" fillcolor=lightblue]
	1677467532080 -> 1677459500544
	1677459500544 [label=AccumulateGrad]
	1677459495216 -> 1677459499968
	1677467532176 [label="features.4.2.block.0.1.bias
 (480)" fillcolor=lightblue]
	1677467532176 -> 1677459495216
	1677459495216 [label=AccumulateGrad]
	1677459499008 -> 1677459499392
	1677467532560 [label="features.4.2.block.1.0.weight
 (480, 1, 3, 3)" fillcolor=lightblue]
	1677467532560 -> 1677459499008
	1677459499008 [label=AccumulateGrad]
	1677459500304 -> 1677459492144
	1677467532656 [label="features.4.2.block.1.1.weight
 (480)" fillcolor=lightblue]
	1677467532656 -> 1677459500304
	1677459500304 [label=AccumulateGrad]
	1677459491184 -> 1677459492144
	1677467532752 [label="features.4.2.block.1.1.bias
 (480)" fillcolor=lightblue]
	1677467532752 -> 1677459491184
	1677459491184 [label=AccumulateGrad]
	1677459493104 -> 1677459502176
	1677467533136 [label="features.4.2.block.2.fc1.weight
 (20, 480, 1, 1)" fillcolor=lightblue]
	1677467533136 -> 1677459493104
	1677459493104 [label=AccumulateGrad]
	1677459490656 -> 1677459502176
	1677467533232 [label="features.4.2.block.2.fc1.bias
 (20)" fillcolor=lightblue]
	1677467533232 -> 1677459490656
	1677459490656 [label=AccumulateGrad]
	1677459497136 -> 1677459497040
	1677464354896 [label="features.4.2.block.2.fc2.weight
 (480, 20, 1, 1)" fillcolor=lightblue]
	1677464354896 -> 1677459497136
	1677459497136 [label=AccumulateGrad]
	1677459491232 -> 1677459497040
	1677459636784 [label="features.4.2.block.2.fc2.bias
 (480)" fillcolor=lightblue]
	1677459636784 -> 1677459491232
	1677459491232 [label=AccumulateGrad]
	1677459498816 -> 1677459501648
	1677459503136 -> 1677459492672
	1677459637936 [label="features.4.2.block.3.0.weight
 (80, 480, 1, 1)" fillcolor=lightblue]
	1677459637936 -> 1677459503136
	1677459503136 [label=AccumulateGrad]
	1677459496272 -> 1677459491376
	1677459636496 [label="features.4.2.block.3.1.weight
 (80)" fillcolor=lightblue]
	1677459636496 -> 1677459496272
	1677459496272 [label=AccumulateGrad]
	1677459494880 -> 1677459491376
	1677459639376 [label="features.4.2.block.3.1.bias
 (80)" fillcolor=lightblue]
	1677459639376 -> 1677459494880
	1677459494880 [label=AccumulateGrad]
	1677459494640 -> 1677459501216
	1677459491808 -> 1677459490992
	1677459642256 [label="features.5.0.block.0.0.weight
 (480, 80, 1, 1)" fillcolor=lightblue]
	1677459642256 -> 1677459491808
	1677459491808 [label=AccumulateGrad]
	1677459493776 -> 1677464306736
	1677459642352 [label="features.5.0.block.0.1.weight
 (480)" fillcolor=lightblue]
	1677459642352 -> 1677459493776
	1677459493776 [label=AccumulateGrad]
	1677459499872 -> 1677464306736
	1677459642448 [label="features.5.0.block.0.1.bias
 (480)" fillcolor=lightblue]
	1677459642448 -> 1677459499872
	1677459499872 [label=AccumulateGrad]
	1677464306592 -> 1677464306352
	1677459642832 [label="features.5.0.block.1.0.weight
 (480, 1, 5, 5)" fillcolor=lightblue]
	1677459642832 -> 1677464306592
	1677464306592 [label=AccumulateGrad]
	1677464306304 -> 1677464306112
	1677459642928 [label="features.5.0.block.1.1.weight
 (480)" fillcolor=lightblue]
	1677459642928 -> 1677464306304
	1677464306304 [label=AccumulateGrad]
	1677464306448 -> 1677464306112
	1677459643024 [label="features.5.0.block.1.1.bias
 (480)" fillcolor=lightblue]
	1677459643024 -> 1677464306448
	1677464306448 [label=AccumulateGrad]
	1677464305776 -> 1677464305872
	1677459643408 [label="features.5.0.block.2.fc1.weight
 (20, 480, 1, 1)" fillcolor=lightblue]
	1677459643408 -> 1677464305776
	1677464305776 [label=AccumulateGrad]
	1677464306016 -> 1677464305872
	1677459643504 [label="features.5.0.block.2.fc1.bias
 (20)" fillcolor=lightblue]
	1677459643504 -> 1677464306016
	1677464306016 [label=AccumulateGrad]
	1677467483872 -> 1677467483968
	1677459643600 [label="features.5.0.block.2.fc2.weight
 (480, 20, 1, 1)" fillcolor=lightblue]
	1677459643600 -> 1677467483872
	1677467483872 [label=AccumulateGrad]
	1677467484112 -> 1677467483968
	1677459643696 [label="features.5.0.block.2.fc2.bias
 (480)" fillcolor=lightblue]
	1677459643696 -> 1677467484112
	1677467484112 [label=AccumulateGrad]
	1677467483776 -> 1677467483680
	1677467483632 -> 1677467483488
	1677459643792 [label="features.5.0.block.3.0.weight
 (112, 480, 1, 1)" fillcolor=lightblue]
	1677459643792 -> 1677467483632
	1677467483632 [label=AccumulateGrad]
	1677467483440 -> 1677467481040
	1677459643888 [label="features.5.0.block.3.1.weight
 (112)" fillcolor=lightblue]
	1677459643888 -> 1677467483440
	1677467483440 [label=AccumulateGrad]
	1677467483296 -> 1677467481040
	1677459643984 [label="features.5.0.block.3.1.bias
 (112)" fillcolor=lightblue]
	1677459643984 -> 1677467483296
	1677467483296 [label=AccumulateGrad]
	1677467483392 -> 1677467483104
	1677459644368 [label="features.5.1.block.0.0.weight
 (672, 112, 1, 1)" fillcolor=lightblue]
	1677459644368 -> 1677467483392
	1677467483392 [label=AccumulateGrad]
	1677467482960 -> 1677467483056
	1677459644464 [label="features.5.1.block.0.1.weight
 (672)" fillcolor=lightblue]
	1677459644464 -> 1677467482960
	1677467482960 [label=AccumulateGrad]
	1677467483200 -> 1677467483056
	1677459644560 [label="features.5.1.block.0.1.bias
 (672)" fillcolor=lightblue]
	1677459644560 -> 1677467483200
	1677467483200 [label=AccumulateGrad]
	1677467482864 -> 1677467482624
	1677459644944 [label="features.5.1.block.1.0.weight
 (672, 1, 5, 5)" fillcolor=lightblue]
	1677459644944 -> 1677467482864
	1677467482864 [label=AccumulateGrad]
	1677467482576 -> 1677467482384
	1677459645040 [label="features.5.1.block.1.1.weight
 (672)" fillcolor=lightblue]
	1677459645040 -> 1677467482576
	1677467482576 [label=AccumulateGrad]
	1677467482720 -> 1677467482384
	1677459645136 [label="features.5.1.block.1.1.bias
 (672)" fillcolor=lightblue]
	1677459645136 -> 1677467482720
	1677467482720 [label=AccumulateGrad]
	1677467482048 -> 1677467482144
	1677459645520 [label="features.5.1.block.2.fc1.weight
 (28, 672, 1, 1)" fillcolor=lightblue]
	1677459645520 -> 1677467482048
	1677467482048 [label=AccumulateGrad]
	1677467482288 -> 1677467482144
	1677459645616 [label="features.5.1.block.2.fc1.bias
 (28)" fillcolor=lightblue]
	1677459645616 -> 1677467482288
	1677467482288 [label=AccumulateGrad]
	1677467481712 -> 1677467481808
	1677459645712 [label="features.5.1.block.2.fc2.weight
 (672, 28, 1, 1)" fillcolor=lightblue]
	1677459645712 -> 1677467481712
	1677467481712 [label=AccumulateGrad]
	1677467481952 -> 1677467481808
	1677459645808 [label="features.5.1.block.2.fc2.bias
 (672)" fillcolor=lightblue]
	1677459645808 -> 1677467481952
	1677467481952 [label=AccumulateGrad]
	1677467481616 -> 1677467481520
	1677467481472 -> 1677467481328
	1677459645904 [label="features.5.1.block.3.0.weight
 (112, 672, 1, 1)" fillcolor=lightblue]
	1677459645904 -> 1677467481472
	1677467481472 [label=AccumulateGrad]
	1677467481280 -> 1677467481232
	1677459646000 [label="features.5.1.block.3.1.weight
 (112)" fillcolor=lightblue]
	1677459646000 -> 1677467481280
	1677467481280 [label=AccumulateGrad]
	1677467481136 -> 1677467481232
	1677459646096 [label="features.5.1.block.3.1.bias
 (112)" fillcolor=lightblue]
	1677459646096 -> 1677467481136
	1677467481136 [label=AccumulateGrad]
	1677467481040 -> 1677467477296
	1677467480992 -> 1677467480704
	1677459646480 [label="features.5.2.block.0.0.weight
 (672, 112, 1, 1)" fillcolor=lightblue]
	1677459646480 -> 1677467480992
	1677467480992 [label=AccumulateGrad]
	1677467480560 -> 1677467480656
	1677459646576 [label="features.5.2.block.0.1.weight
 (672)" fillcolor=lightblue]
	1677459646576 -> 1677467480560
	1677467480560 [label=AccumulateGrad]
	1677467480800 -> 1677467480656
	1677459646672 [label="features.5.2.block.0.1.bias
 (672)" fillcolor=lightblue]
	1677459646672 -> 1677467480800
	1677467480800 [label=AccumulateGrad]
	1677467480464 -> 1677467480224
	1677459647056 [label="features.5.2.block.1.0.weight
 (672, 1, 5, 5)" fillcolor=lightblue]
	1677459647056 -> 1677467480464
	1677467480464 [label=AccumulateGrad]
	1677467480176 -> 1677467479984
	1677459647152 [label="features.5.2.block.1.1.weight
 (672)" fillcolor=lightblue]
	1677459647152 -> 1677467480176
	1677467480176 [label=AccumulateGrad]
	1677467480320 -> 1677467479984
	1677459647248 [label="features.5.2.block.1.1.bias
 (672)" fillcolor=lightblue]
	1677459647248 -> 1677467480320
	1677467480320 [label=AccumulateGrad]
	1677467479648 -> 1677467479744
	1677459647632 [label="features.5.2.block.2.fc1.weight
 (28, 672, 1, 1)" fillcolor=lightblue]
	1677459647632 -> 1677467479648
	1677467479648 [label=AccumulateGrad]
	1677467479888 -> 1677467479744
	1677459647728 [label="features.5.2.block.2.fc1.bias
 (28)" fillcolor=lightblue]
	1677459647728 -> 1677467479888
	1677467479888 [label=AccumulateGrad]
	1677467479312 -> 1677467479408
	1677459647824 [label="features.5.2.block.2.fc2.weight
 (672, 28, 1, 1)" fillcolor=lightblue]
	1677459647824 -> 1677467479312
	1677467479312 [label=AccumulateGrad]
	1677467479552 -> 1677467479408
	1677459647920 [label="features.5.2.block.2.fc2.bias
 (672)" fillcolor=lightblue]
	1677459647920 -> 1677467479552
	1677467479552 [label=AccumulateGrad]
	1677467479216 -> 1677467479120
	1677467479072 -> 1677467478928
	1677459648016 [label="features.5.2.block.3.0.weight
 (112, 672, 1, 1)" fillcolor=lightblue]
	1677459648016 -> 1677467479072
	1677467479072 [label=AccumulateGrad]
	1677467478880 -> 1677467477488
	1677459648112 [label="features.5.2.block.3.1.weight
 (112)" fillcolor=lightblue]
	1677459648112 -> 1677467478880
	1677467478880 [label=AccumulateGrad]
	1677467477392 -> 1677467477488
	1677459648208 [label="features.5.2.block.3.1.bias
 (112)" fillcolor=lightblue]
	1677459648208 -> 1677467477392
	1677467477392 [label=AccumulateGrad]
	1677467477296 -> 1677467477200
	1677467477152 -> 1677467476912
	1677459648592 [label="features.6.0.block.0.0.weight
 (672, 112, 1, 1)" fillcolor=lightblue]
	1677459648592 -> 1677467477152
	1677467477152 [label=AccumulateGrad]
	1677467476768 -> 1677467476864
	1677459648688 [label="features.6.0.block.0.1.weight
 (672)" fillcolor=lightblue]
	1677459648688 -> 1677467476768
	1677467476768 [label=AccumulateGrad]
	1677467477008 -> 1677467476864
	1677459648784 [label="features.6.0.block.0.1.bias
 (672)" fillcolor=lightblue]
	1677459648784 -> 1677467477008
	1677467477008 [label=AccumulateGrad]
	1677467476672 -> 1677467476432
	1677459649168 [label="features.6.0.block.1.0.weight
 (672, 1, 5, 5)" fillcolor=lightblue]
	1677459649168 -> 1677467476672
	1677467476672 [label=AccumulateGrad]
	1677467476384 -> 1677467476192
	1677459649264 [label="features.6.0.block.1.1.weight
 (672)" fillcolor=lightblue]
	1677459649264 -> 1677467476384
	1677467476384 [label=AccumulateGrad]
	1677467476528 -> 1677467476192
	1677459649360 [label="features.6.0.block.1.1.bias
 (672)" fillcolor=lightblue]
	1677459649360 -> 1677467476528
	1677467476528 [label=AccumulateGrad]
	1677467475856 -> 1677467475952
	1677459649744 [label="features.6.0.block.2.fc1.weight
 (28, 672, 1, 1)" fillcolor=lightblue]
	1677459649744 -> 1677467475856
	1677467475856 [label=AccumulateGrad]
	1677467476096 -> 1677467475952
	1677459649840 [label="features.6.0.block.2.fc1.bias
 (28)" fillcolor=lightblue]
	1677459649840 -> 1677467476096
	1677467476096 [label=AccumulateGrad]
	1677467475520 -> 1677467475616
	1677459649936 [label="features.6.0.block.2.fc2.weight
 (672, 28, 1, 1)" fillcolor=lightblue]
	1677459649936 -> 1677467475520
	1677467475520 [label=AccumulateGrad]
	1677467475760 -> 1677467475616
	1677459650032 [label="features.6.0.block.2.fc2.bias
 (672)" fillcolor=lightblue]
	1677459650032 -> 1677467475760
	1677467475760 [label=AccumulateGrad]
	1677467475424 -> 1677467475328
	1677467475280 -> 1677467475136
	1677459650128 [label="features.6.0.block.3.0.weight
 (192, 672, 1, 1)" fillcolor=lightblue]
	1677459650128 -> 1677467475280
	1677467475280 [label=AccumulateGrad]
	1677467475088 -> 1677467472832
	1677459650224 [label="features.6.0.block.3.1.weight
 (192)" fillcolor=lightblue]
	1677459650224 -> 1677467475088
	1677467475088 [label=AccumulateGrad]
	1677467474944 -> 1677467472832
	1677459650320 [label="features.6.0.block.3.1.bias
 (192)" fillcolor=lightblue]
	1677459650320 -> 1677467474944
	1677467474944 [label=AccumulateGrad]
	1677467475040 -> 1677467474752
	1677459650800 [label="features.6.1.block.0.0.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	1677459650800 -> 1677467475040
	1677467475040 [label=AccumulateGrad]
	1677467474608 -> 1677467474704
	1677459650896 [label="features.6.1.block.0.1.weight
 (1152)" fillcolor=lightblue]
	1677459650896 -> 1677467474608
	1677467474608 [label=AccumulateGrad]
	1677467474848 -> 1677467474704
	1677459650992 [label="features.6.1.block.0.1.bias
 (1152)" fillcolor=lightblue]
	1677459650992 -> 1677467474848
	1677467474848 [label=AccumulateGrad]
	1677467474512 -> 1677467474272
	1677459651376 [label="features.6.1.block.1.0.weight
 (1152, 1, 5, 5)" fillcolor=lightblue]
	1677459651376 -> 1677467474512
	1677467474512 [label=AccumulateGrad]
	1677467474128 -> 1677467474224
	1677459651472 [label="features.6.1.block.1.1.weight
 (1152)" fillcolor=lightblue]
	1677459651472 -> 1677467474128
	1677467474128 [label=AccumulateGrad]
	1677467474368 -> 1677467474224
	1677459651568 [label="features.6.1.block.1.1.bias
 (1152)" fillcolor=lightblue]
	1677459651568 -> 1677467474368
	1677467474368 [label=AccumulateGrad]
	1677467473936 -> 1677467473888
	1677459651952 [label="features.6.1.block.2.fc1.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	1677459651952 -> 1677467473936
	1677467473936 [label=AccumulateGrad]
	1677467473792 -> 1677467473888
	1677459652048 [label="features.6.1.block.2.fc1.bias
 (48)" fillcolor=lightblue]
	1677459652048 -> 1677467473792
	1677467473792 [label=AccumulateGrad]
	1677467473648 -> 1677467473600
	1677459652144 [label="features.6.1.block.2.fc2.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	1677459652144 -> 1677467473648
	1677467473648 [label=AccumulateGrad]
	1677467473504 -> 1677467473600
	1677459652240 [label="features.6.1.block.2.fc2.bias
 (1152)" fillcolor=lightblue]
	1677459652240 -> 1677467473504
	1677467473504 [label=AccumulateGrad]
	1677467473408 -> 1677467473312
	1677467473264 -> 1677467473120
	1677459652336 [label="features.6.1.block.3.0.weight
 (192, 1152, 1, 1)" fillcolor=lightblue]
	1677459652336 -> 1677467473264
	1677467473264 [label=AccumulateGrad]
	1677467473072 -> 1677467473024
	1677459652432 [label="features.6.1.block.3.1.weight
 (192)" fillcolor=lightblue]
	1677459652432 -> 1677467473072
	1677467473072 [label=AccumulateGrad]
	1677467472928 -> 1677467473024
	1677459652528 [label="features.6.1.block.3.1.bias
 (192)" fillcolor=lightblue]
	1677459652528 -> 1677467472928
	1677467472928 [label=AccumulateGrad]
	1677467472832 -> 1677467470672
	1677467472784 -> 1677467472592
	1677469939376 [label="features.6.2.block.0.0.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	1677469939376 -> 1677467472784
	1677467472784 [label=AccumulateGrad]
	1677467472544 -> 1677467472496
	1677469939472 [label="features.6.2.block.0.1.weight
 (1152)" fillcolor=lightblue]
	1677469939472 -> 1677467472544
	1677467472544 [label=AccumulateGrad]
	1677467472400 -> 1677467472496
	1677469939568 [label="features.6.2.block.0.1.bias
 (1152)" fillcolor=lightblue]
	1677469939568 -> 1677467472400
	1677467472400 [label=AccumulateGrad]
	1677467472304 -> 1677467472160
	1677469939952 [label="features.6.2.block.1.0.weight
 (1152, 1, 5, 5)" fillcolor=lightblue]
	1677469939952 -> 1677467472304
	1677467472304 [label=AccumulateGrad]
	1677467472112 -> 1677467472064
	1677469940048 [label="features.6.2.block.1.1.weight
 (1152)" fillcolor=lightblue]
	1677469940048 -> 1677467472112
	1677467472112 [label=AccumulateGrad]
	1677467471968 -> 1677467472064
	1677469940144 [label="features.6.2.block.1.1.bias
 (1152)" fillcolor=lightblue]
	1677469940144 -> 1677467471968
	1677467471968 [label=AccumulateGrad]
	1677467471776 -> 1677467471728
	1677469940528 [label="features.6.2.block.2.fc1.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	1677469940528 -> 1677467471776
	1677467471776 [label=AccumulateGrad]
	1677467471632 -> 1677467471728
	1677469940624 [label="features.6.2.block.2.fc1.bias
 (48)" fillcolor=lightblue]
	1677469940624 -> 1677467471632
	1677467471632 [label=AccumulateGrad]
	1677467471488 -> 1677467471440
	1677469940720 [label="features.6.2.block.2.fc2.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	1677469940720 -> 1677467471488
	1677467471488 [label=AccumulateGrad]
	1677467471344 -> 1677467471440
	1677469940816 [label="features.6.2.block.2.fc2.bias
 (1152)" fillcolor=lightblue]
	1677469940816 -> 1677467471344
	1677467471344 [label=AccumulateGrad]
	1677467471248 -> 1677467471152
	1677467471104 -> 1677467470960
	1677469940912 [label="features.6.2.block.3.0.weight
 (192, 1152, 1, 1)" fillcolor=lightblue]
	1677469940912 -> 1677467471104
	1677467471104 [label=AccumulateGrad]
	1677467470912 -> 1677467470864
	1677469941008 [label="features.6.2.block.3.1.weight
 (192)" fillcolor=lightblue]
	1677469941008 -> 1677467470912
	1677467470912 [label=AccumulateGrad]
	1677467470768 -> 1677467470864
	1677469941104 [label="features.6.2.block.3.1.bias
 (192)" fillcolor=lightblue]
	1677469941104 -> 1677467470768
	1677467470768 [label=AccumulateGrad]
	1677467470672 -> 1677467478496
	1677467470624 -> 1677467470432
	1677469941392 [label="features.6.3.block.0.0.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	1677469941392 -> 1677467470624
	1677467470624 [label=AccumulateGrad]
	1677467470384 -> 1677467470336
	1677469941488 [label="features.6.3.block.0.1.weight
 (1152)" fillcolor=lightblue]
	1677469941488 -> 1677467470384
	1677467470384 [label=AccumulateGrad]
	1677467470240 -> 1677467470336
	1677469941584 [label="features.6.3.block.0.1.bias
 (1152)" fillcolor=lightblue]
	1677469941584 -> 1677467470240
	1677467470240 [label=AccumulateGrad]
	1677467470144 -> 1677467470000
	1677463634192 [label="features.6.3.block.1.0.weight
 (1152, 1, 5, 5)" fillcolor=lightblue]
	1677463634192 -> 1677467470144
	1677467470144 [label=AccumulateGrad]
	1677467469952 -> 1677467469904
	1677463634288 [label="features.6.3.block.1.1.weight
 (1152)" fillcolor=lightblue]
	1677463634288 -> 1677467469952
	1677467469952 [label=AccumulateGrad]
	1677467469808 -> 1677467469904
	1677463634384 [label="features.6.3.block.1.1.bias
 (1152)" fillcolor=lightblue]
	1677463634384 -> 1677467469808
	1677467469808 [label=AccumulateGrad]
	1677467469616 -> 1677467469568
	1677463634768 [label="features.6.3.block.2.fc1.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	1677463634768 -> 1677467469616
	1677467469616 [label=AccumulateGrad]
	1677467469472 -> 1677467469568
	1677463634864 [label="features.6.3.block.2.fc1.bias
 (48)" fillcolor=lightblue]
	1677463634864 -> 1677467469472
	1677467469472 [label=AccumulateGrad]
	1677467469328 -> 1677467469280
	1677463634960 [label="features.6.3.block.2.fc2.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	1677463634960 -> 1677467469328
	1677467469328 [label=AccumulateGrad]
	1677467469184 -> 1677467469280
	1677463635056 [label="features.6.3.block.2.fc2.bias
 (1152)" fillcolor=lightblue]
	1677463635056 -> 1677467469184
	1677467469184 [label=AccumulateGrad]
	1677467469088 -> 1677467468992
	1677467468944 -> 1677467478784
	1677463635152 [label="features.6.3.block.3.0.weight
 (192, 1152, 1, 1)" fillcolor=lightblue]
	1677463635152 -> 1677467468944
	1677467468944 [label=AccumulateGrad]
	1677467478736 -> 1677467478688
	1677463635248 [label="features.6.3.block.3.1.weight
 (192)" fillcolor=lightblue]
	1677463635248 -> 1677467478736
	1677467478736 [label=AccumulateGrad]
	1677467478592 -> 1677467478688
	1677463635344 [label="features.6.3.block.3.1.bias
 (192)" fillcolor=lightblue]
	1677463635344 -> 1677467478592
	1677467478592 [label=AccumulateGrad]
	1677467478496 -> 1677467478400
	1677467478352 -> 1677467478208
	1677463635728 [label="features.7.0.block.0.0.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	1677463635728 -> 1677467478352
	1677467478352 [label=AccumulateGrad]
	1677467478160 -> 1677458302112
	1677463635824 [label="features.7.0.block.0.1.weight
 (1152)" fillcolor=lightblue]
	1677463635824 -> 1677467478160
	1677467478160 [label=AccumulateGrad]
	1677467477968 -> 1677458302112
	1677463635920 [label="features.7.0.block.0.1.bias
 (1152)" fillcolor=lightblue]
	1677463635920 -> 1677467477968
	1677467477968 [label=AccumulateGrad]
	1677458300624 -> 1677458303360
	1677463636304 [label="features.7.0.block.1.0.weight
 (1152, 1, 3, 3)" fillcolor=lightblue]
	1677463636304 -> 1677458300624
	1677458300624 [label=AccumulateGrad]
	1677458303840 -> 1677458299616
	1677463636400 [label="features.7.0.block.1.1.weight
 (1152)" fillcolor=lightblue]
	1677463636400 -> 1677458303840
	1677458303840 [label=AccumulateGrad]
	1677458299952 -> 1677458299616
	1677463636496 [label="features.7.0.block.1.1.bias
 (1152)" fillcolor=lightblue]
	1677463636496 -> 1677458299952
	1677458299952 [label=AccumulateGrad]
	1677458298656 -> 1677458299664
	1677463636880 [label="features.7.0.block.2.fc1.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	1677463636880 -> 1677458298656
	1677458298656 [label=AccumulateGrad]
	1677458299136 -> 1677458299664
	1677463636976 [label="features.7.0.block.2.fc1.bias
 (48)" fillcolor=lightblue]
	1677463636976 -> 1677458299136
	1677458299136 [label=AccumulateGrad]
	1677458304272 -> 1677458304560
	1677463637072 [label="features.7.0.block.2.fc2.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	1677463637072 -> 1677458304272
	1677458304272 [label=AccumulateGrad]
	1677458298800 -> 1677458304560
	1677463637168 [label="features.7.0.block.2.fc2.bias
 (1152)" fillcolor=lightblue]
	1677463637168 -> 1677458298800
	1677458298800 [label=AccumulateGrad]
	1677458303264 -> 1677458300576
	1677458302832 -> 1677458302640
	1677463637264 [label="features.7.0.block.3.0.weight
 (320, 1152, 1, 1)" fillcolor=lightblue]
	1677463637264 -> 1677458302832
	1677458302832 [label=AccumulateGrad]
	1677458302784 -> 1677458300672
	1677463637360 [label="features.7.0.block.3.1.weight
 (320)" fillcolor=lightblue]
	1677463637360 -> 1677458302784
	1677458302784 [label=AccumulateGrad]
	1677458302496 -> 1677458300672
	1677463637456 [label="features.7.0.block.3.1.bias
 (320)" fillcolor=lightblue]
	1677463637456 -> 1677458302496
	1677458302496 [label=AccumulateGrad]
	1677458299520 -> 1677458300048
	1677463637840 [label="features.8.0.weight
 (1280, 320, 1, 1)" fillcolor=lightblue]
	1677463637840 -> 1677458299520
	1677458299520 [label=AccumulateGrad]
	1677458306816 -> 1677458301104
	1677463637936 [label="features.8.1.weight
 (1280)" fillcolor=lightblue]
	1677463637936 -> 1677458306816
	1677458306816 [label=AccumulateGrad]
	1677458301872 -> 1677458301104
	1677463638032 [label="features.8.1.bias
 (1280)" fillcolor=lightblue]
	1677463638032 -> 1677458301872
	1677458301872 [label=AccumulateGrad]
	1677458308016 -> 1677458305328
	1677458308016 [label=TBackward0]
	1677458299808 -> 1677458308016
	1677463638704 [label="classifier.1.weight
 (19, 1280)" fillcolor=lightblue]
	1677463638704 -> 1677458299808
	1677458299808 [label=AccumulateGrad]
	1677458305328 -> 1677464035664
}
