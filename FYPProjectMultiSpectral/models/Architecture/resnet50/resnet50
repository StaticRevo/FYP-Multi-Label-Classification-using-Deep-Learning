digraph {
	graph [size="151.95,151.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2968830391600 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2968860734752 [label=AddmmBackward0]
	2968860734416 -> 2968860734752
	2968833636400 [label="fc.bias
 (19)" fillcolor=lightblue]
	2968833636400 -> 2968860734416
	2968860734416 [label=AccumulateGrad]
	2968860733792 -> 2968860734752
	2968860733792 [label=ViewBackward0]
	2968860733312 -> 2968860733792
	2968860733312 [label=MeanBackward1]
	2968860732976 -> 2968860733312
	2968860732976 [label=ReluBackward0]
	2968860732496 -> 2968860732976
	2968860732496 [label=AddBackward0]
	2968860732016 -> 2968860732496
	2968860732016 [label=CudnnBatchNormBackward0]
	2968860730912 -> 2968860732016
	2968860730912 [label=ConvolutionBackward0]
	2968860729952 -> 2968860730912
	2968860729952 [label=ReluBackward0]
	2968860729616 -> 2968860729952
	2968860729616 [label=CudnnBatchNormBackward0]
	2968860729136 -> 2968860729616
	2968860729136 [label=ConvolutionBackward0]
	2968860728176 -> 2968860729136
	2968860728176 [label=ReluBackward0]
	2968860722992 -> 2968860728176
	2968860722992 [label=CudnnBatchNormBackward0]
	2968860725872 -> 2968860722992
	2968860725872 [label=ConvolutionBackward0]
	2968860731872 -> 2968860725872
	2968860731872 [label=ReluBackward0]
	2968860737392 -> 2968860731872
	2968860737392 [label=AddBackward0]
	2968860737248 -> 2968860737392
	2968860737248 [label=CudnnBatchNormBackward0]
	2968860736864 -> 2968860737248
	2968860736864 [label=ConvolutionBackward0]
	2968860737008 -> 2968860736864
	2968860737008 [label=ReluBackward0]
	2968860736576 -> 2968860737008
	2968860736576 [label=CudnnBatchNormBackward0]
	2968860736480 -> 2968860736576
	2968860736480 [label=ConvolutionBackward0]
	2968860736288 -> 2968860736480
	2968860736288 [label=ReluBackward0]
	2968860735904 -> 2968860736288
	2968860735904 [label=CudnnBatchNormBackward0]
	2968860736144 -> 2968860735904
	2968860736144 [label=ConvolutionBackward0]
	2968860737488 -> 2968860736144
	2968860737488 [label=ReluBackward0]
	2968860735424 -> 2968860737488
	2968860735424 [label=AddBackward0]
	2968860735664 -> 2968860735424
	2968860735664 [label=CudnnBatchNormBackward0]
	2968860735328 -> 2968860735664
	2968860735328 [label=ConvolutionBackward0]
	2968860735040 -> 2968860735328
	2968860735040 [label=ReluBackward0]
	2968860735088 -> 2968860735040
	2968860735088 [label=CudnnBatchNormBackward0]
	2968860734800 -> 2968860735088
	2968860734800 [label=ConvolutionBackward0]
	2968860734704 -> 2968860734800
	2968860734704 [label=ReluBackward0]
	2968860734368 -> 2968860734704
	2968860734368 [label=CudnnBatchNormBackward0]
	2968860734176 -> 2968860734368
	2968860734176 [label=ConvolutionBackward0]
	2968860734032 -> 2968860734176
	2968860734032 [label=ReluBackward0]
	2968860733840 -> 2968860734032
	2968860733840 [label=AddBackward0]
	2968860733504 -> 2968860733840
	2968860733504 [label=CudnnBatchNormBackward0]
	2968860733552 -> 2968860733504
	2968860733552 [label=ConvolutionBackward0]
	2968860733216 -> 2968860733552
	2968860733216 [label=ReluBackward0]
	2968860733264 -> 2968860733216
	2968860733264 [label=CudnnBatchNormBackward0]
	2968860733168 -> 2968860733264
	2968860733168 [label=ConvolutionBackward0]
	2968860732544 -> 2968860733168
	2968860732544 [label=ReluBackward0]
	2968860732592 -> 2968860732544
	2968860732592 [label=CudnnBatchNormBackward0]
	2968860732448 -> 2968860732592
	2968860732448 [label=ConvolutionBackward0]
	2968860733696 -> 2968860732448
	2968860733696 [label=ReluBackward0]
	2968860732112 -> 2968860733696
	2968860732112 [label=AddBackward0]
	2968860731968 -> 2968860732112
	2968860731968 [label=CudnnBatchNormBackward0]
	2968860731584 -> 2968860731968
	2968860731584 [label=ConvolutionBackward0]
	2968860731728 -> 2968860731584
	2968860731728 [label=ReluBackward0]
	2968860731296 -> 2968860731728
	2968860731296 [label=CudnnBatchNormBackward0]
	2968860731200 -> 2968860731296
	2968860731200 [label=ConvolutionBackward0]
	2968860731008 -> 2968860731200
	2968860731008 [label=ReluBackward0]
	2968860730624 -> 2968860731008
	2968860730624 [label=CudnnBatchNormBackward0]
	2968860730864 -> 2968860730624
	2968860730864 [label=ConvolutionBackward0]
	2968860732208 -> 2968860730864
	2968860732208 [label=ReluBackward0]
	2968860730144 -> 2968860732208
	2968860730144 [label=AddBackward0]
	2968860730384 -> 2968860730144
	2968860730384 [label=CudnnBatchNormBackward0]
	2968860730048 -> 2968860730384
	2968860730048 [label=ConvolutionBackward0]
	2968860729760 -> 2968860730048
	2968860729760 [label=ReluBackward0]
	2968860729808 -> 2968860729760
	2968860729808 [label=CudnnBatchNormBackward0]
	2968860729520 -> 2968860729808
	2968860729520 [label=ConvolutionBackward0]
	2968860729424 -> 2968860729520
	2968860729424 [label=ReluBackward0]
	2968860729088 -> 2968860729424
	2968860729088 [label=CudnnBatchNormBackward0]
	2968860728896 -> 2968860729088
	2968860728896 [label=ConvolutionBackward0]
	2968860730240 -> 2968860728896
	2968860730240 [label=ReluBackward0]
	2968860728608 -> 2968860730240
	2968860728608 [label=AddBackward0]
	2968860728416 -> 2968860728608
	2968860728416 [label=CudnnBatchNormBackward0]
	2968860728464 -> 2968860728416
	2968860728464 [label=ConvolutionBackward0]
	2968860728080 -> 2968860728464
	2968860728080 [label=ReluBackward0]
	2968860727840 -> 2968860728080
	2968860727840 [label=CudnnBatchNormBackward0]
	2968860727792 -> 2968860727840
	2968860727792 [label=ConvolutionBackward0]
	2968860727456 -> 2968860727792
	2968860727456 [label=ReluBackward0]
	2968860727504 -> 2968860727456
	2968860727504 [label=CudnnBatchNormBackward0]
	2968860727408 -> 2968860727504
	2968860727408 [label=ConvolutionBackward0]
	2968860728560 -> 2968860727408
	2968860728560 [label=ReluBackward0]
	2968860721552 -> 2968860728560
	2968860721552 [label=AddBackward0]
	2968860727216 -> 2968860721552
	2968860727216 [label=CudnnBatchNormBackward0]
	2968860726208 -> 2968860727216
	2968860726208 [label=ConvolutionBackward0]
	2968860724048 -> 2968860726208
	2968860724048 [label=ReluBackward0]
	2968860722224 -> 2968860724048
	2968860722224 [label=CudnnBatchNormBackward0]
	2968860724720 -> 2968860722224
	2968860724720 [label=ConvolutionBackward0]
	2968860724240 -> 2968860724720
	2968860724240 [label=ReluBackward0]
	2968860724912 -> 2968860724240
	2968860724912 [label=CudnnBatchNormBackward0]
	2968860722128 -> 2968860724912
	2968860722128 [label=ConvolutionBackward0]
	2968860723664 -> 2968860722128
	2968860723664 [label=ReluBackward0]
	2968860725440 -> 2968860723664
	2968860725440 [label=AddBackward0]
	2968860725248 -> 2968860725440
	2968860725248 [label=CudnnBatchNormBackward0]
	2968860722560 -> 2968860725248
	2968860722560 [label=ConvolutionBackward0]
	2968860726304 -> 2968860722560
	2968860726304 [label=ReluBackward0]
	2968860726448 -> 2968860726304
	2968860726448 [label=CudnnBatchNormBackward0]
	2968860724768 -> 2968860726448
	2968860724768 [label=ConvolutionBackward0]
	2968860724816 -> 2968860724768
	2968860724816 [label=ReluBackward0]
	2968860724672 -> 2968860724816
	2968860724672 [label=CudnnBatchNormBackward0]
	2968860723568 -> 2968860724672
	2968860723568 [label=ConvolutionBackward0]
	2968860727120 -> 2968860723568
	2968860727120 [label=ReluBackward0]
	2968860724432 -> 2968860727120
	2968860724432 [label=AddBackward0]
	2968860723952 -> 2968860724432
	2968860723952 [label=CudnnBatchNormBackward0]
	2968860723280 -> 2968860723952
	2968860723280 [label=ConvolutionBackward0]
	2968860726544 -> 2968860723280
	2968860726544 [label=ReluBackward0]
	2968860866736 -> 2968860726544
	2968860866736 [label=CudnnBatchNormBackward0]
	2968860852816 -> 2968860866736
	2968860852816 [label=ConvolutionBackward0]
	2968860864672 -> 2968860852816
	2968860864672 [label=ReluBackward0]
	2968860854976 -> 2968860864672
	2968860854976 [label=CudnnBatchNormBackward0]
	2968860864096 -> 2968860854976
	2968860864096 [label=ConvolutionBackward0]
	2968860725824 -> 2968860864096
	2968860725824 [label=ReluBackward0]
	2968860868512 -> 2968860725824
	2968860868512 [label=AddBackward0]
	2968860864048 -> 2968860868512
	2968860864048 [label=CudnnBatchNormBackward0]
	2968860863040 -> 2968860864048
	2968860863040 [label=ConvolutionBackward0]
	2968860859104 -> 2968860863040
	2968860859104 [label=ReluBackward0]
	2968860867504 -> 2968860859104
	2968860867504 [label=CudnnBatchNormBackward0]
	2968860862512 -> 2968860867504
	2968860862512 [label=ConvolutionBackward0]
	2968860865536 -> 2968860862512
	2968860865536 [label=ReluBackward0]
	2968860861648 -> 2968860865536
	2968860861648 [label=CudnnBatchNormBackward0]
	2968860865728 -> 2968860861648
	2968860865728 [label=ConvolutionBackward0]
	2968860855456 -> 2968860865728
	2968860855456 [label=ReluBackward0]
	2968860864624 -> 2968860855456
	2968860864624 [label=AddBackward0]
	2968830793168 -> 2968860864624
	2968830793168 [label=CudnnBatchNormBackward0]
	2968830792064 -> 2968830793168
	2968830792064 [label=ConvolutionBackward0]
	2968830791104 -> 2968830792064
	2968830791104 [label=ReluBackward0]
	2968830790768 -> 2968830791104
	2968830790768 [label=CudnnBatchNormBackward0]
	2968830790288 -> 2968830790768
	2968830790288 [label=ConvolutionBackward0]
	2968830789328 -> 2968830790288
	2968830789328 [label=ReluBackward0]
	2968830788224 -> 2968830789328
	2968830788224 [label=CudnnBatchNormBackward0]
	2968830787744 -> 2968830788224
	2968830787744 [label=ConvolutionBackward0]
	2968830793024 -> 2968830787744
	2968830793024 [label=ReluBackward0]
	2968830793312 -> 2968830793024
	2968830793312 [label=AddBackward0]
	2968830793264 -> 2968830793312
	2968830793264 [label=CudnnBatchNormBackward0]
	2968830793072 -> 2968830793264
	2968830793072 [label=ConvolutionBackward0]
	2968830792976 -> 2968830793072
	2968830792976 [label=ReluBackward0]
	2968830792640 -> 2968830792976
	2968830792640 [label=CudnnBatchNormBackward0]
	2968830792448 -> 2968830792640
	2968830792448 [label=ConvolutionBackward0]
	2968830792304 -> 2968830792448
	2968830792304 [label=ReluBackward0]
	2968830792112 -> 2968830792304
	2968830792112 [label=CudnnBatchNormBackward0]
	2968830791776 -> 2968830792112
	2968830791776 [label=ConvolutionBackward0]
	2968830791920 -> 2968830791776
	2968830791920 [label=ReluBackward0]
	2968830791488 -> 2968830791920
	2968830791488 [label=AddBackward0]
	2968830791392 -> 2968830791488
	2968830791392 [label=CudnnBatchNormBackward0]
	2968830791440 -> 2968830791392
	2968830791440 [label=ConvolutionBackward0]
	2968830790816 -> 2968830791440
	2968830790816 [label=ReluBackward0]
	2968830790864 -> 2968830790816
	2968830790864 [label=CudnnBatchNormBackward0]
	2968830790720 -> 2968830790864
	2968830790720 [label=ConvolutionBackward0]
	2968830790432 -> 2968830790720
	2968830790432 [label=ReluBackward0]
	2968830790480 -> 2968830790432
	2968830790480 [label=CudnnBatchNormBackward0]
	2968830790192 -> 2968830790480
	2968830790192 [label=ConvolutionBackward0]
	2968830791296 -> 2968830790192
	2968830791296 [label=ReluBackward0]
	2968830790000 -> 2968830791296
	2968830790000 [label=AddBackward0]
	2968830789712 -> 2968830790000
	2968830789712 [label=CudnnBatchNormBackward0]
	2968830789472 -> 2968830789712
	2968830789472 [label=ConvolutionBackward0]
	2968830789280 -> 2968830789472
	2968830789280 [label=ReluBackward0]
	2968830788896 -> 2968830789280
	2968830788896 [label=CudnnBatchNormBackward0]
	2968830789136 -> 2968830788896
	2968830789136 [label=ConvolutionBackward0]
	2968830788752 -> 2968830789136
	2968830788752 [label=ReluBackward0]
	2968830788512 -> 2968830788752
	2968830788512 [label=CudnnBatchNormBackward0]
	2968830788464 -> 2968830788512
	2968830788464 [label=ConvolutionBackward0]
	2968830789760 -> 2968830788464
	2968830789760 [label=ReluBackward0]
	2968830788032 -> 2968830789760
	2968830788032 [label=AddBackward0]
	2968830787984 -> 2968830788032
	2968830787984 [label=CudnnBatchNormBackward0]
	2968830787792 -> 2968830787984
	2968830787792 [label=ConvolutionBackward0]
	2968830794080 -> 2968830787792
	2968830794080 [label=ReluBackward0]
	2968830794416 -> 2968830794080
	2968830794416 [label=CudnnBatchNormBackward0]
	2968830794512 -> 2968830794416
	2968830794512 [label=ConvolutionBackward0]
	2968830794704 -> 2968830794512
	2968830794704 [label=ReluBackward0]
	2968830794848 -> 2968830794704
	2968830794848 [label=CudnnBatchNormBackward0]
	2968830794944 -> 2968830794848
	2968830794944 [label=ConvolutionBackward0]
	2968830795136 -> 2968830794944
	2968830795136 [label=MaxPool2DWithIndicesBackward0]
	2968830795280 -> 2968830795136
	2968830795280 [label=ReluBackward0]
	2968830795376 -> 2968830795280
	2968830795376 [label=CudnnBatchNormBackward0]
	2968830795472 -> 2968830795376
	2968830795472 [label=ConvolutionBackward0]
	2968830795664 -> 2968830795472
	2968833636208 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	2968833636208 -> 2968830795664
	2968830795664 [label=AccumulateGrad]
	2968830795424 -> 2968830795376
	2968835803952 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2968835803952 -> 2968830795424
	2968830795424 [label=AccumulateGrad]
	2968830795184 -> 2968830795376
	2968835803664 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2968835803664 -> 2968830795184
	2968830795184 [label=AccumulateGrad]
	2968830795088 -> 2968830794944
	2968835803568 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2968835803568 -> 2968830795088
	2968830795088 [label=AccumulateGrad]
	2968830794896 -> 2968830794848
	2968835803472 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2968835803472 -> 2968830794896
	2968830794896 [label=AccumulateGrad]
	2968830794752 -> 2968830794848
	2968835802704 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2968835802704 -> 2968830794752
	2968830794752 [label=AccumulateGrad]
	2968830794656 -> 2968830794512
	2968835802800 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2968835802800 -> 2968830794656
	2968830794656 [label=AccumulateGrad]
	2968830794464 -> 2968830794416
	2968835802896 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2968835802896 -> 2968830794464
	2968830794464 [label=AccumulateGrad]
	2968830794320 -> 2968830794416
	2968835802992 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2968835802992 -> 2968830794320
	2968830794320 [label=AccumulateGrad]
	2968830794224 -> 2968830787792
	2968835803280 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2968835803280 -> 2968830794224
	2968830794224 [label=AccumulateGrad]
	2968830787840 -> 2968830787984
	2968835802320 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	2968835802320 -> 2968830787840
	2968830787840 [label=AccumulateGrad]
	2968830788080 -> 2968830787984
	2968835802224 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	2968835802224 -> 2968830788080
	2968830788080 [label=AccumulateGrad]
	2968830788176 -> 2968830788032
	2968830788176 [label=CudnnBatchNormBackward0]
	2968830794608 -> 2968830788176
	2968830794608 [label=ConvolutionBackward0]
	2968830795136 -> 2968830794608
	2968830794992 -> 2968830794608
	2968835804144 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2968835804144 -> 2968830794992
	2968830794992 [label=AccumulateGrad]
	2968830787696 -> 2968830788176
	2968835804240 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2968835804240 -> 2968830787696
	2968830787696 [label=AccumulateGrad]
	2968830787648 -> 2968830788176
	2968835804336 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2968835804336 -> 2968830787648
	2968830787648 [label=AccumulateGrad]
	2968830788128 -> 2968830788464
	2968835802032 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2968835802032 -> 2968830788128
	2968830788128 [label=AccumulateGrad]
	2968830788656 -> 2968830788512
	2968835801456 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2968835801456 -> 2968830788656
	2968830788656 [label=AccumulateGrad]
	2968830788608 -> 2968830788512
	2968835801648 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2968835801648 -> 2968830788608
	2968830788608 [label=AccumulateGrad]
	2968830788800 -> 2968830789136
	2968835802128 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2968835802128 -> 2968830788800
	2968830788800 [label=AccumulateGrad]
	2968830788992 -> 2968830788896
	2968835801936 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2968835801936 -> 2968830788992
	2968830788992 [label=AccumulateGrad]
	2968830789232 -> 2968830788896
	2968833986000 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2968833986000 -> 2968830789232
	2968830789232 [label=AccumulateGrad]
	2968830789520 -> 2968830789472
	2968833986384 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2968833986384 -> 2968830789520
	2968830789520 [label=AccumulateGrad]
	2968830789376 -> 2968830789712
	2968833986480 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	2968833986480 -> 2968830789376
	2968830789376 [label=AccumulateGrad]
	2968830789568 -> 2968830789712
	2968833986576 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	2968833986576 -> 2968830789568
	2968830789568 [label=AccumulateGrad]
	2968830789760 -> 2968830790000
	2968830790096 -> 2968830790192
	2968833986960 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2968833986960 -> 2968830790096
	2968830790096 [label=AccumulateGrad]
	2968830790240 -> 2968830790480
	2968833987056 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	2968833987056 -> 2968830790240
	2968830790240 [label=AccumulateGrad]
	2968830790576 -> 2968830790480
	2968833987152 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	2968833987152 -> 2968830790576
	2968830790576 [label=AccumulateGrad]
	2968830790336 -> 2968830790720
	2968833987536 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2968833987536 -> 2968830790336
	2968830790336 [label=AccumulateGrad]
	2968830790960 -> 2968830790864
	2968833987632 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	2968833987632 -> 2968830790960
	2968830790960 [label=AccumulateGrad]
	2968830790912 -> 2968830790864
	2968833987728 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	2968833987728 -> 2968830790912
	2968830790912 [label=AccumulateGrad]
	2968830791008 -> 2968830791440
	2968833988112 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2968833988112 -> 2968830791008
	2968830791008 [label=AccumulateGrad]
	2968830791344 -> 2968830791392
	2968833988208 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	2968833988208 -> 2968830791344
	2968830791344 [label=AccumulateGrad]
	2968830791536 -> 2968830791392
	2968833988304 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	2968833988304 -> 2968830791536
	2968830791536 [label=AccumulateGrad]
	2968830791296 -> 2968830791488
	2968830791824 -> 2968830791776
	2968833989264 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2968833989264 -> 2968830791824
	2968830791824 [label=AccumulateGrad]
	2968830791968 -> 2968830792112
	2968833989360 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2968833989360 -> 2968830791968
	2968830791968 [label=AccumulateGrad]
	2968830792400 -> 2968830792112
	2968833989456 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2968833989456 -> 2968830792400
	2968830792400 [label=AccumulateGrad]
	2968830792496 -> 2968830792448
	2968833989840 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2968833989840 -> 2968830792496
	2968830792496 [label=AccumulateGrad]
	2968830792592 -> 2968830792640
	2968833989936 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2968833989936 -> 2968830792592
	2968830792592 [label=AccumulateGrad]
	2968830792784 -> 2968830792640
	2968833990032 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2968833990032 -> 2968830792784
	2968830792784 [label=AccumulateGrad]
	2968830792832 -> 2968830793072
	2968833990416 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2968833990416 -> 2968830792832
	2968830792832 [label=AccumulateGrad]
	2968830793120 -> 2968830793264
	2968833990512 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	2968833990512 -> 2968830793120
	2968830793120 [label=AccumulateGrad]
	2968830793360 -> 2968830793264
	2968833990608 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	2968833990608 -> 2968830793360
	2968830793360 [label=AccumulateGrad]
	2968830793456 -> 2968830793312
	2968830793456 [label=CudnnBatchNormBackward0]
	2968830792352 -> 2968830793456
	2968830792352 [label=ConvolutionBackward0]
	2968830791920 -> 2968830792352
	2968830791872 -> 2968830792352
	2968833988688 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2968833988688 -> 2968830791872
	2968830791872 [label=AccumulateGrad]
	2968830792736 -> 2968830793456
	2968833988784 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2968833988784 -> 2968830792736
	2968830792736 [label=AccumulateGrad]
	2968830792928 -> 2968830793456
	2968833988880 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2968833988880 -> 2968830792928
	2968830792928 [label=AccumulateGrad]
	2968830793408 -> 2968830787744
	2968833990992 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2968833990992 -> 2968830793408
	2968830793408 [label=AccumulateGrad]
	2968830788368 -> 2968830788224
	2968833991088 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2968833991088 -> 2968830788368
	2968830788368 [label=AccumulateGrad]
	2968830788704 -> 2968830788224
	2968833991184 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2968833991184 -> 2968830788704
	2968830788704 [label=AccumulateGrad]
	2968830789184 -> 2968830790288
	2968833991568 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2968833991568 -> 2968830789184
	2968830789184 [label=AccumulateGrad]
	2968830790144 -> 2968830790768
	2968833991664 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2968833991664 -> 2968830790144
	2968830790144 [label=AccumulateGrad]
	2968830791248 -> 2968830790768
	2968833991760 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2968833991760 -> 2968830791248
	2968830791248 [label=AccumulateGrad]
	2968830791728 -> 2968830792064
	2968833992144 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2968833992144 -> 2968830791728
	2968830791728 [label=AccumulateGrad]
	2968830792688 -> 2968830793168
	2968833992240 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	2968833992240 -> 2968830792688
	2968830792688 [label=AccumulateGrad]
	2968830792544 -> 2968830793168
	2968833992336 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	2968833992336 -> 2968830792544
	2968830792544 [label=AccumulateGrad]
	2968830793024 -> 2968860864624
	2968870547616 -> 2968860865728
	2968833992720 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2968833992720 -> 2968870547616
	2968870547616 [label=AccumulateGrad]
	2968860864912 -> 2968860861648
	2968833992816 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	2968833992816 -> 2968860864912
	2968860864912 [label=AccumulateGrad]
	2968860866496 -> 2968860861648
	2968833992912 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	2968833992912 -> 2968860866496
	2968860866496 [label=AccumulateGrad]
	2968860863472 -> 2968860862512
	2968833993296 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2968833993296 -> 2968860863472
	2968860863472 [label=AccumulateGrad]
	2968860863952 -> 2968860867504
	2968833993392 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	2968833993392 -> 2968860863952
	2968860863952 [label=AccumulateGrad]
	2968860860880 -> 2968860867504
	2968833993488 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	2968833993488 -> 2968860860880
	2968860860880 [label=AccumulateGrad]
	2968860864432 -> 2968860863040
	2968833993872 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2968833993872 -> 2968860864432
	2968860864432 [label=AccumulateGrad]
	2968860866112 -> 2968860864048
	2968833993968 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	2968833993968 -> 2968860866112
	2968860866112 [label=AccumulateGrad]
	2968860865776 -> 2968860864048
	2968833994064 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	2968833994064 -> 2968860865776
	2968860865776 [label=AccumulateGrad]
	2968860855456 -> 2968860868512
	2968860867696 -> 2968860864096
	2968833994448 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2968833994448 -> 2968860867696
	2968860867696 [label=AccumulateGrad]
	2968860860208 -> 2968860854976
	2968833994544 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	2968833994544 -> 2968860860208
	2968860860208 [label=AccumulateGrad]
	2968860860112 -> 2968860854976
	2968833994640 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	2968833994640 -> 2968860860112
	2968860860112 [label=AccumulateGrad]
	2968860860448 -> 2968860852816
	2968833995024 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2968833995024 -> 2968860860448
	2968860860448 [label=AccumulateGrad]
	2968860865104 -> 2968860866736
	2968833995120 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	2968833995120 -> 2968860865104
	2968860865104 [label=AccumulateGrad]
	2968860867744 -> 2968860866736
	2968833995216 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	2968833995216 -> 2968860867744
	2968860867744 [label=AccumulateGrad]
	2968860722464 -> 2968860723280
	2968833995600 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2968833995600 -> 2968860722464
	2968860722464 [label=AccumulateGrad]
	2968860724624 -> 2968860723952
	2968833995696 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	2968833995696 -> 2968860724624
	2968860724624 [label=AccumulateGrad]
	2968860725344 -> 2968860723952
	2968833995792 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	2968833995792 -> 2968860725344
	2968860725344 [label=AccumulateGrad]
	2968860725824 -> 2968860724432
	2968860725296 -> 2968860723568
	2968833996752 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2968833996752 -> 2968860725296
	2968860725296 [label=AccumulateGrad]
	2968860721648 -> 2968860724672
	2968833996848 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2968833996848 -> 2968860721648
	2968860721648 [label=AccumulateGrad]
	2968860726352 -> 2968860724672
	2968833996944 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2968833996944 -> 2968860726352
	2968860726352 [label=AccumulateGrad]
	2968860725728 -> 2968860724768
	2968833997328 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2968833997328 -> 2968860725728
	2968860725728 [label=AccumulateGrad]
	2968860726160 -> 2968860726448
	2968833997424 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2968833997424 -> 2968860726160
	2968860726160 [label=AccumulateGrad]
	2968860722656 -> 2968860726448
	2968833997520 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2968833997520 -> 2968860722656
	2968860722656 [label=AccumulateGrad]
	2968860722416 -> 2968860722560
	2968833997904 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2968833997904 -> 2968860722416
	2968860722416 [label=AccumulateGrad]
	2968860722512 -> 2968860725248
	2968833998000 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	2968833998000 -> 2968860722512
	2968860722512 [label=AccumulateGrad]
	2968860721888 -> 2968860725248
	2968833998096 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	2968833998096 -> 2968860721888
	2968860721888 [label=AccumulateGrad]
	2968860726112 -> 2968860725440
	2968860726112 [label=CudnnBatchNormBackward0]
	2968860725488 -> 2968860726112
	2968860725488 [label=ConvolutionBackward0]
	2968860727120 -> 2968860725488
	2968860726784 -> 2968860725488
	2968833996176 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2968833996176 -> 2968860726784
	2968860726784 [label=AccumulateGrad]
	2968860723376 -> 2968860726112
	2968833996272 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	2968833996272 -> 2968860723376
	2968860723376 [label=AccumulateGrad]
	2968860725632 -> 2968860726112
	2968833996368 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	2968833996368 -> 2968860725632
	2968860725632 [label=AccumulateGrad]
	2968860724480 -> 2968860722128
	2968833998480 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2968833998480 -> 2968860724480
	2968860724480 [label=AccumulateGrad]
	2968860721936 -> 2968860724912
	2968833998576 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2968833998576 -> 2968860721936
	2968860721936 [label=AccumulateGrad]
	2968860725536 -> 2968860724912
	2968833998672 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2968833998672 -> 2968860725536
	2968860725536 [label=AccumulateGrad]
	2968860722608 -> 2968860724720
	2968833622288 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2968833622288 -> 2968860722608
	2968860722608 [label=AccumulateGrad]
	2968860725152 -> 2968860722224
	2968833622384 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2968833622384 -> 2968860725152
	2968860725152 [label=AccumulateGrad]
	2968860726736 -> 2968860722224
	2968833622480 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2968833622480 -> 2968860726736
	2968860726736 [label=AccumulateGrad]
	2968860725584 -> 2968860726208
	2968833622864 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2968833622864 -> 2968860725584
	2968860725584 [label=AccumulateGrad]
	2968860724288 -> 2968860727216
	2968833622960 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	2968833622960 -> 2968860724288
	2968860724288 [label=AccumulateGrad]
	2968860725008 -> 2968860727216
	2968833623056 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	2968833623056 -> 2968860725008
	2968860725008 [label=AccumulateGrad]
	2968860723664 -> 2968860721552
	2968860724384 -> 2968860727408
	2968833623440 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2968833623440 -> 2968860724384
	2968860724384 [label=AccumulateGrad]
	2968860727312 -> 2968860727504
	2968833623536 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	2968833623536 -> 2968860727312
	2968860727312 [label=AccumulateGrad]
	2968860721216 -> 2968860727504
	2968833623632 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	2968833623632 -> 2968860721216
	2968860721216 [label=AccumulateGrad]
	2968860727600 -> 2968860727792
	2968833624016 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2968833624016 -> 2968860727600
	2968860727600 [label=AccumulateGrad]
	2968860727984 -> 2968860727840
	2968833624112 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	2968833624112 -> 2968860727984
	2968860727984 [label=AccumulateGrad]
	2968860727936 -> 2968860727840
	2968833624208 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	2968833624208 -> 2968860727936
	2968860727936 [label=AccumulateGrad]
	2968860728128 -> 2968860728464
	2968833624592 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2968833624592 -> 2968860728128
	2968860728128 [label=AccumulateGrad]
	2968860728320 -> 2968860728416
	2968833624688 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	2968833624688 -> 2968860728320
	2968860728320 [label=AccumulateGrad]
	2968860728224 -> 2968860728416
	2968833624784 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	2968833624784 -> 2968860728224
	2968860728224 [label=AccumulateGrad]
	2968860728560 -> 2968860728608
	2968860728752 -> 2968860728896
	2968833625168 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2968833625168 -> 2968860728752
	2968860728752 [label=AccumulateGrad]
	2968860729040 -> 2968860729088
	2968833625264 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	2968833625264 -> 2968860729040
	2968860729040 [label=AccumulateGrad]
	2968860729232 -> 2968860729088
	2968833625360 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	2968833625360 -> 2968860729232
	2968860729232 [label=AccumulateGrad]
	2968860729280 -> 2968860729520
	2968833625744 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2968833625744 -> 2968860729280
	2968860729280 [label=AccumulateGrad]
	2968860729568 -> 2968860729808
	2968833625840 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	2968833625840 -> 2968860729568
	2968860729568 [label=AccumulateGrad]
	2968860729904 -> 2968860729808
	2968833625936 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	2968833625936 -> 2968860729904
	2968860729904 [label=AccumulateGrad]
	2968860729664 -> 2968860730048
	2968833626320 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2968833626320 -> 2968860729664
	2968860729664 [label=AccumulateGrad]
	2968860730288 -> 2968860730384
	2968833626416 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	2968833626416 -> 2968860730288
	2968860730288 [label=AccumulateGrad]
	2968860730192 -> 2968860730384
	2968833626512 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	2968833626512 -> 2968860730192
	2968860730192 [label=AccumulateGrad]
	2968860730240 -> 2968860730144
	2968860730480 -> 2968860730864
	2968833626896 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2968833626896 -> 2968860730480
	2968860730480 [label=AccumulateGrad]
	2968860730720 -> 2968860730624
	2968833626992 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	2968833626992 -> 2968860730720
	2968860730720 [label=AccumulateGrad]
	2968860730960 -> 2968860730624
	2968833627088 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	2968833627088 -> 2968860730960
	2968860730960 [label=AccumulateGrad]
	2968860731248 -> 2968860731200
	2968833627472 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2968833627472 -> 2968860731248
	2968860731248 [label=AccumulateGrad]
	2968860731104 -> 2968860731296
	2968833627568 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	2968833627568 -> 2968860731104
	2968860731104 [label=AccumulateGrad]
	2968860731488 -> 2968860731296
	2968833627664 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	2968833627664 -> 2968860731488
	2968860731488 [label=AccumulateGrad]
	2968860731632 -> 2968860731584
	2968833628048 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2968833628048 -> 2968860731632
	2968860731632 [label=AccumulateGrad]
	2968860731776 -> 2968860731968
	2968833628144 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	2968833628144 -> 2968860731776
	2968860731776 [label=AccumulateGrad]
	2968860731920 -> 2968860731968
	2968833628240 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	2968833628240 -> 2968860731920
	2968860731920 [label=AccumulateGrad]
	2968860732208 -> 2968860732112
	2968860732160 -> 2968860732448
	2968833628624 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2968833628624 -> 2968860732160
	2968860732160 [label=AccumulateGrad]
	2968860732688 -> 2968860732592
	2968833628720 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	2968833628720 -> 2968860732688
	2968860732688 [label=AccumulateGrad]
	2968860732640 -> 2968860732592
	2968833628816 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	2968833628816 -> 2968860732640
	2968860732640 [label=AccumulateGrad]
	2968860732736 -> 2968860733168
	2968833629200 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2968833629200 -> 2968860732736
	2968860732736 [label=AccumulateGrad]
	2968860733072 -> 2968860733264
	2968833629296 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	2968833629296 -> 2968860733072
	2968860733072 [label=AccumulateGrad]
	2968860733024 -> 2968860733264
	2968833629392 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	2968833629392 -> 2968860733024
	2968860733024 [label=AccumulateGrad]
	2968860733360 -> 2968860733552
	2968833629776 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2968833629776 -> 2968860733360
	2968860733360 [label=AccumulateGrad]
	2968860733744 -> 2968860733504
	2968833629872 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	2968833629872 -> 2968860733744
	2968860733744 [label=AccumulateGrad]
	2968860733600 -> 2968860733504
	2968833629968 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	2968833629968 -> 2968860733600
	2968860733600 [label=AccumulateGrad]
	2968860733696 -> 2968860733840
	2968860734224 -> 2968860734176
	2968833630832 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2968833630832 -> 2968860734224
	2968860734224 [label=AccumulateGrad]
	2968860734320 -> 2968860734368
	2968833630928 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2968833630928 -> 2968860734320
	2968860734320 [label=AccumulateGrad]
	2968860734512 -> 2968860734368
	2968833631024 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2968833631024 -> 2968860734512
	2968860734512 [label=AccumulateGrad]
	2968860734560 -> 2968860734800
	2968833631408 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2968833631408 -> 2968860734560
	2968860734560 [label=AccumulateGrad]
	2968860734848 -> 2968860735088
	2968833631504 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2968833631504 -> 2968860734848
	2968860734848 [label=AccumulateGrad]
	2968860735184 -> 2968860735088
	2968833631600 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2968833631600 -> 2968860735184
	2968860735184 [label=AccumulateGrad]
	2968860734944 -> 2968860735328
	2968833631984 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2968833631984 -> 2968860734944
	2968860734944 [label=AccumulateGrad]
	2968860735568 -> 2968860735664
	2968833632080 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	2968833632080 -> 2968860735568
	2968860735568 [label=AccumulateGrad]
	2968860735472 -> 2968860735664
	2968833632176 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	2968833632176 -> 2968860735472
	2968860735472 [label=AccumulateGrad]
	2968860735520 -> 2968860735424
	2968860735520 [label=CudnnBatchNormBackward0]
	2968860734464 -> 2968860735520
	2968860734464 [label=ConvolutionBackward0]
	2968860734032 -> 2968860734464
	2968860733984 -> 2968860734464
	2968833630256 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	2968833630256 -> 2968860733984
	2968860733984 [label=AccumulateGrad]
	2968860735136 -> 2968860735520
	2968833630352 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	2968833630352 -> 2968860735136
	2968860735136 [label=AccumulateGrad]
	2968860735280 -> 2968860735520
	2968833630448 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	2968833630448 -> 2968860735280
	2968860735280 [label=AccumulateGrad]
	2968860735760 -> 2968860736144
	2968833632560 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2968833632560 -> 2968860735760
	2968860735760 [label=AccumulateGrad]
	2968860736000 -> 2968860735904
	2968833632656 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2968833632656 -> 2968860736000
	2968860736000 [label=AccumulateGrad]
	2968860736240 -> 2968860735904
	2968833632752 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2968833632752 -> 2968860736240
	2968860736240 [label=AccumulateGrad]
	2968860736528 -> 2968860736480
	2968833633136 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2968833633136 -> 2968860736528
	2968860736528 [label=AccumulateGrad]
	2968860736384 -> 2968860736576
	2968833633232 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2968833633232 -> 2968860736384
	2968860736384 [label=AccumulateGrad]
	2968860736768 -> 2968860736576
	2968833633328 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2968833633328 -> 2968860736768
	2968860736768 [label=AccumulateGrad]
	2968860736912 -> 2968860736864
	2968833633712 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2968833633712 -> 2968860736912
	2968860736912 [label=AccumulateGrad]
	2968860737056 -> 2968860737248
	2968833633808 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	2968833633808 -> 2968860737056
	2968860737056 [label=AccumulateGrad]
	2968860737200 -> 2968860737248
	2968833633904 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	2968833633904 -> 2968860737200
	2968860737200 [label=AccumulateGrad]
	2968860737488 -> 2968860737392
	2968860737344 -> 2968860725872
	2968833634288 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2968833634288 -> 2968860737344
	2968860737344 [label=AccumulateGrad]
	2968860726880 -> 2968860722992
	2968833634384 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	2968833634384 -> 2968860726880
	2968860726880 [label=AccumulateGrad]
	2968860727552 -> 2968860722992
	2968833634480 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	2968833634480 -> 2968860727552
	2968860727552 [label=AccumulateGrad]
	2968860728032 -> 2968860729136
	2968833634864 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2968833634864 -> 2968860728032
	2968860728032 [label=AccumulateGrad]
	2968860728992 -> 2968860729616
	2968833634960 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	2968833634960 -> 2968860728992
	2968860728992 [label=AccumulateGrad]
	2968860730096 -> 2968860729616
	2968833635056 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	2968833635056 -> 2968860730096
	2968860730096 [label=AccumulateGrad]
	2968860730576 -> 2968860730912
	2968833635440 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2968833635440 -> 2968860730576
	2968860730576 [label=AccumulateGrad]
	2968860731536 -> 2968860732016
	2968833635536 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	2968833635536 -> 2968860731536
	2968860731536 [label=AccumulateGrad]
	2968860731392 -> 2968860732016
	2968833635632 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	2968833635632 -> 2968860731392
	2968860731392 [label=AccumulateGrad]
	2968860731872 -> 2968860732496
	2968860733936 -> 2968860734752
	2968860733936 [label=TBackward0]
	2968860732352 -> 2968860733936
	2968833636304 [label="fc.weight
 (19, 2048)" fillcolor=lightblue]
	2968833636304 -> 2968860732352
	2968860732352 [label=AccumulateGrad]
	2968860734752 -> 2968830391600
}
