// Randomforest Supervised Classification using Landsat 9

// Step 1 - Loading the Landsat 9 Data
var dataset = ee.ImageCollection("LANDSAT/LC09/C02/T1_L2")
  .filterDate('2023-01-01', '2024-05-30')
  .filterBounds(roi)
  .filterMetadata('CLOUD_COVER', 'less_than', 10);

// Apply cloud mask
function maskL8sr(image) {
  var cloudShadowBitMask = ee.Number(2).pow(3).int();
  var cloudsBitMask = ee.Number(2).pow(5).int();
  var qa = image.select('QA_PIXEL');
  var mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0)
    .and(qa.bitwiseAnd(cloudsBitMask).eq(0));
  return image.updateMask(mask);
}

// Applies scaling factors
function applyScaleFactors(image){
  var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);
  var thermalBands = image.select('SR_B.').multiply(0.00341802).add(149.0);
  return image.addBands(opticalBands, null, true).addBands(thermalBands, null, true);
}

var rescale = dataset.map(maskL8sr).map(applyScaleFactors);
var image = rescale.median();

var ndvi = image.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI');
var evi = image.expression(
  '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {
    'NIR': image.select('SR_B5'),
    'RED': image.select('SR_B4'),
    'BLUE': image.select('SR_B2')
  }).rename('EVI');

image = image.addBands(ndvi).addBands(evi);

var visualization = {
  bands: ['SR_B4', 'SR_B3', 'SR_B2'],
  min: 0.0,
  max: 0.3,
};

Map.addLayer(image, visualization, 'Landsat 9');
Map.centerObject(roi);

// Step 2 - Creating the Training Data
var training = Barren.merge(Woodland).merge(Water).merge(Urban).merge(Crop).merge(Barren);
print(training);

// Export Training Data
Export.table.toAsset(training);

var label = 'Class';
var bands = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'NDVI', 'EVI'];
var input = image.select(bands);

// Overlay the points on the imagery to get training
var trainImage = input.sampleRegions({
  collection: training,
  properties: [label],
  scale: 30
});
//print(trainImage);

var trainingData = trainImage.randomColumn();
var trainSet = trainingData.filter(ee.Filter.lessThan('random', 0.8));
var testSet = trainingData.filter(ee.Filter.greaterThanOrEquals('random', 0.8));

// Step 3 - Creating the classification model by making a Random Forest Classifier and training it
var classifier = ee.Classifier.smileRandomForest({
  numberOfTrees: 50, // Increased number of trees
  variablesPerSplit: 5, // Number of variables per split
  minLeafPopulation: 2, // Minimum leaf population
  seed: 42 // Set random seed for reproducibility
}).train({
  features: trainSet,
  classProperty: label,
  inputProperties: bands
});

// Classify the Image
var classified = input.classify(classifier);
//var importance = classifier.explain().importance;
//print('Feature Importance:', importance);
//print(classified.getInfo()

// Define a palette for the classification
var landcoverPalette = [
  '#0a99ff', // water (0)
  '#8b1b1b', // urban (1)
  '#38e300', // woodland (2)
  '#fbff06', // crop (3)
  '#c2c2c2', // barren (4)
];
Map.addLayer(classified, {palette: landcoverPalette, min: 0, max: 4}, 'classification');

// Step 4 - Accuracy Assessment step, classifying the testingSet and resulting a confusion matrix
var test = testSet.classify(classifier);
var confusionMatrix = test.errorMatrix('Class', 'classification');

print('Confusion matrix:', confusionMatrix);
print('Overall Accuracy:', confusionMatrix.accuracy());
print('Producers Accuracy', confusionMatrix.producersAccuracy());
print('Consumers Accuracy', confusionMatrix.consumersAccuracy());
print('Kappa Coefficient:', confusionMatrix.kappa());

// Step 5 - Exporting the classified map to Google Drive
Export.image.toDrive({
  image: classified,
  description: 'Landsat_Classified_RF',
  scale: 30,
  region: roi,
  maxPixels: 1e13,
});
