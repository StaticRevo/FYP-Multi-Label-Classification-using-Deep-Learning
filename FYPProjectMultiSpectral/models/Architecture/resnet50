digraph {
	graph [size="151.95,151.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2330162209776 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2330157292640 [label=AddmmBackward0]
	2330157292784 -> 2330157292640
	2330168606352 [label="fc.bias
 (19)" fillcolor=lightblue]
	2330168606352 -> 2330157292784
	2330157292784 [label=AccumulateGrad]
	2330157292832 -> 2330157292640
	2330157292832 [label=ViewBackward0]
	2330157292928 -> 2330157292832
	2330157292928 [label=MeanBackward1]
	2330157293072 -> 2330157292928
	2330157293072 [label=ReluBackward0]
	2330157293168 -> 2330157293072
	2330157293168 [label=AddBackward0]
	2330157293264 -> 2330157293168
	2330157293264 [label=CudnnBatchNormBackward0]
	2330157293408 -> 2330157293264
	2330157293408 [label=ConvolutionBackward0]
	2330157293600 -> 2330157293408
	2330157293600 [label=ReluBackward0]
	2330157293744 -> 2330157293600
	2330157293744 [label=CudnnBatchNormBackward0]
	2330157293840 -> 2330157293744
	2330157293840 [label=ConvolutionBackward0]
	2330157294032 -> 2330157293840
	2330157294032 [label=ReluBackward0]
	2330157294176 -> 2330157294032
	2330157294176 [label=CudnnBatchNormBackward0]
	2330157294272 -> 2330157294176
	2330157294272 [label=ConvolutionBackward0]
	2330157293216 -> 2330157294272
	2330157293216 [label=ReluBackward0]
	2330157294560 -> 2330157293216
	2330157294560 [label=AddBackward0]
	2330157294656 -> 2330157294560
	2330157294656 [label=CudnnBatchNormBackward0]
	2330157294800 -> 2330157294656
	2330157294800 [label=ConvolutionBackward0]
	2330157294992 -> 2330157294800
	2330157294992 [label=ReluBackward0]
	2330157295136 -> 2330157294992
	2330157295136 [label=CudnnBatchNormBackward0]
	2330157295232 -> 2330157295136
	2330157295232 [label=ConvolutionBackward0]
	2330157295424 -> 2330157295232
	2330157295424 [label=ReluBackward0]
	2330157295568 -> 2330157295424
	2330157295568 [label=CudnnBatchNormBackward0]
	2330157295664 -> 2330157295568
	2330157295664 [label=ConvolutionBackward0]
	2330157294608 -> 2330157295664
	2330157294608 [label=ReluBackward0]
	2330157295952 -> 2330157294608
	2330157295952 [label=AddBackward0]
	2330157296048 -> 2330157295952
	2330157296048 [label=CudnnBatchNormBackward0]
	2330157296192 -> 2330157296048
	2330157296192 [label=ConvolutionBackward0]
	2330157296384 -> 2330157296192
	2330157296384 [label=ReluBackward0]
	2330157296528 -> 2330157296384
	2330157296528 [label=CudnnBatchNormBackward0]
	2330157296624 -> 2330157296528
	2330157296624 [label=ConvolutionBackward0]
	2330157296816 -> 2330157296624
	2330157296816 [label=ReluBackward0]
	2330157296960 -> 2330157296816
	2330157296960 [label=CudnnBatchNormBackward0]
	2330157297056 -> 2330157296960
	2330157297056 [label=ConvolutionBackward0]
	2330157297248 -> 2330157297056
	2330157297248 [label=ReluBackward0]
	2330157297392 -> 2330157297248
	2330157297392 [label=AddBackward0]
	2330157297488 -> 2330157297392
	2330157297488 [label=CudnnBatchNormBackward0]
	2330157297632 -> 2330157297488
	2330157297632 [label=ConvolutionBackward0]
	2330157297824 -> 2330157297632
	2330157297824 [label=ReluBackward0]
	2330157297968 -> 2330157297824
	2330157297968 [label=CudnnBatchNormBackward0]
	2330157292160 -> 2330157297968
	2330157292160 [label=ConvolutionBackward0]
	2330157298112 -> 2330157292160
	2330157298112 [label=ReluBackward0]
	2330157298256 -> 2330157298112
	2330157298256 [label=CudnnBatchNormBackward0]
	2330157298352 -> 2330157298256
	2330157298352 [label=ConvolutionBackward0]
	2330157297440 -> 2330157298352
	2330157297440 [label=ReluBackward0]
	2330157298640 -> 2330157297440
	2330157298640 [label=AddBackward0]
	2330157298736 -> 2330157298640
	2330157298736 [label=CudnnBatchNormBackward0]
	2330157298880 -> 2330157298736
	2330157298880 [label=ConvolutionBackward0]
	2330157299072 -> 2330157298880
	2330157299072 [label=ReluBackward0]
	2330157299216 -> 2330157299072
	2330157299216 [label=CudnnBatchNormBackward0]
	2330157299312 -> 2330157299216
	2330157299312 [label=ConvolutionBackward0]
	2330157299504 -> 2330157299312
	2330157299504 [label=ReluBackward0]
	2330157299648 -> 2330157299504
	2330157299648 [label=CudnnBatchNormBackward0]
	2330157299744 -> 2330157299648
	2330157299744 [label=ConvolutionBackward0]
	2330157298688 -> 2330157299744
	2330157298688 [label=ReluBackward0]
	2330157300032 -> 2330157298688
	2330157300032 [label=AddBackward0]
	2330157300128 -> 2330157300032
	2330157300128 [label=CudnnBatchNormBackward0]
	2330157300272 -> 2330157300128
	2330157300272 [label=ConvolutionBackward0]
	2330157300464 -> 2330157300272
	2330157300464 [label=ReluBackward0]
	2330157300608 -> 2330157300464
	2330157300608 [label=CudnnBatchNormBackward0]
	2330157300704 -> 2330157300608
	2330157300704 [label=ConvolutionBackward0]
	2330157301136 -> 2330157300704
	2330157301136 [label=ReluBackward0]
	2330164887408 -> 2330157301136
	2330164887408 [label=CudnnBatchNormBackward0]
	2330164887504 -> 2330164887408
	2330164887504 [label=ConvolutionBackward0]
	2330157300080 -> 2330164887504
	2330157300080 [label=ReluBackward0]
	2330157367600 -> 2330157300080
	2330157367600 [label=AddBackward0]
	2330157367696 -> 2330157367600
	2330157367696 [label=CudnnBatchNormBackward0]
	2330157367840 -> 2330157367696
	2330157367840 [label=ConvolutionBackward0]
	2330157368032 -> 2330157367840
	2330157368032 [label=ReluBackward0]
	2330157368176 -> 2330157368032
	2330157368176 [label=CudnnBatchNormBackward0]
	2330157368272 -> 2330157368176
	2330157368272 [label=ConvolutionBackward0]
	2330157368464 -> 2330157368272
	2330157368464 [label=ReluBackward0]
	2330157368608 -> 2330157368464
	2330157368608 [label=CudnnBatchNormBackward0]
	2330157368704 -> 2330157368608
	2330157368704 [label=ConvolutionBackward0]
	2330157367648 -> 2330157368704
	2330157367648 [label=ReluBackward0]
	2330157368992 -> 2330157367648
	2330157368992 [label=AddBackward0]
	2330157369088 -> 2330157368992
	2330157369088 [label=CudnnBatchNormBackward0]
	2330157369232 -> 2330157369088
	2330157369232 [label=ConvolutionBackward0]
	2330157369424 -> 2330157369232
	2330157369424 [label=ReluBackward0]
	2330157369568 -> 2330157369424
	2330157369568 [label=CudnnBatchNormBackward0]
	2330157369664 -> 2330157369568
	2330157369664 [label=ConvolutionBackward0]
	2330157369856 -> 2330157369664
	2330157369856 [label=ReluBackward0]
	2330157370000 -> 2330157369856
	2330157370000 [label=CudnnBatchNormBackward0]
	2330157370096 -> 2330157370000
	2330157370096 [label=ConvolutionBackward0]
	2330157369040 -> 2330157370096
	2330157369040 [label=ReluBackward0]
	2330157370384 -> 2330157369040
	2330157370384 [label=AddBackward0]
	2330157370480 -> 2330157370384
	2330157370480 [label=CudnnBatchNormBackward0]
	2330157370624 -> 2330157370480
	2330157370624 [label=ConvolutionBackward0]
	2330157370816 -> 2330157370624
	2330157370816 [label=ReluBackward0]
	2330157370960 -> 2330157370816
	2330157370960 [label=CudnnBatchNormBackward0]
	2330157371056 -> 2330157370960
	2330157371056 [label=ConvolutionBackward0]
	2330157371248 -> 2330157371056
	2330157371248 [label=ReluBackward0]
	2330157371392 -> 2330157371248
	2330157371392 [label=CudnnBatchNormBackward0]
	2330157371488 -> 2330157371392
	2330157371488 [label=ConvolutionBackward0]
	2330157371680 -> 2330157371488
	2330157371680 [label=ReluBackward0]
	2330157371824 -> 2330157371680
	2330157371824 [label=AddBackward0]
	2330157371920 -> 2330157371824
	2330157371920 [label=CudnnBatchNormBackward0]
	2330157372064 -> 2330157371920
	2330157372064 [label=ConvolutionBackward0]
	2330157372256 -> 2330157372064
	2330157372256 [label=ReluBackward0]
	2330157372400 -> 2330157372256
	2330157372400 [label=CudnnBatchNormBackward0]
	2330157372496 -> 2330157372400
	2330157372496 [label=ConvolutionBackward0]
	2330157372688 -> 2330157372496
	2330157372688 [label=ReluBackward0]
	2330157372832 -> 2330157372688
	2330157372832 [label=CudnnBatchNormBackward0]
	2330157372928 -> 2330157372832
	2330157372928 [label=ConvolutionBackward0]
	2330157371872 -> 2330157372928
	2330157371872 [label=ReluBackward0]
	2330157373216 -> 2330157371872
	2330157373216 [label=AddBackward0]
	2330157373312 -> 2330157373216
	2330157373312 [label=CudnnBatchNormBackward0]
	2330157373456 -> 2330157373312
	2330157373456 [label=ConvolutionBackward0]
	2330157373648 -> 2330157373456
	2330157373648 [label=ReluBackward0]
	2330157373792 -> 2330157373648
	2330157373792 [label=CudnnBatchNormBackward0]
	2330157373888 -> 2330157373792
	2330157373888 [label=ConvolutionBackward0]
	2330157374080 -> 2330157373888
	2330157374080 [label=ReluBackward0]
	2330157374224 -> 2330157374080
	2330157374224 [label=CudnnBatchNormBackward0]
	2330157374320 -> 2330157374224
	2330157374320 [label=ConvolutionBackward0]
	2330157373264 -> 2330157374320
	2330157373264 [label=ReluBackward0]
	2330157374608 -> 2330157373264
	2330157374608 [label=AddBackward0]
	2330157374704 -> 2330157374608
	2330157374704 [label=CudnnBatchNormBackward0]
	2330157374848 -> 2330157374704
	2330157374848 [label=ConvolutionBackward0]
	2330157375040 -> 2330157374848
	2330157375040 [label=ReluBackward0]
	2330157375184 -> 2330157375040
	2330157375184 [label=CudnnBatchNormBackward0]
	2330157375280 -> 2330157375184
	2330157375280 [label=ConvolutionBackward0]
	2330157375472 -> 2330157375280
	2330157375472 [label=ReluBackward0]
	2330157375616 -> 2330157375472
	2330157375616 [label=CudnnBatchNormBackward0]
	2330157375712 -> 2330157375616
	2330157375712 [label=ConvolutionBackward0]
	2330157374656 -> 2330157375712
	2330157374656 [label=ReluBackward0]
	2330157376000 -> 2330157374656
	2330157376000 [label=AddBackward0]
	2330157376096 -> 2330157376000
	2330157376096 [label=CudnnBatchNormBackward0]
	2330157376240 -> 2330157376096
	2330157376240 [label=ConvolutionBackward0]
	2330157376432 -> 2330157376240
	2330157376432 [label=ReluBackward0]
	2330157376576 -> 2330157376432
	2330157376576 [label=CudnnBatchNormBackward0]
	2330157376672 -> 2330157376576
	2330157376672 [label=ConvolutionBackward0]
	2330157376864 -> 2330157376672
	2330157376864 [label=ReluBackward0]
	2330157377008 -> 2330157376864
	2330157377008 [label=CudnnBatchNormBackward0]
	2330157377104 -> 2330157377008
	2330157377104 [label=ConvolutionBackward0]
	2330157377296 -> 2330157377104
	2330157377296 [label=ReluBackward0]
	2330157377440 -> 2330157377296
	2330157377440 [label=AddBackward0]
	2330157377536 -> 2330157377440
	2330157377536 [label=CudnnBatchNormBackward0]
	2330157377680 -> 2330157377536
	2330157377680 [label=ConvolutionBackward0]
	2330157377872 -> 2330157377680
	2330157377872 [label=ReluBackward0]
	2330157378016 -> 2330157377872
	2330157378016 [label=CudnnBatchNormBackward0]
	2330157378112 -> 2330157378016
	2330157378112 [label=ConvolutionBackward0]
	2330157378304 -> 2330157378112
	2330157378304 [label=ReluBackward0]
	2330157378448 -> 2330157378304
	2330157378448 [label=CudnnBatchNormBackward0]
	2330157378544 -> 2330157378448
	2330157378544 [label=ConvolutionBackward0]
	2330157377488 -> 2330157378544
	2330157377488 [label=ReluBackward0]
	2330157378832 -> 2330157377488
	2330157378832 [label=AddBackward0]
	2330157378928 -> 2330157378832
	2330157378928 [label=CudnnBatchNormBackward0]
	2330157379072 -> 2330157378928
	2330157379072 [label=ConvolutionBackward0]
	2330157379264 -> 2330157379072
	2330157379264 [label=ReluBackward0]
	2330157379408 -> 2330157379264
	2330157379408 [label=CudnnBatchNormBackward0]
	2330157379504 -> 2330157379408
	2330157379504 [label=ConvolutionBackward0]
	2330157379696 -> 2330157379504
	2330157379696 [label=ReluBackward0]
	2330157379840 -> 2330157379696
	2330157379840 [label=CudnnBatchNormBackward0]
	2330157379936 -> 2330157379840
	2330157379936 [label=ConvolutionBackward0]
	2330157378880 -> 2330157379936
	2330157378880 [label=ReluBackward0]
	2330157380224 -> 2330157378880
	2330157380224 [label=AddBackward0]
	2330157380320 -> 2330157380224
	2330157380320 [label=CudnnBatchNormBackward0]
	2330157380464 -> 2330157380320
	2330157380464 [label=ConvolutionBackward0]
	2330157380656 -> 2330157380464
	2330157380656 [label=ReluBackward0]
	2330157380800 -> 2330157380656
	2330157380800 [label=CudnnBatchNormBackward0]
	2330157380896 -> 2330157380800
	2330157380896 [label=ConvolutionBackward0]
	2330157381088 -> 2330157380896
	2330157381088 [label=ReluBackward0]
	2330157381232 -> 2330157381088
	2330157381232 [label=CudnnBatchNormBackward0]
	2330157381328 -> 2330157381232
	2330157381328 [label=ConvolutionBackward0]
	2330157381520 -> 2330157381328
	2330157381520 [label=MaxPool2DWithIndicesBackward0]
	2330157381664 -> 2330157381520
	2330157381664 [label=ReluBackward0]
	2330157381760 -> 2330157381664
	2330157381760 [label=CudnnBatchNormBackward0]
	2330157381856 -> 2330157381760
	2330157381856 [label=ConvolutionBackward0]
	2330157382048 -> 2330157381856
	2330168606544 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	2330168606544 -> 2330157382048
	2330157382048 [label=AccumulateGrad]
	2330157381808 -> 2330157381760
	2330047825488 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2330047825488 -> 2330157381808
	2330157381808 [label=AccumulateGrad]
	2330157381568 -> 2330157381760
	2330047825584 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2330047825584 -> 2330157381568
	2330157381568 [label=AccumulateGrad]
	2330157381472 -> 2330157381328
	2330047826544 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2330047826544 -> 2330157381472
	2330157381472 [label=AccumulateGrad]
	2330157381280 -> 2330157381232
	2330047826640 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2330047826640 -> 2330157381280
	2330157381280 [label=AccumulateGrad]
	2330157381136 -> 2330157381232
	2330047826736 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2330047826736 -> 2330157381136
	2330157381136 [label=AccumulateGrad]
	2330157381040 -> 2330157380896
	2330047827120 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2330047827120 -> 2330157381040
	2330157381040 [label=AccumulateGrad]
	2330157380848 -> 2330157380800
	2330047827216 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2330047827216 -> 2330157380848
	2330157380848 [label=AccumulateGrad]
	2330157380704 -> 2330157380800
	2330047827312 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2330047827312 -> 2330157380704
	2330157380704 [label=AccumulateGrad]
	2330157380608 -> 2330157380464
	2330047827696 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2330047827696 -> 2330157380608
	2330157380608 [label=AccumulateGrad]
	2330157380416 -> 2330157380320
	2330047827792 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	2330047827792 -> 2330157380416
	2330157380416 [label=AccumulateGrad]
	2330157380368 -> 2330157380320
	2330047827888 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	2330047827888 -> 2330157380368
	2330157380368 [label=AccumulateGrad]
	2330157380272 -> 2330157380224
	2330157380272 [label=CudnnBatchNormBackward0]
	2330157380992 -> 2330157380272
	2330157380992 [label=ConvolutionBackward0]
	2330157381520 -> 2330157380992
	2330157381376 -> 2330157380992
	2330047825968 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2330047825968 -> 2330157381376
	2330157381376 [label=AccumulateGrad]
	2330157380560 -> 2330157380272
	2330047826064 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2330047826064 -> 2330157380560
	2330157380560 [label=AccumulateGrad]
	2330157380512 -> 2330157380272
	2330047826160 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2330047826160 -> 2330157380512
	2330157380512 [label=AccumulateGrad]
	2330157380128 -> 2330157379936
	2330047828272 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2330047828272 -> 2330157380128
	2330157380128 [label=AccumulateGrad]
	2330157379888 -> 2330157379840
	2330047828368 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2330047828368 -> 2330157379888
	2330157379888 [label=AccumulateGrad]
	2330157379744 -> 2330157379840
	2330047828464 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2330047828464 -> 2330157379744
	2330157379744 [label=AccumulateGrad]
	2330157379648 -> 2330157379504
	2330047828848 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2330047828848 -> 2330157379648
	2330157379648 [label=AccumulateGrad]
	2330157379456 -> 2330157379408
	2330047828944 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2330047828944 -> 2330157379456
	2330157379456 [label=AccumulateGrad]
	2330157379312 -> 2330157379408
	2330047829040 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2330047829040 -> 2330157379312
	2330157379312 [label=AccumulateGrad]
	2330157379216 -> 2330157379072
	2330047829424 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2330047829424 -> 2330157379216
	2330157379216 [label=AccumulateGrad]
	2330157379024 -> 2330157378928
	2330047829520 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	2330047829520 -> 2330157379024
	2330157379024 [label=AccumulateGrad]
	2330157378976 -> 2330157378928
	2330047829616 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	2330047829616 -> 2330157378976
	2330157378976 [label=AccumulateGrad]
	2330157378880 -> 2330157378832
	2330157378736 -> 2330157378544
	2330047830000 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2330047830000 -> 2330157378736
	2330157378736 [label=AccumulateGrad]
	2330157378496 -> 2330157378448
	2330047830096 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	2330047830096 -> 2330157378496
	2330157378496 [label=AccumulateGrad]
	2330157378352 -> 2330157378448
	2330047830192 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	2330047830192 -> 2330157378352
	2330157378352 [label=AccumulateGrad]
	2330157378256 -> 2330157378112
	2330047830576 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2330047830576 -> 2330157378256
	2330157378256 [label=AccumulateGrad]
	2330157378064 -> 2330157378016
	2330047830672 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	2330047830672 -> 2330157378064
	2330157378064 [label=AccumulateGrad]
	2330157377920 -> 2330157378016
	2330047830768 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	2330047830768 -> 2330157377920
	2330157377920 [label=AccumulateGrad]
	2330157377824 -> 2330157377680
	2330047831152 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2330047831152 -> 2330157377824
	2330157377824 [label=AccumulateGrad]
	2330157377632 -> 2330157377536
	2330047831248 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	2330047831248 -> 2330157377632
	2330157377632 [label=AccumulateGrad]
	2330157377584 -> 2330157377536
	2330047831344 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	2330047831344 -> 2330157377584
	2330157377584 [label=AccumulateGrad]
	2330157377488 -> 2330157377440
	2330157377248 -> 2330157377104
	2330047832304 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2330047832304 -> 2330157377248
	2330157377248 [label=AccumulateGrad]
	2330157377056 -> 2330157377008
	2330047832400 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2330047832400 -> 2330157377056
	2330157377056 [label=AccumulateGrad]
	2330157376912 -> 2330157377008
	2330047832496 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2330047832496 -> 2330157376912
	2330157376912 [label=AccumulateGrad]
	2330157376816 -> 2330157376672
	2330047832880 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2330047832880 -> 2330157376816
	2330157376816 [label=AccumulateGrad]
	2330157376624 -> 2330157376576
	2330047832976 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2330047832976 -> 2330157376624
	2330157376624 [label=AccumulateGrad]
	2330157376480 -> 2330157376576
	2330047833072 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2330047833072 -> 2330157376480
	2330157376480 [label=AccumulateGrad]
	2330157376384 -> 2330157376240
	2330047833456 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2330047833456 -> 2330157376384
	2330157376384 [label=AccumulateGrad]
	2330157376192 -> 2330157376096
	2330047833552 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	2330047833552 -> 2330157376192
	2330157376192 [label=AccumulateGrad]
	2330157376144 -> 2330157376096
	2330047833648 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	2330047833648 -> 2330157376144
	2330157376144 [label=AccumulateGrad]
	2330157376048 -> 2330157376000
	2330157376048 [label=CudnnBatchNormBackward0]
	2330157376768 -> 2330157376048
	2330157376768 [label=ConvolutionBackward0]
	2330157377296 -> 2330157376768
	2330157377152 -> 2330157376768
	2330047831728 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2330047831728 -> 2330157377152
	2330157377152 [label=AccumulateGrad]
	2330157376336 -> 2330157376048
	2330047831824 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2330047831824 -> 2330157376336
	2330157376336 [label=AccumulateGrad]
	2330157376288 -> 2330157376048
	2330047831920 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2330047831920 -> 2330157376288
	2330157376288 [label=AccumulateGrad]
	2330157375904 -> 2330157375712
	2330047834032 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2330047834032 -> 2330157375904
	2330157375904 [label=AccumulateGrad]
	2330157375664 -> 2330157375616
	2330047834128 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2330047834128 -> 2330157375664
	2330157375664 [label=AccumulateGrad]
	2330157375520 -> 2330157375616
	2330047834224 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2330047834224 -> 2330157375520
	2330157375520 [label=AccumulateGrad]
	2330157375424 -> 2330157375280
	2330047834608 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2330047834608 -> 2330157375424
	2330157375424 [label=AccumulateGrad]
	2330157375232 -> 2330157375184
	2330047834704 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2330047834704 -> 2330157375232
	2330157375232 [label=AccumulateGrad]
	2330157375088 -> 2330157375184
	2330047834800 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2330047834800 -> 2330157375088
	2330157375088 [label=AccumulateGrad]
	2330157374992 -> 2330157374848
	2330047835184 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2330047835184 -> 2330157374992
	2330157374992 [label=AccumulateGrad]
	2330157374800 -> 2330157374704
	2330047835280 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	2330047835280 -> 2330157374800
	2330157374800 [label=AccumulateGrad]
	2330157374752 -> 2330157374704
	2330047835376 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	2330047835376 -> 2330157374752
	2330157374752 [label=AccumulateGrad]
	2330157374656 -> 2330157374608
	2330157374512 -> 2330157374320
	2330047835760 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2330047835760 -> 2330157374512
	2330157374512 [label=AccumulateGrad]
	2330157374272 -> 2330157374224
	2330047835856 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	2330047835856 -> 2330157374272
	2330157374272 [label=AccumulateGrad]
	2330157374128 -> 2330157374224
	2330047835952 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	2330047835952 -> 2330157374128
	2330157374128 [label=AccumulateGrad]
	2330157374032 -> 2330157373888
	2330047836336 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2330047836336 -> 2330157374032
	2330157374032 [label=AccumulateGrad]
	2330157373840 -> 2330157373792
	2330047836432 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	2330047836432 -> 2330157373840
	2330157373840 [label=AccumulateGrad]
	2330157373696 -> 2330157373792
	2330047836528 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	2330047836528 -> 2330157373696
	2330157373696 [label=AccumulateGrad]
	2330157373600 -> 2330157373456
	2330047836912 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2330047836912 -> 2330157373600
	2330157373600 [label=AccumulateGrad]
	2330157373408 -> 2330157373312
	2330047837008 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	2330047837008 -> 2330157373408
	2330157373408 [label=AccumulateGrad]
	2330157373360 -> 2330157373312
	2330047837104 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	2330047837104 -> 2330157373360
	2330157373360 [label=AccumulateGrad]
	2330157373264 -> 2330157373216
	2330157373120 -> 2330157372928
	2330047837488 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2330047837488 -> 2330157373120
	2330157373120 [label=AccumulateGrad]
	2330157372880 -> 2330157372832
	2330047837584 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	2330047837584 -> 2330157372880
	2330157372880 [label=AccumulateGrad]
	2330157372736 -> 2330157372832
	2330047837680 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	2330047837680 -> 2330157372736
	2330157372736 [label=AccumulateGrad]
	2330157372640 -> 2330157372496
	2330047838064 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2330047838064 -> 2330157372640
	2330157372640 [label=AccumulateGrad]
	2330157372448 -> 2330157372400
	2330047838160 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	2330047838160 -> 2330157372448
	2330157372448 [label=AccumulateGrad]
	2330157372304 -> 2330157372400
	2330047838256 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	2330047838256 -> 2330157372304
	2330157372304 [label=AccumulateGrad]
	2330157372208 -> 2330157372064
	2330047838640 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2330047838640 -> 2330157372208
	2330157372208 [label=AccumulateGrad]
	2330157372016 -> 2330157371920
	2330047838736 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	2330047838736 -> 2330157372016
	2330157372016 [label=AccumulateGrad]
	2330157371968 -> 2330157371920
	2330047838832 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	2330047838832 -> 2330157371968
	2330157371968 [label=AccumulateGrad]
	2330157371872 -> 2330157371824
	2330157371632 -> 2330157371488
	2330047839792 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2330047839792 -> 2330157371632
	2330157371632 [label=AccumulateGrad]
	2330157371440 -> 2330157371392
	2330047839888 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2330047839888 -> 2330157371440
	2330157371440 [label=AccumulateGrad]
	2330157371296 -> 2330157371392
	2330047839984 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2330047839984 -> 2330157371296
	2330157371296 [label=AccumulateGrad]
	2330157371200 -> 2330157371056
	2330158219440 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2330158219440 -> 2330157371200
	2330157371200 [label=AccumulateGrad]
	2330157371008 -> 2330157370960
	2330158219536 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2330158219536 -> 2330157371008
	2330157371008 [label=AccumulateGrad]
	2330157370864 -> 2330157370960
	2330158219632 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2330158219632 -> 2330157370864
	2330157370864 [label=AccumulateGrad]
	2330157370768 -> 2330157370624
	2330158220016 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2330158220016 -> 2330157370768
	2330157370768 [label=AccumulateGrad]
	2330157370576 -> 2330157370480
	2330158220112 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	2330158220112 -> 2330157370576
	2330157370576 [label=AccumulateGrad]
	2330157370528 -> 2330157370480
	2330158220208 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	2330158220208 -> 2330157370528
	2330157370528 [label=AccumulateGrad]
	2330157370432 -> 2330157370384
	2330157370432 [label=CudnnBatchNormBackward0]
	2330157371152 -> 2330157370432
	2330157371152 [label=ConvolutionBackward0]
	2330157371680 -> 2330157371152
	2330157371536 -> 2330157371152
	2330047839216 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2330047839216 -> 2330157371536
	2330157371536 [label=AccumulateGrad]
	2330157370720 -> 2330157370432
	2330047839312 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	2330047839312 -> 2330157370720
	2330157370720 [label=AccumulateGrad]
	2330157370672 -> 2330157370432
	2330047839408 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	2330047839408 -> 2330157370672
	2330157370672 [label=AccumulateGrad]
	2330157370288 -> 2330157370096
	2330158220592 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2330158220592 -> 2330157370288
	2330157370288 [label=AccumulateGrad]
	2330157370048 -> 2330157370000
	2330158220688 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2330158220688 -> 2330157370048
	2330157370048 [label=AccumulateGrad]
	2330157369904 -> 2330157370000
	2330158220784 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2330158220784 -> 2330157369904
	2330157369904 [label=AccumulateGrad]
	2330157369808 -> 2330157369664
	2330158221168 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2330158221168 -> 2330157369808
	2330157369808 [label=AccumulateGrad]
	2330157369616 -> 2330157369568
	2330158221264 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2330158221264 -> 2330157369616
	2330157369616 [label=AccumulateGrad]
	2330157369472 -> 2330157369568
	2330158221360 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2330158221360 -> 2330157369472
	2330157369472 [label=AccumulateGrad]
	2330157369376 -> 2330157369232
	2330158221744 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2330158221744 -> 2330157369376
	2330157369376 [label=AccumulateGrad]
	2330157369184 -> 2330157369088
	2330158221840 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	2330158221840 -> 2330157369184
	2330157369184 [label=AccumulateGrad]
	2330157369136 -> 2330157369088
	2330158221936 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	2330158221936 -> 2330157369136
	2330157369136 [label=AccumulateGrad]
	2330157369040 -> 2330157368992
	2330157368896 -> 2330157368704
	2330158222320 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2330158222320 -> 2330157368896
	2330157368896 [label=AccumulateGrad]
	2330157368656 -> 2330157368608
	2330158222416 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	2330158222416 -> 2330157368656
	2330157368656 [label=AccumulateGrad]
	2330157368512 -> 2330157368608
	2330158222512 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	2330158222512 -> 2330157368512
	2330157368512 [label=AccumulateGrad]
	2330157368416 -> 2330157368272
	2330158222896 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2330158222896 -> 2330157368416
	2330157368416 [label=AccumulateGrad]
	2330157368224 -> 2330157368176
	2330158222992 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	2330158222992 -> 2330157368224
	2330157368224 [label=AccumulateGrad]
	2330157368080 -> 2330157368176
	2330158223088 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	2330158223088 -> 2330157368080
	2330157368080 [label=AccumulateGrad]
	2330157367984 -> 2330157367840
	2330158223472 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2330158223472 -> 2330157367984
	2330157367984 [label=AccumulateGrad]
	2330157367792 -> 2330157367696
	2330158223568 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	2330158223568 -> 2330157367792
	2330157367792 [label=AccumulateGrad]
	2330157367744 -> 2330157367696
	2330158223664 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	2330158223664 -> 2330157367744
	2330157367744 [label=AccumulateGrad]
	2330157367648 -> 2330157367600
	2330157367504 -> 2330164887504
	2330158224048 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2330158224048 -> 2330157367504
	2330157367504 [label=AccumulateGrad]
	2330164887456 -> 2330164887408
	2330158224144 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	2330158224144 -> 2330164887456
	2330164887456 [label=AccumulateGrad]
	2330164887312 -> 2330164887408
	2330158224240 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	2330158224240 -> 2330164887312
	2330164887312 [label=AccumulateGrad]
	2330157300848 -> 2330157300704
	2330158224624 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2330158224624 -> 2330157300848
	2330157300848 [label=AccumulateGrad]
	2330157300656 -> 2330157300608
	2330158224720 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	2330158224720 -> 2330157300656
	2330157300656 [label=AccumulateGrad]
	2330157300512 -> 2330157300608
	2330158224816 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	2330158224816 -> 2330157300512
	2330157300512 [label=AccumulateGrad]
	2330157300416 -> 2330157300272
	2330158225200 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2330158225200 -> 2330157300416
	2330157300416 [label=AccumulateGrad]
	2330157300224 -> 2330157300128
	2330158225296 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	2330158225296 -> 2330157300224
	2330157300224 [label=AccumulateGrad]
	2330157300176 -> 2330157300128
	2330158225392 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	2330158225392 -> 2330157300176
	2330157300176 [label=AccumulateGrad]
	2330157300080 -> 2330157300032
	2330157299936 -> 2330157299744
	2330158225776 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2330158225776 -> 2330157299936
	2330157299936 [label=AccumulateGrad]
	2330157299696 -> 2330157299648
	2330158225872 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	2330158225872 -> 2330157299696
	2330157299696 [label=AccumulateGrad]
	2330157299552 -> 2330157299648
	2330158225968 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	2330158225968 -> 2330157299552
	2330157299552 [label=AccumulateGrad]
	2330157299456 -> 2330157299312
	2330158226352 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2330158226352 -> 2330157299456
	2330157299456 [label=AccumulateGrad]
	2330157299264 -> 2330157299216
	2330158226448 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	2330158226448 -> 2330157299264
	2330157299264 [label=AccumulateGrad]
	2330157299120 -> 2330157299216
	2330158226544 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	2330158226544 -> 2330157299120
	2330157299120 [label=AccumulateGrad]
	2330157299024 -> 2330157298880
	2330158226928 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2330158226928 -> 2330157299024
	2330157299024 [label=AccumulateGrad]
	2330157298832 -> 2330157298736
	2330158227024 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	2330158227024 -> 2330157298832
	2330157298832 [label=AccumulateGrad]
	2330157298784 -> 2330157298736
	2330158227120 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	2330158227120 -> 2330157298784
	2330157298784 [label=AccumulateGrad]
	2330157298688 -> 2330157298640
	2330157298544 -> 2330157298352
	2330158227504 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2330158227504 -> 2330157298544
	2330157298544 [label=AccumulateGrad]
	2330157298304 -> 2330157298256
	2330158227600 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	2330158227600 -> 2330157298304
	2330157298304 [label=AccumulateGrad]
	2330157298160 -> 2330157298256
	2330158227696 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	2330158227696 -> 2330157298160
	2330157298160 [label=AccumulateGrad]
	2330157298064 -> 2330157292160
	2330158228080 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2330158228080 -> 2330157298064
	2330157298064 [label=AccumulateGrad]
	2330157292064 -> 2330157297968
	2330158228176 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	2330158228176 -> 2330157292064
	2330157292064 [label=AccumulateGrad]
	2330157297872 -> 2330157297968
	2330158228272 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	2330158228272 -> 2330157297872
	2330157297872 [label=AccumulateGrad]
	2330157297776 -> 2330157297632
	2330158228656 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2330158228656 -> 2330157297776
	2330157297776 [label=AccumulateGrad]
	2330157297584 -> 2330157297488
	2330158228752 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	2330158228752 -> 2330157297584
	2330157297584 [label=AccumulateGrad]
	2330157297536 -> 2330157297488
	2330158228848 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	2330158228848 -> 2330157297536
	2330157297536 [label=AccumulateGrad]
	2330157297440 -> 2330157297392
	2330157297200 -> 2330157297056
	2330158229808 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2330158229808 -> 2330157297200
	2330157297200 [label=AccumulateGrad]
	2330157297008 -> 2330157296960
	2330158229904 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2330158229904 -> 2330157297008
	2330157297008 [label=AccumulateGrad]
	2330157296864 -> 2330157296960
	2330158230000 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2330158230000 -> 2330157296864
	2330157296864 [label=AccumulateGrad]
	2330157296768 -> 2330157296624
	2330158230384 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2330158230384 -> 2330157296768
	2330157296768 [label=AccumulateGrad]
	2330157296576 -> 2330157296528
	2330158230480 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2330158230480 -> 2330157296576
	2330157296576 [label=AccumulateGrad]
	2330157296432 -> 2330157296528
	2330158230576 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2330158230576 -> 2330157296432
	2330157296432 [label=AccumulateGrad]
	2330157296336 -> 2330157296192
	2330158230960 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2330158230960 -> 2330157296336
	2330157296336 [label=AccumulateGrad]
	2330157296144 -> 2330157296048
	2330158231056 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	2330158231056 -> 2330157296144
	2330157296144 [label=AccumulateGrad]
	2330157296096 -> 2330157296048
	2330158231152 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	2330158231152 -> 2330157296096
	2330157296096 [label=AccumulateGrad]
	2330157296000 -> 2330157295952
	2330157296000 [label=CudnnBatchNormBackward0]
	2330157296720 -> 2330157296000
	2330157296720 [label=ConvolutionBackward0]
	2330157297248 -> 2330157296720
	2330157297104 -> 2330157296720
	2330158229232 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	2330158229232 -> 2330157297104
	2330157297104 [label=AccumulateGrad]
	2330157296288 -> 2330157296000
	2330158229328 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	2330158229328 -> 2330157296288
	2330157296288 [label=AccumulateGrad]
	2330157296240 -> 2330157296000
	2330158229424 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	2330158229424 -> 2330157296240
	2330157296240 [label=AccumulateGrad]
	2330157295856 -> 2330157295664
	2330158231536 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2330158231536 -> 2330157295856
	2330157295856 [label=AccumulateGrad]
	2330157295616 -> 2330157295568
	2330158231632 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2330158231632 -> 2330157295616
	2330157295616 [label=AccumulateGrad]
	2330157295472 -> 2330157295568
	2330158231728 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2330158231728 -> 2330157295472
	2330157295472 [label=AccumulateGrad]
	2330157295376 -> 2330157295232
	2330158232112 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2330158232112 -> 2330157295376
	2330157295376 [label=AccumulateGrad]
	2330157295184 -> 2330157295136
	2330158232208 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2330158232208 -> 2330157295184
	2330157295184 [label=AccumulateGrad]
	2330157295040 -> 2330157295136
	2330158232304 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2330158232304 -> 2330157295040
	2330157295040 [label=AccumulateGrad]
	2330157294944 -> 2330157294800
	2330158232688 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2330158232688 -> 2330157294944
	2330157294944 [label=AccumulateGrad]
	2330157294752 -> 2330157294656
	2330158232784 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	2330158232784 -> 2330157294752
	2330157294752 [label=AccumulateGrad]
	2330157294704 -> 2330157294656
	2330158232880 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	2330158232880 -> 2330157294704
	2330157294704 [label=AccumulateGrad]
	2330157294608 -> 2330157294560
	2330157294464 -> 2330157294272
	2330158233264 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2330158233264 -> 2330157294464
	2330157294464 [label=AccumulateGrad]
	2330157294224 -> 2330157294176
	2330158233360 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	2330158233360 -> 2330157294224
	2330157294224 [label=AccumulateGrad]
	2330157294080 -> 2330157294176
	2330158233456 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	2330158233456 -> 2330157294080
	2330157294080 [label=AccumulateGrad]
	2330157293984 -> 2330157293840
	2330158233840 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2330158233840 -> 2330157293984
	2330157293984 [label=AccumulateGrad]
	2330157293792 -> 2330157293744
	2330158233936 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	2330158233936 -> 2330157293792
	2330157293792 [label=AccumulateGrad]
	2330157293648 -> 2330157293744
	2330158234032 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	2330158234032 -> 2330157293648
	2330157293648 [label=AccumulateGrad]
	2330157293552 -> 2330157293408
	2330161738192 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2330161738192 -> 2330157293552
	2330157293552 [label=AccumulateGrad]
	2330157293360 -> 2330157293264
	2330161738288 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	2330161738288 -> 2330157293360
	2330157293360 [label=AccumulateGrad]
	2330157293312 -> 2330157293264
	2330161738384 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	2330161738384 -> 2330157293312
	2330157293312 [label=AccumulateGrad]
	2330157293216 -> 2330157293168
	2330157292880 -> 2330157292640
	2330157292880 [label=TBackward0]
	2330157293120 -> 2330157292880
	2330168606448 [label="fc.weight
 (19, 2048)" fillcolor=lightblue]
	2330168606448 -> 2330157293120
	2330157293120 [label=AccumulateGrad]
	2330157292640 -> 2330162209776
}
