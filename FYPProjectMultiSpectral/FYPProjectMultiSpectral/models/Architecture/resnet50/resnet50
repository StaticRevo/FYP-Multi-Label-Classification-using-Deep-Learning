digraph {
	graph [size="151.95,151.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2293870442448 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2293781214496 [label=AddmmBackward0]
	2293781214160 -> 2293781214496
	2293773693392 [label="fc.bias
 (19)" fillcolor=lightblue]
	2293773693392 -> 2293781214160
	2293781214160 [label=AccumulateGrad]
	2293781213536 -> 2293781214496
	2293781213536 [label=ViewBackward0]
	2293781213056 -> 2293781213536
	2293781213056 [label=MeanBackward1]
	2293781212720 -> 2293781213056
	2293781212720 [label=ReluBackward0]
	2293781212240 -> 2293781212720
	2293781212240 [label=AddBackward0]
	2293781211760 -> 2293781212240
	2293781211760 [label=CudnnBatchNormBackward0]
	2293781210656 -> 2293781211760
	2293781210656 [label=ConvolutionBackward0]
	2293781209696 -> 2293781210656
	2293781209696 [label=ReluBackward0]
	2293781209360 -> 2293781209696
	2293781209360 [label=CudnnBatchNormBackward0]
	2293781208880 -> 2293781209360
	2293781208880 [label=ConvolutionBackward0]
	2293781205568 -> 2293781208880
	2293781205568 [label=ReluBackward0]
	2293781205328 -> 2293781205568
	2293781205328 [label=CudnnBatchNormBackward0]
	2293781217088 -> 2293781205328
	2293781217088 [label=ConvolutionBackward0]
	2293781211616 -> 2293781217088
	2293781211616 [label=ReluBackward0]
	2293781216800 -> 2293781211616
	2293781216800 [label=AddBackward0]
	2293781216704 -> 2293781216800
	2293781216704 [label=CudnnBatchNormBackward0]
	2293781216752 -> 2293781216704
	2293781216752 [label=ConvolutionBackward0]
	2293781216128 -> 2293781216752
	2293781216128 [label=ReluBackward0]
	2293781216176 -> 2293781216128
	2293781216176 [label=CudnnBatchNormBackward0]
	2293781216032 -> 2293781216176
	2293781216032 [label=ConvolutionBackward0]
	2293781215744 -> 2293781216032
	2293781215744 [label=ReluBackward0]
	2293781215792 -> 2293781215744
	2293781215792 [label=CudnnBatchNormBackward0]
	2293781215504 -> 2293781215792
	2293781215504 [label=ConvolutionBackward0]
	2293781216608 -> 2293781215504
	2293781216608 [label=ReluBackward0]
	2293781215312 -> 2293781216608
	2293781215312 [label=AddBackward0]
	2293781215024 -> 2293781215312
	2293781215024 [label=CudnnBatchNormBackward0]
	2293781214784 -> 2293781215024
	2293781214784 [label=ConvolutionBackward0]
	2293781214592 -> 2293781214784
	2293781214592 [label=ReluBackward0]
	2293781214208 -> 2293781214592
	2293781214208 [label=CudnnBatchNormBackward0]
	2293781214448 -> 2293781214208
	2293781214448 [label=ConvolutionBackward0]
	2293781214064 -> 2293781214448
	2293781214064 [label=ReluBackward0]
	2293781213824 -> 2293781214064
	2293781213824 [label=CudnnBatchNormBackward0]
	2293781213776 -> 2293781213824
	2293781213776 [label=ConvolutionBackward0]
	2293781213440 -> 2293781213776
	2293781213440 [label=ReluBackward0]
	2293781213488 -> 2293781213440
	2293781213488 [label=AddBackward0]
	2293781213392 -> 2293781213488
	2293781213392 [label=CudnnBatchNormBackward0]
	2293781212960 -> 2293781213392
	2293781212960 [label=ConvolutionBackward0]
	2293781212816 -> 2293781212960
	2293781212816 [label=ReluBackward0]
	2293781212624 -> 2293781212816
	2293781212624 [label=CudnnBatchNormBackward0]
	2293781212288 -> 2293781212624
	2293781212288 [label=ConvolutionBackward0]
	2293781212432 -> 2293781212288
	2293781212432 [label=ReluBackward0]
	2293781212000 -> 2293781212432
	2293781212000 [label=CudnnBatchNormBackward0]
	2293781211904 -> 2293781212000
	2293781211904 [label=ConvolutionBackward0]
	2293781213296 -> 2293781211904
	2293781213296 [label=ReluBackward0]
	2293781211520 -> 2293781213296
	2293781211520 [label=AddBackward0]
	2293781211424 -> 2293781211520
	2293781211424 [label=CudnnBatchNormBackward0]
	2293781211472 -> 2293781211424
	2293781211472 [label=ConvolutionBackward0]
	2293781210848 -> 2293781211472
	2293781210848 [label=ReluBackward0]
	2293781210896 -> 2293781210848
	2293781210896 [label=CudnnBatchNormBackward0]
	2293781210752 -> 2293781210896
	2293781210752 [label=ConvolutionBackward0]
	2293781210464 -> 2293781210752
	2293781210464 [label=ReluBackward0]
	2293781210512 -> 2293781210464
	2293781210512 [label=CudnnBatchNormBackward0]
	2293781210224 -> 2293781210512
	2293781210224 [label=ConvolutionBackward0]
	2293781211328 -> 2293781210224
	2293781211328 [label=ReluBackward0]
	2293781210032 -> 2293781211328
	2293781210032 [label=AddBackward0]
	2293781209744 -> 2293781210032
	2293781209744 [label=CudnnBatchNormBackward0]
	2293781209504 -> 2293781209744
	2293781209504 [label=ConvolutionBackward0]
	2293781209312 -> 2293781209504
	2293781209312 [label=ReluBackward0]
	2293781208928 -> 2293781209312
	2293781208928 [label=CudnnBatchNormBackward0]
	2293781209168 -> 2293781208928
	2293781209168 [label=ConvolutionBackward0]
	2293781208784 -> 2293781209168
	2293781208784 [label=ReluBackward0]
	2293781208544 -> 2293781208784
	2293781208544 [label=CudnnBatchNormBackward0]
	2293781208496 -> 2293781208544
	2293781208496 [label=ConvolutionBackward0]
	2293781209792 -> 2293781208496
	2293781209792 [label=ReluBackward0]
	2293781207200 -> 2293781209792
	2293781207200 [label=AddBackward0]
	2293781204608 -> 2293781207200
	2293781204608 [label=CudnnBatchNormBackward0]
	2293781208160 -> 2293781204608
	2293781208160 [label=ConvolutionBackward0]
	2293781202640 -> 2293781208160
	2293781202640 [label=ReluBackward0]
	2293781205088 -> 2293781202640
	2293781205088 [label=CudnnBatchNormBackward0]
	2293781204416 -> 2293781205088
	2293781204416 [label=ConvolutionBackward0]
	2293781205280 -> 2293781204416
	2293781205280 [label=ReluBackward0]
	2293781205760 -> 2293781205280
	2293781205760 [label=CudnnBatchNormBackward0]
	2293781204032 -> 2293781205760
	2293781204032 [label=ConvolutionBackward0]
	2293781208208 -> 2293781204032
	2293781208208 [label=ReluBackward0]
	2293781200960 -> 2293781208208
	2293781200960 [label=AddBackward0]
	2293781203216 -> 2293781200960
	2293781203216 [label=CudnnBatchNormBackward0]
	2293781204560 -> 2293781203216
	2293781204560 [label=ConvolutionBackward0]
	2293781201296 -> 2293781204560
	2293781201296 [label=ReluBackward0]
	2293781202928 -> 2293781201296
	2293781202928 [label=CudnnBatchNormBackward0]
	2293781203408 -> 2293781202928
	2293781203408 [label=ConvolutionBackward0]
	2293781207680 -> 2293781203408
	2293781207680 [label=ReluBackward0]
	2293781204128 -> 2293781207680
	2293781204128 [label=CudnnBatchNormBackward0]
	2293781203600 -> 2293781204128
	2293781203600 [label=ConvolutionBackward0]
	2293781204512 -> 2293781203600
	2293781204512 [label=ReluBackward0]
	2293781207872 -> 2293781204512
	2293781207872 [label=AddBackward0]
	2293781204800 -> 2293781207872
	2293781204800 [label=CudnnBatchNormBackward0]
	2293781204080 -> 2293781204800
	2293781204080 [label=ConvolutionBackward0]
	2293781204656 -> 2293781204080
	2293781204656 [label=ReluBackward0]
	2293781207248 -> 2293781204656
	2293781207248 [label=CudnnBatchNormBackward0]
	2293781202688 -> 2293781207248
	2293781202688 [label=ConvolutionBackward0]
	2293781202352 -> 2293781202688
	2293781202352 [label=ReluBackward0]
	2293781206240 -> 2293781202352
	2293781206240 [label=CudnnBatchNormBackward0]
	2293781201920 -> 2293781206240
	2293781201920 [label=ConvolutionBackward0]
	2293781206720 -> 2293781201920
	2293781206720 [label=ReluBackward0]
	2293781207296 -> 2293781206720
	2293781207296 [label=AddBackward0]
	2293781206672 -> 2293781207296
	2293781206672 [label=CudnnBatchNormBackward0]
	2293781205712 -> 2293781206672
	2293781205712 [label=ConvolutionBackward0]
	2293781205232 -> 2293781205712
	2293781205232 [label=ReluBackward0]
	2293781206096 -> 2293781205232
	2293781206096 [label=CudnnBatchNormBackward0]
	2293781205952 -> 2293781206096
	2293781205952 [label=ConvolutionBackward0]
	2293781201680 -> 2293781205952
	2293781201680 [label=ReluBackward0]
	2293781204464 -> 2293781201680
	2293781204464 [label=CudnnBatchNormBackward0]
	2293781207584 -> 2293781204464
	2293781207584 [label=ConvolutionBackward0]
	2293781207968 -> 2293781207584
	2293781207968 [label=ReluBackward0]
	2293781206336 -> 2293781207968
	2293781206336 [label=AddBackward0]
	2293781202400 -> 2293781206336
	2293781202400 [label=CudnnBatchNormBackward0]
	2293781206432 -> 2293781202400
	2293781206432 [label=ConvolutionBackward0]
	2293784226896 -> 2293781206432
	2293784226896 [label=ReluBackward0]
	2293773326112 -> 2293784226896
	2293773326112 [label=CudnnBatchNormBackward0]
	2293773325632 -> 2293773326112
	2293773325632 [label=ConvolutionBackward0]
	2293773324672 -> 2293773325632
	2293773324672 [label=ReluBackward0]
	2293773324336 -> 2293773324672
	2293773324336 [label=CudnnBatchNormBackward0]
	2293773323856 -> 2293773324336
	2293773323856 [label=ConvolutionBackward0]
	2293781204176 -> 2293773323856
	2293781204176 [label=ReluBackward0]
	2293773322416 -> 2293781204176
	2293773322416 [label=AddBackward0]
	2293773321936 -> 2293773322416
	2293773321936 [label=CudnnBatchNormBackward0]
	2293773320832 -> 2293773321936
	2293773320832 [label=ConvolutionBackward0]
	2293773327168 -> 2293773320832
	2293773327168 [label=ReluBackward0]
	2293773326784 -> 2293773327168
	2293773326784 [label=CudnnBatchNormBackward0]
	2293773327024 -> 2293773326784
	2293773327024 [label=ConvolutionBackward0]
	2293773326640 -> 2293773327024
	2293773326640 [label=ReluBackward0]
	2293773326400 -> 2293773326640
	2293773326400 [label=CudnnBatchNormBackward0]
	2293773326352 -> 2293773326400
	2293773326352 [label=ConvolutionBackward0]
	2293773321792 -> 2293773326352
	2293773321792 [label=ReluBackward0]
	2293773325920 -> 2293773321792
	2293773325920 [label=AddBackward0]
	2293773325872 -> 2293773325920
	2293773325872 [label=CudnnBatchNormBackward0]
	2293773325680 -> 2293773325872
	2293773325680 [label=ConvolutionBackward0]
	2293773325584 -> 2293773325680
	2293773325584 [label=ReluBackward0]
	2293773325248 -> 2293773325584
	2293773325248 [label=CudnnBatchNormBackward0]
	2293773325056 -> 2293773325248
	2293773325056 [label=ConvolutionBackward0]
	2293773324912 -> 2293773325056
	2293773324912 [label=ReluBackward0]
	2293773324720 -> 2293773324912
	2293773324720 [label=CudnnBatchNormBackward0]
	2293773324384 -> 2293773324720
	2293773324384 [label=ConvolutionBackward0]
	2293773324528 -> 2293773324384
	2293773324528 [label=ReluBackward0]
	2293773324096 -> 2293773324528
	2293773324096 [label=AddBackward0]
	2293773324000 -> 2293773324096
	2293773324000 [label=CudnnBatchNormBackward0]
	2293773324048 -> 2293773324000
	2293773324048 [label=ConvolutionBackward0]
	2293773323424 -> 2293773324048
	2293773323424 [label=ReluBackward0]
	2293773323472 -> 2293773323424
	2293773323472 [label=CudnnBatchNormBackward0]
	2293773323328 -> 2293773323472
	2293773323328 [label=ConvolutionBackward0]
	2293773323040 -> 2293773323328
	2293773323040 [label=ReluBackward0]
	2293773323088 -> 2293773323040
	2293773323088 [label=CudnnBatchNormBackward0]
	2293773322800 -> 2293773323088
	2293773322800 [label=ConvolutionBackward0]
	2293773323904 -> 2293773322800
	2293773323904 [label=ReluBackward0]
	2293773322608 -> 2293773323904
	2293773322608 [label=AddBackward0]
	2293773322320 -> 2293773322608
	2293773322320 [label=CudnnBatchNormBackward0]
	2293773322080 -> 2293773322320
	2293773322080 [label=ConvolutionBackward0]
	2293773321888 -> 2293773322080
	2293773321888 [label=ReluBackward0]
	2293773321504 -> 2293773321888
	2293773321504 [label=CudnnBatchNormBackward0]
	2293773321744 -> 2293773321504
	2293773321744 [label=ConvolutionBackward0]
	2293773321360 -> 2293773321744
	2293773321360 [label=ReluBackward0]
	2293773321120 -> 2293773321360
	2293773321120 [label=CudnnBatchNormBackward0]
	2293773321072 -> 2293773321120
	2293773321072 [label=ConvolutionBackward0]
	2293773322368 -> 2293773321072
	2293773322368 [label=ReluBackward0]
	2293773320640 -> 2293773322368
	2293773320640 [label=AddBackward0]
	2293773320592 -> 2293773320640
	2293773320592 [label=CudnnBatchNormBackward0]
	2293773320400 -> 2293773320592
	2293773320400 [label=ConvolutionBackward0]
	2293773327600 -> 2293773320400
	2293773327600 [label=ReluBackward0]
	2293773327936 -> 2293773327600
	2293773327936 [label=CudnnBatchNormBackward0]
	2293773328032 -> 2293773327936
	2293773328032 [label=ConvolutionBackward0]
	2293773328224 -> 2293773328032
	2293773328224 [label=ReluBackward0]
	2293773328368 -> 2293773328224
	2293773328368 [label=CudnnBatchNormBackward0]
	2293773328464 -> 2293773328368
	2293773328464 [label=ConvolutionBackward0]
	2293773328656 -> 2293773328464
	2293773328656 [label=MaxPool2DWithIndicesBackward0]
	2293773328800 -> 2293773328656
	2293773328800 [label=ReluBackward0]
	2293773328896 -> 2293773328800
	2293773328896 [label=CudnnBatchNormBackward0]
	2293773328992 -> 2293773328896
	2293773328992 [label=ConvolutionBackward0]
	2293773329184 -> 2293773328992
	2293773693200 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	2293773693200 -> 2293773329184
	2293773329184 [label=AccumulateGrad]
	2293773328944 -> 2293773328896
	2293780415600 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2293780415600 -> 2293773328944
	2293773328944 [label=AccumulateGrad]
	2293773328704 -> 2293773328896
	2293780415312 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2293780415312 -> 2293773328704
	2293773328704 [label=AccumulateGrad]
	2293773328608 -> 2293773328464
	2293780416176 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2293780416176 -> 2293773328608
	2293773328608 [label=AccumulateGrad]
	2293773328416 -> 2293773328368
	2293780415216 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2293780415216 -> 2293773328416
	2293773328416 [label=AccumulateGrad]
	2293773328272 -> 2293773328368
	2293780415120 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2293780415120 -> 2293773328272
	2293773328272 [label=AccumulateGrad]
	2293773328176 -> 2293773328032
	2293780414832 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2293780414832 -> 2293773328176
	2293773328176 [label=AccumulateGrad]
	2293773327984 -> 2293773327936
	2293780415024 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2293780415024 -> 2293773327984
	2293773327984 [label=AccumulateGrad]
	2293773327840 -> 2293773327936
	2293780414928 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2293780414928 -> 2293773327840
	2293773327840 [label=AccumulateGrad]
	2293773327744 -> 2293773320400
	2293781266160 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2293781266160 -> 2293773327744
	2293773327744 [label=AccumulateGrad]
	2293773320448 -> 2293773320592
	2293781266352 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	2293781266352 -> 2293773320448
	2293773320448 [label=AccumulateGrad]
	2293773320688 -> 2293773320592
	2293781265872 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	2293781265872 -> 2293773320688
	2293773320688 [label=AccumulateGrad]
	2293773320784 -> 2293773320640
	2293773320784 [label=CudnnBatchNormBackward0]
	2293773328128 -> 2293773320784
	2293773328128 [label=ConvolutionBackward0]
	2293773328656 -> 2293773328128
	2293773328512 -> 2293773328128
	2293780415696 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2293780415696 -> 2293773328512
	2293773328512 [label=AccumulateGrad]
	2293773320304 -> 2293773320784
	2293780415792 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2293780415792 -> 2293773320304
	2293773320304 [label=AccumulateGrad]
	2293773320256 -> 2293773320784
	2293780415888 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2293780415888 -> 2293773320256
	2293773320256 [label=AccumulateGrad]
	2293773320736 -> 2293773321072
	2293781264720 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2293781264720 -> 2293773320736
	2293773320736 [label=AccumulateGrad]
	2293773321264 -> 2293773321120
	2293781265584 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2293781265584 -> 2293773321264
	2293773321264 [label=AccumulateGrad]
	2293773321216 -> 2293773321120
	2293781265104 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2293781265104 -> 2293773321216
	2293773321216 [label=AccumulateGrad]
	2293773321408 -> 2293773321744
	2293781265392 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2293781265392 -> 2293773321408
	2293773321408 [label=AccumulateGrad]
	2293773321600 -> 2293773321504
	2293781265680 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2293781265680 -> 2293773321600
	2293773321600 [label=AccumulateGrad]
	2293773321840 -> 2293773321504
	2293781265488 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2293781265488 -> 2293773321840
	2293773321840 [label=AccumulateGrad]
	2293773322128 -> 2293773322080
	2293777500304 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2293777500304 -> 2293773322128
	2293773322128 [label=AccumulateGrad]
	2293773321984 -> 2293773322320
	2293777500400 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	2293777500400 -> 2293773321984
	2293773321984 [label=AccumulateGrad]
	2293773322176 -> 2293773322320
	2293777500496 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	2293777500496 -> 2293773322176
	2293773322176 [label=AccumulateGrad]
	2293773322368 -> 2293773322608
	2293773322704 -> 2293773322800
	2293777500880 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2293777500880 -> 2293773322704
	2293773322704 [label=AccumulateGrad]
	2293773322848 -> 2293773323088
	2293777500976 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	2293777500976 -> 2293773322848
	2293773322848 [label=AccumulateGrad]
	2293773323184 -> 2293773323088
	2293777501072 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	2293777501072 -> 2293773323184
	2293773323184 [label=AccumulateGrad]
	2293773322944 -> 2293773323328
	2293777501456 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2293777501456 -> 2293773322944
	2293773322944 [label=AccumulateGrad]
	2293773323568 -> 2293773323472
	2293777501552 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	2293777501552 -> 2293773323568
	2293773323568 [label=AccumulateGrad]
	2293773323520 -> 2293773323472
	2293777501648 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	2293777501648 -> 2293773323520
	2293773323520 [label=AccumulateGrad]
	2293773323616 -> 2293773324048
	2293777502032 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2293777502032 -> 2293773323616
	2293773323616 [label=AccumulateGrad]
	2293773323952 -> 2293773324000
	2293777502128 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	2293777502128 -> 2293773323952
	2293773323952 [label=AccumulateGrad]
	2293773324144 -> 2293773324000
	2293777502224 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	2293777502224 -> 2293773324144
	2293773324144 [label=AccumulateGrad]
	2293773323904 -> 2293773324096
	2293773324432 -> 2293773324384
	2293777503184 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2293777503184 -> 2293773324432
	2293773324432 [label=AccumulateGrad]
	2293773324576 -> 2293773324720
	2293777503280 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2293777503280 -> 2293773324576
	2293773324576 [label=AccumulateGrad]
	2293773325008 -> 2293773324720
	2293777503376 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2293777503376 -> 2293773325008
	2293773325008 [label=AccumulateGrad]
	2293773325104 -> 2293773325056
	2293777503760 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2293777503760 -> 2293773325104
	2293773325104 [label=AccumulateGrad]
	2293773325200 -> 2293773325248
	2293777503856 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2293777503856 -> 2293773325200
	2293773325200 [label=AccumulateGrad]
	2293773325392 -> 2293773325248
	2293777503952 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2293777503952 -> 2293773325392
	2293773325392 [label=AccumulateGrad]
	2293773325440 -> 2293773325680
	2293777504336 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2293777504336 -> 2293773325440
	2293773325440 [label=AccumulateGrad]
	2293773325728 -> 2293773325872
	2293777504432 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	2293777504432 -> 2293773325728
	2293773325728 [label=AccumulateGrad]
	2293773325968 -> 2293773325872
	2293777504528 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	2293777504528 -> 2293773325968
	2293773325968 [label=AccumulateGrad]
	2293773326064 -> 2293773325920
	2293773326064 [label=CudnnBatchNormBackward0]
	2293773324960 -> 2293773326064
	2293773324960 [label=ConvolutionBackward0]
	2293773324528 -> 2293773324960
	2293773324480 -> 2293773324960
	2293777502608 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2293777502608 -> 2293773324480
	2293773324480 [label=AccumulateGrad]
	2293773325344 -> 2293773326064
	2293777502704 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2293777502704 -> 2293773325344
	2293773325344 [label=AccumulateGrad]
	2293773325536 -> 2293773326064
	2293777502800 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2293777502800 -> 2293773325536
	2293773325536 [label=AccumulateGrad]
	2293773326016 -> 2293773326352
	2293777504912 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2293777504912 -> 2293773326016
	2293773326016 [label=AccumulateGrad]
	2293773326544 -> 2293773326400
	2293777505008 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2293777505008 -> 2293773326544
	2293773326544 [label=AccumulateGrad]
	2293773326496 -> 2293773326400
	2293777505104 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2293777505104 -> 2293773326496
	2293773326496 [label=AccumulateGrad]
	2293773326688 -> 2293773327024
	2293777505488 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2293777505488 -> 2293773326688
	2293773326688 [label=AccumulateGrad]
	2293773326880 -> 2293773326784
	2293777505584 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2293777505584 -> 2293773326880
	2293773326880 [label=AccumulateGrad]
	2293773327120 -> 2293773326784
	2293777505680 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2293777505680 -> 2293773327120
	2293773327120 [label=AccumulateGrad]
	2293773320496 -> 2293773320832
	2293777506064 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2293777506064 -> 2293773320496
	2293773320496 [label=AccumulateGrad]
	2293773321456 -> 2293773321936
	2293777506160 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	2293777506160 -> 2293773321456
	2293773321456 [label=AccumulateGrad]
	2293773321312 -> 2293773321936
	2293777506256 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	2293777506256 -> 2293773321312
	2293773321312 [label=AccumulateGrad]
	2293773321792 -> 2293773322416
	2293773322896 -> 2293773323856
	2293777506640 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2293777506640 -> 2293773322896
	2293773322896 [label=AccumulateGrad]
	2293773323712 -> 2293773324336
	2293777506736 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	2293777506736 -> 2293773323712
	2293773323712 [label=AccumulateGrad]
	2293773324816 -> 2293773324336
	2293777506832 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	2293777506832 -> 2293773324816
	2293773324816 [label=AccumulateGrad]
	2293773325296 -> 2293773325632
	2293777507216 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2293777507216 -> 2293773325296
	2293773325296 [label=AccumulateGrad]
	2293773326256 -> 2293773326112
	2293777507312 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	2293777507312 -> 2293773326256
	2293773326256 [label=AccumulateGrad]
	2293773326592 -> 2293773326112
	2293777507408 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	2293777507408 -> 2293773326592
	2293773326592 [label=AccumulateGrad]
	2293773327072 -> 2293781206432
	2293777507792 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2293777507792 -> 2293773327072
	2293773327072 [label=AccumulateGrad]
	2293781207536 -> 2293781202400
	2293777507888 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	2293777507888 -> 2293781207536
	2293781207536 [label=AccumulateGrad]
	2293781204368 -> 2293781202400
	2293777507984 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	2293777507984 -> 2293781204368
	2293781204368 [label=AccumulateGrad]
	2293781204176 -> 2293781206336
	2293781203168 -> 2293781207584
	2293777508368 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2293777508368 -> 2293781203168
	2293781203168 [label=AccumulateGrad]
	2293781206288 -> 2293781204464
	2293777508464 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	2293777508464 -> 2293781206288
	2293781206288 [label=AccumulateGrad]
	2293781205520 -> 2293781204464
	2293777508560 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	2293777508560 -> 2293781205520
	2293781205520 [label=AccumulateGrad]
	2293781203936 -> 2293781205952
	2293777508944 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2293777508944 -> 2293781203936
	2293781203936 [label=AccumulateGrad]
	2293781205664 -> 2293781206096
	2293777509040 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	2293777509040 -> 2293781205664
	2293781205664 [label=AccumulateGrad]
	2293781205472 -> 2293781206096
	2293777509136 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	2293777509136 -> 2293781205472
	2293781205472 [label=AccumulateGrad]
	2293781206960 -> 2293781205712
	2293777509520 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2293777509520 -> 2293781206960
	2293781206960 [label=AccumulateGrad]
	2293781206192 -> 2293781206672
	2293777509616 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	2293777509616 -> 2293781206192
	2293781206192 [label=AccumulateGrad]
	2293781204992 -> 2293781206672
	2293777509712 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	2293777509712 -> 2293781204992
	2293781204992 [label=AccumulateGrad]
	2293781207968 -> 2293781207296
	2293781205904 -> 2293781201920
	2293777510672 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2293777510672 -> 2293781205904
	2293781205904 [label=AccumulateGrad]
	2293781206912 -> 2293781206240
	2293777510768 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2293777510768 -> 2293781206912
	2293781206912 [label=AccumulateGrad]
	2293781201968 -> 2293781206240
	2293777510864 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2293777510864 -> 2293781201968
	2293781201968 [label=AccumulateGrad]
	2293781201008 -> 2293781202688
	2293777511248 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2293777511248 -> 2293781201008
	2293781201008 [label=AccumulateGrad]
	2293781206576 -> 2293781207248
	2293777511344 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2293777511344 -> 2293781206576
	2293781206576 [label=AccumulateGrad]
	2293781205424 -> 2293781207248
	2293777511440 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2293777511440 -> 2293781205424
	2293781205424 [label=AccumulateGrad]
	2293781205040 -> 2293781204080
	2293777511824 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2293777511824 -> 2293781205040
	2293781205040 [label=AccumulateGrad]
	2293781203840 -> 2293781204800
	2293777511920 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	2293777511920 -> 2293781203840
	2293781203840 [label=AccumulateGrad]
	2293781201392 -> 2293781204800
	2293777512016 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	2293777512016 -> 2293781201392
	2293781201392 [label=AccumulateGrad]
	2293781201824 -> 2293781207872
	2293781201824 [label=CudnnBatchNormBackward0]
	2293781203072 -> 2293781201824
	2293781203072 [label=ConvolutionBackward0]
	2293781206720 -> 2293781203072
	2293781203264 -> 2293781203072
	2293777510096 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2293777510096 -> 2293781203264
	2293781203264 [label=AccumulateGrad]
	2293781204704 -> 2293781201824
	2293777510192 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	2293777510192 -> 2293781204704
	2293781204704 [label=AccumulateGrad]
	2293781203984 -> 2293781201824
	2293777510288 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	2293777510288 -> 2293781203984
	2293781203984 [label=AccumulateGrad]
	2293781205856 -> 2293781203600
	2293777512400 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2293777512400 -> 2293781205856
	2293781205856 [label=AccumulateGrad]
	2293781204896 -> 2293781204128
	2293777512496 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2293777512496 -> 2293781204896
	2293781204896 [label=AccumulateGrad]
	2293781207008 -> 2293781204128
	2293777512592 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2293777512592 -> 2293781207008
	2293781207008 [label=AccumulateGrad]
	2293781202544 -> 2293781203408
	2293777512976 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2293777512976 -> 2293781202544
	2293781202544 [label=AccumulateGrad]
	2293781202016 -> 2293781202928
	2293777513072 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2293777513072 -> 2293781202016
	2293781202016 [label=AccumulateGrad]
	2293781201056 -> 2293781202928
	2293777513168 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2293777513168 -> 2293781201056
	2293781201056 [label=AccumulateGrad]
	2293781205136 -> 2293781204560
	2293777513552 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2293777513552 -> 2293781205136
	2293781205136 [label=AccumulateGrad]
	2293781202736 -> 2293781203216
	2293777513648 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	2293777513648 -> 2293781202736
	2293781202736 [label=AccumulateGrad]
	2293781201152 -> 2293781203216
	2293777513744 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	2293777513744 -> 2293781201152
	2293781201152 [label=AccumulateGrad]
	2293781204512 -> 2293781200960
	2293781205808 -> 2293781204032
	2293777514128 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2293777514128 -> 2293781205808
	2293781205808 [label=AccumulateGrad]
	2293781204320 -> 2293781205760
	2293777514224 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	2293777514224 -> 2293781204320
	2293781204320 [label=AccumulateGrad]
	2293781203696 -> 2293781205760
	2293777514320 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	2293777514320 -> 2293781203696
	2293781203696 [label=AccumulateGrad]
	2293781206048 -> 2293781204416
	2293773680912 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2293773680912 -> 2293781206048
	2293781206048 [label=AccumulateGrad]
	2293781203024 -> 2293781205088
	2293773681008 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	2293773681008 -> 2293781203024
	2293781203024 [label=AccumulateGrad]
	2293781207488 -> 2293781205088
	2293773681104 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	2293773681104 -> 2293781207488
	2293781207488 [label=AccumulateGrad]
	2293781203120 -> 2293781208160
	2293773681488 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2293773681488 -> 2293781203120
	2293781203120 [label=AccumulateGrad]
	2293781204224 -> 2293781204608
	2293773681584 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	2293773681584 -> 2293781204224
	2293781204224 [label=AccumulateGrad]
	2293781204752 -> 2293781204608
	2293773681680 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	2293773681680 -> 2293781204752
	2293781204752 [label=AccumulateGrad]
	2293781208208 -> 2293781207200
	2293781201488 -> 2293781208496
	2293773682064 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2293773682064 -> 2293781201488
	2293781201488 [label=AccumulateGrad]
	2293781208688 -> 2293781208544
	2293773682160 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	2293773682160 -> 2293781208688
	2293781208688 [label=AccumulateGrad]
	2293781208640 -> 2293781208544
	2293773682256 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	2293773682256 -> 2293781208640
	2293781208640 [label=AccumulateGrad]
	2293781208832 -> 2293781209168
	2293773682640 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2293773682640 -> 2293781208832
	2293781208832 [label=AccumulateGrad]
	2293781209024 -> 2293781208928
	2293773682736 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	2293773682736 -> 2293781209024
	2293781209024 [label=AccumulateGrad]
	2293781209264 -> 2293781208928
	2293773682832 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	2293773682832 -> 2293781209264
	2293781209264 [label=AccumulateGrad]
	2293781209552 -> 2293781209504
	2293773683216 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2293773683216 -> 2293781209552
	2293781209552 [label=AccumulateGrad]
	2293781209408 -> 2293781209744
	2293773683312 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	2293773683312 -> 2293781209408
	2293781209408 [label=AccumulateGrad]
	2293781209600 -> 2293781209744
	2293773683408 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	2293773683408 -> 2293781209600
	2293781209600 [label=AccumulateGrad]
	2293781209792 -> 2293781210032
	2293781210128 -> 2293781210224
	2293773683792 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2293773683792 -> 2293781210128
	2293781210128 [label=AccumulateGrad]
	2293781210272 -> 2293781210512
	2293773683888 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	2293773683888 -> 2293781210272
	2293781210272 [label=AccumulateGrad]
	2293781210608 -> 2293781210512
	2293773683984 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	2293773683984 -> 2293781210608
	2293781210608 [label=AccumulateGrad]
	2293781210368 -> 2293781210752
	2293773684368 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2293773684368 -> 2293781210368
	2293781210368 [label=AccumulateGrad]
	2293781210992 -> 2293781210896
	2293773684464 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	2293773684464 -> 2293781210992
	2293781210992 [label=AccumulateGrad]
	2293781210944 -> 2293781210896
	2293773684560 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	2293773684560 -> 2293781210944
	2293781210944 [label=AccumulateGrad]
	2293781211040 -> 2293781211472
	2293773684944 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2293773684944 -> 2293781211040
	2293781211040 [label=AccumulateGrad]
	2293781211376 -> 2293781211424
	2293773685040 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	2293773685040 -> 2293781211376
	2293781211376 [label=AccumulateGrad]
	2293781211568 -> 2293781211424
	2293773685136 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	2293773685136 -> 2293781211568
	2293781211568 [label=AccumulateGrad]
	2293781211328 -> 2293781211520
	2293781211712 -> 2293781211904
	2293773685520 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2293773685520 -> 2293781211712
	2293781211712 [label=AccumulateGrad]
	2293781211808 -> 2293781212000
	2293773685616 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	2293773685616 -> 2293781211808
	2293781211808 [label=AccumulateGrad]
	2293781212192 -> 2293781212000
	2293773685712 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	2293773685712 -> 2293781212192
	2293781212192 [label=AccumulateGrad]
	2293781212336 -> 2293781212288
	2293773686096 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2293773686096 -> 2293781212336
	2293781212336 [label=AccumulateGrad]
	2293781212480 -> 2293781212624
	2293773686192 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	2293773686192 -> 2293781212480
	2293781212480 [label=AccumulateGrad]
	2293781212912 -> 2293781212624
	2293773686288 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	2293773686288 -> 2293781212912
	2293781212912 [label=AccumulateGrad]
	2293781213008 -> 2293781212960
	2293773686672 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2293773686672 -> 2293781213008
	2293781213008 [label=AccumulateGrad]
	2293781213104 -> 2293781213392
	2293773686768 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	2293773686768 -> 2293781213104
	2293781213104 [label=AccumulateGrad]
	2293781213152 -> 2293781213392
	2293773686864 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	2293773686864 -> 2293781213152
	2293781213152 [label=AccumulateGrad]
	2293781213296 -> 2293781213488
	2293781213584 -> 2293781213776
	2293773687824 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2293773687824 -> 2293781213584
	2293781213584 [label=AccumulateGrad]
	2293781213968 -> 2293781213824
	2293773687920 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2293773687920 -> 2293781213968
	2293781213968 [label=AccumulateGrad]
	2293781213920 -> 2293781213824
	2293773688016 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2293773688016 -> 2293781213920
	2293781213920 [label=AccumulateGrad]
	2293781214112 -> 2293781214448
	2293773688400 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2293773688400 -> 2293781214112
	2293781214112 [label=AccumulateGrad]
	2293781214304 -> 2293781214208
	2293773688496 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2293773688496 -> 2293781214304
	2293781214304 [label=AccumulateGrad]
	2293781214544 -> 2293781214208
	2293773688592 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2293773688592 -> 2293781214544
	2293781214544 [label=AccumulateGrad]
	2293781214832 -> 2293781214784
	2293773688976 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2293773688976 -> 2293781214832
	2293781214832 [label=AccumulateGrad]
	2293781214688 -> 2293781215024
	2293773689072 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	2293773689072 -> 2293781214688
	2293781214688 [label=AccumulateGrad]
	2293781214880 -> 2293781215024
	2293773689168 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	2293773689168 -> 2293781214880
	2293781214880 [label=AccumulateGrad]
	2293781215072 -> 2293781215312
	2293781215072 [label=CudnnBatchNormBackward0]
	2293781214352 -> 2293781215072
	2293781214352 [label=ConvolutionBackward0]
	2293781213440 -> 2293781214352
	2293781213872 -> 2293781214352
	2293773687248 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	2293773687248 -> 2293781213872
	2293781213872 [label=AccumulateGrad]
	2293781214736 -> 2293781215072
	2293773687344 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	2293773687344 -> 2293781214736
	2293781214736 [label=AccumulateGrad]
	2293781214928 -> 2293781215072
	2293773687440 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	2293773687440 -> 2293781214928
	2293781214928 [label=AccumulateGrad]
	2293781215408 -> 2293781215504
	2293773689552 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2293773689552 -> 2293781215408
	2293781215408 [label=AccumulateGrad]
	2293781215552 -> 2293781215792
	2293773689648 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2293773689648 -> 2293781215552
	2293781215552 [label=AccumulateGrad]
	2293781215888 -> 2293781215792
	2293773689744 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2293773689744 -> 2293781215888
	2293781215888 [label=AccumulateGrad]
	2293781215648 -> 2293781216032
	2293773690128 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2293773690128 -> 2293781215648
	2293781215648 [label=AccumulateGrad]
	2293781216272 -> 2293781216176
	2293773690224 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2293773690224 -> 2293781216272
	2293781216272 [label=AccumulateGrad]
	2293781216224 -> 2293781216176
	2293773690320 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2293773690320 -> 2293781216224
	2293781216224 [label=AccumulateGrad]
	2293781216320 -> 2293781216752
	2293773690704 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2293773690704 -> 2293781216320
	2293781216320 [label=AccumulateGrad]
	2293781216656 -> 2293781216704
	2293773690800 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	2293773690800 -> 2293781216656
	2293781216656 [label=AccumulateGrad]
	2293781216848 -> 2293781216704
	2293773690896 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	2293773690896 -> 2293781216848
	2293781216848 [label=AccumulateGrad]
	2293781216608 -> 2293781216800
	2293781216992 -> 2293781217088
	2293773691280 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2293773691280 -> 2293781216992
	2293781216992 [label=AccumulateGrad]
	2293781207392 -> 2293781205328
	2293773691376 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	2293773691376 -> 2293781207392
	2293781207392 [label=AccumulateGrad]
	2293781207104 -> 2293781205328
	2293773691472 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	2293773691472 -> 2293781207104
	2293781207104 [label=AccumulateGrad]
	2293781201104 -> 2293781208880
	2293773691856 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2293773691856 -> 2293781201104
	2293781201104 [label=AccumulateGrad]
	2293781208736 -> 2293781209360
	2293773691952 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	2293773691952 -> 2293781208736
	2293781208736 [label=AccumulateGrad]
	2293781209840 -> 2293781209360
	2293773692048 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	2293773692048 -> 2293781209840
	2293781209840 [label=AccumulateGrad]
	2293781210320 -> 2293781210656
	2293773692432 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2293773692432 -> 2293781210320
	2293781210320 [label=AccumulateGrad]
	2293781211280 -> 2293781211760
	2293773692528 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	2293773692528 -> 2293781211280
	2293781211280 [label=AccumulateGrad]
	2293781211136 -> 2293781211760
	2293773692624 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	2293773692624 -> 2293781211136
	2293781211136 [label=AccumulateGrad]
	2293781211616 -> 2293781212240
	2293781213680 -> 2293781214496
	2293781213680 [label=TBackward0]
	2293781212096 -> 2293781213680
	2293773693296 [label="fc.weight
 (19, 2048)" fillcolor=lightblue]
	2293773693296 -> 2293781212096
	2293781212096 [label=AccumulateGrad]
	2293781214496 -> 2293870442448
}
