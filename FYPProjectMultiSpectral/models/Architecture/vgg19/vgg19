digraph {
	graph [size="37.65,37.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1656358745392 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1656466031712 [label=AddmmBackward0]
	1656466039344 -> 1656466031712
	1656358442896 [label="classifier.6.bias
 (19)" fillcolor=lightblue]
	1656358442896 -> 1656466039344
	1656466039344 [label=AccumulateGrad]
	1656466037424 -> 1656466031712
	1656466037424 [label=NativeDropoutBackward0]
	1656466033872 -> 1656466037424
	1656466033872 [label=ReluBackward0]
	1656466043520 -> 1656466033872
	1656466043520 [label=AddmmBackward0]
	1656466037856 -> 1656466043520
	1656356388496 [label="classifier.3.bias
 (4096)" fillcolor=lightblue]
	1656356388496 -> 1656466037856
	1656466037856 [label=AccumulateGrad]
	1656466041264 -> 1656466043520
	1656466041264 [label=NativeDropoutBackward0]
	1656466039968 -> 1656466041264
	1656466039968 [label=ReluBackward0]
	1656466037904 -> 1656466039968
	1656466037904 [label=AddmmBackward0]
	1656466045728 -> 1656466037904
	1656356388208 [label="classifier.0.bias
 (4096)" fillcolor=lightblue]
	1656356388208 -> 1656466045728
	1656466045728 [label=AccumulateGrad]
	1656466037520 -> 1656466037904
	1656466037520 [label=ViewBackward0]
	1656466032240 -> 1656466037520
	1656466032240 [label=AdaptiveAvgPool2DBackward0]
	1656466040160 -> 1656466032240
	1656466040160 [label=MaxPool2DWithIndicesBackward0]
	1656466032576 -> 1656466040160
	1656466032576 [label=ReluBackward0]
	1656466043712 -> 1656466032576
	1656466043712 [label=ConvolutionBackward0]
	1656466035648 -> 1656466043712
	1656466035648 [label=ReluBackward0]
	1656466041024 -> 1656466035648
	1656466041024 [label=ConvolutionBackward0]
	1656466044480 -> 1656466041024
	1656466044480 [label=ReluBackward0]
	1656466045056 -> 1656466044480
	1656466045056 [label=ConvolutionBackward0]
	1656466034832 -> 1656466045056
	1656466034832 [label=ReluBackward0]
	1656466045296 -> 1656466034832
	1656466045296 [label=ConvolutionBackward0]
	1656466033392 -> 1656466045296
	1656466033392 [label=MaxPool2DWithIndicesBackward0]
	1656466031184 -> 1656466033392
	1656466031184 [label=ReluBackward0]
	1656466033920 -> 1656466031184
	1656466033920 [label=ConvolutionBackward0]
	1656466046880 -> 1656466033920
	1656466046880 [label=ReluBackward0]
	1656466031952 -> 1656466046880
	1656466031952 [label=ConvolutionBackward0]
	1656466045008 -> 1656466031952
	1656466045008 [label=ReluBackward0]
	1656466035072 -> 1656466045008
	1656466035072 [label=ConvolutionBackward0]
	1656466043616 -> 1656466035072
	1656466043616 [label=ReluBackward0]
	1656466038816 -> 1656466043616
	1656466038816 [label=ConvolutionBackward0]
	1656466039008 -> 1656466038816
	1656466039008 [label=MaxPool2DWithIndicesBackward0]
	1656466031376 -> 1656466039008
	1656466031376 [label=ReluBackward0]
	1656466041744 -> 1656466031376
	1656466041744 [label=ConvolutionBackward0]
	1656466036608 -> 1656466041744
	1656466036608 [label=ReluBackward0]
	1656466033536 -> 1656466036608
	1656466033536 [label=ConvolutionBackward0]
	1656466037808 -> 1656466033536
	1656466037808 [label=ReluBackward0]
	1656466039584 -> 1656466037808
	1656466039584 [label=ConvolutionBackward0]
	1656466038336 -> 1656466039584
	1656466038336 [label=ReluBackward0]
	1656466046544 -> 1656466038336
	1656466046544 [label=ConvolutionBackward0]
	1656466042176 -> 1656466046544
	1656466042176 [label=MaxPool2DWithIndicesBackward0]
	1656466035936 -> 1656466042176
	1656466035936 [label=ReluBackward0]
	1656466032048 -> 1656466035936
	1656466032048 [label=ConvolutionBackward0]
	1656466039728 -> 1656466032048
	1656466039728 [label=ReluBackward0]
	1656466034112 -> 1656466039728
	1656466034112 [label=ConvolutionBackward0]
	1656466034496 -> 1656466034112
	1656466034496 [label=MaxPool2DWithIndicesBackward0]
	1656466046592 -> 1656466034496
	1656466046592 [label=ReluBackward0]
	1656466044624 -> 1656466046592
	1656466044624 [label=ConvolutionBackward0]
	1656466034208 -> 1656466044624
	1656466034208 [label=ReluBackward0]
	1656466040832 -> 1656466034208
	1656466040832 [label=ConvolutionBackward0]
	1656466041504 -> 1656466040832
	1656358442608 [label="features.0.weight
 (64, 12, 3, 3)" fillcolor=lightblue]
	1656358442608 -> 1656466041504
	1656466041504 [label=AccumulateGrad]
	1656466037328 -> 1656466040832
	1656358442704 [label="features.0.bias
 (64)" fillcolor=lightblue]
	1656358442704 -> 1656466037328
	1656466037328 [label=AccumulateGrad]
	1656466036752 -> 1656466044624
	1656335173104 [label="features.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1656335173104 -> 1656466036752
	1656466036752 [label=AccumulateGrad]
	1656466040208 -> 1656466044624
	1656335173200 [label="features.2.bias
 (64)" fillcolor=lightblue]
	1656335173200 -> 1656466040208
	1656466040208 [label=AccumulateGrad]
	1656466034736 -> 1656466034112
	1656335173296 [label="features.5.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1656335173296 -> 1656466034736
	1656466034736 [label=AccumulateGrad]
	1656466041312 -> 1656466034112
	1656335173488 [label="features.5.bias
 (128)" fillcolor=lightblue]
	1656335173488 -> 1656466041312
	1656466041312 [label=AccumulateGrad]
	1656466033968 -> 1656466032048
	1656335173584 [label="features.7.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1656335173584 -> 1656466033968
	1656466033968 [label=AccumulateGrad]
	1656466044336 -> 1656466032048
	1656335173680 [label="features.7.bias
 (128)" fillcolor=lightblue]
	1656335173680 -> 1656466044336
	1656466044336 [label=AccumulateGrad]
	1656466046112 -> 1656466046544
	1656335173776 [label="features.10.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1656335173776 -> 1656466046112
	1656466046112 [label=AccumulateGrad]
	1656466041168 -> 1656466046544
	1656335173872 [label="features.10.bias
 (256)" fillcolor=lightblue]
	1656335173872 -> 1656466041168
	1656466041168 [label=AccumulateGrad]
	1656466038912 -> 1656466039584
	1656335174064 [label="features.12.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1656335174064 -> 1656466038912
	1656466038912 [label=AccumulateGrad]
	1656466033152 -> 1656466039584
	1656335173968 [label="features.12.bias
 (256)" fillcolor=lightblue]
	1656335173968 -> 1656466033152
	1656466033152 [label=AccumulateGrad]
	1656466038720 -> 1656466033536
	1656335173008 [label="features.14.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1656335173008 -> 1656466038720
	1656466038720 [label=AccumulateGrad]
	1656466038576 -> 1656466033536
	1656335172912 [label="features.14.bias
 (256)" fillcolor=lightblue]
	1656335172912 -> 1656466038576
	1656466038576 [label=AccumulateGrad]
	1656466034976 -> 1656466041744
	1656335172144 [label="features.16.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1656335172144 -> 1656466034976
	1656466034976 [label=AccumulateGrad]
	1656466036320 -> 1656466041744
	1656335171856 [label="features.16.bias
 (256)" fillcolor=lightblue]
	1656335171856 -> 1656466036320
	1656466036320 [label=AccumulateGrad]
	1656466033344 -> 1656466038816
	1656335171952 [label="features.19.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1656335171952 -> 1656466033344
	1656466033344 [label=AccumulateGrad]
	1656466042368 -> 1656466038816
	1656335172048 [label="features.19.bias
 (512)" fillcolor=lightblue]
	1656335172048 -> 1656466042368
	1656466042368 [label=AccumulateGrad]
	1656466043760 -> 1656466035072
	1656335172240 [label="features.21.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1656335172240 -> 1656466043760
	1656466043760 [label=AccumulateGrad]
	1656466045920 -> 1656466035072
	1656335172336 [label="features.21.bias
 (512)" fillcolor=lightblue]
	1656335172336 -> 1656466045920
	1656466045920 [label=AccumulateGrad]
	1656466043808 -> 1656466031952
	1656335172432 [label="features.23.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1656335172432 -> 1656466043808
	1656466043808 [label=AccumulateGrad]
	1656466045392 -> 1656466031952
	1656335172528 [label="features.23.bias
 (512)" fillcolor=lightblue]
	1656335172528 -> 1656466045392
	1656466045392 [label=AccumulateGrad]
	1656466045152 -> 1656466033920
	1656335172624 [label="features.25.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1656335172624 -> 1656466045152
	1656466045152 [label=AccumulateGrad]
	1656466031328 -> 1656466033920
	1656335172816 [label="features.25.bias
 (512)" fillcolor=lightblue]
	1656335172816 -> 1656466031328
	1656466031328 [label=AccumulateGrad]
	1656466035984 -> 1656466045296
	1656335172720 [label="features.28.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1656335172720 -> 1656466035984
	1656466035984 [label=AccumulateGrad]
	1656466035120 -> 1656466045296
	1656335171760 [label="features.28.bias
 (512)" fillcolor=lightblue]
	1656335171760 -> 1656466035120
	1656466035120 [label=AccumulateGrad]
	1656466045248 -> 1656466045056
	1656335171664 [label="features.30.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1656335171664 -> 1656466045248
	1656466045248 [label=AccumulateGrad]
	1656466031568 -> 1656466045056
	1656356388112 [label="features.30.bias
 (512)" fillcolor=lightblue]
	1656356388112 -> 1656466031568
	1656466031568 [label=AccumulateGrad]
	1656466031136 -> 1656466041024
	1656356387728 [label="features.32.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1656356387728 -> 1656466031136
	1656466031136 [label=AccumulateGrad]
	1656466030944 -> 1656466041024
	1656356388592 [label="features.32.bias
 (512)" fillcolor=lightblue]
	1656356388592 -> 1656466030944
	1656466030944 [label=AccumulateGrad]
	1656466038240 -> 1656466043712
	1656356386192 [label="features.34.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1656356386192 -> 1656466038240
	1656466038240 [label=AccumulateGrad]
	1656466031280 -> 1656466043712
	1656356386384 [label="features.34.bias
 (512)" fillcolor=lightblue]
	1656356386384 -> 1656466031280
	1656466031280 [label=AccumulateGrad]
	1656466032480 -> 1656466037904
	1656466032480 [label=TBackward0]
	1656466039632 -> 1656466032480
	1656356388016 [label="classifier.0.weight
 (4096, 25088)" fillcolor=lightblue]
	1656356388016 -> 1656466039632
	1656466039632 [label=AccumulateGrad]
	1656466037568 -> 1656466043520
	1656466037568 [label=TBackward0]
	1656466040448 -> 1656466037568
	1656356388400 [label="classifier.3.weight
 (4096, 4096)" fillcolor=lightblue]
	1656356388400 -> 1656466040448
	1656466040448 [label=AccumulateGrad]
	1656466040592 -> 1656466031712
	1656466040592 [label=TBackward0]
	1656466035744 -> 1656466040592
	1656358442800 [label="classifier.6.weight
 (19, 4096)" fillcolor=lightblue]
	1656358442800 -> 1656466035744
	1656466035744 [label=AccumulateGrad]
	1656466031712 -> 1656358745392
}
