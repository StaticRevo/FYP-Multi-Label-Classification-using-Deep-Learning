digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2199150932624 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2199098620656 [label=AddmmBackward0]
	2199098620800 -> 2199098620656
	2199063314896 [label="fc.bias
 (19)" fillcolor=lightblue]
	2199063314896 -> 2199098620800
	2199098620800 [label=AccumulateGrad]
	2199098620848 -> 2199098620656
	2199098620848 [label=ViewBackward0]
	2199098620944 -> 2199098620848
	2199098620944 [label=MeanBackward1]
	2199098621088 -> 2199098620944
	2199098621088 [label=ReluBackward0]
	2199098621184 -> 2199098621088
	2199098621184 [label=AddBackward0]
	2199098621280 -> 2199098621184
	2199098621280 [label=CudnnBatchNormBackward0]
	2199098621424 -> 2199098621280
	2199098621424 [label=ConvolutionBackward0]
	2199098621616 -> 2199098621424
	2199098621616 [label=ReluBackward0]
	2199098621760 -> 2199098621616
	2199098621760 [label=CudnnBatchNormBackward0]
	2199098621856 -> 2199098621760
	2199098621856 [label=ConvolutionBackward0]
	2199098621232 -> 2199098621856
	2199098621232 [label=ReluBackward0]
	2199098619984 -> 2199098621232
	2199098619984 [label=AddBackward0]
	2199059874000 -> 2199098619984
	2199059874000 [label=CudnnBatchNormBackward0]
	2199059874144 -> 2199059874000
	2199059874144 [label=ConvolutionBackward0]
	2199059874336 -> 2199059874144
	2199059874336 [label=ReluBackward0]
	2199059874480 -> 2199059874336
	2199059874480 [label=CudnnBatchNormBackward0]
	2199059874576 -> 2199059874480
	2199059874576 [label=ConvolutionBackward0]
	2199059874768 -> 2199059874576
	2199059874768 [label=ReluBackward0]
	2199059874912 -> 2199059874768
	2199059874912 [label=AddBackward0]
	2199059875008 -> 2199059874912
	2199059875008 [label=CudnnBatchNormBackward0]
	2199059875152 -> 2199059875008
	2199059875152 [label=ConvolutionBackward0]
	2199059875344 -> 2199059875152
	2199059875344 [label=ReluBackward0]
	2199059875488 -> 2199059875344
	2199059875488 [label=CudnnBatchNormBackward0]
	2199059875584 -> 2199059875488
	2199059875584 [label=ConvolutionBackward0]
	2199059874960 -> 2199059875584
	2199059874960 [label=ReluBackward0]
	2199059875872 -> 2199059874960
	2199059875872 [label=AddBackward0]
	2199059875968 -> 2199059875872
	2199059875968 [label=CudnnBatchNormBackward0]
	2199059876112 -> 2199059875968
	2199059876112 [label=ConvolutionBackward0]
	2199059876304 -> 2199059876112
	2199059876304 [label=ReluBackward0]
	2199059876448 -> 2199059876304
	2199059876448 [label=CudnnBatchNormBackward0]
	2199059876544 -> 2199059876448
	2199059876544 [label=ConvolutionBackward0]
	2199059876736 -> 2199059876544
	2199059876736 [label=ReluBackward0]
	2199059876880 -> 2199059876736
	2199059876880 [label=AddBackward0]
	2199059876976 -> 2199059876880
	2199059876976 [label=CudnnBatchNormBackward0]
	2199059877120 -> 2199059876976
	2199059877120 [label=ConvolutionBackward0]
	2199059877312 -> 2199059877120
	2199059877312 [label=ReluBackward0]
	2199059877456 -> 2199059877312
	2199059877456 [label=CudnnBatchNormBackward0]
	2199059877552 -> 2199059877456
	2199059877552 [label=ConvolutionBackward0]
	2199059876928 -> 2199059877552
	2199059876928 [label=ReluBackward0]
	2199059877840 -> 2199059876928
	2199059877840 [label=AddBackward0]
	2199059877936 -> 2199059877840
	2199059877936 [label=CudnnBatchNormBackward0]
	2199059878080 -> 2199059877936
	2199059878080 [label=ConvolutionBackward0]
	2199059878272 -> 2199059878080
	2199059878272 [label=ReluBackward0]
	2199059878416 -> 2199059878272
	2199059878416 [label=CudnnBatchNormBackward0]
	2199059878512 -> 2199059878416
	2199059878512 [label=ConvolutionBackward0]
	2199059878704 -> 2199059878512
	2199059878704 [label=ReluBackward0]
	2199059878848 -> 2199059878704
	2199059878848 [label=AddBackward0]
	2199059878944 -> 2199059878848
	2199059878944 [label=CudnnBatchNormBackward0]
	2199059879088 -> 2199059878944
	2199059879088 [label=ConvolutionBackward0]
	2199059879280 -> 2199059879088
	2199059879280 [label=ReluBackward0]
	2199059879424 -> 2199059879280
	2199059879424 [label=CudnnBatchNormBackward0]
	2199059879520 -> 2199059879424
	2199059879520 [label=ConvolutionBackward0]
	2199059878896 -> 2199059879520
	2199059878896 [label=ReluBackward0]
	2199059879808 -> 2199059878896
	2199059879808 [label=AddBackward0]
	2199059879904 -> 2199059879808
	2199059879904 [label=CudnnBatchNormBackward0]
	2199059880048 -> 2199059879904
	2199059880048 [label=ConvolutionBackward0]
	2199059880240 -> 2199059880048
	2199059880240 [label=ReluBackward0]
	2199059880384 -> 2199059880240
	2199059880384 [label=CudnnBatchNormBackward0]
	2199059880480 -> 2199059880384
	2199059880480 [label=ConvolutionBackward0]
	2199059879856 -> 2199059880480
	2199059879856 [label=MaxPool2DWithIndicesBackward0]
	2199059880768 -> 2199059879856
	2199059880768 [label=ReluBackward0]
	2199059880864 -> 2199059880768
	2199059880864 [label=CudnnBatchNormBackward0]
	2199059880960 -> 2199059880864
	2199059880960 [label=ConvolutionBackward0]
	2199059881152 -> 2199059880960
	2199063314800 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	2199063314800 -> 2199059881152
	2199059881152 [label=AccumulateGrad]
	2199059880912 -> 2199059880864
	2199026848624 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2199026848624 -> 2199059880912
	2199059880912 [label=AccumulateGrad]
	2199059880576 -> 2199059880864
	2199026848720 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2199026848720 -> 2199059880576
	2199059880576 [label=AccumulateGrad]
	2199059880672 -> 2199059880480
	2199026849200 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2199026849200 -> 2199059880672
	2199059880672 [label=AccumulateGrad]
	2199059880432 -> 2199059880384
	2199026849296 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2199026849296 -> 2199059880432
	2199059880432 [label=AccumulateGrad]
	2199059880288 -> 2199059880384
	2199026849392 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2199026849392 -> 2199059880288
	2199059880288 [label=AccumulateGrad]
	2199059880192 -> 2199059880048
	2199026849776 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2199026849776 -> 2199059880192
	2199059880192 [label=AccumulateGrad]
	2199059880000 -> 2199059879904
	2199026849872 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2199026849872 -> 2199059880000
	2199059880000 [label=AccumulateGrad]
	2199059879952 -> 2199059879904
	2199026849968 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2199026849968 -> 2199059879952
	2199059879952 [label=AccumulateGrad]
	2199059879856 -> 2199059879808
	2199059879712 -> 2199059879520
	2199026850352 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2199026850352 -> 2199059879712
	2199059879712 [label=AccumulateGrad]
	2199059879472 -> 2199059879424
	2199026850448 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2199026850448 -> 2199059879472
	2199059879472 [label=AccumulateGrad]
	2199059879328 -> 2199059879424
	2199026850544 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2199026850544 -> 2199059879328
	2199059879328 [label=AccumulateGrad]
	2199059879232 -> 2199059879088
	2199026850928 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2199026850928 -> 2199059879232
	2199059879232 [label=AccumulateGrad]
	2199059879040 -> 2199059878944
	2199026851024 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2199026851024 -> 2199059879040
	2199059879040 [label=AccumulateGrad]
	2199059878992 -> 2199059878944
	2199026851120 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2199026851120 -> 2199059878992
	2199059878992 [label=AccumulateGrad]
	2199059878896 -> 2199059878848
	2199059878656 -> 2199059878512
	2199026852080 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2199026852080 -> 2199059878656
	2199059878656 [label=AccumulateGrad]
	2199059878464 -> 2199059878416
	2199026852176 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2199026852176 -> 2199059878464
	2199059878464 [label=AccumulateGrad]
	2199059878320 -> 2199059878416
	2199026852272 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2199026852272 -> 2199059878320
	2199059878320 [label=AccumulateGrad]
	2199059878224 -> 2199059878080
	2199026852656 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2199026852656 -> 2199059878224
	2199059878224 [label=AccumulateGrad]
	2199059878032 -> 2199059877936
	2199026852752 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2199026852752 -> 2199059878032
	2199059878032 [label=AccumulateGrad]
	2199059877984 -> 2199059877936
	2199026852848 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2199026852848 -> 2199059877984
	2199059877984 [label=AccumulateGrad]
	2199059877888 -> 2199059877840
	2199059877888 [label=CudnnBatchNormBackward0]
	2199059878608 -> 2199059877888
	2199059878608 [label=ConvolutionBackward0]
	2199059878704 -> 2199059878608
	2199059878752 -> 2199059878608
	2199026851504 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2199026851504 -> 2199059878752
	2199059878752 [label=AccumulateGrad]
	2199059878176 -> 2199059877888
	2199026851600 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2199026851600 -> 2199059878176
	2199059878176 [label=AccumulateGrad]
	2199059878128 -> 2199059877888
	2199026851696 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2199026851696 -> 2199059878128
	2199059878128 [label=AccumulateGrad]
	2199059877744 -> 2199059877552
	2199026853232 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2199026853232 -> 2199059877744
	2199059877744 [label=AccumulateGrad]
	2199059877504 -> 2199059877456
	2199026853328 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2199026853328 -> 2199059877504
	2199059877504 [label=AccumulateGrad]
	2199059877360 -> 2199059877456
	2199026853424 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2199026853424 -> 2199059877360
	2199059877360 [label=AccumulateGrad]
	2199059877264 -> 2199059877120
	2199026853808 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2199026853808 -> 2199059877264
	2199059877264 [label=AccumulateGrad]
	2199059877072 -> 2199059876976
	2199026853904 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2199026853904 -> 2199059877072
	2199059877072 [label=AccumulateGrad]
	2199059877024 -> 2199059876976
	2199026854000 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2199026854000 -> 2199059877024
	2199059877024 [label=AccumulateGrad]
	2199059876928 -> 2199059876880
	2199059876688 -> 2199059876544
	2199026854960 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2199026854960 -> 2199059876688
	2199059876688 [label=AccumulateGrad]
	2199059876496 -> 2199059876448
	2199026855056 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2199026855056 -> 2199059876496
	2199059876496 [label=AccumulateGrad]
	2199059876352 -> 2199059876448
	2199026855152 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2199026855152 -> 2199059876352
	2199059876352 [label=AccumulateGrad]
	2199059876256 -> 2199059876112
	2199026855536 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2199026855536 -> 2199059876256
	2199059876256 [label=AccumulateGrad]
	2199059876064 -> 2199059875968
	2199026855632 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2199026855632 -> 2199059876064
	2199059876064 [label=AccumulateGrad]
	2199059876016 -> 2199059875968
	2199026855728 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2199026855728 -> 2199059876016
	2199059876016 [label=AccumulateGrad]
	2199059875920 -> 2199059875872
	2199059875920 [label=CudnnBatchNormBackward0]
	2199059876640 -> 2199059875920
	2199059876640 [label=ConvolutionBackward0]
	2199059876736 -> 2199059876640
	2199059876784 -> 2199059876640
	2199026854384 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2199026854384 -> 2199059876784
	2199059876784 [label=AccumulateGrad]
	2199059876208 -> 2199059875920
	2199026854480 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2199026854480 -> 2199059876208
	2199059876208 [label=AccumulateGrad]
	2199059876160 -> 2199059875920
	2199026854576 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2199026854576 -> 2199059876160
	2199059876160 [label=AccumulateGrad]
	2199059875776 -> 2199059875584
	2199026856112 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2199026856112 -> 2199059875776
	2199059875776 [label=AccumulateGrad]
	2199059875536 -> 2199059875488
	2199026856208 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2199026856208 -> 2199059875536
	2199059875536 [label=AccumulateGrad]
	2199059875392 -> 2199059875488
	2199026856304 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2199026856304 -> 2199059875392
	2199059875392 [label=AccumulateGrad]
	2199059875296 -> 2199059875152
	2199026856688 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2199026856688 -> 2199059875296
	2199059875296 [label=AccumulateGrad]
	2199059875104 -> 2199059875008
	2199026856784 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2199026856784 -> 2199059875104
	2199059875104 [label=AccumulateGrad]
	2199059875056 -> 2199059875008
	2199026856880 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2199026856880 -> 2199059875056
	2199059875056 [label=AccumulateGrad]
	2199059874960 -> 2199059874912
	2199059874720 -> 2199059874576
	2199026857840 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2199026857840 -> 2199059874720
	2199059874720 [label=AccumulateGrad]
	2199059874528 -> 2199059874480
	2199026857936 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2199026857936 -> 2199059874528
	2199059874528 [label=AccumulateGrad]
	2199059874384 -> 2199059874480
	2199026858032 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2199026858032 -> 2199059874384
	2199059874384 [label=AccumulateGrad]
	2199059874288 -> 2199059874144
	2199026858416 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2199026858416 -> 2199059874288
	2199059874288 [label=AccumulateGrad]
	2199059874096 -> 2199059874000
	2199026858512 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2199026858512 -> 2199059874096
	2199059874096 [label=AccumulateGrad]
	2199059874048 -> 2199059874000
	2199026858608 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2199026858608 -> 2199059874048
	2199059874048 [label=AccumulateGrad]
	2199059873952 -> 2199098619984
	2199059873952 [label=CudnnBatchNormBackward0]
	2199059874672 -> 2199059873952
	2199059874672 [label=ConvolutionBackward0]
	2199059874768 -> 2199059874672
	2199059874816 -> 2199059874672
	2199026857264 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2199026857264 -> 2199059874816
	2199059874816 [label=AccumulateGrad]
	2199059874240 -> 2199059873952
	2199026857360 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2199026857360 -> 2199059874240
	2199059874240 [label=AccumulateGrad]
	2199059874192 -> 2199059873952
	2199026857456 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2199026857456 -> 2199059874192
	2199059874192 [label=AccumulateGrad]
	2199098620128 -> 2199098621856
	2199026858992 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2199026858992 -> 2199098620128
	2199098620128 [label=AccumulateGrad]
	2199098621808 -> 2199098621760
	2199026859088 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2199026859088 -> 2199098621808
	2199098621808 [label=AccumulateGrad]
	2199098621664 -> 2199098621760
	2199026859184 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2199026859184 -> 2199098621664
	2199098621664 [label=AccumulateGrad]
	2199098621568 -> 2199098621424
	2199026859568 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2199026859568 -> 2199098621568
	2199098621568 [label=AccumulateGrad]
	2199098621376 -> 2199098621280
	2199026859664 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2199026859664 -> 2199098621376
	2199098621376 [label=AccumulateGrad]
	2199098621328 -> 2199098621280
	2199026859760 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2199026859760 -> 2199098621328
	2199098621328 [label=AccumulateGrad]
	2199098621232 -> 2199098621184
	2199098620896 -> 2199098620656
	2199098620896 [label=TBackward0]
	2199098621136 -> 2199098620896
	2199063315184 [label="fc.weight
 (19, 512)" fillcolor=lightblue]
	2199063315184 -> 2199098621136
	2199098621136 [label=AccumulateGrad]
	2199098620656 -> 2199150932624
}
