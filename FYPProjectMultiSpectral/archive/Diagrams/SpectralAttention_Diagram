// SpectralAttention Module
digraph {
	graph [bgcolor="#f0f0f0" fontcolor="#333333" fontsize=18 label="SpectralAttention Module" labelloc=t nodesep=0.5 pad=0.5 rankdir=TB splines=true]
	node [fontcolor="#333333" fontname=Arial fontsize=12 shape=box style="filled,rounded"]
	edge [arrowsize=0.8 color="#555555"]
	SA_Input [label="Input
[B, C, H, W]" fillcolor="#e6ccff"]
	SA_Pool [label="GlobalAvgPool
[B, C]" fillcolor="#e6ccff"]
	SA_FC1 [label="Linear
C -> C//r
bias=True" fillcolor="#e6ccff"]
	SA_ReLU [label="ReLU
inplace=True" fillcolor="#e6ccff"]
	SA_FC2 [label="Linear
C//r -> C
bias=True" fillcolor="#e6ccff"]
	SA_Sigmoid [label="Sigmoid
Reshape [B, C, 1, 1]" fillcolor="#e6ccff"]
	SA_Skip_Dummy [label="" shape=point style=invisible width=0.01]
	SA_Add [label="+
Attention
[B, C, H, W]" fillcolor="#ffcccc" shape=circle width=0.5]
	SA_Input -> SA_Pool
	SA_Pool -> SA_FC1
	SA_FC1 -> SA_ReLU
	SA_ReLU -> SA_FC2
	SA_FC2 -> SA_Sigmoid
	SA_Sigmoid -> SA_Add
	SA_Input -> SA_Skip_Dummy [color="#ff3333" constraint=false penwidth=2 style=dashed]
	SA_Skip_Dummy -> SA_Add [label="Channel-wise Attention" color="#ff3333" penwidth=2 style=dashed]
}
