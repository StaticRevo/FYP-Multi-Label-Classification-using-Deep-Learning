digraph {
	graph [size="151.95,151.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2907144534640 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	2907143503056 [label=AddmmBackward0]
	2907143491680 -> 2907143503056
	2907144535792 [label="fc.bias
 (10)" fillcolor=lightblue]
	2907144535792 -> 2907143491680
	2907143491680 [label=AccumulateGrad]
	2907143503680 -> 2907143503056
	2907143503680 [label=ViewBackward0]
	2907143490432 -> 2907143503680
	2907143490432 [label=MeanBackward1]
	2907143497008 -> 2907143490432
	2907143497008 [label=ReluBackward0]
	2907143499504 -> 2907143497008
	2907143499504 [label=AddBackward0]
	2907143489520 -> 2907143499504
	2907143489520 [label=NativeBatchNormBackward0]
	2907143501664 -> 2907143489520
	2907143501664 [label=ConvolutionBackward0]
	2907143339600 -> 2907143501664
	2907143339600 [label=ReluBackward0]
	2907143338784 -> 2907143339600
	2907143338784 [label=NativeBatchNormBackward0]
	2907143338208 -> 2907143338784
	2907143338208 [label=ConvolutionBackward0]
	2907143585408 -> 2907143338208
	2907143585408 [label=ReluBackward0]
	2907143585312 -> 2907143585408
	2907143585312 [label=NativeBatchNormBackward0]
	2907137931488 -> 2907143585312
	2907137931488 [label=ConvolutionBackward0]
	2907143501280 -> 2907137931488
	2907143501280 [label=ReluBackward0]
	2907137927360 -> 2907143501280
	2907137927360 [label=AddBackward0]
	2907137923280 -> 2907137927360
	2907137923280 [label=NativeBatchNormBackward0]
	2907137927600 -> 2907137923280
	2907137927600 [label=ConvolutionBackward0]
	2907137931440 -> 2907137927600
	2907137931440 [label=ReluBackward0]
	2907137929040 -> 2907137931440
	2907137929040 [label=NativeBatchNormBackward0]
	2907137930480 -> 2907137929040
	2907137930480 [label=ConvolutionBackward0]
	2907137931824 -> 2907137930480
	2907137931824 [label=ReluBackward0]
	2907137923472 -> 2907137931824
	2907137923472 [label=NativeBatchNormBackward0]
	2907137931392 -> 2907137923472
	2907137931392 [label=ConvolutionBackward0]
	2907137927408 -> 2907137931392
	2907137927408 [label=ReluBackward0]
	2907137932400 -> 2907137927408
	2907137932400 [label=AddBackward0]
	2907137923424 -> 2907137932400
	2907137923424 [label=NativeBatchNormBackward0]
	2907144104992 -> 2907137923424
	2907144104992 [label=ConvolutionBackward0]
	2907144108784 -> 2907144104992
	2907144108784 [label=ReluBackward0]
	2907144105040 -> 2907144108784
	2907144105040 [label=NativeBatchNormBackward0]
	2907144108352 -> 2907144105040
	2907144108352 [label=ConvolutionBackward0]
	2907144107776 -> 2907144108352
	2907144107776 [label=ReluBackward0]
	2907144109744 -> 2907144107776
	2907144109744 [label=NativeBatchNormBackward0]
	2907137390384 -> 2907144109744
	2907137390384 [label=ConvolutionBackward0]
	2907143760016 -> 2907137390384
	2907143760016 [label=ReluBackward0]
	2907143759872 -> 2907143760016
	2907143759872 [label=AddBackward0]
	2907143759776 -> 2907143759872
	2907143759776 [label=NativeBatchNormBackward0]
	2907143759632 -> 2907143759776
	2907143759632 [label=ConvolutionBackward0]
	2907143759440 -> 2907143759632
	2907143759440 [label=ReluBackward0]
	2907143759296 -> 2907143759440
	2907143759296 [label=NativeBatchNormBackward0]
	2907143759200 -> 2907143759296
	2907143759200 [label=ConvolutionBackward0]
	2907143759008 -> 2907143759200
	2907143759008 [label=ReluBackward0]
	2907143758864 -> 2907143759008
	2907143758864 [label=NativeBatchNormBackward0]
	2907143758768 -> 2907143758864
	2907143758768 [label=ConvolutionBackward0]
	2907143759824 -> 2907143758768
	2907143759824 [label=ReluBackward0]
	2907143758480 -> 2907143759824
	2907143758480 [label=AddBackward0]
	2907143758384 -> 2907143758480
	2907143758384 [label=NativeBatchNormBackward0]
	2907143758240 -> 2907143758384
	2907143758240 [label=ConvolutionBackward0]
	2907143758048 -> 2907143758240
	2907143758048 [label=ReluBackward0]
	2907143757904 -> 2907143758048
	2907143757904 [label=NativeBatchNormBackward0]
	2907143757808 -> 2907143757904
	2907143757808 [label=ConvolutionBackward0]
	2907143757616 -> 2907143757808
	2907143757616 [label=ReluBackward0]
	2907143757472 -> 2907143757616
	2907143757472 [label=NativeBatchNormBackward0]
	2907143757376 -> 2907143757472
	2907143757376 [label=ConvolutionBackward0]
	2907143758432 -> 2907143757376
	2907143758432 [label=ReluBackward0]
	2907143757088 -> 2907143758432
	2907143757088 [label=AddBackward0]
	2907143756992 -> 2907143757088
	2907143756992 [label=NativeBatchNormBackward0]
	2907143756848 -> 2907143756992
	2907143756848 [label=ConvolutionBackward0]
	2907143756656 -> 2907143756848
	2907143756656 [label=ReluBackward0]
	2907143756512 -> 2907143756656
	2907143756512 [label=NativeBatchNormBackward0]
	2907143756416 -> 2907143756512
	2907143756416 [label=ConvolutionBackward0]
	2907143755600 -> 2907143756416
	2907143755600 [label=ReluBackward0]
	2907143754592 -> 2907143755600
	2907143754592 [label=NativeBatchNormBackward0]
	2907143755360 -> 2907143754592
	2907143755360 [label=ConvolutionBackward0]
	2907143757040 -> 2907143755360
	2907143757040 [label=ReluBackward0]
	2907143754016 -> 2907143757040
	2907143754016 [label=AddBackward0]
	2907143753200 -> 2907143754016
	2907143753200 [label=NativeBatchNormBackward0]
	2907143752816 -> 2907143753200
	2907143752816 [label=ConvolutionBackward0]
	2907143752576 -> 2907143752816
	2907143752576 [label=ReluBackward0]
	2907143751808 -> 2907143752576
	2907143751808 [label=NativeBatchNormBackward0]
	2907143750944 -> 2907143751808
	2907143750944 [label=ConvolutionBackward0]
	2907143750368 -> 2907143750944
	2907143750368 [label=ReluBackward0]
	2907143749984 -> 2907143750368
	2907143749984 [label=NativeBatchNormBackward0]
	2907143750272 -> 2907143749984
	2907143750272 [label=ConvolutionBackward0]
	2907143753584 -> 2907143750272
	2907143753584 [label=ReluBackward0]
	2907143760736 -> 2907143753584
	2907143760736 [label=AddBackward0]
	2907143760496 -> 2907143760736
	2907143760496 [label=NativeBatchNormBackward0]
	2907143760304 -> 2907143760496
	2907143760304 [label=ConvolutionBackward0]
	2907143760832 -> 2907143760304
	2907143760832 [label=ReluBackward0]
	2907143760976 -> 2907143760832
	2907143760976 [label=NativeBatchNormBackward0]
	2907143761072 -> 2907143760976
	2907143761072 [label=ConvolutionBackward0]
	2907143761264 -> 2907143761072
	2907143761264 [label=ReluBackward0]
	2907143761408 -> 2907143761264
	2907143761408 [label=NativeBatchNormBackward0]
	2907143761504 -> 2907143761408
	2907143761504 [label=ConvolutionBackward0]
	2907143760448 -> 2907143761504
	2907143760448 [label=ReluBackward0]
	2907143761792 -> 2907143760448
	2907143761792 [label=AddBackward0]
	2907143761888 -> 2907143761792
	2907143761888 [label=NativeBatchNormBackward0]
	2907143762032 -> 2907143761888
	2907143762032 [label=ConvolutionBackward0]
	2907143762224 -> 2907143762032
	2907143762224 [label=ReluBackward0]
	2907143762368 -> 2907143762224
	2907143762368 [label=NativeBatchNormBackward0]
	2907143762464 -> 2907143762368
	2907143762464 [label=ConvolutionBackward0]
	2907143762656 -> 2907143762464
	2907143762656 [label=ReluBackward0]
	2907143762800 -> 2907143762656
	2907143762800 [label=NativeBatchNormBackward0]
	2907143762896 -> 2907143762800
	2907143762896 [label=ConvolutionBackward0]
	2907143763088 -> 2907143762896
	2907143763088 [label=ReluBackward0]
	2907143763232 -> 2907143763088
	2907143763232 [label=AddBackward0]
	2907143763328 -> 2907143763232
	2907143763328 [label=NativeBatchNormBackward0]
	2907143763472 -> 2907143763328
	2907143763472 [label=ConvolutionBackward0]
	2907143763664 -> 2907143763472
	2907143763664 [label=ReluBackward0]
	2907143763808 -> 2907143763664
	2907143763808 [label=NativeBatchNormBackward0]
	2907143763904 -> 2907143763808
	2907143763904 [label=ConvolutionBackward0]
	2907143764096 -> 2907143763904
	2907143764096 [label=ReluBackward0]
	2907143764240 -> 2907143764096
	2907143764240 [label=NativeBatchNormBackward0]
	2907143764336 -> 2907143764240
	2907143764336 [label=ConvolutionBackward0]
	2907143763280 -> 2907143764336
	2907143763280 [label=ReluBackward0]
	2907143764624 -> 2907143763280
	2907143764624 [label=AddBackward0]
	2907143764720 -> 2907143764624
	2907143764720 [label=NativeBatchNormBackward0]
	2907143764864 -> 2907143764720
	2907143764864 [label=ConvolutionBackward0]
	2907143765056 -> 2907143764864
	2907143765056 [label=ReluBackward0]
	2907143765200 -> 2907143765056
	2907143765200 [label=NativeBatchNormBackward0]
	2907143765296 -> 2907143765200
	2907143765296 [label=ConvolutionBackward0]
	2907143765488 -> 2907143765296
	2907143765488 [label=ReluBackward0]
	2907143765632 -> 2907143765488
	2907143765632 [label=NativeBatchNormBackward0]
	2907143765728 -> 2907143765632
	2907143765728 [label=ConvolutionBackward0]
	2907143764672 -> 2907143765728
	2907143764672 [label=ReluBackward0]
	2907143765968 -> 2907143764672
	2907143765968 [label=AddBackward0]
	2907144372384 -> 2907143765968
	2907144372384 [label=NativeBatchNormBackward0]
	2907144372528 -> 2907144372384
	2907144372528 [label=ConvolutionBackward0]
	2907144372720 -> 2907144372528
	2907144372720 [label=ReluBackward0]
	2907144372864 -> 2907144372720
	2907144372864 [label=NativeBatchNormBackward0]
	2907144372960 -> 2907144372864
	2907144372960 [label=ConvolutionBackward0]
	2907144373152 -> 2907144372960
	2907144373152 [label=ReluBackward0]
	2907144373296 -> 2907144373152
	2907144373296 [label=NativeBatchNormBackward0]
	2907144373392 -> 2907144373296
	2907144373392 [label=ConvolutionBackward0]
	2907144372336 -> 2907144373392
	2907144372336 [label=ReluBackward0]
	2907144373680 -> 2907144372336
	2907144373680 [label=AddBackward0]
	2907144373776 -> 2907144373680
	2907144373776 [label=NativeBatchNormBackward0]
	2907144373920 -> 2907144373776
	2907144373920 [label=ConvolutionBackward0]
	2907144374112 -> 2907144373920
	2907144374112 [label=ReluBackward0]
	2907144374256 -> 2907144374112
	2907144374256 [label=NativeBatchNormBackward0]
	2907144374352 -> 2907144374256
	2907144374352 [label=ConvolutionBackward0]
	2907144374544 -> 2907144374352
	2907144374544 [label=ReluBackward0]
	2907144374688 -> 2907144374544
	2907144374688 [label=NativeBatchNormBackward0]
	2907144374784 -> 2907144374688
	2907144374784 [label=ConvolutionBackward0]
	2907144374976 -> 2907144374784
	2907144374976 [label=ReluBackward0]
	2907144375120 -> 2907144374976
	2907144375120 [label=AddBackward0]
	2907144375216 -> 2907144375120
	2907144375216 [label=NativeBatchNormBackward0]
	2907144375360 -> 2907144375216
	2907144375360 [label=ConvolutionBackward0]
	2907144375552 -> 2907144375360
	2907144375552 [label=ReluBackward0]
	2907144375696 -> 2907144375552
	2907144375696 [label=NativeBatchNormBackward0]
	2907144375792 -> 2907144375696
	2907144375792 [label=ConvolutionBackward0]
	2907144375984 -> 2907144375792
	2907144375984 [label=ReluBackward0]
	2907144376128 -> 2907144375984
	2907144376128 [label=NativeBatchNormBackward0]
	2907144376224 -> 2907144376128
	2907144376224 [label=ConvolutionBackward0]
	2907144375168 -> 2907144376224
	2907144375168 [label=ReluBackward0]
	2907144376512 -> 2907144375168
	2907144376512 [label=AddBackward0]
	2907144376608 -> 2907144376512
	2907144376608 [label=NativeBatchNormBackward0]
	2907144376752 -> 2907144376608
	2907144376752 [label=ConvolutionBackward0]
	2907144376944 -> 2907144376752
	2907144376944 [label=ReluBackward0]
	2907144377088 -> 2907144376944
	2907144377088 [label=NativeBatchNormBackward0]
	2907144377184 -> 2907144377088
	2907144377184 [label=ConvolutionBackward0]
	2907144377376 -> 2907144377184
	2907144377376 [label=ReluBackward0]
	2907144377520 -> 2907144377376
	2907144377520 [label=NativeBatchNormBackward0]
	2907144377616 -> 2907144377520
	2907144377616 [label=ConvolutionBackward0]
	2907144376560 -> 2907144377616
	2907144376560 [label=ReluBackward0]
	2907144377904 -> 2907144376560
	2907144377904 [label=AddBackward0]
	2907144378000 -> 2907144377904
	2907144378000 [label=NativeBatchNormBackward0]
	2907144378144 -> 2907144378000
	2907144378144 [label=ConvolutionBackward0]
	2907144378336 -> 2907144378144
	2907144378336 [label=ReluBackward0]
	2907144378480 -> 2907144378336
	2907144378480 [label=NativeBatchNormBackward0]
	2907144378576 -> 2907144378480
	2907144378576 [label=ConvolutionBackward0]
	2907144378768 -> 2907144378576
	2907144378768 [label=ReluBackward0]
	2907144378912 -> 2907144378768
	2907144378912 [label=NativeBatchNormBackward0]
	2907144379008 -> 2907144378912
	2907144379008 [label=ConvolutionBackward0]
	2907144379200 -> 2907144379008
	2907144379200 [label=MaxPool2DWithIndicesBackward0]
	2907144379344 -> 2907144379200
	2907144379344 [label=ReluBackward0]
	2907144379440 -> 2907144379344
	2907144379440 [label=NativeBatchNormBackward0]
	2907144379536 -> 2907144379440
	2907144379536 [label=ConvolutionBackward0]
	2907144379728 -> 2907144379536
	2907143824656 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2907143824656 -> 2907144379728
	2907144379728 [label=AccumulateGrad]
	2907144379488 -> 2907144379440
	2907143824752 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2907143824752 -> 2907144379488
	2907144379488 [label=AccumulateGrad]
	2907144379248 -> 2907144379440
	2907143824272 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2907143824272 -> 2907144379248
	2907144379248 [label=AccumulateGrad]
	2907144379152 -> 2907144379008
	2907143825808 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2907143825808 -> 2907144379152
	2907144379152 [label=AccumulateGrad]
	2907144378960 -> 2907144378912
	2907143825904 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2907143825904 -> 2907144378960
	2907144378960 [label=AccumulateGrad]
	2907144378816 -> 2907144378912
	2907143826000 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2907143826000 -> 2907144378816
	2907144378816 [label=AccumulateGrad]
	2907144378720 -> 2907144378576
	2907143826384 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2907143826384 -> 2907144378720
	2907144378720 [label=AccumulateGrad]
	2907144378528 -> 2907144378480
	2907143826480 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2907143826480 -> 2907144378528
	2907144378528 [label=AccumulateGrad]
	2907144378384 -> 2907144378480
	2907143826576 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2907143826576 -> 2907144378384
	2907144378384 [label=AccumulateGrad]
	2907144378288 -> 2907144378144
	2907143826864 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2907143826864 -> 2907144378288
	2907144378288 [label=AccumulateGrad]
	2907144378096 -> 2907144378000
	2907143827056 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	2907143827056 -> 2907144378096
	2907144378096 [label=AccumulateGrad]
	2907144378048 -> 2907144378000
	2907143827248 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	2907143827248 -> 2907144378048
	2907144378048 [label=AccumulateGrad]
	2907144377952 -> 2907144377904
	2907144377952 [label=NativeBatchNormBackward0]
	2907144378672 -> 2907144377952
	2907144378672 [label=ConvolutionBackward0]
	2907144379200 -> 2907144378672
	2907144379056 -> 2907144378672
	2907143824080 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2907143824080 -> 2907144379056
	2907144379056 [label=AccumulateGrad]
	2907144378240 -> 2907144377952
	2907143824560 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2907143824560 -> 2907144378240
	2907144378240 [label=AccumulateGrad]
	2907144378192 -> 2907144377952
	2907143824848 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2907143824848 -> 2907144378192
	2907144378192 [label=AccumulateGrad]
	2907144377808 -> 2907144377616
	2907143827536 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2907143827536 -> 2907144377808
	2907144377808 [label=AccumulateGrad]
	2907144377568 -> 2907144377520
	2907143827632 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2907143827632 -> 2907144377568
	2907144377568 [label=AccumulateGrad]
	2907144377424 -> 2907144377520
	2907143827728 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2907143827728 -> 2907144377424
	2907144377424 [label=AccumulateGrad]
	2907144377328 -> 2907144377184
	2907143828112 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2907143828112 -> 2907144377328
	2907144377328 [label=AccumulateGrad]
	2907144377136 -> 2907144377088
	2907143828208 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2907143828208 -> 2907144377136
	2907144377136 [label=AccumulateGrad]
	2907144376992 -> 2907144377088
	2907143828304 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2907143828304 -> 2907144376992
	2907144376992 [label=AccumulateGrad]
	2907144376896 -> 2907144376752
	2907143828688 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2907143828688 -> 2907144376896
	2907144376896 [label=AccumulateGrad]
	2907144376704 -> 2907144376608
	2907143828784 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	2907143828784 -> 2907144376704
	2907144376704 [label=AccumulateGrad]
	2907144376656 -> 2907144376608
	2907143828880 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	2907143828880 -> 2907144376656
	2907144376656 [label=AccumulateGrad]
	2907144376560 -> 2907144376512
	2907144376416 -> 2907144376224
	2907143829264 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2907143829264 -> 2907144376416
	2907144376416 [label=AccumulateGrad]
	2907144376176 -> 2907144376128
	2907143829360 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	2907143829360 -> 2907144376176
	2907144376176 [label=AccumulateGrad]
	2907144376032 -> 2907144376128
	2907143829456 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	2907143829456 -> 2907144376032
	2907144376032 [label=AccumulateGrad]
	2907144375936 -> 2907144375792
	2907143829840 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2907143829840 -> 2907144375936
	2907144375936 [label=AccumulateGrad]
	2907144375744 -> 2907144375696
	2907143829936 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	2907143829936 -> 2907144375744
	2907144375744 [label=AccumulateGrad]
	2907144375600 -> 2907144375696
	2907143830032 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	2907143830032 -> 2907144375600
	2907144375600 [label=AccumulateGrad]
	2907144375504 -> 2907144375360
	2907143830416 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2907143830416 -> 2907144375504
	2907144375504 [label=AccumulateGrad]
	2907144375312 -> 2907144375216
	2907143830512 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	2907143830512 -> 2907144375312
	2907144375312 [label=AccumulateGrad]
	2907144375264 -> 2907144375216
	2907143830608 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	2907143830608 -> 2907144375264
	2907144375264 [label=AccumulateGrad]
	2907144375168 -> 2907144375120
	2907144374928 -> 2907144374784
	2907143766096 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2907143766096 -> 2907144374928
	2907144374928 [label=AccumulateGrad]
	2907144374736 -> 2907144374688
	2907143766192 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2907143766192 -> 2907144374736
	2907144374736 [label=AccumulateGrad]
	2907144374592 -> 2907144374688
	2907143766288 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2907143766288 -> 2907144374592
	2907144374592 [label=AccumulateGrad]
	2907144374496 -> 2907144374352
	2907143766672 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2907143766672 -> 2907144374496
	2907144374496 [label=AccumulateGrad]
	2907144374304 -> 2907144374256
	2907143766768 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2907143766768 -> 2907144374304
	2907144374304 [label=AccumulateGrad]
	2907144374160 -> 2907144374256
	2907143766864 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2907143766864 -> 2907144374160
	2907144374160 [label=AccumulateGrad]
	2907144374064 -> 2907144373920
	2907143767248 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2907143767248 -> 2907144374064
	2907144374064 [label=AccumulateGrad]
	2907144373872 -> 2907144373776
	2907143767344 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	2907143767344 -> 2907144373872
	2907144373872 [label=AccumulateGrad]
	2907144373824 -> 2907144373776
	2907143767440 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	2907143767440 -> 2907144373824
	2907144373824 [label=AccumulateGrad]
	2907144373728 -> 2907144373680
	2907144373728 [label=NativeBatchNormBackward0]
	2907144374448 -> 2907144373728
	2907144374448 [label=ConvolutionBackward0]
	2907144374976 -> 2907144374448
	2907144374832 -> 2907144374448
	2907143830992 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2907143830992 -> 2907144374832
	2907144374832 [label=AccumulateGrad]
	2907144374016 -> 2907144373728
	2907143831088 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2907143831088 -> 2907144374016
	2907144374016 [label=AccumulateGrad]
	2907144373968 -> 2907144373728
	2907143831184 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2907143831184 -> 2907144373968
	2907144373968 [label=AccumulateGrad]
	2907144373584 -> 2907144373392
	2907143767824 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2907143767824 -> 2907144373584
	2907144373584 [label=AccumulateGrad]
	2907144373344 -> 2907144373296
	2907143767920 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2907143767920 -> 2907144373344
	2907144373344 [label=AccumulateGrad]
	2907144373200 -> 2907144373296
	2907143768016 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2907143768016 -> 2907144373200
	2907144373200 [label=AccumulateGrad]
	2907144373104 -> 2907144372960
	2907143768400 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2907143768400 -> 2907144373104
	2907144373104 [label=AccumulateGrad]
	2907144372912 -> 2907144372864
	2907143768496 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2907143768496 -> 2907144372912
	2907144372912 [label=AccumulateGrad]
	2907144372768 -> 2907144372864
	2907143768592 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2907143768592 -> 2907144372768
	2907144372768 [label=AccumulateGrad]
	2907144372672 -> 2907144372528
	2907143768976 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2907143768976 -> 2907144372672
	2907144372672 [label=AccumulateGrad]
	2907144372480 -> 2907144372384
	2907143769072 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	2907143769072 -> 2907144372480
	2907144372480 [label=AccumulateGrad]
	2907144372432 -> 2907144372384
	2907143769168 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	2907143769168 -> 2907144372432
	2907144372432 [label=AccumulateGrad]
	2907144372336 -> 2907143765968
	2907143765920 -> 2907143765728
	2907143769552 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2907143769552 -> 2907143765920
	2907143765920 [label=AccumulateGrad]
	2907143765680 -> 2907143765632
	2907143769648 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	2907143769648 -> 2907143765680
	2907143765680 [label=AccumulateGrad]
	2907143765536 -> 2907143765632
	2907143769744 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	2907143769744 -> 2907143765536
	2907143765536 [label=AccumulateGrad]
	2907143765440 -> 2907143765296
	2907143770128 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2907143770128 -> 2907143765440
	2907143765440 [label=AccumulateGrad]
	2907143765248 -> 2907143765200
	2907143770224 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	2907143770224 -> 2907143765248
	2907143765248 [label=AccumulateGrad]
	2907143765104 -> 2907143765200
	2907143770320 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	2907143770320 -> 2907143765104
	2907143765104 [label=AccumulateGrad]
	2907143765008 -> 2907143764864
	2907143770704 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2907143770704 -> 2907143765008
	2907143765008 [label=AccumulateGrad]
	2907143764816 -> 2907143764720
	2907143770800 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	2907143770800 -> 2907143764816
	2907143764816 [label=AccumulateGrad]
	2907143764768 -> 2907143764720
	2907143770896 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	2907143770896 -> 2907143764768
	2907143764768 [label=AccumulateGrad]
	2907143764672 -> 2907143764624
	2907143764528 -> 2907143764336
	2907143771280 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2907143771280 -> 2907143764528
	2907143764528 [label=AccumulateGrad]
	2907143764288 -> 2907143764240
	2907143771376 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	2907143771376 -> 2907143764288
	2907143764288 [label=AccumulateGrad]
	2907143764144 -> 2907143764240
	2907143771472 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	2907143771472 -> 2907143764144
	2907143764144 [label=AccumulateGrad]
	2907143764048 -> 2907143763904
	2907143771856 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2907143771856 -> 2907143764048
	2907143764048 [label=AccumulateGrad]
	2907143763856 -> 2907143763808
	2907143771952 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	2907143771952 -> 2907143763856
	2907143763856 [label=AccumulateGrad]
	2907143763712 -> 2907143763808
	2907143772048 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	2907143772048 -> 2907143763712
	2907143763712 [label=AccumulateGrad]
	2907143763616 -> 2907143763472
	2907143772432 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2907143772432 -> 2907143763616
	2907143763616 [label=AccumulateGrad]
	2907143763424 -> 2907143763328
	2907143772528 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	2907143772528 -> 2907143763424
	2907143763424 [label=AccumulateGrad]
	2907143763376 -> 2907143763328
	2907143772624 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	2907143772624 -> 2907143763376
	2907143763376 [label=AccumulateGrad]
	2907143763280 -> 2907143763232
	2907143763040 -> 2907143762896
	2907143773584 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2907143773584 -> 2907143763040
	2907143763040 [label=AccumulateGrad]
	2907143762848 -> 2907143762800
	2907143773680 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2907143773680 -> 2907143762848
	2907143762848 [label=AccumulateGrad]
	2907143762704 -> 2907143762800
	2907143773776 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2907143773776 -> 2907143762704
	2907143762704 [label=AccumulateGrad]
	2907143762608 -> 2907143762464
	2907143774160 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2907143774160 -> 2907143762608
	2907143762608 [label=AccumulateGrad]
	2907143762416 -> 2907143762368
	2907143774256 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2907143774256 -> 2907143762416
	2907143762416 [label=AccumulateGrad]
	2907143762272 -> 2907143762368
	2907143774352 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2907143774352 -> 2907143762272
	2907143762272 [label=AccumulateGrad]
	2907143762176 -> 2907143762032
	2907143774736 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2907143774736 -> 2907143762176
	2907143762176 [label=AccumulateGrad]
	2907143761984 -> 2907143761888
	2907143774832 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	2907143774832 -> 2907143761984
	2907143761984 [label=AccumulateGrad]
	2907143761936 -> 2907143761888
	2907143774928 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	2907143774928 -> 2907143761936
	2907143761936 [label=AccumulateGrad]
	2907143761840 -> 2907143761792
	2907143761840 [label=NativeBatchNormBackward0]
	2907143762560 -> 2907143761840
	2907143762560 [label=ConvolutionBackward0]
	2907143763088 -> 2907143762560
	2907143762944 -> 2907143762560
	2907143773008 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2907143773008 -> 2907143762944
	2907143762944 [label=AccumulateGrad]
	2907143762128 -> 2907143761840
	2907143773104 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	2907143773104 -> 2907143762128
	2907143762128 [label=AccumulateGrad]
	2907143762080 -> 2907143761840
	2907143773200 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	2907143773200 -> 2907143762080
	2907143762080 [label=AccumulateGrad]
	2907143761696 -> 2907143761504
	2907143775312 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2907143775312 -> 2907143761696
	2907143761696 [label=AccumulateGrad]
	2907143761456 -> 2907143761408
	2907143775408 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2907143775408 -> 2907143761456
	2907143761456 [label=AccumulateGrad]
	2907143761312 -> 2907143761408
	2907143775504 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2907143775504 -> 2907143761312
	2907143761312 [label=AccumulateGrad]
	2907143761216 -> 2907143761072
	2907143775888 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2907143775888 -> 2907143761216
	2907143761216 [label=AccumulateGrad]
	2907143761024 -> 2907143760976
	2907143775984 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2907143775984 -> 2907143761024
	2907143761024 [label=AccumulateGrad]
	2907143760880 -> 2907143760976
	2907143776080 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2907143776080 -> 2907143760880
	2907143760880 [label=AccumulateGrad]
	2907143760784 -> 2907143760304
	2907143776464 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2907143776464 -> 2907143760784
	2907143760784 [label=AccumulateGrad]
	2907143760256 -> 2907143760496
	2907143776560 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	2907143776560 -> 2907143760256
	2907143760256 [label=AccumulateGrad]
	2907143760544 -> 2907143760496
	2907143776656 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	2907143776656 -> 2907143760544
	2907143760544 [label=AccumulateGrad]
	2907143760448 -> 2907143760736
	2907143760640 -> 2907143750272
	2907143777040 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2907143777040 -> 2907143760640
	2907143760640 [label=AccumulateGrad]
	2907143750176 -> 2907143749984
	2907143777136 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	2907143777136 -> 2907143750176
	2907143750176 [label=AccumulateGrad]
	2907143750224 -> 2907143749984
	2907143777232 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	2907143777232 -> 2907143750224
	2907143750224 [label=AccumulateGrad]
	2907143751616 -> 2907143750944
	2907143777616 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2907143777616 -> 2907143751616
	2907143751616 [label=AccumulateGrad]
	2907143751760 -> 2907143751808
	2907143777712 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	2907143777712 -> 2907143751760
	2907143751760 [label=AccumulateGrad]
	2907143752624 -> 2907143751808
	2907143777808 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	2907143777808 -> 2907143752624
	2907143752624 [label=AccumulateGrad]
	2907143752384 -> 2907143752816
	2907143778192 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2907143778192 -> 2907143752384
	2907143752384 [label=AccumulateGrad]
	2907143753536 -> 2907143753200
	2907143778288 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	2907143778288 -> 2907143753536
	2907143753536 [label=AccumulateGrad]
	2907143753056 -> 2907143753200
	2907143778384 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	2907143778384 -> 2907143753056
	2907143753056 [label=AccumulateGrad]
	2907143753584 -> 2907143754016
	2907143753776 -> 2907143755360
	2907143778768 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2907143778768 -> 2907143753776
	2907143753776 [label=AccumulateGrad]
	2907143754448 -> 2907143754592
	2907143778864 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	2907143778864 -> 2907143754448
	2907143754448 [label=AccumulateGrad]
	2907143756320 -> 2907143754592
	2907143778960 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	2907143778960 -> 2907143756320
	2907143756320 [label=AccumulateGrad]
	2907143755168 -> 2907143756416
	2907143779344 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2907143779344 -> 2907143755168
	2907143755168 [label=AccumulateGrad]
	2907143756560 -> 2907143756512
	2907143779440 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	2907143779440 -> 2907143756560
	2907143756560 [label=AccumulateGrad]
	2907143756608 -> 2907143756512
	2907143779536 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	2907143779536 -> 2907143756608
	2907143756608 [label=AccumulateGrad]
	2907143756704 -> 2907143756848
	2907143779920 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2907143779920 -> 2907143756704
	2907143756704 [label=AccumulateGrad]
	2907143756896 -> 2907143756992
	2907143780016 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	2907143780016 -> 2907143756896
	2907143756896 [label=AccumulateGrad]
	2907143756944 -> 2907143756992
	2907143780112 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	2907143780112 -> 2907143756944
	2907143756944 [label=AccumulateGrad]
	2907143757040 -> 2907143757088
	2907143757184 -> 2907143757376
	2907143780496 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2907143780496 -> 2907143757184
	2907143757184 [label=AccumulateGrad]
	2907143757424 -> 2907143757472
	2907143780592 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	2907143780592 -> 2907143757424
	2907143757424 [label=AccumulateGrad]
	2907143757568 -> 2907143757472
	2907143780688 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	2907143780688 -> 2907143757568
	2907143757568 [label=AccumulateGrad]
	2907143757664 -> 2907143757808
	2907143781072 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2907143781072 -> 2907143757664
	2907143757664 [label=AccumulateGrad]
	2907143757856 -> 2907143757904
	2907143781168 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	2907143781168 -> 2907143757856
	2907143757856 [label=AccumulateGrad]
	2907143758000 -> 2907143757904
	2907143781264 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	2907143781264 -> 2907143758000
	2907143758000 [label=AccumulateGrad]
	2907143758096 -> 2907143758240
	2907143781648 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2907143781648 -> 2907143758096
	2907143758096 [label=AccumulateGrad]
	2907143758288 -> 2907143758384
	2907143781744 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	2907143781744 -> 2907143758288
	2907143758288 [label=AccumulateGrad]
	2907143758336 -> 2907143758384
	2907143781840 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	2907143781840 -> 2907143758336
	2907143758336 [label=AccumulateGrad]
	2907143758432 -> 2907143758480
	2907143758576 -> 2907143758768
	2907143782224 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2907143782224 -> 2907143758576
	2907143758576 [label=AccumulateGrad]
	2907143758816 -> 2907143758864
	2907143782320 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	2907143782320 -> 2907143758816
	2907143758816 [label=AccumulateGrad]
	2907143758960 -> 2907143758864
	2907144519760 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	2907144519760 -> 2907143758960
	2907143758960 [label=AccumulateGrad]
	2907143759056 -> 2907143759200
	2907144520144 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2907144520144 -> 2907143759056
	2907143759056 [label=AccumulateGrad]
	2907143759248 -> 2907143759296
	2907144520240 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	2907144520240 -> 2907143759248
	2907143759248 [label=AccumulateGrad]
	2907143759392 -> 2907143759296
	2907144520336 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	2907144520336 -> 2907143759392
	2907143759392 [label=AccumulateGrad]
	2907143759488 -> 2907143759632
	2907144520720 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2907144520720 -> 2907143759488
	2907143759488 [label=AccumulateGrad]
	2907143759680 -> 2907143759776
	2907144520816 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	2907144520816 -> 2907143759680
	2907143759680 [label=AccumulateGrad]
	2907143759728 -> 2907143759776
	2907144520912 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	2907144520912 -> 2907143759728
	2907143759728 [label=AccumulateGrad]
	2907143759824 -> 2907143759872
	2907143760064 -> 2907137390384
	2907144521872 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2907144521872 -> 2907143760064
	2907143760064 [label=AccumulateGrad]
	2907144107872 -> 2907144109744
	2907144521968 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2907144521968 -> 2907144107872
	2907144107872 [label=AccumulateGrad]
	2907143760208 -> 2907144109744
	2907144522064 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2907144522064 -> 2907143760208
	2907143760208 [label=AccumulateGrad]
	2907144107584 -> 2907144108352
	2907144522448 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2907144522448 -> 2907144107584
	2907144107584 [label=AccumulateGrad]
	2907144109264 -> 2907144105040
	2907144522544 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2907144522544 -> 2907144109264
	2907144109264 [label=AccumulateGrad]
	2907144109696 -> 2907144105040
	2907144522640 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2907144522640 -> 2907144109696
	2907144109696 [label=AccumulateGrad]
	2907144107968 -> 2907144104992
	2907144523024 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2907144523024 -> 2907144107968
	2907144107968 [label=AccumulateGrad]
	2907144104944 -> 2907137923424
	2907144523120 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	2907144523120 -> 2907144104944
	2907144104944 [label=AccumulateGrad]
	2907144104752 -> 2907137923424
	2907144523216 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	2907144523216 -> 2907144104752
	2907144104752 [label=AccumulateGrad]
	2907137923328 -> 2907137932400
	2907137923328 [label=NativeBatchNormBackward0]
	2907144107824 -> 2907137923328
	2907144107824 [label=ConvolutionBackward0]
	2907143760016 -> 2907144107824
	2907144109360 -> 2907144107824
	2907144521296 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	2907144521296 -> 2907144109360
	2907144109360 [label=AccumulateGrad]
	2907144104320 -> 2907137923328
	2907144521392 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	2907144521392 -> 2907144104320
	2907144104320 [label=AccumulateGrad]
	2907144109168 -> 2907137923328
	2907144521488 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	2907144521488 -> 2907144109168
	2907144109168 [label=AccumulateGrad]
	2907137932448 -> 2907137931392
	2907144523600 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2907144523600 -> 2907137932448
	2907137932448 [label=AccumulateGrad]
	2907137929136 -> 2907137923472
	2907144523696 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2907144523696 -> 2907137929136
	2907137929136 [label=AccumulateGrad]
	2907137923664 -> 2907137923472
	2907144523792 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2907144523792 -> 2907137923664
	2907137923664 [label=AccumulateGrad]
	2907137928752 -> 2907137930480
	2907144524176 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2907144524176 -> 2907137928752
	2907137928752 [label=AccumulateGrad]
	2907137931248 -> 2907137929040
	2907144524272 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2907144524272 -> 2907137931248
	2907137931248 [label=AccumulateGrad]
	2907137923952 -> 2907137929040
	2907144524368 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2907144524368 -> 2907137923952
	2907137923952 [label=AccumulateGrad]
	2907137929184 -> 2907137927600
	2907144524752 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2907144524752 -> 2907137929184
	2907137929184 [label=AccumulateGrad]
	2907137927456 -> 2907137923280
	2907144524848 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	2907144524848 -> 2907137927456
	2907137927456 [label=AccumulateGrad]
	2907137924144 -> 2907137923280
	2907144524944 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	2907144524944 -> 2907137924144
	2907137924144 [label=AccumulateGrad]
	2907137927408 -> 2907137927360
	2907137932832 -> 2907137931488
	2907144525328 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2907144525328 -> 2907137932832
	2907137932832 [label=AccumulateGrad]
	2907137933024 -> 2907143585312
	2907144525424 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	2907144525424 -> 2907137933024
	2907137933024 [label=AccumulateGrad]
	2907137923856 -> 2907143585312
	2907144525520 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	2907144525520 -> 2907137923856
	2907137923856 [label=AccumulateGrad]
	2907143582000 -> 2907143338208
	2907144525904 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2907144525904 -> 2907143582000
	2907143582000 [label=AccumulateGrad]
	2907143331776 -> 2907143338784
	2907144526000 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	2907144526000 -> 2907143331776
	2907143331776 [label=AccumulateGrad]
	2907143336816 -> 2907143338784
	2907144526096 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	2907144526096 -> 2907143336816
	2907143336816 [label=AccumulateGrad]
	2907143337632 -> 2907143501664
	2907144526480 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2907144526480 -> 2907143337632
	2907143337632 [label=AccumulateGrad]
	2907143489472 -> 2907143489520
	2907144526576 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	2907144526576 -> 2907143489472
	2907143489472 [label=AccumulateGrad]
	2907143490672 -> 2907143489520
	2907144526672 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	2907144526672 -> 2907143490672
	2907143490672 [label=AccumulateGrad]
	2907143501280 -> 2907143499504
	2907143492352 -> 2907143503056
	2907143492352 [label=TBackward0]
	2907143502864 -> 2907143492352
	2907144535984 [label="fc.weight
 (10, 2048)" fillcolor=lightblue]
	2907144535984 -> 2907143502864
	2907143502864 [label=AccumulateGrad]
	2907143503056 -> 2907144534640
}
