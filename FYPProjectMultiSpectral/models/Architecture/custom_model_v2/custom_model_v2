digraph {
	graph [size="101.39999999999999,101.39999999999999"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1563143565776 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1563146892768 [label=AddmmBackward0]
	1563146892432 -> 1563146892768
	1563147730480 [label="29.bias
 (19)" fillcolor=lightblue]
	1563147730480 -> 1563146892432
	1563146892432 [label=AccumulateGrad]
	1563146891808 -> 1563146892768
	1563146891808 [label=NativeDropoutBackward0]
	1563146891328 -> 1563146891808
	1563146891328 [label=ViewBackward0]
	1563146890992 -> 1563146891328
	1563146890992 [label=MeanBackward1]
	1563146890512 -> 1563146890992
	1563146890512 [label=MulBackward0]
	1563146890032 -> 1563146890512
	1563146890032 [label=AddBackward0]
	1563146888928 -> 1563146890032
	1563146888928 [label=ReluBackward0]
	1563146888592 -> 1563146888928
	1563146888592 [label=AddBackward0]
	1563146888112 -> 1563146888592
	1563146888112 [label=CudnnBatchNormBackward0]
	1563146887008 -> 1563146888112
	1563146887008 [label=ConvolutionBackward0]
	1563146886048 -> 1563146887008
	1563146886048 [label=ReluBackward0]
	1563146885712 -> 1563146886048
	1563146885712 [label=CudnnBatchNormBackward0]
	1563146885232 -> 1563146885712
	1563146885232 [label=ConvolutionBackward0]
	1563146887968 -> 1563146885232
	1563146887968 [label=ReluBackward0]
	1563146883792 -> 1563146887968
	1563146883792 [label=CudnnBatchNormBackward0]
	1563146883312 -> 1563146883792
	1563146883312 [label=AddBackward0]
	1563146882352 -> 1563146883312
	1563146882352 [label=CudnnBatchNormBackward0]
	1563146881248 -> 1563146882352
	1563146881248 [label=ConvolutionBackward0]
	1563146880288 -> 1563146881248
	1563146880288 [label=MulBackward0]
	1563146879952 -> 1563146880288
	1563146879952 [label=ReluBackward0]
	1563146895264 -> 1563146879952
	1563146895264 [label=AddBackward0]
	1563146894496 -> 1563146895264
	1563146894496 [label=CudnnBatchNormBackward0]
	1563146894544 -> 1563146894496
	1563146894544 [label=ConvolutionBackward0]
	1563146893920 -> 1563146894544
	1563146893920 [label=ReluBackward0]
	1563146893968 -> 1563146893920
	1563146893968 [label=CudnnBatchNormBackward0]
	1563146893824 -> 1563146893968
	1563146893824 [label=ConvolutionBackward0]
	1563146894400 -> 1563146893824
	1563146894400 [label=AddBackward0]
	1563146893488 -> 1563146894400
	1563146893488 [label=ReluBackward0]
	1563146893296 -> 1563146893488
	1563146893296 [label=CudnnBatchNormBackward0]
	1563146892960 -> 1563146893296
	1563146892960 [label=AddBackward0]
	1563146893104 -> 1563146892960
	1563146893104 [label=CudnnBatchNormBackward0]
	1563146892672 -> 1563146893104
	1563146892672 [label=ConvolutionBackward0]
	1563146892528 -> 1563146892672
	1563146892528 [label=MulBackward0]
	1563146892336 -> 1563146892528
	1563146892336 [label=ReluBackward0]
	1563146892096 -> 1563146892336
	1563146892096 [label=AddBackward0]
	1563146892048 -> 1563146892096
	1563146892048 [label=CudnnBatchNormBackward0]
	1563146891856 -> 1563146892048
	1563146891856 [label=ConvolutionBackward0]
	1563146891760 -> 1563146891856
	1563146891760 [label=ReluBackward0]
	1563146891424 -> 1563146891760
	1563146891424 [label=CudnnBatchNormBackward0]
	1563146891232 -> 1563146891424
	1563146891232 [label=ConvolutionBackward0]
	1563146892240 -> 1563146891232
	1563146892240 [label=AddBackward0]
	1563146890944 -> 1563146892240
	1563146890944 [label=ReluBackward0]
	1563146890560 -> 1563146890944
	1563146890560 [label=CudnnBatchNormBackward0]
	1563146890800 -> 1563146890560
	1563146890800 [label=AddBackward0]
	1563146890416 -> 1563146890800
	1563146890416 [label=CudnnBatchNormBackward0]
	1563146890176 -> 1563146890416
	1563146890176 [label=ConvolutionBackward0]
	1563146889984 -> 1563146890176
	1563146889984 [label=MulBackward0]
	1563146889600 -> 1563146889984
	1563146889600 [label=MulBackward0]
	1563146889648 -> 1563146889600
	1563146889648 [label=AddBackward0]
	1563146889456 -> 1563146889648
	1563146889456 [label=ReluBackward0]
	1563146889216 -> 1563146889456
	1563146889216 [label=AddBackward0]
	1563146889168 -> 1563146889216
	1563146889168 [label=CudnnBatchNormBackward0]
	1563146888976 -> 1563146889168
	1563146888976 [label=ConvolutionBackward0]
	1563146888880 -> 1563146888976
	1563146888880 [label=ReluBackward0]
	1563146888544 -> 1563146888880
	1563146888544 [label=CudnnBatchNormBackward0]
	1563146888352 -> 1563146888544
	1563146888352 [label=ConvolutionBackward0]
	1563146889360 -> 1563146888352
	1563146889360 [label=ReluBackward0]
	1563146888064 -> 1563146889360
	1563146888064 [label=CudnnBatchNormBackward0]
	1563146887872 -> 1563146888064
	1563146887872 [label=AddBackward0]
	1563146887728 -> 1563146887872
	1563146887728 [label=CudnnBatchNormBackward0]
	1563146887536 -> 1563146887728
	1563146887536 [label=ConvolutionBackward0]
	1563146887440 -> 1563146887536
	1563146887440 [label=ReluBackward0]
	1563146887104 -> 1563146887440
	1563146887104 [label=CudnnBatchNormBackward0]
	1563146886912 -> 1563146887104
	1563146886912 [label=ConvolutionBackward0]
	1563146886768 -> 1563146886912
	1563171673904 [label="0.weight
 (16, 12, 1, 1)" fillcolor=lightblue]
	1563171673904 -> 1563146886768
	1563146886768 [label=AccumulateGrad]
	1563146887056 -> 1563146887104
	1563171673136 [label="1.weight
 (16)" fillcolor=lightblue]
	1563171673136 -> 1563146887056
	1563146887056 [label=AccumulateGrad]
	1563146887248 -> 1563146887104
	1563171672848 [label="1.bias
 (16)" fillcolor=lightblue]
	1563171672848 -> 1563146887248
	1563146887248 [label=AccumulateGrad]
	1563146887296 -> 1563146887536
	1563171673328 [label="3.downsample.0.weight
 (32, 16, 1, 1)" fillcolor=lightblue]
	1563171673328 -> 1563146887296
	1563146887296 [label=AccumulateGrad]
	1563146887584 -> 1563146887728
	1563171673616 [label="3.downsample.1.weight
 (32)" fillcolor=lightblue]
	1563171673616 -> 1563146887584
	1563146887584 [label=AccumulateGrad]
	1563146887824 -> 1563146887728
	1563171673808 [label="3.downsample.1.bias
 (32)" fillcolor=lightblue]
	1563171673808 -> 1563146887824
	1563146887824 [label=AccumulateGrad]
	1563146887920 -> 1563146887872
	1563146887920 [label=ConvolutionBackward0]
	1563146886960 -> 1563146887920
	1563146886960 [label=ConvolutionBackward0]
	1563146887440 -> 1563146886960
	1563146886624 -> 1563146886960
	1563171673424 [label="3.depthwise.weight
 (16, 1, 3, 3)" fillcolor=lightblue]
	1563171673424 -> 1563146886624
	1563146886624 [label=AccumulateGrad]
	1563146887200 -> 1563146887920
	1563171673520 [label="3.pointwise.weight
 (32, 16, 1, 1)" fillcolor=lightblue]
	1563171673520 -> 1563146887200
	1563146887200 [label=AccumulateGrad]
	1563146888016 -> 1563146888064
	1563171671888 [label="4.weight
 (32)" fillcolor=lightblue]
	1563171671888 -> 1563146888016
	1563146888016 [label=AccumulateGrad]
	1563146888256 -> 1563146888064
	1563171671600 [label="4.bias
 (32)" fillcolor=lightblue]
	1563171671600 -> 1563146888256
	1563146888256 [label=AccumulateGrad]
	1563146888208 -> 1563146888352
	1563171672080 [label="6.conv1.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1563171672080 -> 1563146888208
	1563146888208 [label=AccumulateGrad]
	1563146888496 -> 1563146888544
	1563171672176 [label="6.bn1.weight
 (32)" fillcolor=lightblue]
	1563171672176 -> 1563146888496
	1563146888496 [label=AccumulateGrad]
	1563146888688 -> 1563146888544
	1563171672272 [label="6.bn1.bias
 (32)" fillcolor=lightblue]
	1563171672272 -> 1563146888688
	1563146888688 [label=AccumulateGrad]
	1563146888736 -> 1563146888976
	1563171671504 [label="6.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1563171671504 -> 1563146888736
	1563146888736 [label=AccumulateGrad]
	1563146889024 -> 1563146889168
	1563171671408 [label="6.bn2.weight
 (32)" fillcolor=lightblue]
	1563171671408 -> 1563146889024
	1563146889024 [label=AccumulateGrad]
	1563146889264 -> 1563146889168
	1563171670640 [label="6.bn2.bias
 (32)" fillcolor=lightblue]
	1563171670640 -> 1563146889264
	1563146889264 [label=AccumulateGrad]
	1563146889360 -> 1563146889216
	1563146889504 -> 1563146889648
	1563146889504 [label=ViewBackward0]
	1563146888832 -> 1563146889504
	1563146888832 [label=SigmoidBackward0]
	1563146888400 -> 1563146888832
	1563146888400 [label=AddmmBackward0]
	1563146888784 -> 1563146888400
	1563171670928 [label="7.fc2.bias
 (32)" fillcolor=lightblue]
	1563171670928 -> 1563146888784
	1563146888784 [label=AccumulateGrad]
	1563146888160 -> 1563146888400
	1563146888160 [label=ReluBackward0]
	1563146887680 -> 1563146888160
	1563146887680 [label=AddmmBackward0]
	1563146886816 -> 1563146887680
	1563171670544 [label="7.fc1.bias
 (2)" fillcolor=lightblue]
	1563171670544 -> 1563146886816
	1563146886816 [label=AccumulateGrad]
	1563146886864 -> 1563146887680
	1563146886864 [label=MeanBackward1]
	1563146886720 -> 1563146886864
	1563146886720 [label=ViewBackward0]
	1563146889456 -> 1563146886720
	1563146887392 -> 1563146887680
	1563146887392 [label=TBackward0]
	1563146886240 -> 1563146887392
	1563171668912 [label="7.fc1.weight
 (2, 32)" fillcolor=lightblue]
	1563171668912 -> 1563146886240
	1563146886240 [label=AccumulateGrad]
	1563146889120 -> 1563146888400
	1563146889120 [label=TBackward0]
	1563146886336 -> 1563146889120
	1563171670736 [label="7.fc2.weight
 (32, 2)" fillcolor=lightblue]
	1563171670736 -> 1563146886336
	1563146886336 [label=AccumulateGrad]
	1563146889840 -> 1563146889600
	1563146889840 [label=SigmoidBackward0]
	1563146888640 -> 1563146889840
	1563146888640 [label=ConvolutionBackward0]
	1563146887344 -> 1563146888640
	1563146887344 [label=SplitWithSizesBackward0]
	1563146888304 -> 1563146887344
	1563146888304 [label=ReluBackward0]
	1563146886288 -> 1563146888304
	1563146886288 [label=CudnnBatchNormBackward0]
	1563146886144 -> 1563146886288
	1563146886144 [label=ConvolutionBackward0]
	1563146885856 -> 1563146886144
	1563146885856 [label=CatBackward0]
	1563146885904 -> 1563146885856
	1563146885904 [label=AdaptiveAvgPool2DBackward0]
	1563146889648 -> 1563146885904
	1563146885808 -> 1563146885856
	1563146885808 [label=PermuteBackward0]
	1563146885664 -> 1563146885808
	1563146885664 [label=AdaptiveAvgPool2DBackward0]
	1563146889648 -> 1563146885664
	1563146885760 -> 1563146886144
	1563171671312 [label="8.conv1.weight
 (8, 32, 1, 1)" fillcolor=lightblue]
	1563171671312 -> 1563146885760
	1563146885760 [label=AccumulateGrad]
	1563146886384 -> 1563146886288
	1563171671024 [label="8.bn1.weight
 (8)" fillcolor=lightblue]
	1563171671024 -> 1563146886384
	1563146886384 [label=AccumulateGrad]
	1563146886432 -> 1563146886288
	1563171671216 [label="8.bn1.bias
 (8)" fillcolor=lightblue]
	1563171671216 -> 1563146886432
	1563146886432 [label=AccumulateGrad]
	1563146887776 -> 1563146888640
	1563147720880 [label="8.conv_h.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	1563147720880 -> 1563146887776
	1563146887776 [label=AccumulateGrad]
	1563146889792 -> 1563146889984
	1563146889792 [label=PermuteBackward0]
	1563146889744 -> 1563146889792
	1563146889744 [label=SigmoidBackward0]
	1563146886576 -> 1563146889744
	1563146886576 [label=ConvolutionBackward0]
	1563146887344 -> 1563146886576
	1563146885952 -> 1563146886576
	1563147720784 [label="8.conv_w.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	1563147720784 -> 1563146885952
	1563146885952 [label=AccumulateGrad]
	1563146890224 -> 1563146890176
	1563147720976 [label="9.downsample.0.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	1563147720976 -> 1563146890224
	1563146890224 [label=AccumulateGrad]
	1563146890080 -> 1563146890416
	1563147721264 [label="9.downsample.1.weight
 (64)" fillcolor=lightblue]
	1563147721264 -> 1563146890080
	1563146890080 [label=AccumulateGrad]
	1563146890272 -> 1563146890416
	1563147721360 [label="9.downsample.1.bias
 (64)" fillcolor=lightblue]
	1563147721360 -> 1563146890272
	1563146890272 [label=AccumulateGrad]
	1563146890464 -> 1563146890800
	1563146890464 [label=ConvolutionBackward0]
	1563146886096 -> 1563146890464
	1563146886096 [label=ConvolutionBackward0]
	1563146889984 -> 1563146886096
	1563146886480 -> 1563146886096
	1563147721072 [label="9.depthwise.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	1563147721072 -> 1563146886480
	1563146886480 [label=AccumulateGrad]
	1563146890128 -> 1563146890464
	1563147721168 [label="9.pointwise.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	1563147721168 -> 1563146890128
	1563146890128 [label=AccumulateGrad]
	1563146890656 -> 1563146890560
	1563147721744 [label="10.weight
 (64)" fillcolor=lightblue]
	1563147721744 -> 1563146890656
	1563146890656 [label=AccumulateGrad]
	1563146890896 -> 1563146890560
	1563147721840 [label="10.bias
 (64)" fillcolor=lightblue]
	1563147721840 -> 1563146890896
	1563146890896 [label=AccumulateGrad]
	1563146891184 -> 1563146892240
	1563146891184 [label=ReluBackward0]
	1563146890704 -> 1563146891184
	1563146890704 [label=ConvolutionBackward0]
	1563146885616 -> 1563146890704
	1563146885616 [label=CatBackward0]
	1563146889312 -> 1563146885616
	1563146889312 [label=AddBackward0]
	1563146890944 -> 1563146889312
	1563146885472 -> 1563146889312
	1563146885472 [label=ConvolutionBackward0]
	1563146885328 -> 1563146885472
	1563146885328 [label=ConvolutionBackward0]
	1563146890944 -> 1563146885328
	1563146885136 -> 1563146885328
	1563147722416 [label="12.conv_dil1.depthwise.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	1563147722416 -> 1563146885136
	1563146885136 [label=AccumulateGrad]
	1563146885520 -> 1563146885472
	1563147722512 [label="12.conv_dil1.pointwise.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	1563147722512 -> 1563146885520
	1563146885520 [label=AccumulateGrad]
	1563146889936 -> 1563146885616
	1563146889936 [label=AddBackward0]
	1563146890944 -> 1563146889936
	1563146884992 -> 1563146889936
	1563146884992 [label=ConvolutionBackward0]
	1563146885184 -> 1563146884992
	1563146885184 [label=ConvolutionBackward0]
	1563146890944 -> 1563146885184
	1563146885040 -> 1563146885184
	1563147722608 [label="12.conv_dil2.depthwise.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	1563147722608 -> 1563146885040
	1563146885040 [label=AccumulateGrad]
	1563146884800 -> 1563146884992
	1563147722704 [label="12.conv_dil2.pointwise.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	1563147722704 -> 1563146884800
	1563146884800 [label=AccumulateGrad]
	1563146885376 -> 1563146885616
	1563146885376 [label=AddBackward0]
	1563146890944 -> 1563146885376
	1563146884848 -> 1563146885376
	1563146884848 [label=ConvolutionBackward0]
	1563146884896 -> 1563146884848
	1563146884896 [label=ConvolutionBackward0]
	1563146890944 -> 1563146884896
	1563146884656 -> 1563146884896
	1563147722800 [label="12.conv_dil3.depthwise.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	1563147722800 -> 1563146884656
	1563146884656 [label=AccumulateGrad]
	1563146884944 -> 1563146884848
	1563147722896 [label="12.conv_dil3.pointwise.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	1563147722896 -> 1563146884944
	1563146884944 [label=AccumulateGrad]
	1563146890320 -> 1563146890704
	1563147722992 [label="12.fuse.weight
 (64, 192, 1, 1)" fillcolor=lightblue]
	1563147722992 -> 1563146890320
	1563146890320 [label=AccumulateGrad]
	1563146891088 -> 1563146891232
	1563147722320 [label="13.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1563147722320 -> 1563146891088
	1563146891088 [label=AccumulateGrad]
	1563146891376 -> 1563146891424
	1563147723088 [label="13.bn1.weight
 (64)" fillcolor=lightblue]
	1563147723088 -> 1563146891376
	1563146891376 [label=AccumulateGrad]
	1563146891568 -> 1563146891424
	1563147723184 [label="13.bn1.bias
 (64)" fillcolor=lightblue]
	1563147723184 -> 1563146891568
	1563146891568 [label=AccumulateGrad]
	1563146891616 -> 1563146891856
	1563147723568 [label="13.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1563147723568 -> 1563146891616
	1563146891616 [label=AccumulateGrad]
	1563146891904 -> 1563146892048
	1563147723664 [label="13.bn2.weight
 (64)" fillcolor=lightblue]
	1563147723664 -> 1563146891904
	1563146891904 [label=AccumulateGrad]
	1563146892144 -> 1563146892048
	1563147723760 [label="13.bn2.bias
 (64)" fillcolor=lightblue]
	1563147723760 -> 1563146892144
	1563146892144 [label=AccumulateGrad]
	1563146892240 -> 1563146892096
	1563146892384 -> 1563146892528
	1563146892384 [label=SigmoidBackward0]
	1563146891712 -> 1563146892384
	1563146891712 [label=UnsqueezeBackward0]
	1563146891280 -> 1563146891712
	1563146891280 [label=UnsqueezeBackward0]
	1563146891664 -> 1563146891280
	1563146891664 [label=SqueezeBackward1]
	1563146890608 -> 1563146891664
	1563146890608 [label=ConvolutionBackward0]
	1563146886000 -> 1563146890608
	1563146886000 [label=UnsqueezeBackward0]
	1563146884512 -> 1563146886000
	1563146884512 [label=ViewBackward0]
	1563146884704 -> 1563146884512
	1563146884704 [label=MeanBackward1]
	1563146892336 -> 1563146884704
	1563146891136 -> 1563146890608
	1563147724144 [label="14.conv.weight
 (1, 1, 3)" fillcolor=lightblue]
	1563147724144 -> 1563146891136
	1563146891136 [label=AccumulateGrad]
	1563146892720 -> 1563146892672
	1563147724240 [label="15.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1563147724240 -> 1563146892720
	1563146892720 [label=AccumulateGrad]
	1563146892816 -> 1563146893104
	1563147724528 [label="15.downsample.1.weight
 (128)" fillcolor=lightblue]
	1563147724528 -> 1563146892816
	1563146892816 [label=AccumulateGrad]
	1563146892864 -> 1563146893104
	1563147724624 [label="15.downsample.1.bias
 (128)" fillcolor=lightblue]
	1563147724624 -> 1563146892864
	1563146892864 [label=AccumulateGrad]
	1563146893008 -> 1563146892960
	1563146893008 [label=ConvolutionBackward0]
	1563146891520 -> 1563146893008
	1563146891520 [label=ConvolutionBackward0]
	1563146892528 -> 1563146891520
	1563146891040 -> 1563146891520
	1563147724336 [label="15.depthwise.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	1563147724336 -> 1563146891040
	1563146891040 [label=AccumulateGrad]
	1563146892576 -> 1563146893008
	1563147724432 [label="15.pointwise.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1563147724432 -> 1563146892576
	1563146892576 [label=AccumulateGrad]
	1563146893152 -> 1563146893296
	1563147725008 [label="16.weight
 (128)" fillcolor=lightblue]
	1563147725008 -> 1563146893152
	1563146893152 [label=AccumulateGrad]
	1563146893584 -> 1563146893296
	1563147725104 [label="16.bias
 (128)" fillcolor=lightblue]
	1563147725104 -> 1563146893584
	1563146893584 [label=AccumulateGrad]
	1563146893680 -> 1563146894400
	1563146893680 [label=ReluBackward0]
	1563146893200 -> 1563146893680
	1563146893200 [label=ConvolutionBackward0]
	1563146890752 -> 1563146893200
	1563146890752 [label=CatBackward0]
	1563146892192 -> 1563146890752
	1563146892192 [label=AddBackward0]
	1563146893488 -> 1563146892192
	1563146885424 -> 1563146892192
	1563146885424 [label=ConvolutionBackward0]
	1563146884560 -> 1563146885424
	1563146884560 [label=ConvolutionBackward0]
	1563146893488 -> 1563146884560
	1563146884224 -> 1563146884560
	1563147725584 [label="18.conv_dil1.depthwise.weight
 (128, 1, 3, 3)" fillcolor=lightblue]
	1563147725584 -> 1563146884224
	1563146884224 [label=AccumulateGrad]
	1563146885280 -> 1563146885424
	1563147725680 [label="18.conv_dil1.pointwise.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	1563147725680 -> 1563146885280
	1563146885280 [label=AccumulateGrad]
	1563146892624 -> 1563146890752
	1563146892624 [label=AddBackward0]
	1563146893488 -> 1563146892624
	1563146884176 -> 1563146892624
	1563146884176 [label=ConvolutionBackward0]
	1563146884464 -> 1563146884176
	1563146884464 [label=ConvolutionBackward0]
	1563146893488 -> 1563146884464
	1563146883936 -> 1563146884464
	1563147725776 [label="18.conv_dil2.depthwise.weight
 (128, 1, 3, 3)" fillcolor=lightblue]
	1563147725776 -> 1563146883936
	1563146883936 [label=AccumulateGrad]
	1563146884032 -> 1563146884176
	1563147725872 [label="18.conv_dil2.pointwise.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	1563147725872 -> 1563146884032
	1563146884032 [label=AccumulateGrad]
	1563146892000 -> 1563146890752
	1563146892000 [label=AddBackward0]
	1563146893488 -> 1563146892000
	1563146884080 -> 1563146892000
	1563146884080 [label=ConvolutionBackward0]
	1563146883840 -> 1563146884080
	1563146883840 [label=ConvolutionBackward0]
	1563146893488 -> 1563146883840
	1563146883744 -> 1563146883840
	1563147725968 [label="18.conv_dil3.depthwise.weight
 (128, 1, 3, 3)" fillcolor=lightblue]
	1563147725968 -> 1563146883744
	1563146883744 [label=AccumulateGrad]
	1563146883888 -> 1563146884080
	1563147726064 [label="18.conv_dil3.pointwise.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	1563147726064 -> 1563146883888
	1563146883888 [label=AccumulateGrad]
	1563146892480 -> 1563146893200
	1563147726160 [label="18.fuse.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	1563147726160 -> 1563146892480
	1563146892480 [label=AccumulateGrad]
	1563146893536 -> 1563146893824
	1563147725488 [label="19.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1563147725488 -> 1563146893536
	1563146893536 [label=AccumulateGrad]
	1563146894064 -> 1563146893968
	1563147726256 [label="19.bn1.weight
 (128)" fillcolor=lightblue]
	1563147726256 -> 1563146894064
	1563146894064 [label=AccumulateGrad]
	1563146894016 -> 1563146893968
	1563147726352 [label="19.bn1.bias
 (128)" fillcolor=lightblue]
	1563147726352 -> 1563146894016
	1563146894016 [label=AccumulateGrad]
	1563146894112 -> 1563146894544
	1563147726736 [label="19.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1563147726736 -> 1563146894112
	1563146894112 [label=AccumulateGrad]
	1563146894448 -> 1563146894496
	1563147726832 [label="19.bn2.weight
 (128)" fillcolor=lightblue]
	1563147726832 -> 1563146894448
	1563146894448 [label=AccumulateGrad]
	1563146894640 -> 1563146894496
	1563147726928 [label="19.bn2.bias
 (128)" fillcolor=lightblue]
	1563147726928 -> 1563146894640
	1563146894640 [label=AccumulateGrad]
	1563146894400 -> 1563146895264
	1563146879808 -> 1563146880288
	1563146879808 [label=SigmoidBackward0]
	1563146894304 -> 1563146879808
	1563146894304 [label=ConvolutionBackward0]
	1563146893440 -> 1563146894304
	1563146893440 [label=NativeDropoutBackward0]
	1563146893344 -> 1563146893440
	1563146893344 [label=ReluBackward0]
	1563146893632 -> 1563146893344
	1563146893632 [label=ConvolutionBackward0]
	1563146889696 -> 1563146893632
	1563146889696 [label=MeanBackward1]
	1563146879952 -> 1563146889696
	1563146884320 -> 1563146893632
	1563147727312 [label="20.fc1.weight
 (8, 128, 1, 1)" fillcolor=lightblue]
	1563147727312 -> 1563146884320
	1563146884320 [label=AccumulateGrad]
	1563146894256 -> 1563146894304
	1563147727408 [label="20.fc2.weight
 (128, 8, 1, 1)" fillcolor=lightblue]
	1563147727408 -> 1563146894256
	1563146894256 [label=AccumulateGrad]
	1563146880912 -> 1563146881248
	1563147727504 [label="21.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1563147727504 -> 1563146880912
	1563146880912 [label=AccumulateGrad]
	1563146881872 -> 1563146882352
	1563147727792 [label="21.downsample.1.weight
 (256)" fillcolor=lightblue]
	1563147727792 -> 1563146881872
	1563146881872 [label=AccumulateGrad]
	1563146881728 -> 1563146882352
	1563147727888 [label="21.downsample.1.bias
 (256)" fillcolor=lightblue]
	1563147727888 -> 1563146881728
	1563146881728 [label=AccumulateGrad]
	1563146882208 -> 1563146883312
	1563146882208 [label=ConvolutionBackward0]
	1563146879472 -> 1563146882208
	1563146879472 [label=ConvolutionBackward0]
	1563146880288 -> 1563146879472
	1563146893776 -> 1563146879472
	1563147727600 [label="21.depthwise.weight
 (128, 1, 3, 3)" fillcolor=lightblue]
	1563147727600 -> 1563146893776
	1563146893776 [label=AccumulateGrad]
	1563146880768 -> 1563146882208
	1563147727696 [label="21.pointwise.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1563147727696 -> 1563146880768
	1563146880768 [label=AccumulateGrad]
	1563146883168 -> 1563146883792
	1563147728272 [label="22.weight
 (256)" fillcolor=lightblue]
	1563147728272 -> 1563146883168
	1563146883168 [label=AccumulateGrad]
	1563146884752 -> 1563146883792
	1563147728368 [label="22.bias
 (256)" fillcolor=lightblue]
	1563147728368 -> 1563146884752
	1563146884752 [label=AccumulateGrad]
	1563146884272 -> 1563146885232
	1563147728752 [label="24.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1563147728752 -> 1563146884272
	1563146884272 [label=AccumulateGrad]
	1563146885088 -> 1563146885712
	1563147728848 [label="24.bn1.weight
 (256)" fillcolor=lightblue]
	1563147728848 -> 1563146885088
	1563146885088 [label=AccumulateGrad]
	1563146886192 -> 1563146885712
	1563147728944 [label="24.bn1.bias
 (256)" fillcolor=lightblue]
	1563147728944 -> 1563146886192
	1563146886192 [label=AccumulateGrad]
	1563146886672 -> 1563146887008
	1563147729328 [label="24.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1563147729328 -> 1563146886672
	1563146886672 [label=AccumulateGrad]
	1563146887632 -> 1563146888112
	1563147729424 [label="24.bn2.weight
 (256)" fillcolor=lightblue]
	1563147729424 -> 1563146887632
	1563146887632 [label=AccumulateGrad]
	1563146887488 -> 1563146888112
	1563147729520 [label="24.bn2.bias
 (256)" fillcolor=lightblue]
	1563147729520 -> 1563146887488
	1563146887488 [label=AccumulateGrad]
	1563146887968 -> 1563146888592
	1563146889552 -> 1563146890032
	1563146889552 [label=ViewBackward0]
	1563146887152 -> 1563146889552
	1563146887152 [label=SigmoidBackward0]
	1563146884128 -> 1563146887152
	1563146884128 [label=AddmmBackward0]
	1563146885568 -> 1563146884128
	1563147730192 [label="25.channel_att.fc2.bias
 (256)" fillcolor=lightblue]
	1563147730192 -> 1563146885568
	1563146885568 [label=AccumulateGrad]
	1563146884608 -> 1563146884128
	1563146884608 [label=ReluBackward0]
	1563146882688 -> 1563146884608
	1563146882688 [label=AddmmBackward0]
	1563146894160 -> 1563146882688
	1563147730000 [label="25.channel_att.fc1.bias
 (16)" fillcolor=lightblue]
	1563147730000 -> 1563146894160
	1563146894160 [label=AccumulateGrad]
	1563146893056 -> 1563146882688
	1563146893056 [label=MeanBackward1]
	1563146879328 -> 1563146893056
	1563146879328 [label=ViewBackward0]
	1563146888928 -> 1563146879328
	1563146881392 -> 1563146882688
	1563146881392 [label=TBackward0]
	1563146883552 -> 1563146881392
	1563147729904 [label="25.channel_att.fc1.weight
 (16, 256)" fillcolor=lightblue]
	1563147729904 -> 1563146883552
	1563146883552 [label=AccumulateGrad]
	1563146888448 -> 1563146884128
	1563146888448 [label=TBackward0]
	1563146883984 -> 1563146888448
	1563147730096 [label="25.channel_att.fc2.weight
 (256, 16)" fillcolor=lightblue]
	1563147730096 -> 1563146883984
	1563146883984 [label=AccumulateGrad]
	1563146889888 -> 1563146890512
	1563146889888 [label=SigmoidBackward0]
	1563146886528 -> 1563146889888
	1563146886528 [label=ConvolutionBackward0]
	1563146880432 -> 1563146886528
	1563146880432 [label=CatBackward0]
	1563146883648 -> 1563146880432
	1563146883648 [label=MeanBackward1]
	1563146890032 -> 1563146883648
	1563146884368 -> 1563146880432
	1563146884368 [label=MaxBackward0]
	1563146890032 -> 1563146884368
	1563146882832 -> 1563146886528
	1563147730384 [label="25.spatial_att.conv.weight
 (1, 2, 3, 3)" fillcolor=lightblue]
	1563147730384 -> 1563146882832
	1563146882832 [label=AccumulateGrad]
	1563146891952 -> 1563146892768
	1563146891952 [label=TBackward0]
	1563146890368 -> 1563146891952
	1563147730288 [label="29.weight
 (19, 256)" fillcolor=lightblue]
	1563147730288 -> 1563146890368
	1563146890368 [label=AccumulateGrad]
	1563146892768 -> 1563143565776
}
