digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2727723657712 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2727776368096 [label=AddmmBackward0]
	2727776367760 -> 2727776368096
	2727727365776 [label="fc.bias
 (19)" fillcolor=lightblue]
	2727727365776 -> 2727776367760
	2727776367760 [label=AccumulateGrad]
	2727776367136 -> 2727776368096
	2727776367136 [label=ViewBackward0]
	2727776366656 -> 2727776367136
	2727776366656 [label=MeanBackward1]
	2727776366320 -> 2727776366656
	2727776366320 [label=ReluBackward0]
	2727776365840 -> 2727776366320
	2727776365840 [label=AddBackward0]
	2727776365360 -> 2727776365840
	2727776365360 [label=CudnnBatchNormBackward0]
	2727776364256 -> 2727776365360
	2727776364256 [label=ConvolutionBackward0]
	2727776363296 -> 2727776364256
	2727776363296 [label=ReluBackward0]
	2727776362960 -> 2727776363296
	2727776362960 [label=CudnnBatchNormBackward0]
	2727776362480 -> 2727776362960
	2727776362480 [label=ConvolutionBackward0]
	2727776365216 -> 2727776362480
	2727776365216 [label=ReluBackward0]
	2727776361040 -> 2727776365216
	2727776361040 [label=AddBackward0]
	2727776360560 -> 2727776361040
	2727776360560 [label=CudnnBatchNormBackward0]
	2727776359456 -> 2727776360560
	2727776359456 [label=ConvolutionBackward0]
	2727776357728 -> 2727776359456
	2727776357728 [label=ReluBackward0]
	2727776358304 -> 2727776357728
	2727776358304 [label=CudnnBatchNormBackward0]
	2727776356912 -> 2727776358304
	2727776356912 [label=ConvolutionBackward0]
	2727776370112 -> 2727776356912
	2727776370112 [label=ReluBackward0]
	2727776369728 -> 2727776370112
	2727776369728 [label=AddBackward0]
	2727776369968 -> 2727776369728
	2727776369968 [label=CudnnBatchNormBackward0]
	2727776369632 -> 2727776369968
	2727776369632 [label=ConvolutionBackward0]
	2727776369344 -> 2727776369632
	2727776369344 [label=ReluBackward0]
	2727776369392 -> 2727776369344
	2727776369392 [label=CudnnBatchNormBackward0]
	2727776369104 -> 2727776369392
	2727776369104 [label=ConvolutionBackward0]
	2727776369824 -> 2727776369104
	2727776369824 [label=ReluBackward0]
	2727776368912 -> 2727776369824
	2727776368912 [label=AddBackward0]
	2727776368624 -> 2727776368912
	2727776368624 [label=CudnnBatchNormBackward0]
	2727776368384 -> 2727776368624
	2727776368384 [label=ConvolutionBackward0]
	2727776368192 -> 2727776368384
	2727776368192 [label=ReluBackward0]
	2727776367808 -> 2727776368192
	2727776367808 [label=CudnnBatchNormBackward0]
	2727776368048 -> 2727776367808
	2727776368048 [label=ConvolutionBackward0]
	2727776367664 -> 2727776368048
	2727776367664 [label=ReluBackward0]
	2727776367424 -> 2727776367664
	2727776367424 [label=AddBackward0]
	2727776367376 -> 2727776367424
	2727776367376 [label=CudnnBatchNormBackward0]
	2727776367184 -> 2727776367376
	2727776367184 [label=ConvolutionBackward0]
	2727776367088 -> 2727776367184
	2727776367088 [label=ReluBackward0]
	2727776366752 -> 2727776367088
	2727776366752 [label=CudnnBatchNormBackward0]
	2727776366560 -> 2727776366752
	2727776366560 [label=ConvolutionBackward0]
	2727776367568 -> 2727776366560
	2727776367568 [label=ReluBackward0]
	2727776366272 -> 2727776367568
	2727776366272 [label=AddBackward0]
	2727776366080 -> 2727776366272
	2727776366080 [label=CudnnBatchNormBackward0]
	2727776366128 -> 2727776366080
	2727776366128 [label=ConvolutionBackward0]
	2727776365744 -> 2727776366128
	2727776365744 [label=ReluBackward0]
	2727776365504 -> 2727776365744
	2727776365504 [label=CudnnBatchNormBackward0]
	2727776365456 -> 2727776365504
	2727776365456 [label=ConvolutionBackward0]
	2727776365120 -> 2727776365456
	2727776365120 [label=ReluBackward0]
	2727776365168 -> 2727776365120
	2727776365168 [label=AddBackward0]
	2727776365072 -> 2727776365168
	2727776365072 [label=CudnnBatchNormBackward0]
	2727776364640 -> 2727776365072
	2727776364640 [label=ConvolutionBackward0]
	2727776364496 -> 2727776364640
	2727776364496 [label=ReluBackward0]
	2727776364304 -> 2727776364496
	2727776364304 [label=CudnnBatchNormBackward0]
	2727776363968 -> 2727776364304
	2727776363968 [label=ConvolutionBackward0]
	2727776364976 -> 2727776363968
	2727776364976 [label=ReluBackward0]
	2727776363824 -> 2727776364976
	2727776363824 [label=AddBackward0]
	2727776363488 -> 2727776363824
	2727776363488 [label=CudnnBatchNormBackward0]
	2727776363536 -> 2727776363488
	2727776363536 [label=ConvolutionBackward0]
	2727776363200 -> 2727776363536
	2727776363200 [label=ReluBackward0]
	2727776363248 -> 2727776363200
	2727776363248 [label=CudnnBatchNormBackward0]
	2727776363152 -> 2727776363248
	2727776363152 [label=ConvolutionBackward0]
	2727776363680 -> 2727776363152
	2727776363680 [label=MaxPool2DWithIndicesBackward0]
	2727776362768 -> 2727776363680
	2727776362768 [label=ReluBackward0]
	2727776362672 -> 2727776362768
	2727776362672 [label=CudnnBatchNormBackward0]
	2727776362384 -> 2727776362672
	2727776362384 [label=ConvolutionBackward0]
	2727776362288 -> 2727776362384
	2727750821904 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2727750821904 -> 2727776362288
	2727776362288 [label=AccumulateGrad]
	2727776362432 -> 2727776362672
	2727750821136 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2727750821136 -> 2727776362432
	2727776362432 [label=AccumulateGrad]
	2727776362864 -> 2727776362672
	2727750820848 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2727750820848 -> 2727776362864
	2727776362864 [label=AccumulateGrad]
	2727776362528 -> 2727776363152
	2727750821328 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2727750821328 -> 2727776362528
	2727776362528 [label=AccumulateGrad]
	2727776363056 -> 2727776363248
	2727750821424 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2727750821424 -> 2727776363056
	2727776363056 [label=AccumulateGrad]
	2727776363008 -> 2727776363248
	2727750821520 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2727750821520 -> 2727776363008
	2727776363008 [label=AccumulateGrad]
	2727776363344 -> 2727776363536
	2727750820752 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2727750820752 -> 2727776363344
	2727776363344 [label=AccumulateGrad]
	2727776363728 -> 2727776363488
	2727750820656 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2727750820656 -> 2727776363728
	2727776363728 [label=AccumulateGrad]
	2727776363584 -> 2727776363488
	2727750819888 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2727750819888 -> 2727776363584
	2727776363584 [label=AccumulateGrad]
	2727776363680 -> 2727776363824
	2727776364112 -> 2727776363968
	2727750819984 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2727750819984 -> 2727776364112
	2727776364112 [label=AccumulateGrad]
	2727776364160 -> 2727776364304
	2727750820080 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2727750820080 -> 2727776364160
	2727776364160 [label=AccumulateGrad]
	2727776364592 -> 2727776364304
	2727750820176 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2727750820176 -> 2727776364592
	2727776364592 [label=AccumulateGrad]
	2727776364688 -> 2727776364640
	2727750820464 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2727750820464 -> 2727776364688
	2727776364688 [label=AccumulateGrad]
	2727776364784 -> 2727776365072
	2727750819504 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2727750819504 -> 2727776364784
	2727776364784 [label=AccumulateGrad]
	2727776364832 -> 2727776365072
	2727750819408 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2727750819408 -> 2727776364832
	2727776364832 [label=AccumulateGrad]
	2727776364976 -> 2727776365168
	2727776365264 -> 2727776365456
	2727750819312 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2727750819312 -> 2727776365264
	2727776365264 [label=AccumulateGrad]
	2727776365648 -> 2727776365504
	2727750819216 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2727750819216 -> 2727776365648
	2727776365648 [label=AccumulateGrad]
	2727776365600 -> 2727776365504
	2727727556624 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2727727556624 -> 2727776365600
	2727776365600 [label=AccumulateGrad]
	2727776365792 -> 2727776366128
	2727727557008 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2727727557008 -> 2727776365792
	2727776365792 [label=AccumulateGrad]
	2727776365984 -> 2727776366080
	2727727557104 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2727727557104 -> 2727776365984
	2727776365984 [label=AccumulateGrad]
	2727776365888 -> 2727776366080
	2727727557200 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2727727557200 -> 2727776365888
	2727776365888 [label=AccumulateGrad]
	2727776366224 -> 2727776366272
	2727776366224 [label=CudnnBatchNormBackward0]
	2727776365312 -> 2727776366224
	2727776365312 [label=ConvolutionBackward0]
	2727776365120 -> 2727776365312
	2727776364928 -> 2727776365312
	2727750816720 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2727750816720 -> 2727776364928
	2727776364928 [label=AccumulateGrad]
	2727776366032 -> 2727776366224
	2727750816912 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2727750816912 -> 2727776366032
	2727776366032 [label=AccumulateGrad]
	2727776365936 -> 2727776366224
	2727750818544 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2727750818544 -> 2727776365936
	2727776365936 [label=AccumulateGrad]
	2727776366416 -> 2727776366560
	2727727557584 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2727727557584 -> 2727776366416
	2727776366416 [label=AccumulateGrad]
	2727776366704 -> 2727776366752
	2727727557680 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2727727557680 -> 2727776366704
	2727776366704 [label=AccumulateGrad]
	2727776366896 -> 2727776366752
	2727727557776 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2727727557776 -> 2727776366896
	2727776366896 [label=AccumulateGrad]
	2727776366944 -> 2727776367184
	2727727558160 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2727727558160 -> 2727776366944
	2727776366944 [label=AccumulateGrad]
	2727776367232 -> 2727776367376
	2727727558256 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2727727558256 -> 2727776367232
	2727776367232 [label=AccumulateGrad]
	2727776367472 -> 2727776367376
	2727727558352 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2727727558352 -> 2727776367472
	2727776367472 [label=AccumulateGrad]
	2727776367568 -> 2727776367424
	2727776367712 -> 2727776368048
	2727727559312 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2727727559312 -> 2727776367712
	2727776367712 [label=AccumulateGrad]
	2727776367904 -> 2727776367808
	2727727559408 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2727727559408 -> 2727776367904
	2727776367904 [label=AccumulateGrad]
	2727776368144 -> 2727776367808
	2727727559504 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2727727559504 -> 2727776368144
	2727776368144 [label=AccumulateGrad]
	2727776368432 -> 2727776368384
	2727727559888 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2727727559888 -> 2727776368432
	2727776368432 [label=AccumulateGrad]
	2727776368288 -> 2727776368624
	2727727559984 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2727727559984 -> 2727776368288
	2727776368288 [label=AccumulateGrad]
	2727776368480 -> 2727776368624
	2727727560080 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2727727560080 -> 2727776368480
	2727776368480 [label=AccumulateGrad]
	2727776368672 -> 2727776368912
	2727776368672 [label=CudnnBatchNormBackward0]
	2727776367952 -> 2727776368672
	2727776367952 [label=ConvolutionBackward0]
	2727776367664 -> 2727776367952
	2727776367520 -> 2727776367952
	2727727558736 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2727727558736 -> 2727776367520
	2727776367520 [label=AccumulateGrad]
	2727776368336 -> 2727776368672
	2727727558832 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2727727558832 -> 2727776368336
	2727776368336 [label=AccumulateGrad]
	2727776368528 -> 2727776368672
	2727727558928 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2727727558928 -> 2727776368528
	2727776368528 [label=AccumulateGrad]
	2727776369008 -> 2727776369104
	2727727560464 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2727727560464 -> 2727776369008
	2727776369008 [label=AccumulateGrad]
	2727776369152 -> 2727776369392
	2727727560560 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2727727560560 -> 2727776369152
	2727776369152 [label=AccumulateGrad]
	2727776369488 -> 2727776369392
	2727727560656 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2727727560656 -> 2727776369488
	2727776369488 [label=AccumulateGrad]
	2727776369248 -> 2727776369632
	2727727561040 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2727727561040 -> 2727776369248
	2727776369248 [label=AccumulateGrad]
	2727776369872 -> 2727776369968
	2727727561136 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2727727561136 -> 2727776369872
	2727776369872 [label=AccumulateGrad]
	2727776369776 -> 2727776369968
	2727727561232 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2727727561232 -> 2727776369776
	2727776369776 [label=AccumulateGrad]
	2727776369824 -> 2727776369728
	2727776370352 -> 2727776356912
	2727727562192 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2727727562192 -> 2727776370352
	2727776370352 [label=AccumulateGrad]
	2727776357056 -> 2727776358304
	2727727562288 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2727727562288 -> 2727776357056
	2727776357056 [label=AccumulateGrad]
	2727776358592 -> 2727776358304
	2727727562384 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2727727562384 -> 2727776358592
	2727776358592 [label=AccumulateGrad]
	2727776359120 -> 2727776359456
	2727727349840 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2727727349840 -> 2727776359120
	2727776359120 [label=AccumulateGrad]
	2727776360080 -> 2727776360560
	2727727349936 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2727727349936 -> 2727776360080
	2727776360080 [label=AccumulateGrad]
	2727776359936 -> 2727776360560
	2727727350032 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2727727350032 -> 2727776359936
	2727776359936 [label=AccumulateGrad]
	2727776360416 -> 2727776361040
	2727776360416 [label=CudnnBatchNormBackward0]
	2727776370256 -> 2727776360416
	2727776370256 [label=ConvolutionBackward0]
	2727776370112 -> 2727776370256
	2727776370064 -> 2727776370256
	2727727561616 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2727727561616 -> 2727776370064
	2727776370064 [label=AccumulateGrad]
	2727776358976 -> 2727776360416
	2727727561712 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2727727561712 -> 2727776358976
	2727776358976 [label=AccumulateGrad]
	2727776359600 -> 2727776360416
	2727727561808 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2727727561808 -> 2727776359600
	2727776359600 [label=AccumulateGrad]
	2727776361520 -> 2727776362480
	2727727350416 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2727727350416 -> 2727776361520
	2727776361520 [label=AccumulateGrad]
	2727776362336 -> 2727776362960
	2727727350512 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2727727350512 -> 2727776362336
	2727776362336 [label=AccumulateGrad]
	2727776363440 -> 2727776362960
	2727727350608 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2727727350608 -> 2727776363440
	2727776363440 [label=AccumulateGrad]
	2727776363920 -> 2727776364256
	2727727350992 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2727727350992 -> 2727776363920
	2727776363920 [label=AccumulateGrad]
	2727776364880 -> 2727776365360
	2727727351088 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2727727351088 -> 2727776364880
	2727776364880 [label=AccumulateGrad]
	2727776364736 -> 2727776365360
	2727727351184 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2727727351184 -> 2727776364736
	2727776364736 [label=AccumulateGrad]
	2727776365216 -> 2727776365840
	2727776367280 -> 2727776368096
	2727776367280 [label=TBackward0]
	2727776365696 -> 2727776367280
	2727727365872 [label="fc.weight
 (19, 512)" fillcolor=lightblue]
	2727727365872 -> 2727776365696
	2727776365696 [label=AccumulateGrad]
	2727776368096 -> 2727723657712
}
