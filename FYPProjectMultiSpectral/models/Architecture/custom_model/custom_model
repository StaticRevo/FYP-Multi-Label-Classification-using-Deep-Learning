digraph {
	graph [size="59.849999999999994,59.849999999999994"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1993805124176 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1993775619504 [label=AddmmBackward0]
	1993775627232 -> 1993775619504
	1993804704432 [label="23.bias
 (19)" fillcolor=lightblue]
	1993804704432 -> 1993775627232
	1993775627232 [label=AccumulateGrad]
	1993775627088 -> 1993775619504
	1993775627088 [label=NativeDropoutBackward0]
	1993775623680 -> 1993775627088
	1993775623680 [label=ViewBackward0]
	1993775619456 -> 1993775623680
	1993775619456 [label=MeanBackward1]
	1993775627856 -> 1993775619456
	1993775627856 [label=MulBackward0]
	1993775627952 -> 1993775627856
	1993775627952 [label=MulBackward0]
	1993775624640 -> 1993775627952
	1993775624640 [label=ReluBackward0]
	1993775612544 -> 1993775624640
	1993775612544 [label=AddBackward0]
	1993775622480 -> 1993775612544
	1993775622480 [label=CudnnBatchNormBackward0]
	1993775626512 -> 1993775622480
	1993775626512 [label=ConvolutionBackward0]
	1993775624736 -> 1993775626512
	1993775624736 [label=ReluBackward0]
	1993775628000 -> 1993775624736
	1993775628000 [label=CudnnBatchNormBackward0]
	1993775624112 -> 1993775628000
	1993775624112 [label=ConvolutionBackward0]
	1993775628096 -> 1993775624112
	1993775628096 [label=ReluBackward0]
	1993775615040 -> 1993775628096
	1993775615040 [label=CudnnBatchNormBackward0]
	1993775619168 -> 1993775615040
	1993775619168 [label=ConvolutionBackward0]
	1993775612640 -> 1993775619168
	1993775612640 [label=MulBackward0]
	1993775627760 -> 1993775612640
	1993775627760 [label=ReluBackward0]
	1993775624256 -> 1993775627760
	1993775624256 [label=AddBackward0]
	1993775615424 -> 1993775624256
	1993775615424 [label=CudnnBatchNormBackward0]
	1993775627712 -> 1993775615424
	1993775627712 [label=ConvolutionBackward0]
	1993775620416 -> 1993775627712
	1993775620416 [label=ReluBackward0]
	1993775625600 -> 1993775620416
	1993775625600 [label=CudnnBatchNormBackward0]
	1993775614656 -> 1993775625600
	1993775614656 [label=ConvolutionBackward0]
	1993775623056 -> 1993775614656
	1993775623056 [label=ReluBackward0]
	1993775616480 -> 1993775623056
	1993775616480 [label=CudnnBatchNormBackward0]
	1993775624688 -> 1993775616480
	1993775624688 [label=ConvolutionBackward0]
	1993775624352 -> 1993775624688
	1993775624352 [label=MulBackward0]
	1993775614320 -> 1993775624352
	1993775614320 [label=ReluBackward0]
	1993775614848 -> 1993775614320
	1993775614848 [label=AddBackward0]
	1993775626224 -> 1993775614848
	1993775626224 [label=CudnnBatchNormBackward0]
	1993775626320 -> 1993775626224
	1993775626320 [label=ConvolutionBackward0]
	1993775625072 -> 1993775626320
	1993775625072 [label=ReluBackward0]
	1993775622384 -> 1993775625072
	1993775622384 [label=CudnnBatchNormBackward0]
	1993775613648 -> 1993775622384
	1993775613648 [label=ConvolutionBackward0]
	1993775625840 -> 1993775613648
	1993775625840 [label=ReluBackward0]
	1993775627904 -> 1993775625840
	1993775627904 [label=CudnnBatchNormBackward0]
	1993775625024 -> 1993775627904
	1993775625024 [label=ConvolutionBackward0]
	1993775622288 -> 1993775625024
	1993775622288 [label=MulBackward0]
	1993775624064 -> 1993775622288
	1993775624064 [label=ReluBackward0]
	1993775624832 -> 1993775624064
	1993775624832 [label=AddBackward0]
	1993775612832 -> 1993775624832
	1993775612832 [label=CudnnBatchNormBackward0]
	1993775620752 -> 1993775612832
	1993775620752 [label=ConvolutionBackward0]
	1993775617392 -> 1993775620752
	1993775617392 [label=ReluBackward0]
	1993775621328 -> 1993775617392
	1993775621328 [label=CudnnBatchNormBackward0]
	1993775616336 -> 1993775621328
	1993775616336 [label=ConvolutionBackward0]
	1993775621952 -> 1993775616336
	1993775621952 [label=ReluBackward0]
	1993775622720 -> 1993775621952
	1993775622720 [label=CudnnBatchNormBackward0]
	1993775613504 -> 1993775622720
	1993775613504 [label=ConvolutionBackward0]
	1993775617296 -> 1993775613504
	1993815162320 [label="0.weight
 (32, 12, 3, 3)" fillcolor=lightblue]
	1993815162320 -> 1993775617296
	1993775617296 [label=AccumulateGrad]
	1993775613408 -> 1993775622720
	1993815162704 [label="1.weight
 (32)" fillcolor=lightblue]
	1993815162704 -> 1993775613408
	1993775613408 [label=AccumulateGrad]
	1993775618880 -> 1993775622720
	1993815160976 [label="1.bias
 (32)" fillcolor=lightblue]
	1993815160976 -> 1993775618880
	1993775618880 [label=AccumulateGrad]
	1993775619072 -> 1993775616336
	1993849260368 [label="3.conv1.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1993849260368 -> 1993775619072
	1993775619072 [label=AccumulateGrad]
	1993775627568 -> 1993775621328
	1993849260080 [label="3.bn1.weight
 (32)" fillcolor=lightblue]
	1993849260080 -> 1993775627568
	1993775627568 [label=AccumulateGrad]
	1993775625984 -> 1993775621328
	1993849260176 [label="3.bn1.bias
 (32)" fillcolor=lightblue]
	1993849260176 -> 1993775625984
	1993775625984 [label=AccumulateGrad]
	1993775616048 -> 1993775620752
	1993849260656 [label="3.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1993849260656 -> 1993775616048
	1993775616048 [label=AccumulateGrad]
	1993775625504 -> 1993775612832
	1993849260752 [label="3.bn2.weight
 (32)" fillcolor=lightblue]
	1993849260752 -> 1993775625504
	1993775625504 [label=AccumulateGrad]
	1993775625936 -> 1993775612832
	1993849260848 [label="3.bn2.bias
 (32)" fillcolor=lightblue]
	1993849260848 -> 1993775625936
	1993775625936 [label=AccumulateGrad]
	1993775621952 -> 1993775624832
	1993775624304 -> 1993775622288
	1993775624304 [label=ViewBackward0]
	1993775623728 -> 1993775624304
	1993775623728 [label=SigmoidBackward0]
	1993775619264 -> 1993775623728
	1993775619264 [label=AddmmBackward0]
	1993775622816 -> 1993775619264
	1993849258928 [label="4.fc2.bias
 (32)" fillcolor=lightblue]
	1993849258928 -> 1993775622816
	1993775622816 [label=AccumulateGrad]
	1993775624544 -> 1993775619264
	1993775624544 [label=ReluBackward0]
	1993775615808 -> 1993775624544
	1993775615808 [label=AddmmBackward0]
	1993775613264 -> 1993775615808
	1993849259120 [label="4.fc1.bias
 (2)" fillcolor=lightblue]
	1993849259120 -> 1993775613264
	1993775613264 [label=AccumulateGrad]
	1993775617968 -> 1993775615808
	1993775617968 [label=MeanBackward1]
	1993775617008 -> 1993775617968
	1993775617008 [label=ViewBackward0]
	1993775624064 -> 1993775617008
	1993775617536 -> 1993775615808
	1993775617536 [label=TBackward0]
	1993775621520 -> 1993775617536
	1993849259888 [label="4.fc1.weight
 (2, 32)" fillcolor=lightblue]
	1993849259888 -> 1993775621520
	1993775621520 [label=AccumulateGrad]
	1993775620608 -> 1993775619264
	1993775620608 [label=TBackward0]
	1993775618592 -> 1993775620608
	1993849258832 [label="4.fc2.weight
 (32, 2)" fillcolor=lightblue]
	1993849258832 -> 1993775618592
	1993775618592 [label=AccumulateGrad]
	1993775623104 -> 1993775625024
	1993849259024 [label="5.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	1993849259024 -> 1993775623104
	1993775623104 [label=AccumulateGrad]
	1993775623920 -> 1993775625024
	1993849259216 [label="5.bias
 (64)" fillcolor=lightblue]
	1993849259216 -> 1993775623920
	1993775623920 [label=AccumulateGrad]
	1993775620512 -> 1993775627904
	1993849259312 [label="6.weight
 (64)" fillcolor=lightblue]
	1993849259312 -> 1993775620512
	1993775620512 [label=AccumulateGrad]
	1993775628192 -> 1993775627904
	1993849259408 [label="6.bias
 (64)" fillcolor=lightblue]
	1993849259408 -> 1993775628192
	1993775628192 [label=AccumulateGrad]
	1993775624496 -> 1993775613648
	1993849259696 [label="8.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1993849259696 -> 1993775624496
	1993775624496 [label=AccumulateGrad]
	1993775619408 -> 1993775622384
	1993849258736 [label="8.bn1.weight
 (64)" fillcolor=lightblue]
	1993849258736 -> 1993775619408
	1993775619408 [label=AccumulateGrad]
	1993775621136 -> 1993775622384
	1993849258640 [label="8.bn1.bias
 (64)" fillcolor=lightblue]
	1993849258640 -> 1993775621136
	1993775621136 [label=AccumulateGrad]
	1993775623776 -> 1993775626320
	1993849258256 [label="8.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1993849258256 -> 1993775623776
	1993775623776 [label=AccumulateGrad]
	1993775626368 -> 1993775626224
	1993849258544 [label="8.bn2.weight
 (64)" fillcolor=lightblue]
	1993849258544 -> 1993775626368
	1993775626368 [label=AccumulateGrad]
	1993775626752 -> 1993775626224
	1993849258448 [label="8.bn2.bias
 (64)" fillcolor=lightblue]
	1993849258448 -> 1993775626752
	1993775626752 [label=AccumulateGrad]
	1993775625840 -> 1993775614848
	1993775613984 -> 1993775624352
	1993775613984 [label=UnsqueezeBackward0]
	1993775626848 -> 1993775613984
	1993775626848 [label=UnsqueezeBackward0]
	1993775625648 -> 1993775626848
	1993775625648 [label=SigmoidBackward0]
	1993775621424 -> 1993775625648
	1993775621424 [label=SqueezeBackward1]
	1993775627472 -> 1993775621424
	1993775627472 [label=ConvolutionBackward0]
	1993775625792 -> 1993775627472
	1993775625792 [label=UnsqueezeBackward0]
	1993775621232 -> 1993775625792
	1993775621232 [label=SqueezeBackward1]
	1993775623296 -> 1993775621232
	1993775623296 [label=SqueezeBackward1]
	1993775614224 -> 1993775623296
	1993775614224 [label=MeanBackward1]
	1993775614320 -> 1993775614224
	1993775627520 -> 1993775627472
	1993804699920 [label="9.conv.weight
 (1, 1, 3)" fillcolor=lightblue]
	1993804699920 -> 1993775627520
	1993775627520 [label=AccumulateGrad]
	1993775612016 -> 1993775624688
	1993804700016 [label="10.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1993804700016 -> 1993775612016
	1993775612016 [label=AccumulateGrad]
	1993775623248 -> 1993775616480
	1993804700112 [label="11.weight
 (128)" fillcolor=lightblue]
	1993804700112 -> 1993775623248
	1993775623248 [label=AccumulateGrad]
	1993775613792 -> 1993775616480
	1993804700208 [label="11.bias
 (128)" fillcolor=lightblue]
	1993804700208 -> 1993775613792
	1993775613792 [label=AccumulateGrad]
	1993775622240 -> 1993775614656
	1993804700592 [label="13.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1993804700592 -> 1993775622240
	1993775622240 [label=AccumulateGrad]
	1993775614944 -> 1993775625600
	1993804700688 [label="13.bn1.weight
 (128)" fillcolor=lightblue]
	1993804700688 -> 1993775614944
	1993775614944 [label=AccumulateGrad]
	1993775614080 -> 1993775625600
	1993804700784 [label="13.bn1.bias
 (128)" fillcolor=lightblue]
	1993804700784 -> 1993775614080
	1993775614080 [label=AccumulateGrad]
	1993775627376 -> 1993775627712
	1993804701168 [label="13.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1993804701168 -> 1993775627376
	1993775627376 [label=AccumulateGrad]
	1993775613360 -> 1993775615424
	1993804701264 [label="13.bn2.weight
 (128)" fillcolor=lightblue]
	1993804701264 -> 1993775613360
	1993775613360 [label=AccumulateGrad]
	1993775624592 -> 1993775615424
	1993804701360 [label="13.bn2.bias
 (128)" fillcolor=lightblue]
	1993804701360 -> 1993775624592
	1993775624592 [label=AccumulateGrad]
	1993775623056 -> 1993775624256
	1993775620368 -> 1993775612640
	1993775620368 [label=SigmoidBackward0]
	1993775615232 -> 1993775620368
	1993775615232 [label=ConvolutionBackward0]
	1993775614608 -> 1993775615232
	1993775614608 [label=NativeDropoutBackward0]
	1993775627184 -> 1993775614608
	1993775627184 [label=ReluBackward0]
	1993775628240 -> 1993775627184
	1993775628240 [label=ConvolutionBackward0]
	1993775612352 -> 1993775628240
	1993775612352 [label=MeanBackward1]
	1993775627760 -> 1993775612352
	1993775614560 -> 1993775628240
	1993804701744 [label="14.fc1.weight
 (8, 128, 1, 1)" fillcolor=lightblue]
	1993804701744 -> 1993775614560
	1993775614560 [label=AccumulateGrad]
	1993775620656 -> 1993775628240
	1993804701840 [label="14.fc1.bias
 (8)" fillcolor=lightblue]
	1993804701840 -> 1993775620656
	1993775620656 [label=AccumulateGrad]
	1993775622096 -> 1993775615232
	1993804701936 [label="14.fc2.weight
 (128, 8, 1, 1)" fillcolor=lightblue]
	1993804701936 -> 1993775622096
	1993775622096 [label=AccumulateGrad]
	1993775622528 -> 1993775615232
	1993804702032 [label="14.fc2.bias
 (128)" fillcolor=lightblue]
	1993804702032 -> 1993775622528
	1993775622528 [label=AccumulateGrad]
	1993775618736 -> 1993775619168
	1993804702128 [label="15.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1993804702128 -> 1993775618736
	1993775618736 [label=AccumulateGrad]
	1993775612592 -> 1993775615040
	1993804702224 [label="16.weight
 (256)" fillcolor=lightblue]
	1993804702224 -> 1993775612592
	1993775612592 [label=AccumulateGrad]
	1993775612976 -> 1993775615040
	1993804702320 [label="16.bias
 (256)" fillcolor=lightblue]
	1993804702320 -> 1993775612976
	1993775612976 [label=AccumulateGrad]
	1993775612448 -> 1993775624112
	1993804702704 [label="18.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1993804702704 -> 1993775612448
	1993775612448 [label=AccumulateGrad]
	1993775625888 -> 1993775628000
	1993804702800 [label="18.bn1.weight
 (256)" fillcolor=lightblue]
	1993804702800 -> 1993775625888
	1993775625888 [label=AccumulateGrad]
	1993775617344 -> 1993775628000
	1993804702896 [label="18.bn1.bias
 (256)" fillcolor=lightblue]
	1993804702896 -> 1993775617344
	1993775617344 [label=AccumulateGrad]
	1993775625744 -> 1993775626512
	1993804703280 [label="18.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1993804703280 -> 1993775625744
	1993775625744 [label=AccumulateGrad]
	1993775619792 -> 1993775622480
	1993804703376 [label="18.bn2.weight
 (256)" fillcolor=lightblue]
	1993804703376 -> 1993775619792
	1993775619792 [label=AccumulateGrad]
	1993775614800 -> 1993775622480
	1993804703472 [label="18.bn2.bias
 (256)" fillcolor=lightblue]
	1993804703472 -> 1993775614800
	1993775614800 [label=AccumulateGrad]
	1993775628096 -> 1993775612544
	1993775614176 -> 1993775627952
	1993775614176 [label=ViewBackward0]
	1993775624208 -> 1993775614176
	1993775624208 [label=SigmoidBackward0]
	1993775625312 -> 1993775624208
	1993775625312 [label=AddmmBackward0]
	1993775616768 -> 1993775625312
	1993804704144 [label="19.channel_att.fc2.bias
 (256)" fillcolor=lightblue]
	1993804704144 -> 1993775616768
	1993775616768 [label=AccumulateGrad]
	1993775619552 -> 1993775625312
	1993775619552 [label=ReluBackward0]
	1993775622960 -> 1993775619552
	1993775622960 [label=AddmmBackward0]
	1993775618160 -> 1993775622960
	1993804703952 [label="19.channel_att.fc1.bias
 (16)" fillcolor=lightblue]
	1993804703952 -> 1993775618160
	1993775618160 [label=AccumulateGrad]
	1993775624928 -> 1993775622960
	1993775624928 [label=MeanBackward1]
	1993775628144 -> 1993775624928
	1993775628144 [label=ViewBackward0]
	1993775624640 -> 1993775628144
	1993775618352 -> 1993775622960
	1993775618352 [label=TBackward0]
	1993775626080 -> 1993775618352
	1993804703856 [label="19.channel_att.fc1.weight
 (16, 256)" fillcolor=lightblue]
	1993804703856 -> 1993775626080
	1993775626080 [label=AccumulateGrad]
	1993775624160 -> 1993775625312
	1993775624160 [label=TBackward0]
	1993775622864 -> 1993775624160
	1993804704048 [label="19.channel_att.fc2.weight
 (256, 16)" fillcolor=lightblue]
	1993804704048 -> 1993775622864
	1993775622864 [label=AccumulateGrad]
	1993775621376 -> 1993775627856
	1993775621376 [label=SigmoidBackward0]
	1993775623488 -> 1993775621376
	1993775623488 [label=ConvolutionBackward0]
	1993775613456 -> 1993775623488
	1993775613456 [label=CatBackward0]
	1993775619744 -> 1993775613456
	1993775619744 [label=MeanBackward1]
	1993775627952 -> 1993775619744
	1993775619840 -> 1993775613456
	1993775619840 [label=MaxBackward0]
	1993775627952 -> 1993775619840
	1993775616192 -> 1993775623488
	1993804704240 [label="19.spatial_att.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1993804704240 -> 1993775616192
	1993775616192 [label=AccumulateGrad]
	1993775615520 -> 1993775619504
	1993775615520 [label=TBackward0]
	1993775618448 -> 1993775615520
	1993804704336 [label="23.weight
 (19, 256)" fillcolor=lightblue]
	1993804704336 -> 1993775618448
	1993775618448 [label=AccumulateGrad]
	1993775619504 -> 1993805124176
}
