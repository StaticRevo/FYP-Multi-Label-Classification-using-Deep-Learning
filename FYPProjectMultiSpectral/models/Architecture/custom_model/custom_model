digraph {
	graph [size="89.1,89.1"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1682927241648 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	1682927367408 [label=AddmmBackward0]
	1682927367072 -> 1682927367408
	1682928070160 [label="29.bias
 (19)" fillcolor=lightblue]
	1682928070160 -> 1682927367072
	1682927367072 [label=AccumulateGrad]
	1682927366448 -> 1682927367408
	1682927366448 [label=NativeDropoutBackward0]
	1682927365968 -> 1682927366448
	1682927365968 [label=ViewBackward0]
	1682927365632 -> 1682927365968
	1682927365632 [label=MeanBackward1]
	1682927365152 -> 1682927365632
	1682927365152 [label=MulBackward0]
	1682927364672 -> 1682927365152
	1682927364672 [label=MulBackward0]
	1682927363568 -> 1682927364672
	1682927363568 [label=ReluBackward0]
	1682927363232 -> 1682927363568
	1682927363232 [label=AddBackward0]
	1682927362752 -> 1682927363232
	1682927362752 [label=MulBackward0]
	1682927361648 -> 1682927362752
	1682927361648 [label=DivBackward0]
	1682927361168 -> 1682927361648
	1682927361168 [label=CudnnBatchNormBackward0]
	1682927360688 -> 1682927361168
	1682927360688 [label=ConvolutionBackward0]
	1682927359728 -> 1682927360688
	1682927359728 [label=NativeDropoutBackward0]
	1682927359392 -> 1682927359728
	1682927359392 [label=ReluBackward0]
	1682927358912 -> 1682927359392
	1682927358912 [label=CudnnBatchNormBackward0]
	1682927358432 -> 1682927358912
	1682927358432 [label=ConvolutionBackward0]
	1682927362608 -> 1682927358432
	1682927362608 [label=ReluBackward0]
	1682927356992 -> 1682927362608
	1682927356992 [label=CudnnBatchNormBackward0]
	1682927356512 -> 1682927356992
	1682927356512 [label=ConvolutionBackward0]
	1682927355552 -> 1682927356512
	1682927355552 [label=ConvolutionBackward0]
	1682927354448 -> 1682927355552
	1682927354448 [label=MulBackward0]
	1682927354112 -> 1682927354448
	1682927354112 [label=ReluBackward0]
	1682927370144 -> 1682927354112
	1682927370144 [label=AddBackward0]
	1682927369856 -> 1682927370144
	1682927369856 [label=MulBackward0]
	1682927369616 -> 1682927369856
	1682927369616 [label=DivBackward0]
	1682927369568 -> 1682927369616
	1682927369568 [label=CudnnBatchNormBackward0]
	1682927369424 -> 1682927369568
	1682927369424 [label=ConvolutionBackward0]
	1682927369136 -> 1682927369424
	1682927369136 [label=NativeDropoutBackward0]
	1682927369184 -> 1682927369136
	1682927369184 [label=ReluBackward0]
	1682927368896 -> 1682927369184
	1682927368896 [label=CudnnBatchNormBackward0]
	1682927368560 -> 1682927368896
	1682927368560 [label=ConvolutionBackward0]
	1682927369904 -> 1682927368560
	1682927369904 [label=ConvolutionBackward0]
	1682927368416 -> 1682927369904
	1682927368416 [label=CatBackward0]
	1682927368320 -> 1682927368416
	1682927368320 [label=ConvolutionBackward0]
	1682927367936 -> 1682927368320
	1682927367936 [label=ReluBackward0]
	1682927367840 -> 1682927367936
	1682927367840 [label=CudnnBatchNormBackward0]
	1682927367744 -> 1682927367840
	1682927367744 [label=ConvolutionBackward0]
	1682927367120 -> 1682927367744
	1682927367120 [label=ConvolutionBackward0]
	1682927367168 -> 1682927367120
	1682927367168 [label=MulBackward0]
	1682927366976 -> 1682927367168
	1682927366976 [label=ReluBackward0]
	1682927366736 -> 1682927366976
	1682927366736 [label=AddBackward0]
	1682927366688 -> 1682927366736
	1682927366688 [label=MulBackward0]
	1682927366496 -> 1682927366688
	1682927366496 [label=DivBackward0]
	1682927366160 -> 1682927366496
	1682927366160 [label=CudnnBatchNormBackward0]
	1682927366400 -> 1682927366160
	1682927366400 [label=ConvolutionBackward0]
	1682927366016 -> 1682927366400
	1682927366016 [label=NativeDropoutBackward0]
	1682927365776 -> 1682927366016
	1682927365776 [label=ReluBackward0]
	1682927365728 -> 1682927365776
	1682927365728 [label=CudnnBatchNormBackward0]
	1682927365584 -> 1682927365728
	1682927365584 [label=ConvolutionBackward0]
	1682927366880 -> 1682927365584
	1682927366880 [label=ConvolutionBackward0]
	1682927365248 -> 1682927366880
	1682927365248 [label=CatBackward0]
	1682927364912 -> 1682927365248
	1682927364912 [label=ConvolutionBackward0]
	1682927364768 -> 1682927364912
	1682927364768 [label=ReluBackward0]
	1682927364432 -> 1682927364768
	1682927364432 [label=CudnnBatchNormBackward0]
	1682927364336 -> 1682927364432
	1682927364336 [label=ConvolutionBackward0]
	1682927364144 -> 1682927364336
	1682927364144 [label=ConvolutionBackward0]
	1682927363760 -> 1682927364144
	1682927363760 [label=MulBackward0]
	1682927363808 -> 1682927363760
	1682927363808 [label=MulBackward0]
	1682927363616 -> 1682927363808
	1682927363616 [label=MulBackward0]
	1682927363376 -> 1682927363616
	1682927363376 [label=ReluBackward0]
	1682927363424 -> 1682927363376
	1682927363424 [label=AddBackward0]
	1682927363136 -> 1682927363424
	1682927363136 [label=MulBackward0]
	1682927362896 -> 1682927363136
	1682927362896 [label=DivBackward0]
	1682927362848 -> 1682927362896
	1682927362848 [label=CudnnBatchNormBackward0]
	1682927362704 -> 1682927362848
	1682927362704 [label=ConvolutionBackward0]
	1682927362416 -> 1682927362704
	1682927362416 [label=NativeDropoutBackward0]
	1682927362464 -> 1682927362416
	1682927362464 [label=ReluBackward0]
	1682927362176 -> 1682927362464
	1682927362176 [label=CudnnBatchNormBackward0]
	1682927361840 -> 1682927362176
	1682927361840 [label=ConvolutionBackward0]
	1682927363184 -> 1682927361840
	1682927363184 [label=ReluBackward0]
	1682927361696 -> 1682927363184
	1682927361696 [label=CudnnBatchNormBackward0]
	1682927361360 -> 1682927361696
	1682927361360 [label=ConvolutionBackward0]
	1682927361504 -> 1682927361360
	1682927361504 [label=ConvolutionBackward0]
	1682927361072 -> 1682927361504
	1682927361072 [label=ReluBackward0]
	1682927361120 -> 1682927361072
	1682927361120 [label=CudnnBatchNormBackward0]
	1682927361024 -> 1682927361120
	1682927361024 [label=ConvolutionBackward0]
	1682927360400 -> 1682927361024
	1682968694704 [label="0.weight
 (16, 12, 1, 1)" fillcolor=lightblue]
	1682968694704 -> 1682927360400
	1682927360400 [label=AccumulateGrad]
	1682927360928 -> 1682927361120
	1682968693936 [label="1.weight
 (16)" fillcolor=lightblue]
	1682968693936 -> 1682927360928
	1682927360928 [label=AccumulateGrad]
	1682927360880 -> 1682927361120
	1682968693648 [label="1.bias
 (16)" fillcolor=lightblue]
	1682968693648 -> 1682927360880
	1682927360880 [label=AccumulateGrad]
	1682927361216 -> 1682927361504
	1682968694224 [label="3.depthwise.weight
 (16, 1, 3, 3)" fillcolor=lightblue]
	1682968694224 -> 1682927361216
	1682927361216 [label=AccumulateGrad]
	1682927361408 -> 1682927361360
	1682968694320 [label="3.pointwise.weight
 (32, 16, 1, 1)" fillcolor=lightblue]
	1682968694320 -> 1682927361408
	1682927361408 [label=AccumulateGrad]
	1682927361552 -> 1682927361696
	1682968694128 [label="4.weight
 (32)" fillcolor=lightblue]
	1682968694128 -> 1682927361552
	1682927361552 [label=AccumulateGrad]
	1682927362080 -> 1682927361696
	1682968694416 [label="4.bias
 (32)" fillcolor=lightblue]
	1682968694416 -> 1682927362080
	1682927362080 [label=AccumulateGrad]
	1682927361984 -> 1682927361840
	1682968692688 [label="6.conv1.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1682968692688 -> 1682927361984
	1682927361984 [label=AccumulateGrad]
	1682927362032 -> 1682927362176
	1682968693456 [label="6.bn1.weight
 (32)" fillcolor=lightblue]
	1682968693456 -> 1682927362032
	1682927362032 [label=AccumulateGrad]
	1682927362560 -> 1682927362176
	1682968692400 [label="6.bn1.bias
 (32)" fillcolor=lightblue]
	1682968692400 -> 1682927362560
	1682927362560 [label=AccumulateGrad]
	1682927362320 -> 1682927362704
	1682968692976 [label="6.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1682968692976 -> 1682927362320
	1682927362320 [label=AccumulateGrad]
	1682927362944 -> 1682927362848
	1682968692880 [label="6.bn2.weight
 (32)" fillcolor=lightblue]
	1682968692880 -> 1682927362944
	1682927362944 [label=AccumulateGrad]
	1682927362992 -> 1682927362848
	1682968693072 [label="6.bn2.bias
 (32)" fillcolor=lightblue]
	1682968693072 -> 1682927362992
	1682927362992 [label=AccumulateGrad]
	1682927363184 -> 1682927363424
	1682927363280 -> 1682927363616
	1682927363280 [label=ViewBackward0]
	1682927362800 -> 1682927363280
	1682927362800 [label=SigmoidBackward0]
	1682927362656 -> 1682927362800
	1682927362656 [label=AddmmBackward0]
	1682927361936 -> 1682927362656
	1682968691056 [label="7.fc2.bias
 (32)" fillcolor=lightblue]
	1682968691056 -> 1682927361936
	1682927361936 [label=AccumulateGrad]
	1682927362512 -> 1682927362656
	1682927362512 [label=ReluBackward0]
	1682927362368 -> 1682927362512
	1682927362368 [label=AddmmBackward0]
	1682927361744 -> 1682927362368
	1682968692208 [label="7.fc1.bias
 (2)" fillcolor=lightblue]
	1682968692208 -> 1682927361744
	1682927361744 [label=AccumulateGrad]
	1682927361456 -> 1682927362368
	1682927361456 [label=MeanBackward1]
	1682927360592 -> 1682927361456
	1682927360592 [label=ViewBackward0]
	1682927363376 -> 1682927360592
	1682927361600 -> 1682927362368
	1682927361600 [label=TBackward0]
	1682927360640 -> 1682927361600
	1682968692304 [label="7.fc1.weight
 (2, 32)" fillcolor=lightblue]
	1682968692304 -> 1682927360640
	1682927360640 [label=AccumulateGrad]
	1682927363328 -> 1682927362656
	1682927363328 [label=TBackward0]
	1682927360496 -> 1682927363328
	1682968691632 [label="7.fc2.weight
 (32, 2)" fillcolor=lightblue]
	1682968691632 -> 1682927360496
	1682927360496 [label=AccumulateGrad]
	1682927363664 -> 1682927363808
	1682927363664 [label=SigmoidBackward0]
	1682927363040 -> 1682927363664
	1682927363040 [label=ConvolutionBackward0]
	1682927360784 -> 1682927363040
	1682927360784 [label=SplitWithSizesBackward0]
	1682927361888 -> 1682927360784
	1682927361888 [label=ReluBackward0]
	1682927360448 -> 1682927361888
	1682927360448 [label=CudnnBatchNormBackward0]
	1682927360304 -> 1682927360448
	1682927360304 [label=ConvolutionBackward0]
	1682927360016 -> 1682927360304
	1682927360016 [label=CatBackward0]
	1682927360064 -> 1682927360016
	1682927360064 [label=AdaptiveAvgPool2DBackward0]
	1682927363616 -> 1682927360064
	1682927359968 -> 1682927360016
	1682927359968 [label=PermuteBackward0]
	1682927359824 -> 1682927359968
	1682927359824 [label=AdaptiveAvgPool2DBackward0]
	1682927363616 -> 1682927359824
	1682927359920 -> 1682927360304
	1682968692016 [label="8.conv1.weight
 (8, 32, 1, 1)" fillcolor=lightblue]
	1682968692016 -> 1682927359920
	1682927359920 [label=AccumulateGrad]
	1682927360544 -> 1682927360448
	1682968691248 [label="8.bn1.weight
 (8)" fillcolor=lightblue]
	1682968691248 -> 1682927360544
	1682927360544 [label=AccumulateGrad]
	1682927360976 -> 1682927360448
	1682968690960 [label="8.bn1.bias
 (8)" fillcolor=lightblue]
	1682968690960 -> 1682927360976
	1682927360976 [label=AccumulateGrad]
	1682927362224 -> 1682927363040
	1682968692112 [label="8.conv_h.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	1682968692112 -> 1682927362224
	1682927362224 [label=AccumulateGrad]
	1682927364000 -> 1682927363760
	1682927364000 [label=PermuteBackward0]
	1682927363472 -> 1682927364000
	1682927363472 [label=SigmoidBackward0]
	1682927361264 -> 1682927363472
	1682927361264 [label=ConvolutionBackward0]
	1682927360784 -> 1682927361264
	1682927360112 -> 1682927361264
	1682968691824 [label="8.conv_w.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	1682968691824 -> 1682927360112
	1682927360112 [label=AccumulateGrad]
	1682927363952 -> 1682927364144
	1682928062384 [label="9.depthwise.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	1682928062384 -> 1682927363952
	1682927363952 [label=AccumulateGrad]
	1682927364384 -> 1682927364336
	1682928062480 [label="9.pointwise.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	1682928062480 -> 1682927364384
	1682927364384 [label=AccumulateGrad]
	1682927364240 -> 1682927364432
	1682968691920 [label="10.weight
 (64)" fillcolor=lightblue]
	1682968691920 -> 1682927364240
	1682927364240 [label=AccumulateGrad]
	1682927364624 -> 1682927364432
	1682928062576 [label="10.bias
 (64)" fillcolor=lightblue]
	1682928062576 -> 1682927364624
	1682927364624 [label=AccumulateGrad]
	1682927364960 -> 1682927364912
	1682928063056 [label="12.conv_dil1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1682928063056 -> 1682927364960
	1682927364960 [label=AccumulateGrad]
	1682927364816 -> 1682927364912
	1682928063152 [label="12.conv_dil1.bias
 (64)" fillcolor=lightblue]
	1682928063152 -> 1682927364816
	1682927364816 [label=AccumulateGrad]
	1682927365056 -> 1682927365248
	1682927365056 [label=ConvolutionBackward0]
	1682927364768 -> 1682927365056
	1682927364480 -> 1682927365056
	1682928063248 [label="12.conv_dil2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1682928063248 -> 1682927364480
	1682927364480 [label=AccumulateGrad]
	1682927364576 -> 1682927365056
	1682928063344 [label="12.conv_dil2.bias
 (64)" fillcolor=lightblue]
	1682928063344 -> 1682927364576
	1682927364576 [label=AccumulateGrad]
	1682927365104 -> 1682927365248
	1682927365104 [label=ConvolutionBackward0]
	1682927364768 -> 1682927365104
	1682927363520 -> 1682927365104
	1682928063440 [label="12.conv_dil3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1682928063440 -> 1682927363520
	1682927363520 [label=AccumulateGrad]
	1682927364288 -> 1682927365104
	1682928063536 [label="12.conv_dil3.bias
 (64)" fillcolor=lightblue]
	1682928063536 -> 1682927364288
	1682927364288 [label=AccumulateGrad]
	1682927365440 -> 1682927366880
	1682928063632 [label="12.fuse.weight
 (64, 192, 1, 1)" fillcolor=lightblue]
	1682928063632 -> 1682927365440
	1682927365440 [label=AccumulateGrad]
	1682927365392 -> 1682927366880
	1682928063728 [label="12.fuse.bias
 (64)" fillcolor=lightblue]
	1682928063728 -> 1682927365392
	1682927365392 [label=AccumulateGrad]
	1682927365296 -> 1682927365584
	1682928063824 [label="13.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1682928063824 -> 1682927365296
	1682927365296 [label=AccumulateGrad]
	1682927365824 -> 1682927365728
	1682928062960 [label="13.bn1.weight
 (64)" fillcolor=lightblue]
	1682928062960 -> 1682927365824
	1682927365824 [label=AccumulateGrad]
	1682927365872 -> 1682927365728
	1682928063920 [label="13.bn1.bias
 (64)" fillcolor=lightblue]
	1682928063920 -> 1682927365872
	1682927365872 [label=AccumulateGrad]
	1682927366064 -> 1682927366400
	1682928064400 [label="13.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1682928064400 -> 1682927366064
	1682927366064 [label=AccumulateGrad]
	1682927366256 -> 1682927366160
	1682928064304 [label="13.bn2.weight
 (64)" fillcolor=lightblue]
	1682928064304 -> 1682927366256
	1682927366256 [label=AccumulateGrad]
	1682927366784 -> 1682927366160
	1682928064496 [label="13.bn2.bias
 (64)" fillcolor=lightblue]
	1682928064496 -> 1682927366784
	1682927366784 [label=AccumulateGrad]
	1682927366880 -> 1682927366736
	1682927367024 -> 1682927367168
	1682927367024 [label=UnsqueezeBackward0]
	1682927366544 -> 1682927367024
	1682927366544 [label=UnsqueezeBackward0]
	1682927366208 -> 1682927366544
	1682927366208 [label=SigmoidBackward0]
	1682927365536 -> 1682927366208
	1682927365536 [label=SqueezeBackward1]
	1682927365680 -> 1682927365536
	1682927365680 [label=ConvolutionBackward0]
	1682927364864 -> 1682927365680
	1682927364864 [label=UnsqueezeBackward0]
	1682927360256 -> 1682927364864
	1682927360256 [label=SqueezeBackward1]
	1682927363856 -> 1682927360256
	1682927363856 [label=SqueezeBackward1]
	1682927359776 -> 1682927363856
	1682927359776 [label=MeanBackward1]
	1682927366976 -> 1682927359776
	1682927365200 -> 1682927365680
	1682928064976 [label="14.conv.weight
 (1, 1, 3)" fillcolor=lightblue]
	1682928064976 -> 1682927365200
	1682927365200 [label=AccumulateGrad]
	1682927367360 -> 1682927367120
	1682928065072 [label="15.depthwise.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	1682928065072 -> 1682927367360
	1682927367360 [label=AccumulateGrad]
	1682927367312 -> 1682927367744
	1682928065168 [label="15.pointwise.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1682928065168 -> 1682927367312
	1682927367312 [label=AccumulateGrad]
	1682927367648 -> 1682927367840
	1682928064880 [label="16.weight
 (128)" fillcolor=lightblue]
	1682928064880 -> 1682927367648
	1682927367648 [label=AccumulateGrad]
	1682927367600 -> 1682927367840
	1682928065264 [label="16.bias
 (128)" fillcolor=lightblue]
	1682928065264 -> 1682927367600
	1682927367600 [label=AccumulateGrad]
	1682927367984 -> 1682927368320
	1682928065744 [label="18.conv_dil1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1682928065744 -> 1682927367984
	1682927367984 [label=AccumulateGrad]
	1682927368224 -> 1682927368320
	1682928065840 [label="18.conv_dil1.bias
 (128)" fillcolor=lightblue]
	1682928065840 -> 1682927368224
	1682927368224 [label=AccumulateGrad]
	1682927368176 -> 1682927368416
	1682927368176 [label=ConvolutionBackward0]
	1682927367936 -> 1682927368176
	1682927367504 -> 1682927368176
	1682928065936 [label="18.conv_dil2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1682928065936 -> 1682927367504
	1682927367504 [label=AccumulateGrad]
	1682927367696 -> 1682927368176
	1682928066032 [label="18.conv_dil2.bias
 (128)" fillcolor=lightblue]
	1682928066032 -> 1682927367696
	1682927367696 [label=AccumulateGrad]
	1682927368080 -> 1682927368416
	1682927368080 [label=ConvolutionBackward0]
	1682927367936 -> 1682927368080
	1682927366832 -> 1682927368080
	1682928066128 [label="18.conv_dil3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1682928066128 -> 1682927366832
	1682927366832 [label=AccumulateGrad]
	1682927367456 -> 1682927368080
	1682928066224 [label="18.conv_dil3.bias
 (128)" fillcolor=lightblue]
	1682928066224 -> 1682927367456
	1682927367456 [label=AccumulateGrad]
	1682927368464 -> 1682927369904
	1682928066320 [label="18.fuse.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	1682928066320 -> 1682927368464
	1682927368464 [label=AccumulateGrad]
	1682927368800 -> 1682927369904
	1682928066416 [label="18.fuse.bias
 (128)" fillcolor=lightblue]
	1682928066416 -> 1682927368800
	1682927368800 [label=AccumulateGrad]
	1682927368704 -> 1682927368560
	1682928066512 [label="19.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1682928066512 -> 1682927368704
	1682927368704 [label=AccumulateGrad]
	1682927368752 -> 1682927368896
	1682928065648 [label="19.bn1.weight
 (128)" fillcolor=lightblue]
	1682928065648 -> 1682927368752
	1682927368752 [label=AccumulateGrad]
	1682927369280 -> 1682927368896
	1682928066608 [label="19.bn1.bias
 (128)" fillcolor=lightblue]
	1682928066608 -> 1682927369280
	1682927369280 [label=AccumulateGrad]
	1682927369040 -> 1682927369424
	1682928067088 [label="19.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1682928067088 -> 1682927369040
	1682927369040 [label=AccumulateGrad]
	1682927369664 -> 1682927369568
	1682928066992 [label="19.bn2.weight
 (128)" fillcolor=lightblue]
	1682928066992 -> 1682927369664
	1682927369664 [label=AccumulateGrad]
	1682927369712 -> 1682927369568
	1682928067184 [label="19.bn2.bias
 (128)" fillcolor=lightblue]
	1682928067184 -> 1682927369712
	1682927369712 [label=AccumulateGrad]
	1682927369904 -> 1682927370144
	1682927353968 -> 1682927354448
	1682927353968 [label=SigmoidBackward0]
	1682927369520 -> 1682927353968
	1682927369520 [label=ConvolutionBackward0]
	1682927369376 -> 1682927369520
	1682927369376 [label=NativeDropoutBackward0]
	1682927368944 -> 1682927369376
	1682927368944 [label=ReluBackward0]
	1682927368608 -> 1682927368944
	1682927368608 [label=ConvolutionBackward0]
	1682927368128 -> 1682927368608
	1682927368128 [label=MeanBackward1]
	1682927354112 -> 1682927368128
	1682927367792 -> 1682927368608
	1682928067664 [label="20.fc1.weight
 (8, 128, 1, 1)" fillcolor=lightblue]
	1682928067664 -> 1682927367792
	1682927367792 [label=AccumulateGrad]
	1682927369760 -> 1682927369520
	1682928067760 [label="20.fc2.weight
 (128, 8, 1, 1)" fillcolor=lightblue]
	1682928067760 -> 1682927369760
	1682927369760 [label=AccumulateGrad]
	1682927355072 -> 1682927355552
	1682928067856 [label="21.depthwise.weight
 (128, 1, 3, 3)" fillcolor=lightblue]
	1682928067856 -> 1682927355072
	1682927355072 [label=AccumulateGrad]
	1682927355408 -> 1682927356512
	1682928067952 [label="21.pointwise.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1682928067952 -> 1682927355408
	1682927355408 [label=AccumulateGrad]
	1682927356368 -> 1682927356992
	1682928067568 [label="22.weight
 (256)" fillcolor=lightblue]
	1682928067568 -> 1682927356368
	1682927356368 [label=AccumulateGrad]
	1682927357952 -> 1682927356992
	1682928068048 [label="22.bias
 (256)" fillcolor=lightblue]
	1682928068048 -> 1682927357952
	1682927357952 [label=AccumulateGrad]
	1682927357472 -> 1682927358432
	1682928068528 [label="24.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1682928068528 -> 1682927357472
	1682927357472 [label=AccumulateGrad]
	1682927358288 -> 1682927358912
	1682928068432 [label="24.bn1.weight
 (256)" fillcolor=lightblue]
	1682928068432 -> 1682927358288
	1682927358288 [label=AccumulateGrad]
	1682927359872 -> 1682927358912
	1682928068624 [label="24.bn1.bias
 (256)" fillcolor=lightblue]
	1682928068624 -> 1682927359872
	1682927359872 [label=AccumulateGrad]
	1682927360352 -> 1682927360688
	1682928069104 [label="24.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1682928069104 -> 1682927360352
	1682927360352 [label=AccumulateGrad]
	1682927361312 -> 1682927361168
	1682928069008 [label="24.bn2.weight
 (256)" fillcolor=lightblue]
	1682928069008 -> 1682927361312
	1682927361312 [label=AccumulateGrad]
	1682927362128 -> 1682927361168
	1682928069200 [label="24.bn2.bias
 (256)" fillcolor=lightblue]
	1682928069200 -> 1682927362128
	1682927362128 [label=AccumulateGrad]
	1682927362608 -> 1682927363232
	1682927364192 -> 1682927364672
	1682927364192 [label=ViewBackward0]
	1682927362272 -> 1682927364192
	1682927362272 [label=SigmoidBackward0]
	1682927360832 -> 1682927362272
	1682927360832 [label=AddmmBackward0]
	1682927357808 -> 1682927360832
	1682928069872 [label="25.channel_att.fc2.bias
 (256)" fillcolor=lightblue]
	1682928069872 -> 1682927357808
	1682927357808 [label=AccumulateGrad]
	1682927360208 -> 1682927360832
	1682927360208 [label=ReluBackward0]
	1682927359248 -> 1682927360208
	1682927359248 [label=AddmmBackward0]
	1682927356848 -> 1682927359248
	1682928069680 [label="25.channel_att.fc1.bias
 (16)" fillcolor=lightblue]
	1682928069680 -> 1682927356848
	1682927356848 [label=AccumulateGrad]
	1682927355888 -> 1682927359248
	1682927355888 [label=MeanBackward1]
	1682927370048 -> 1682927355888
	1682927370048 [label=ViewBackward0]
	1682927363568 -> 1682927370048
	1682927356032 -> 1682927359248
	1682927356032 [label=TBackward0]
	1682927369232 -> 1682927356032
	1682928069584 [label="25.channel_att.fc1.weight
 (16, 256)" fillcolor=lightblue]
	1682928069584 -> 1682927369232
	1682927369232 [label=AccumulateGrad]
	1682927363088 -> 1682927360832
	1682927363088 [label=TBackward0]
	1682927369088 -> 1682927363088
	1682928069776 [label="25.channel_att.fc2.weight
 (256, 16)" fillcolor=lightblue]
	1682928069776 -> 1682927369088
	1682927369088 [label=AccumulateGrad]
	1682927364528 -> 1682927365152
	1682927364528 [label=SigmoidBackward0]
	1682927361792 -> 1682927364528
	1682927361792 [label=ConvolutionBackward0]
	1682927370192 -> 1682927361792
	1682927370192 [label=CatBackward0]
	1682927357328 -> 1682927370192
	1682927357328 [label=MeanBackward1]
	1682927364672 -> 1682927357328
	1682927368656 -> 1682927370192
	1682927368656 [label=MaxBackward0]
	1682927364672 -> 1682927368656
	1682927358768 -> 1682927361792
	1682928070064 [label="25.spatial_att.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1682928070064 -> 1682927358768
	1682927358768 [label=AccumulateGrad]
	1682927366592 -> 1682927367408
	1682927366592 [label=TBackward0]
	1682927365008 -> 1682927366592
	1682928069968 [label="29.weight
 (19, 256)" fillcolor=lightblue]
	1682928069968 -> 1682927365008
	1682927365008 [label=AccumulateGrad]
	1682927367408 -> 1682927241648
}
