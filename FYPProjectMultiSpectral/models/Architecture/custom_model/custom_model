digraph {
	graph [size="86.7,86.7"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2440536328912 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2440536209056 [label=AddmmBackward0]
	2440536207952 -> 2440536209056
	2440537010832 [label="29.bias
 (19)" fillcolor=lightblue]
	2440537010832 -> 2440536207952
	2440536207952 [label=AccumulateGrad]
	2440536208096 -> 2440536209056
	2440536208096 [label=NativeDropoutBackward0]
	2440536207616 -> 2440536208096
	2440536207616 [label=ViewBackward0]
	2440536206512 -> 2440536207616
	2440536206512 [label=MeanBackward1]
	2440536206032 -> 2440536206512
	2440536206032 [label=MulBackward0]
	2440536205552 -> 2440536206032
	2440536205552 [label=MulBackward0]
	2440536205216 -> 2440536205552
	2440536205216 [label=ReluBackward0]
	2440536204112 -> 2440536205216
	2440536204112 [label=AddBackward0]
	2440536203632 -> 2440536204112
	2440536203632 [label=CudnnBatchNormBackward0]
	2440536203296 -> 2440536203632
	2440536203296 [label=ConvolutionBackward0]
	2440536202336 -> 2440536203296
	2440536202336 [label=ReluBackward0]
	2440536201232 -> 2440536202336
	2440536201232 [label=CudnnBatchNormBackward0]
	2440536200752 -> 2440536201232
	2440536200752 [label=ConvolutionBackward0]
	2440536204256 -> 2440536200752
	2440536204256 [label=ReluBackward0]
	2440536199312 -> 2440536204256
	2440536199312 [label=CudnnBatchNormBackward0]
	2440536198832 -> 2440536199312
	2440536198832 [label=ConvolutionBackward0]
	2440536197872 -> 2440536198832
	2440536197872 [label=ConvolutionBackward0]
	2440536197536 -> 2440536197872
	2440536197536 [label=MulBackward0]
	2440536196432 -> 2440536197536
	2440536196432 [label=ReluBackward0]
	2440536196096 -> 2440536196432
	2440536196096 [label=AddBackward0]
	2440536195616 -> 2440536196096
	2440536195616 [label=CudnnBatchNormBackward0]
	2440536211168 -> 2440536195616
	2440536211168 [label=ConvolutionBackward0]
	2440536210544 -> 2440536211168
	2440536210544 [label=ReluBackward0]
	2440536210592 -> 2440536210544
	2440536210592 [label=CudnnBatchNormBackward0]
	2440536210448 -> 2440536210592
	2440536210448 [label=ConvolutionBackward0]
	2440536195472 -> 2440536210448
	2440536195472 [label=ConvolutionBackward0]
	2440536210112 -> 2440536195472
	2440536210112 [label=CatBackward0]
	2440536209776 -> 2440536210112
	2440536209776 [label=ConvolutionBackward0]
	2440536209632 -> 2440536209776
	2440536209632 [label=ReluBackward0]
	2440536209296 -> 2440536209632
	2440536209296 [label=CudnnBatchNormBackward0]
	2440536209200 -> 2440536209296
	2440536209200 [label=ConvolutionBackward0]
	2440536209008 -> 2440536209200
	2440536209008 [label=ConvolutionBackward0]
	2440536208624 -> 2440536209008
	2440536208624 [label=MulBackward0]
	2440536208672 -> 2440536208624
	2440536208672 [label=ReluBackward0]
	2440536208480 -> 2440536208672
	2440536208480 [label=AddBackward0]
	2440536208144 -> 2440536208480
	2440536208144 [label=CudnnBatchNormBackward0]
	2440536208192 -> 2440536208144
	2440536208192 [label=ConvolutionBackward0]
	2440536207856 -> 2440536208192
	2440536207856 [label=ReluBackward0]
	2440536207904 -> 2440536207856
	2440536207904 [label=CudnnBatchNormBackward0]
	2440536207808 -> 2440536207904
	2440536207808 [label=ConvolutionBackward0]
	2440536208336 -> 2440536207808
	2440536208336 [label=ConvolutionBackward0]
	2440536207424 -> 2440536208336
	2440536207424 [label=CatBackward0]
	2440536207040 -> 2440536207424
	2440536207040 [label=ConvolutionBackward0]
	2440536206944 -> 2440536207040
	2440536206944 [label=ReluBackward0]
	2440536206560 -> 2440536206944
	2440536206560 [label=CudnnBatchNormBackward0]
	2440536206224 -> 2440536206560
	2440536206224 [label=ConvolutionBackward0]
	2440536206368 -> 2440536206224
	2440536206368 [label=ConvolutionBackward0]
	2440536205936 -> 2440536206368
	2440536205936 [label=MulBackward0]
	2440536205984 -> 2440536205936
	2440536205984 [label=MulBackward0]
	2440536205648 -> 2440536205984
	2440536205648 [label=MulBackward0]
	2440536205264 -> 2440536205648
	2440536205264 [label=ReluBackward0]
	2440536205312 -> 2440536205264
	2440536205312 [label=AddBackward0]
	2440536205168 -> 2440536205312
	2440536205168 [label=CudnnBatchNormBackward0]
	2440536204784 -> 2440536205168
	2440536204784 [label=ConvolutionBackward0]
	2440536204928 -> 2440536204784
	2440536204928 [label=ReluBackward0]
	2440536204496 -> 2440536204928
	2440536204496 [label=CudnnBatchNormBackward0]
	2440536204400 -> 2440536204496
	2440536204400 [label=ConvolutionBackward0]
	2440536205408 -> 2440536204400
	2440536205408 [label=ReluBackward0]
	2440536204016 -> 2440536205408
	2440536204016 [label=CudnnBatchNormBackward0]
	2440536203920 -> 2440536204016
	2440536203920 [label=ConvolutionBackward0]
	2440536203728 -> 2440536203920
	2440536203728 [label=ConvolutionBackward0]
	2440536203344 -> 2440536203728
	2440536203344 [label=ReluBackward0]
	2440536203392 -> 2440536203344
	2440536203392 [label=CudnnBatchNormBackward0]
	2440536203248 -> 2440536203392
	2440536203248 [label=ConvolutionBackward0]
	2440536202960 -> 2440536203248
	2440693306224 [label="0.weight
 (16, 12, 1, 1)" fillcolor=lightblue]
	2440693306224 -> 2440536202960
	2440536202960 [label=AccumulateGrad]
	2440536203488 -> 2440536203392
	2440693305456 [label="1.weight
 (16)" fillcolor=lightblue]
	2440693305456 -> 2440536203488
	2440536203488 [label=AccumulateGrad]
	2440536203440 -> 2440536203392
	2440693305168 [label="1.bias
 (16)" fillcolor=lightblue]
	2440693305168 -> 2440536203440
	2440536203440 [label=AccumulateGrad]
	2440536203536 -> 2440536203728
	2440693305648 [label="3.depthwise.weight
 (16, 1, 3, 3)" fillcolor=lightblue]
	2440693305648 -> 2440536203536
	2440536203536 [label=AccumulateGrad]
	2440536203968 -> 2440536203920
	2440693305744 [label="3.pointwise.weight
 (32, 16, 1, 1)" fillcolor=lightblue]
	2440693305744 -> 2440536203968
	2440536203968 [label=AccumulateGrad]
	2440536203824 -> 2440536204016
	2440693305840 [label="4.weight
 (32)" fillcolor=lightblue]
	2440693305840 -> 2440536203824
	2440536203824 [label=AccumulateGrad]
	2440536204352 -> 2440536204016
	2440693305936 [label="4.bias
 (32)" fillcolor=lightblue]
	2440693305936 -> 2440536204352
	2440536204352 [label=AccumulateGrad]
	2440536204208 -> 2440536204400
	2440693304976 [label="6.conv1.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2440693304976 -> 2440536204208
	2440536204208 [label=AccumulateGrad]
	2440536204304 -> 2440536204496
	2440693304208 [label="6.bn1.weight
 (32)" fillcolor=lightblue]
	2440693304208 -> 2440536204304
	2440536204304 [label=AccumulateGrad]
	2440536204688 -> 2440536204496
	2440693303920 [label="6.bn1.bias
 (32)" fillcolor=lightblue]
	2440693303920 -> 2440536204688
	2440536204688 [label=AccumulateGrad]
	2440536204832 -> 2440536204784
	2440693304400 [label="6.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2440693304400 -> 2440536204832
	2440536204832 [label=AccumulateGrad]
	2440536204976 -> 2440536205168
	2440693304496 [label="6.bn2.weight
 (32)" fillcolor=lightblue]
	2440693304496 -> 2440536204976
	2440536204976 [label=AccumulateGrad]
	2440536205120 -> 2440536205168
	2440693304592 [label="6.bn2.bias
 (32)" fillcolor=lightblue]
	2440693304592 -> 2440536205120
	2440536205120 [label=AccumulateGrad]
	2440536205408 -> 2440536205312
	2440536205456 -> 2440536205648
	2440536205456 [label=ViewBackward0]
	2440536204880 -> 2440536205456
	2440536204880 [label=SigmoidBackward0]
	2440536204448 -> 2440536204880
	2440536204448 [label=AddmmBackward0]
	2440536204640 -> 2440536204448
	2440693302576 [label="7.fc2.bias
 (32)" fillcolor=lightblue]
	2440693302576 -> 2440536204640
	2440536204640 [label=AccumulateGrad]
	2440536204544 -> 2440536204448
	2440536204544 [label=ReluBackward0]
	2440536204064 -> 2440536204544
	2440536204064 [label=AddmmBackward0]
	2440536203680 -> 2440536204064
	2440693303728 [label="7.fc1.bias
 (2)" fillcolor=lightblue]
	2440693303728 -> 2440536203680
	2440536203680 [label=AccumulateGrad]
	2440536202864 -> 2440536204064
	2440536202864 [label=MeanBackward1]
	2440536202912 -> 2440536202864
	2440536202912 [label=ViewBackward0]
	2440536205264 -> 2440536202912
	2440536203200 -> 2440536204064
	2440536203200 [label=TBackward0]
	2440536203008 -> 2440536203200
	2440693303824 [label="7.fc1.weight
 (2, 32)" fillcolor=lightblue]
	2440693303824 -> 2440536203008
	2440536203008 [label=AccumulateGrad]
	2440536205504 -> 2440536204448
	2440536205504 [label=TBackward0]
	2440536202768 -> 2440536205504
	2440693302960 [label="7.fc2.weight
 (32, 2)" fillcolor=lightblue]
	2440693302960 -> 2440536202768
	2440536202768 [label=AccumulateGrad]
	2440536205888 -> 2440536205984
	2440536205888 [label=SigmoidBackward0]
	2440536205024 -> 2440536205888
	2440536205024 [label=ConvolutionBackward0]
	2440536203584 -> 2440536205024
	2440536203584 [label=SplitWithSizesBackward0]
	2440536204160 -> 2440536203584
	2440536204160 [label=ReluBackward0]
	2440536202576 -> 2440536204160
	2440536202576 [label=CudnnBatchNormBackward0]
	2440536202480 -> 2440536202576
	2440536202480 [label=ConvolutionBackward0]
	2440536202288 -> 2440536202480
	2440536202288 [label=CatBackward0]
	2440536201904 -> 2440536202288
	2440536201904 [label=AdaptiveAvgPool2DBackward0]
	2440536205648 -> 2440536201904
	2440536202096 -> 2440536202288
	2440536202096 [label=PermuteBackward0]
	2440536202000 -> 2440536202096
	2440536202000 [label=AdaptiveAvgPool2DBackward0]
	2440536205648 -> 2440536202000
	2440536202528 -> 2440536202480
	2440693303440 [label="8.conv1.weight
 (8, 32, 1, 1)" fillcolor=lightblue]
	2440693303440 -> 2440536202528
	2440536202528 [label=AccumulateGrad]
	2440536202384 -> 2440536202576
	2440693301616 [label="8.bn1.weight
 (8)" fillcolor=lightblue]
	2440693301616 -> 2440536202384
	2440536202384 [label=AccumulateGrad]
	2440536203056 -> 2440536202576
	2440693302480 [label="8.bn1.bias
 (8)" fillcolor=lightblue]
	2440693302480 -> 2440536203056
	2440536203056 [label=AccumulateGrad]
	2440536203872 -> 2440536205024
	2440693303344 [label="8.conv_h.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	2440693303344 -> 2440536203872
	2440536203872 [label=AccumulateGrad]
	2440536205840 -> 2440536205936
	2440536205840 [label=PermuteBackward0]
	2440536205600 -> 2440536205840
	2440536205600 [label=SigmoidBackward0]
	2440536203104 -> 2440536205600
	2440536203104 [label=ConvolutionBackward0]
	2440536203584 -> 2440536203104
	2440536202432 -> 2440536203104
	2440693303632 [label="8.conv_w.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	2440693303632 -> 2440536202432
	2440536202432 [label=AccumulateGrad]
	2440536206080 -> 2440536206368
	2440693303536 [label="9.depthwise.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	2440693303536 -> 2440536206080
	2440536206080 [label=AccumulateGrad]
	2440536206272 -> 2440536206224
	2440537002864 [label="9.pointwise.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	2440537002864 -> 2440536206272
	2440536206272 [label=AccumulateGrad]
	2440536206416 -> 2440536206560
	2440537002960 [label="10.weight
 (64)" fillcolor=lightblue]
	2440537002960 -> 2440536206416
	2440536206416 [label=AccumulateGrad]
	2440536206848 -> 2440536206560
	2440537003056 [label="10.bias
 (64)" fillcolor=lightblue]
	2440537003056 -> 2440536206848
	2440536206848 [label=AccumulateGrad]
	2440536206800 -> 2440536207040
	2440537003440 [label="12.conv_dil1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2440537003440 -> 2440536206800
	2440536206800 [label=AccumulateGrad]
	2440536206704 -> 2440536207040
	2440537003536 [label="12.conv_dil1.bias
 (64)" fillcolor=lightblue]
	2440537003536 -> 2440536206704
	2440536206704 [label=AccumulateGrad]
	2440536207088 -> 2440536207424
	2440536207088 [label=ConvolutionBackward0]
	2440536206944 -> 2440536207088
	2440536206320 -> 2440536207088
	2440537003632 [label="12.conv_dil2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2440537003632 -> 2440536206320
	2440536206320 [label=AccumulateGrad]
	2440536206608 -> 2440536207088
	2440537003728 [label="12.conv_dil2.bias
 (64)" fillcolor=lightblue]
	2440537003728 -> 2440536206608
	2440536206608 [label=AccumulateGrad]
	2440536207328 -> 2440536207424
	2440536207328 [label=ConvolutionBackward0]
	2440536206944 -> 2440536207328
	2440536205360 -> 2440536207328
	2440537003824 [label="12.conv_dil3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2440537003824 -> 2440536205360
	2440536205360 [label=AccumulateGrad]
	2440536206464 -> 2440536207328
	2440537003920 [label="12.conv_dil3.bias
 (64)" fillcolor=lightblue]
	2440537003920 -> 2440536206464
	2440536206464 [label=AccumulateGrad]
	2440536207280 -> 2440536208336
	2440537004016 [label="12.fuse.weight
 (64, 192, 1, 1)" fillcolor=lightblue]
	2440537004016 -> 2440536207280
	2440536207280 [label=AccumulateGrad]
	2440536207520 -> 2440536208336
	2440537004112 [label="12.fuse.bias
 (64)" fillcolor=lightblue]
	2440537004112 -> 2440536207520
	2440536207520 [label=AccumulateGrad]
	2440536207184 -> 2440536207808
	2440537004208 [label="13.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2440537004208 -> 2440536207184
	2440536207184 [label=AccumulateGrad]
	2440536207712 -> 2440536207904
	2440537004304 [label="13.bn1.weight
 (64)" fillcolor=lightblue]
	2440537004304 -> 2440536207712
	2440536207712 [label=AccumulateGrad]
	2440536207664 -> 2440536207904
	2440537004400 [label="13.bn1.bias
 (64)" fillcolor=lightblue]
	2440537004400 -> 2440536207664
	2440536207664 [label=AccumulateGrad]
	2440536208000 -> 2440536208192
	2440537004784 [label="13.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2440537004784 -> 2440536208000
	2440536208000 [label=AccumulateGrad]
	2440536208384 -> 2440536208144
	2440537004880 [label="13.bn2.weight
 (64)" fillcolor=lightblue]
	2440537004880 -> 2440536208384
	2440536208384 [label=AccumulateGrad]
	2440536208240 -> 2440536208144
	2440537004976 [label="13.bn2.bias
 (64)" fillcolor=lightblue]
	2440537004976 -> 2440536208240
	2440536208240 [label=AccumulateGrad]
	2440536208336 -> 2440536208480
	2440536208864 -> 2440536208624
	2440536208864 [label=UnsqueezeBackward0]
	2440536208288 -> 2440536208864
	2440536208288 [label=UnsqueezeBackward0]
	2440536207376 -> 2440536208288
	2440536207376 [label=SigmoidBackward0]
	2440536207760 -> 2440536207376
	2440536207760 [label=SqueezeBackward1]
	2440536206896 -> 2440536207760
	2440536206896 [label=ConvolutionBackward0]
	2440536202624 -> 2440536206896
	2440536202624 [label=UnsqueezeBackward0]
	2440536202720 -> 2440536202624
	2440536202720 [label=SqueezeBackward1]
	2440536201808 -> 2440536202720
	2440536201808 [label=SqueezeBackward1]
	2440536202240 -> 2440536201808
	2440536202240 [label=MeanBackward1]
	2440536208672 -> 2440536202240
	2440536207232 -> 2440536206896
	2440537005360 [label="14.conv.weight
 (1, 1, 3)" fillcolor=lightblue]
	2440537005360 -> 2440536207232
	2440536207232 [label=AccumulateGrad]
	2440536208816 -> 2440536209008
	2440537005456 [label="15.depthwise.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	2440537005456 -> 2440536208816
	2440536208816 [label=AccumulateGrad]
	2440536209248 -> 2440536209200
	2440537005552 [label="15.pointwise.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2440537005552 -> 2440536209248
	2440536209248 [label=AccumulateGrad]
	2440536209104 -> 2440536209296
	2440537005648 [label="16.weight
 (128)" fillcolor=lightblue]
	2440537005648 -> 2440536209104
	2440536209104 [label=AccumulateGrad]
	2440536209488 -> 2440536209296
	2440537005744 [label="16.bias
 (128)" fillcolor=lightblue]
	2440537005744 -> 2440536209488
	2440536209488 [label=AccumulateGrad]
	2440536209824 -> 2440536209776
	2440537006128 [label="18.conv_dil1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2440537006128 -> 2440536209824
	2440536209824 [label=AccumulateGrad]
	2440536209680 -> 2440536209776
	2440537006224 [label="18.conv_dil1.bias
 (128)" fillcolor=lightblue]
	2440537006224 -> 2440536209680
	2440536209680 [label=AccumulateGrad]
	2440536209920 -> 2440536210112
	2440536209920 [label=ConvolutionBackward0]
	2440536209632 -> 2440536209920
	2440536209344 -> 2440536209920
	2440537006320 [label="18.conv_dil2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2440537006320 -> 2440536209344
	2440536209344 [label=AccumulateGrad]
	2440536209440 -> 2440536209920
	2440537006416 [label="18.conv_dil2.bias
 (128)" fillcolor=lightblue]
	2440537006416 -> 2440536209440
	2440536209440 [label=AccumulateGrad]
	2440536209968 -> 2440536210112
	2440536209968 [label=ConvolutionBackward0]
	2440536209632 -> 2440536209968
	2440536208768 -> 2440536209968
	2440537006512 [label="18.conv_dil3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2440537006512 -> 2440536208768
	2440536208768 [label=AccumulateGrad]
	2440536209152 -> 2440536209968
	2440537006608 [label="18.conv_dil3.bias
 (128)" fillcolor=lightblue]
	2440537006608 -> 2440536209152
	2440536209152 [label=AccumulateGrad]
	2440536210304 -> 2440536195472
	2440537006704 [label="18.fuse.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	2440537006704 -> 2440536210304
	2440536210304 [label=AccumulateGrad]
	2440536210256 -> 2440536195472
	2440537006800 [label="18.fuse.bias
 (128)" fillcolor=lightblue]
	2440537006800 -> 2440536210256
	2440536210256 [label=AccumulateGrad]
	2440536210160 -> 2440536210448
	2440537006896 [label="19.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2440537006896 -> 2440536210160
	2440536210160 [label=AccumulateGrad]
	2440536210688 -> 2440536210592
	2440537006992 [label="19.bn1.weight
 (128)" fillcolor=lightblue]
	2440537006992 -> 2440536210688
	2440536210688 [label=AccumulateGrad]
	2440536210640 -> 2440536210592
	2440537007088 [label="19.bn1.bias
 (128)" fillcolor=lightblue]
	2440537007088 -> 2440536210640
	2440536210640 [label=AccumulateGrad]
	2440536210736 -> 2440536211168
	2440537007472 [label="19.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2440537007472 -> 2440536210736
	2440536210736 [label=AccumulateGrad]
	2440536211408 -> 2440536195616
	2440537007568 [label="19.bn2.weight
 (128)" fillcolor=lightblue]
	2440537007568 -> 2440536211408
	2440536211408 [label=AccumulateGrad]
	2440536195136 -> 2440536195616
	2440537007664 [label="19.bn2.bias
 (128)" fillcolor=lightblue]
	2440537007664 -> 2440536195136
	2440536195136 [label=AccumulateGrad]
	2440536195472 -> 2440536196096
	2440536197056 -> 2440536197536
	2440536197056 [label=SigmoidBackward0]
	2440536210928 -> 2440536197056
	2440536210928 [label=ConvolutionBackward0]
	2440536210064 -> 2440536210928
	2440536210064 [label=NativeDropoutBackward0]
	2440536209584 -> 2440536210064
	2440536209584 [label=ReluBackward0]
	2440536208048 -> 2440536209584
	2440536208048 [label=ConvolutionBackward0]
	2440536208720 -> 2440536208048
	2440536208720 [label=MeanBackward1]
	2440536196432 -> 2440536208720
	2440536208960 -> 2440536208048
	2440537008048 [label="20.fc1.weight
 (8, 128, 1, 1)" fillcolor=lightblue]
	2440537008048 -> 2440536208960
	2440536208960 [label=AccumulateGrad]
	2440536210784 -> 2440536208048
	2440537008144 [label="20.fc1.bias
 (8)" fillcolor=lightblue]
	2440537008144 -> 2440536210784
	2440536210784 [label=AccumulateGrad]
	2440536210880 -> 2440536210928
	2440537008240 [label="20.fc2.weight
 (128, 8, 1, 1)" fillcolor=lightblue]
	2440537008240 -> 2440536210880
	2440536210880 [label=AccumulateGrad]
	2440536195952 -> 2440536210928
	2440537008336 [label="20.fc2.bias
 (128)" fillcolor=lightblue]
	2440537008336 -> 2440536195952
	2440536195952 [label=AccumulateGrad]
	2440536197392 -> 2440536197872
	2440537008432 [label="21.depthwise.weight
 (128, 1, 3, 3)" fillcolor=lightblue]
	2440537008432 -> 2440536197392
	2440536197392 [label=AccumulateGrad]
	2440536198496 -> 2440536198832
	2440537008528 [label="21.pointwise.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2440537008528 -> 2440536198496
	2440536198496 [label=AccumulateGrad]
	2440536199456 -> 2440536199312
	2440537008624 [label="22.weight
 (256)" fillcolor=lightblue]
	2440537008624 -> 2440536199456
	2440536199456 [label=AccumulateGrad]
	2440536200272 -> 2440536199312
	2440537008720 [label="22.bias
 (256)" fillcolor=lightblue]
	2440537008720 -> 2440536200272
	2440536200272 [label=AccumulateGrad]
	2440536199792 -> 2440536200752
	2440537009104 [label="24.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2440537009104 -> 2440536199792
	2440536199792 [label=AccumulateGrad]
	2440536201376 -> 2440536201232
	2440537009200 [label="24.bn1.weight
 (256)" fillcolor=lightblue]
	2440537009200 -> 2440536201376
	2440536201376 [label=AccumulateGrad]
	2440536201712 -> 2440536201232
	2440537009296 [label="24.bn1.bias
 (256)" fillcolor=lightblue]
	2440537009296 -> 2440536201712
	2440536201712 [label=AccumulateGrad]
	2440536202192 -> 2440536203296
	2440537009680 [label="24.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2440537009680 -> 2440536202192
	2440536202192 [label=AccumulateGrad]
	2440536203152 -> 2440536203632
	2440537009776 [label="24.bn2.weight
 (256)" fillcolor=lightblue]
	2440537009776 -> 2440536203152
	2440536203152 [label=AccumulateGrad]
	2440536203776 -> 2440536203632
	2440537009872 [label="24.bn2.bias
 (256)" fillcolor=lightblue]
	2440537009872 -> 2440536203776
	2440536203776 [label=AccumulateGrad]
	2440536204256 -> 2440536204112
	2440536205072 -> 2440536205552
	2440536205072 [label=ViewBackward0]
	2440536202672 -> 2440536205072
	2440536202672 [label=SigmoidBackward0]
	2440536200416 -> 2440536202672
	2440536200416 [label=AddmmBackward0]
	2440536201856 -> 2440536200416
	2440537010544 [label="25.channel_att.fc2.bias
 (256)" fillcolor=lightblue]
	2440537010544 -> 2440536201856
	2440536201856 [label=AccumulateGrad]
	2440536200896 -> 2440536200416
	2440536200896 [label=ReluBackward0]
	2440536198976 -> 2440536200896
	2440536198976 [label=AddmmBackward0]
	2440536198016 -> 2440536198976
	2440537010352 [label="25.channel_att.fc1.bias
 (16)" fillcolor=lightblue]
	2440537010352 -> 2440536198016
	2440536198016 [label=AccumulateGrad]
	2440536210400 -> 2440536198976
	2440536210400 [label=MeanBackward1]
	2440536209728 -> 2440536210400
	2440536209728 [label=ViewBackward0]
	2440536205216 -> 2440536209728
	2440536196576 -> 2440536198976
	2440536196576 [label=TBackward0]
	2440536205792 -> 2440536196576
	2440537010256 [label="25.channel_att.fc1.weight
 (16, 256)" fillcolor=lightblue]
	2440537010256 -> 2440536205792
	2440536205792 [label=AccumulateGrad]
	2440536204736 -> 2440536200416
	2440536204736 [label=TBackward0]
	2440536208528 -> 2440536204736
	2440537010448 [label="25.channel_att.fc2.weight
 (256, 16)" fillcolor=lightblue]
	2440537010448 -> 2440536208528
	2440536208528 [label=AccumulateGrad]
	2440536206176 -> 2440536206032
	2440536206176 [label=SigmoidBackward0]
	2440536202816 -> 2440536206176
	2440536202816 [label=ConvolutionBackward0]
	2440536196912 -> 2440536202816
	2440536196912 [label=CatBackward0]
	2440536199936 -> 2440536196912
	2440536199936 [label=MeanBackward1]
	2440536205552 -> 2440536199936
	2440536206752 -> 2440536196912
	2440536206752 [label=MaxBackward0]
	2440536205552 -> 2440536206752
	2440536198352 -> 2440536202816
	2440537010640 [label="25.spatial_att.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	2440537010640 -> 2440536198352
	2440536198352 [label=AccumulateGrad]
	2440536207472 -> 2440536209056
	2440536207472 [label=TBackward0]
	2440536206656 -> 2440536207472
	2440537010736 [label="29.weight
 (19, 256)" fillcolor=lightblue]
	2440537010736 -> 2440536206656
	2440536206656 [label=AccumulateGrad]
	2440536209056 -> 2440536328912
}
