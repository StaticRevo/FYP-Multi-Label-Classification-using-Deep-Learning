digraph {
	graph [size="151.95,151.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2285955288912 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2285986182624 [label=AddmmBackward0]
	2285986182288 -> 2285986182624
	2285955830448 [label="fc.bias
 (19)" fillcolor=lightblue]
	2285955830448 -> 2285986182288
	2285986182288 [label=AccumulateGrad]
	2285986181664 -> 2285986182624
	2285986181664 [label=ViewBackward0]
	2285986181184 -> 2285986181664
	2285986181184 [label=MeanBackward1]
	2285986180848 -> 2285986181184
	2285986180848 [label=ReluBackward0]
	2285986180368 -> 2285986180848
	2285986180368 [label=AddBackward0]
	2285986179888 -> 2285986180368
	2285986179888 [label=CudnnBatchNormBackward0]
	2285986178784 -> 2285986179888
	2285986178784 [label=ConvolutionBackward0]
	2285986177824 -> 2285986178784
	2285986177824 [label=ReluBackward0]
	2285986177488 -> 2285986177824
	2285986177488 [label=CudnnBatchNormBackward0]
	2285986177008 -> 2285986177488
	2285986177008 [label=ConvolutionBackward0]
	2285986176048 -> 2285986177008
	2285986176048 [label=ReluBackward0]
	2285986174944 -> 2285986176048
	2285986174944 [label=CudnnBatchNormBackward0]
	2285986174464 -> 2285986174944
	2285986174464 [label=ConvolutionBackward0]
	2285986179744 -> 2285986174464
	2285986179744 [label=ReluBackward0]
	2285986172016 -> 2285986179744
	2285986172016 [label=AddBackward0]
	2285986172352 -> 2285986172016
	2285986172352 [label=CudnnBatchNormBackward0]
	2285986170576 -> 2285986172352
	2285986170576 [label=ConvolutionBackward0]
	2285986184736 -> 2285986170576
	2285986184736 [label=ReluBackward0]
	2285986184784 -> 2285986184736
	2285986184784 [label=CudnnBatchNormBackward0]
	2285986184640 -> 2285986184784
	2285986184640 [label=ConvolutionBackward0]
	2285986184352 -> 2285986184640
	2285986184352 [label=ReluBackward0]
	2285986184400 -> 2285986184352
	2285986184400 [label=CudnnBatchNormBackward0]
	2285986184112 -> 2285986184400
	2285986184112 [label=ConvolutionBackward0]
	2285986173168 -> 2285986184112
	2285986173168 [label=ReluBackward0]
	2285986183920 -> 2285986173168
	2285986183920 [label=AddBackward0]
	2285986183632 -> 2285986183920
	2285986183632 [label=CudnnBatchNormBackward0]
	2285986183392 -> 2285986183632
	2285986183392 [label=ConvolutionBackward0]
	2285986183200 -> 2285986183392
	2285986183200 [label=ReluBackward0]
	2285986182816 -> 2285986183200
	2285986182816 [label=CudnnBatchNormBackward0]
	2285986183056 -> 2285986182816
	2285986183056 [label=ConvolutionBackward0]
	2285986182672 -> 2285986183056
	2285986182672 [label=ReluBackward0]
	2285986182432 -> 2285986182672
	2285986182432 [label=CudnnBatchNormBackward0]
	2285986182384 -> 2285986182432
	2285986182384 [label=ConvolutionBackward0]
	2285986182048 -> 2285986182384
	2285986182048 [label=ReluBackward0]
	2285986182096 -> 2285986182048
	2285986182096 [label=AddBackward0]
	2285986182000 -> 2285986182096
	2285986182000 [label=CudnnBatchNormBackward0]
	2285986181568 -> 2285986182000
	2285986181568 [label=ConvolutionBackward0]
	2285986181424 -> 2285986181568
	2285986181424 [label=ReluBackward0]
	2285986181232 -> 2285986181424
	2285986181232 [label=CudnnBatchNormBackward0]
	2285986180896 -> 2285986181232
	2285986180896 [label=ConvolutionBackward0]
	2285986181040 -> 2285986180896
	2285986181040 [label=ReluBackward0]
	2285986180608 -> 2285986181040
	2285986180608 [label=CudnnBatchNormBackward0]
	2285986180512 -> 2285986180608
	2285986180512 [label=ConvolutionBackward0]
	2285986181904 -> 2285986180512
	2285986181904 [label=ReluBackward0]
	2285986180128 -> 2285986181904
	2285986180128 [label=AddBackward0]
	2285986180032 -> 2285986180128
	2285986180032 [label=CudnnBatchNormBackward0]
	2285986180080 -> 2285986180032
	2285986180080 [label=ConvolutionBackward0]
	2285986179456 -> 2285986180080
	2285986179456 [label=ReluBackward0]
	2285986179504 -> 2285986179456
	2285986179504 [label=CudnnBatchNormBackward0]
	2285986179360 -> 2285986179504
	2285986179360 [label=ConvolutionBackward0]
	2285986179072 -> 2285986179360
	2285986179072 [label=ReluBackward0]
	2285986179120 -> 2285986179072
	2285986179120 [label=CudnnBatchNormBackward0]
	2285986178832 -> 2285986179120
	2285986178832 [label=ConvolutionBackward0]
	2285986179936 -> 2285986178832
	2285986179936 [label=ReluBackward0]
	2285986178640 -> 2285986179936
	2285986178640 [label=AddBackward0]
	2285986178352 -> 2285986178640
	2285986178352 [label=CudnnBatchNormBackward0]
	2285986178112 -> 2285986178352
	2285986178112 [label=ConvolutionBackward0]
	2285986177920 -> 2285986178112
	2285986177920 [label=ReluBackward0]
	2285986177536 -> 2285986177920
	2285986177536 [label=CudnnBatchNormBackward0]
	2285986177776 -> 2285986177536
	2285986177776 [label=ConvolutionBackward0]
	2285986177392 -> 2285986177776
	2285986177392 [label=ReluBackward0]
	2285986177152 -> 2285986177392
	2285986177152 [label=CudnnBatchNormBackward0]
	2285986177104 -> 2285986177152
	2285986177104 [label=ConvolutionBackward0]
	2285986178400 -> 2285986177104
	2285986178400 [label=ReluBackward0]
	2285986176672 -> 2285986178400
	2285986176672 [label=AddBackward0]
	2285986176624 -> 2285986176672
	2285986176624 [label=CudnnBatchNormBackward0]
	2285986176432 -> 2285986176624
	2285986176432 [label=ConvolutionBackward0]
	2285986176336 -> 2285986176432
	2285986176336 [label=ReluBackward0]
	2285986176000 -> 2285986176336
	2285986176000 [label=CudnnBatchNormBackward0]
	2285986175808 -> 2285986176000
	2285986175808 [label=ConvolutionBackward0]
	2285986175664 -> 2285986175808
	2285986175664 [label=ReluBackward0]
	2285986175472 -> 2285986175664
	2285986175472 [label=CudnnBatchNormBackward0]
	2285986175136 -> 2285986175472
	2285986175136 [label=ConvolutionBackward0]
	2285986176816 -> 2285986175136
	2285986176816 [label=ReluBackward0]
	2285986174992 -> 2285986176816
	2285986174992 [label=AddBackward0]
	2285986174656 -> 2285986174992
	2285986174656 [label=CudnnBatchNormBackward0]
	2285986174704 -> 2285986174656
	2285986174704 [label=ConvolutionBackward0]
	2285986174368 -> 2285986174704
	2285986174368 [label=ReluBackward0]
	2285986174416 -> 2285986174368
	2285986174416 [label=CudnnBatchNormBackward0]
	2285986174320 -> 2285986174416
	2285986174320 [label=ConvolutionBackward0]
	2285986173696 -> 2285986174320
	2285986173696 [label=ReluBackward0]
	2285986173744 -> 2285986173696
	2285986173744 [label=CudnnBatchNormBackward0]
	2285986173600 -> 2285986173744
	2285986173600 [label=ConvolutionBackward0]
	2285986174848 -> 2285986173600
	2285986174848 [label=ReluBackward0]
	2285986173216 -> 2285986174848
	2285986173216 [label=AddBackward0]
	2285986171104 -> 2285986173216
	2285986171104 [label=CudnnBatchNormBackward0]
	2285986172928 -> 2285986171104
	2285986172928 [label=ConvolutionBackward0]
	2285986169664 -> 2285986172928
	2285986169664 [label=ReluBackward0]
	2285986171440 -> 2285986169664
	2285986171440 [label=CudnnBatchNormBackward0]
	2285986169904 -> 2285986171440
	2285986169904 [label=ConvolutionBackward0]
	2285986171152 -> 2285986169904
	2285986171152 [label=ReluBackward0]
	2285986169952 -> 2285986171152
	2285986169952 [label=CudnnBatchNormBackward0]
	2285986169760 -> 2285986169952
	2285986169760 [label=ConvolutionBackward0]
	2285986171536 -> 2285986169760
	2285986171536 [label=ReluBackward0]
	2285986169424 -> 2285986171536
	2285986169424 [label=AddBackward0]
	2285986171488 -> 2285986169424
	2285986171488 [label=CudnnBatchNormBackward0]
	2285986171248 -> 2285986171488
	2285986171248 [label=ConvolutionBackward0]
	2285986169136 -> 2285986171248
	2285986169136 [label=ReluBackward0]
	2285986170672 -> 2285986169136
	2285986170672 [label=CudnnBatchNormBackward0]
	2285986171200 -> 2285986170672
	2285986171200 [label=ConvolutionBackward0]
	2285986171632 -> 2285986171200
	2285986171632 [label=ReluBackward0]
	2285986172976 -> 2285986171632
	2285986172976 [label=CudnnBatchNormBackward0]
	2286009707552 -> 2285986172976
	2286009707552 [label=ConvolutionBackward0]
	2285986171584 -> 2286009707552
	2285986171584 [label=ReluBackward0]
	2286009712064 -> 2285986171584
	2286009712064 [label=AddBackward0]
	2286009710048 -> 2286009712064
	2286009710048 [label=CudnnBatchNormBackward0]
	2286009709040 -> 2286009710048
	2286009709040 [label=ConvolutionBackward0]
	2286009708272 -> 2286009709040
	2286009708272 [label=ReluBackward0]
	2286009711200 -> 2286009708272
	2286009711200 [label=CudnnBatchNormBackward0]
	2286009711584 -> 2286009711200
	2286009711584 [label=ConvolutionBackward0]
	2286009712592 -> 2286009711584
	2286009712592 [label=ReluBackward0]
	2286009710288 -> 2286009712592
	2286009710288 [label=CudnnBatchNormBackward0]
	2286009710528 -> 2286009710288
	2286009710528 [label=ConvolutionBackward0]
	2286009707456 -> 2286009710528
	2286009707456 [label=ReluBackward0]
	2286009706400 -> 2286009707456
	2286009706400 [label=AddBackward0]
	2286009711248 -> 2286009706400
	2286009711248 [label=CudnnBatchNormBackward0]
	2286009707408 -> 2286009711248
	2286009707408 [label=ConvolutionBackward0]
	2286009708128 -> 2286009707408
	2286009708128 [label=ReluBackward0]
	2286009711152 -> 2286009708128
	2286009711152 [label=CudnnBatchNormBackward0]
	2286009708176 -> 2286009711152
	2286009708176 [label=ConvolutionBackward0]
	2286009707072 -> 2286009708176
	2286009707072 [label=ReluBackward0]
	2286009707840 -> 2286009707072
	2286009707840 [label=CudnnBatchNormBackward0]
	2286009708464 -> 2286009707840
	2286009708464 [label=ConvolutionBackward0]
	2286009708032 -> 2286009708464
	2286009708032 [label=ReluBackward0]
	2286009709568 -> 2286009708032
	2286009709568 [label=AddBackward0]
	2286009708896 -> 2286009709568
	2286009708896 [label=CudnnBatchNormBackward0]
	2285986304768 -> 2286009708896
	2285986304768 [label=ConvolutionBackward0]
	2285955141392 -> 2285986304768
	2285955141392 [label=ReluBackward0]
	2285955140288 -> 2285955141392
	2285955140288 [label=CudnnBatchNormBackward0]
	2285955139808 -> 2285955140288
	2285955139808 [label=ConvolutionBackward0]
	2285955138848 -> 2285955139808
	2285955138848 [label=ReluBackward0]
	2285955138512 -> 2285955138848
	2285955138512 [label=CudnnBatchNormBackward0]
	2285955138032 -> 2285955138512
	2285955138032 [label=ConvolutionBackward0]
	2285955141440 -> 2285955138032
	2285955141440 [label=ReluBackward0]
	2285955141488 -> 2285955141440
	2285955141488 [label=AddBackward0]
	2285955141344 -> 2285955141488
	2285955141344 [label=CudnnBatchNormBackward0]
	2285955140960 -> 2285955141344
	2285955140960 [label=ConvolutionBackward0]
	2285955141104 -> 2285955140960
	2285955141104 [label=ReluBackward0]
	2285955140672 -> 2285955141104
	2285955140672 [label=CudnnBatchNormBackward0]
	2285955140576 -> 2285955140672
	2285955140576 [label=ConvolutionBackward0]
	2285955140384 -> 2285955140576
	2285955140384 [label=ReluBackward0]
	2285955140000 -> 2285955140384
	2285955140000 [label=CudnnBatchNormBackward0]
	2285955140240 -> 2285955140000
	2285955140240 [label=ConvolutionBackward0]
	2285955141584 -> 2285955140240
	2285955141584 [label=ReluBackward0]
	2285955139520 -> 2285955141584
	2285955139520 [label=AddBackward0]
	2285955139760 -> 2285955139520
	2285955139760 [label=CudnnBatchNormBackward0]
	2285955139424 -> 2285955139760
	2285955139424 [label=ConvolutionBackward0]
	2285955139136 -> 2285955139424
	2285955139136 [label=ReluBackward0]
	2285955139184 -> 2285955139136
	2285955139184 [label=CudnnBatchNormBackward0]
	2285955138896 -> 2285955139184
	2285955138896 [label=ConvolutionBackward0]
	2285955138800 -> 2285955138896
	2285955138800 [label=ReluBackward0]
	2285955138464 -> 2285955138800
	2285955138464 [label=CudnnBatchNormBackward0]
	2285955138272 -> 2285955138464
	2285955138272 [label=ConvolutionBackward0]
	2285955139616 -> 2285955138272
	2285955139616 [label=ReluBackward0]
	2285955137984 -> 2285955139616
	2285955137984 [label=AddBackward0]
	2285955137792 -> 2285955137984
	2285955137792 [label=CudnnBatchNormBackward0]
	2285955137840 -> 2285955137792
	2285955137840 [label=ConvolutionBackward0]
	2285955142304 -> 2285955137840
	2285955142304 [label=ReluBackward0]
	2285955142640 -> 2285955142304
	2285955142640 [label=CudnnBatchNormBackward0]
	2285955142736 -> 2285955142640
	2285955142736 [label=ConvolutionBackward0]
	2285955142928 -> 2285955142736
	2285955142928 [label=ReluBackward0]
	2285955143072 -> 2285955142928
	2285955143072 [label=CudnnBatchNormBackward0]
	2285955143168 -> 2285955143072
	2285955143168 [label=ConvolutionBackward0]
	2285955143360 -> 2285955143168
	2285955143360 [label=MaxPool2DWithIndicesBackward0]
	2285955143504 -> 2285955143360
	2285955143504 [label=ReluBackward0]
	2285955143600 -> 2285955143504
	2285955143600 [label=CudnnBatchNormBackward0]
	2285955143696 -> 2285955143600
	2285955143696 [label=ConvolutionBackward0]
	2285955143888 -> 2285955143696
	2285955830256 [label="conv1.weight
 (64, 12, 7, 7)" fillcolor=lightblue]
	2285955830256 -> 2285955143888
	2285955143888 [label=AccumulateGrad]
	2285955143648 -> 2285955143600
	2285978526896 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2285978526896 -> 2285955143648
	2285955143648 [label=AccumulateGrad]
	2285955143408 -> 2285955143600
	2285978526608 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2285978526608 -> 2285955143408
	2285955143408 [label=AccumulateGrad]
	2285955143312 -> 2285955143168
	2285978526512 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2285978526512 -> 2285955143312
	2285955143312 [label=AccumulateGrad]
	2285955143120 -> 2285955143072
	2285978526416 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2285978526416 -> 2285955143120
	2285955143120 [label=AccumulateGrad]
	2285955142976 -> 2285955143072
	2285978525648 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2285978525648 -> 2285955142976
	2285955142976 [label=AccumulateGrad]
	2285955142880 -> 2285955142736
	2285978525744 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2285978525744 -> 2285955142880
	2285955142880 [label=AccumulateGrad]
	2285955142688 -> 2285955142640
	2285978525840 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2285978525840 -> 2285955142688
	2285955142688 [label=AccumulateGrad]
	2285955142544 -> 2285955142640
	2285978525936 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2285978525936 -> 2285955142544
	2285955142544 [label=AccumulateGrad]
	2285955142448 -> 2285955137840
	2285978526224 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2285978526224 -> 2285955142448
	2285955142448 [label=AccumulateGrad]
	2285955137696 -> 2285955137792
	2285978525264 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	2285978525264 -> 2285955137696
	2285955137696 [label=AccumulateGrad]
	2285955137600 -> 2285955137792
	2285978525168 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	2285978525168 -> 2285955137600
	2285955137600 [label=AccumulateGrad]
	2285955137936 -> 2285955137984
	2285955137936 [label=CudnnBatchNormBackward0]
	2285955142832 -> 2285955137936
	2285955142832 [label=ConvolutionBackward0]
	2285955143360 -> 2285955142832
	2285955143216 -> 2285955142832
	2285978527088 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2285978527088 -> 2285955143216
	2285955143216 [label=AccumulateGrad]
	2285955137744 -> 2285955137936
	2285978527184 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2285978527184 -> 2285955137744
	2285955137744 [label=AccumulateGrad]
	2285955137648 -> 2285955137936
	2285978527280 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2285978527280 -> 2285955137648
	2285955137648 [label=AccumulateGrad]
	2285955138128 -> 2285955138272
	2285978522480 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2285978522480 -> 2285955138128
	2285955138128 [label=AccumulateGrad]
	2285955138416 -> 2285955138464
	2285978522672 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2285978522672 -> 2285955138416
	2285955138416 [label=AccumulateGrad]
	2285955138608 -> 2285955138464
	2285978524304 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2285978524304 -> 2285955138608
	2285955138608 [label=AccumulateGrad]
	2285955138656 -> 2285955138896
	2285978525072 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2285978525072 -> 2285955138656
	2285955138656 [label=AccumulateGrad]
	2285955138944 -> 2285955139184
	2285978524976 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2285978524976 -> 2285955138944
	2285955138944 [label=AccumulateGrad]
	2285955139280 -> 2285955139184
	2285956310960 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2285956310960 -> 2285955139280
	2285955139280 [label=AccumulateGrad]
	2285955139040 -> 2285955139424
	2285956311344 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2285956311344 -> 2285955139040
	2285955139040 [label=AccumulateGrad]
	2285955139664 -> 2285955139760
	2285956311440 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	2285956311440 -> 2285955139664
	2285955139664 [label=AccumulateGrad]
	2285955139568 -> 2285955139760
	2285956311536 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	2285956311536 -> 2285955139568
	2285955139568 [label=AccumulateGrad]
	2285955139616 -> 2285955139520
	2285955139856 -> 2285955140240
	2285956311920 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2285956311920 -> 2285955139856
	2285955139856 [label=AccumulateGrad]
	2285955140096 -> 2285955140000
	2285956312016 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	2285956312016 -> 2285955140096
	2285955140096 [label=AccumulateGrad]
	2285955140336 -> 2285955140000
	2285956312112 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	2285956312112 -> 2285955140336
	2285955140336 [label=AccumulateGrad]
	2285955140624 -> 2285955140576
	2285956312496 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2285956312496 -> 2285955140624
	2285955140624 [label=AccumulateGrad]
	2285955140480 -> 2285955140672
	2285956312592 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	2285956312592 -> 2285955140480
	2285955140480 [label=AccumulateGrad]
	2285955140864 -> 2285955140672
	2285956312688 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	2285956312688 -> 2285955140864
	2285955140864 [label=AccumulateGrad]
	2285955141008 -> 2285955140960
	2285956313072 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2285956313072 -> 2285955141008
	2285955141008 [label=AccumulateGrad]
	2285955141152 -> 2285955141344
	2285956313168 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	2285956313168 -> 2285955141152
	2285955141152 [label=AccumulateGrad]
	2285955141296 -> 2285955141344
	2285956313264 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	2285956313264 -> 2285955141296
	2285955141296 [label=AccumulateGrad]
	2285955141584 -> 2285955141488
	2285955141632 -> 2285955138032
	2285956314224 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2285956314224 -> 2285955141632
	2285955141632 [label=AccumulateGrad]
	2285955137888 -> 2285955138512
	2285956314320 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2285956314320 -> 2285955137888
	2285955137888 [label=AccumulateGrad]
	2285955138992 -> 2285955138512
	2285956314416 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2285956314416 -> 2285955138992
	2285955138992 [label=AccumulateGrad]
	2285955139472 -> 2285955139808
	2285956314800 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2285956314800 -> 2285955139472
	2285955139472 [label=AccumulateGrad]
	2285955140432 -> 2285955140288
	2285956314896 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2285956314896 -> 2285955140432
	2285955140432 [label=AccumulateGrad]
	2285955140768 -> 2285955140288
	2285956314992 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2285956314992 -> 2285955140768
	2285955140768 [label=AccumulateGrad]
	2285955141248 -> 2285986304768
	2285956315376 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2285956315376 -> 2285955141248
	2285955141248 [label=AccumulateGrad]
	2286009709616 -> 2286009708896
	2285956315472 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	2285956315472 -> 2286009709616
	2286009709616 [label=AccumulateGrad]
	2286009712160 -> 2286009708896
	2285956315568 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	2285956315568 -> 2286009712160
	2286009712160 [label=AccumulateGrad]
	2286009707936 -> 2286009709568
	2286009707936 [label=CudnnBatchNormBackward0]
	2285955139328 -> 2286009707936
	2285955139328 [label=ConvolutionBackward0]
	2285955141440 -> 2285955139328
	2285955141824 -> 2285955139328
	2285956313648 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2285956313648 -> 2285955141824
	2285955141824 [label=AccumulateGrad]
	2285955141728 -> 2286009707936
	2285956313744 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2285956313744 -> 2285955141728
	2285955141728 [label=AccumulateGrad]
	2285955141872 -> 2286009707936
	2285956313840 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2285956313840 -> 2285955141872
	2285955141872 [label=AccumulateGrad]
	2286009707984 -> 2286009708464
	2285956315952 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2285956315952 -> 2286009707984
	2286009707984 [label=AccumulateGrad]
	2286009709760 -> 2286009707840
	2285956316048 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2285956316048 -> 2286009709760
	2286009709760 [label=AccumulateGrad]
	2286009711008 -> 2286009707840
	2285956316144 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2285956316144 -> 2286009711008
	2286009711008 [label=AccumulateGrad]
	2286009710864 -> 2286009708176
	2285956316528 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2285956316528 -> 2286009710864
	2286009710864 [label=AccumulateGrad]
	2286009709376 -> 2286009711152
	2285956316624 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2285956316624 -> 2286009709376
	2286009709376 [label=AccumulateGrad]
	2286009711104 -> 2286009711152
	2285956316720 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2285956316720 -> 2286009711104
	2286009711104 [label=AccumulateGrad]
	2286009708944 -> 2286009707408
	2285956317104 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2285956317104 -> 2286009708944
	2286009708944 [label=AccumulateGrad]
	2286009711776 -> 2286009711248
	2285956137040 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	2285956137040 -> 2286009711776
	2286009711776 [label=AccumulateGrad]
	2286009711296 -> 2286009711248
	2285956137136 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	2285956137136 -> 2286009711296
	2286009711296 [label=AccumulateGrad]
	2286009708032 -> 2286009706400
	2286009707696 -> 2286009710528
	2285956137520 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2285956137520 -> 2286009707696
	2286009707696 [label=AccumulateGrad]
	2286009710672 -> 2286009710288
	2285956137616 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	2285956137616 -> 2286009710672
	2286009710672 [label=AccumulateGrad]
	2286009710816 -> 2286009710288
	2285956137712 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	2285956137712 -> 2286009710816
	2286009710816 [label=AccumulateGrad]
	2286009708800 -> 2286009711584
	2285956138096 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2285956138096 -> 2286009708800
	2286009708800 [label=AccumulateGrad]
	2286009709712 -> 2286009711200
	2285956138192 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	2285956138192 -> 2286009709712
	2286009709712 [label=AccumulateGrad]
	2286009710768 -> 2286009711200
	2285956138288 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	2285956138288 -> 2286009710768
	2286009710768 [label=AccumulateGrad]
	2286009710336 -> 2286009709040
	2285956138672 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2285956138672 -> 2286009710336
	2286009710336 [label=AccumulateGrad]
	2286009709808 -> 2286009710048
	2285956138768 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	2285956138768 -> 2286009709808
	2286009709808 [label=AccumulateGrad]
	2286009711968 -> 2286009710048
	2285956138864 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	2285956138864 -> 2286009711968
	2286009711968 [label=AccumulateGrad]
	2286009707456 -> 2286009712064
	2286009706688 -> 2286009707552
	2285956139248 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2285956139248 -> 2286009706688
	2286009706688 [label=AccumulateGrad]
	2286009709232 -> 2285986172976
	2285956139344 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	2285956139344 -> 2286009709232
	2286009709232 [label=AccumulateGrad]
	2286009709856 -> 2285986172976
	2285956139440 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	2285956139440 -> 2286009709856
	2286009709856 [label=AccumulateGrad]
	2285986170288 -> 2285986171200
	2285956139824 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2285956139824 -> 2285986170288
	2285986170288 [label=AccumulateGrad]
	2285986171728 -> 2285986170672
	2285956139920 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	2285956139920 -> 2285986171728
	2285986171728 [label=AccumulateGrad]
	2285986170144 -> 2285986170672
	2285956140016 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	2285956140016 -> 2285986170144
	2285986170144 [label=AccumulateGrad]
	2285986169616 -> 2285986171248
	2285956140400 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2285956140400 -> 2285986169616
	2285986169616 [label=AccumulateGrad]
	2285986172736 -> 2285986171488
	2285956140496 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	2285956140496 -> 2285986172736
	2285986172736 [label=AccumulateGrad]
	2285986172400 -> 2285986171488
	2285956140592 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	2285956140592 -> 2285986172400
	2285986172400 [label=AccumulateGrad]
	2285986171584 -> 2285986169424
	2285986170384 -> 2285986169760
	2285956141552 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2285956141552 -> 2285986170384
	2285986170384 [label=AccumulateGrad]
	2285986172064 -> 2285986169952
	2285956141648 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2285956141648 -> 2285986172064
	2285986172064 [label=AccumulateGrad]
	2285986169376 -> 2285986169952
	2285956141744 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2285956141744 -> 2285986169376
	2285986169376 [label=AccumulateGrad]
	2285986171008 -> 2285986169904
	2285956142128 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2285956142128 -> 2285986171008
	2285986171008 [label=AccumulateGrad]
	2285986169232 -> 2285986171440
	2285956142224 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2285956142224 -> 2285986169232
	2285986169232 [label=AccumulateGrad]
	2285986172640 -> 2285986171440
	2285956142320 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2285956142320 -> 2285986172640
	2285986172640 [label=AccumulateGrad]
	2285986173024 -> 2285986172928
	2285956142704 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2285956142704 -> 2285986173024
	2285986173024 [label=AccumulateGrad]
	2285986170192 -> 2285986171104
	2285956142800 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	2285956142800 -> 2285986170192
	2285986170192 [label=AccumulateGrad]
	2285986173360 -> 2285986171104
	2285956142896 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	2285956142896 -> 2285986173360
	2285986173360 [label=AccumulateGrad]
	2285986173120 -> 2285986173216
	2285986173120 [label=CudnnBatchNormBackward0]
	2285986171680 -> 2285986173120
	2285986171680 [label=ConvolutionBackward0]
	2285986171536 -> 2285986171680
	2285986169280 -> 2285986171680
	2285956140976 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2285956140976 -> 2285986169280
	2285986169280 [label=AccumulateGrad]
	2285986172160 -> 2285986173120
	2285956141072 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	2285956141072 -> 2285986172160
	2285986172160 [label=AccumulateGrad]
	2285986172496 -> 2285986173120
	2285956141168 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	2285956141168 -> 2285986172496
	2285986172496 [label=AccumulateGrad]
	2285986169808 -> 2285986173600
	2285956143280 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2285956143280 -> 2285986169808
	2285986169808 [label=AccumulateGrad]
	2285986173840 -> 2285986173744
	2285956143376 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2285956143376 -> 2285986173840
	2285986173840 [label=AccumulateGrad]
	2285986173792 -> 2285986173744
	2285956143472 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2285956143472 -> 2285986173792
	2285986173792 [label=AccumulateGrad]
	2285986173888 -> 2285986174320
	2285956143856 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2285956143856 -> 2285986173888
	2285986173888 [label=AccumulateGrad]
	2285986174224 -> 2285986174416
	2285956143952 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2285956143952 -> 2285986174224
	2285986174224 [label=AccumulateGrad]
	2285986174176 -> 2285986174416
	2285956144048 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2285956144048 -> 2285986174176
	2285986174176 [label=AccumulateGrad]
	2285986174512 -> 2285986174704
	2285956144432 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2285956144432 -> 2285986174512
	2285986174512 [label=AccumulateGrad]
	2285986174896 -> 2285986174656
	2285956144528 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	2285956144528 -> 2285986174896
	2285986174896 [label=AccumulateGrad]
	2285986174752 -> 2285986174656
	2285956144624 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	2285956144624 -> 2285986174752
	2285986174752 [label=AccumulateGrad]
	2285986174848 -> 2285986174992
	2285986175280 -> 2285986175136
	2285956145008 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2285956145008 -> 2285986175280
	2285986175280 [label=AccumulateGrad]
	2285986175328 -> 2285986175472
	2285956145104 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	2285956145104 -> 2285986175328
	2285986175328 [label=AccumulateGrad]
	2285986175760 -> 2285986175472
	2285956145200 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	2285956145200 -> 2285986175760
	2285986175760 [label=AccumulateGrad]
	2285986175856 -> 2285986175808
	2285956145584 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2285956145584 -> 2285986175856
	2285986175856 [label=AccumulateGrad]
	2285986175952 -> 2285986176000
	2285956145680 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	2285956145680 -> 2285986175952
	2285986175952 [label=AccumulateGrad]
	2285986176144 -> 2285986176000
	2285956145776 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	2285956145776 -> 2285986176144
	2285986176144 [label=AccumulateGrad]
	2285986176192 -> 2285986176432
	2285956146160 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2285956146160 -> 2285986176192
	2285986176192 [label=AccumulateGrad]
	2285986176480 -> 2285986176624
	2285956146256 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	2285956146256 -> 2285986176480
	2285986176480 [label=AccumulateGrad]
	2285986176720 -> 2285986176624
	2285956146352 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	2285956146352 -> 2285986176720
	2285986176720 [label=AccumulateGrad]
	2285986176816 -> 2285986176672
	2285986176768 -> 2285986177104
	2285956146736 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2285956146736 -> 2285986176768
	2285986176768 [label=AccumulateGrad]
	2285986177296 -> 2285986177152
	2285956146832 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	2285956146832 -> 2285986177296
	2285986177296 [label=AccumulateGrad]
	2285986177248 -> 2285986177152
	2285956146928 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	2285956146928 -> 2285986177248
	2285986177248 [label=AccumulateGrad]
	2285986177440 -> 2285986177776
	2285956147312 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2285956147312 -> 2285986177440
	2285986177440 [label=AccumulateGrad]
	2285986177632 -> 2285986177536
	2285956147408 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	2285956147408 -> 2285986177632
	2285986177632 [label=AccumulateGrad]
	2285986177872 -> 2285986177536
	2285956147504 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	2285956147504 -> 2285986177872
	2285986177872 [label=AccumulateGrad]
	2285986178160 -> 2285986178112
	2285956147888 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2285956147888 -> 2285986178160
	2285986178160 [label=AccumulateGrad]
	2285986178016 -> 2285986178352
	2285956147984 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	2285956147984 -> 2285986178016
	2285986178016 [label=AccumulateGrad]
	2285986178208 -> 2285986178352
	2285956148080 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	2285956148080 -> 2285986178208
	2285986178208 [label=AccumulateGrad]
	2285986178400 -> 2285986178640
	2285986178736 -> 2285986178832
	2285956148464 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2285956148464 -> 2285986178736
	2285986178736 [label=AccumulateGrad]
	2285986178880 -> 2285986179120
	2285956148560 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	2285956148560 -> 2285986178880
	2285986178880 [label=AccumulateGrad]
	2285986179216 -> 2285986179120
	2285956148656 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	2285956148656 -> 2285986179216
	2285986179216 [label=AccumulateGrad]
	2285986178976 -> 2285986179360
	2285956149040 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2285956149040 -> 2285986178976
	2285986178976 [label=AccumulateGrad]
	2285986179600 -> 2285986179504
	2285956149136 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	2285956149136 -> 2285986179600
	2285986179600 [label=AccumulateGrad]
	2285986179552 -> 2285986179504
	2285956149232 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	2285956149232 -> 2285986179552
	2285986179552 [label=AccumulateGrad]
	2285986179648 -> 2285986180080
	2285956149616 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2285956149616 -> 2285986179648
	2285986179648 [label=AccumulateGrad]
	2285986179984 -> 2285986180032
	2285956149712 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	2285956149712 -> 2285986179984
	2285986179984 [label=AccumulateGrad]
	2285986180176 -> 2285986180032
	2285956149808 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	2285956149808 -> 2285986180176
	2285986180176 [label=AccumulateGrad]
	2285986179936 -> 2285986180128
	2285986180320 -> 2285986180512
	2285956150192 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2285956150192 -> 2285986180320
	2285986180320 [label=AccumulateGrad]
	2285986180416 -> 2285986180608
	2285956150288 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	2285956150288 -> 2285986180416
	2285986180416 [label=AccumulateGrad]
	2285986180800 -> 2285986180608
	2285956150384 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	2285956150384 -> 2285986180800
	2285986180800 [label=AccumulateGrad]
	2285986180944 -> 2285986180896
	2285956150768 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2285956150768 -> 2285986180944
	2285986180944 [label=AccumulateGrad]
	2285986181088 -> 2285986181232
	2285956150864 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	2285956150864 -> 2285986181088
	2285986181088 [label=AccumulateGrad]
	2285986181520 -> 2285986181232
	2285956150960 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	2285956150960 -> 2285986181520
	2285986181520 [label=AccumulateGrad]
	2285986181616 -> 2285986181568
	2285956151344 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2285956151344 -> 2285986181616
	2285986181616 [label=AccumulateGrad]
	2285986181712 -> 2285986182000
	2285956151440 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	2285956151440 -> 2285986181712
	2285986181712 [label=AccumulateGrad]
	2285986181760 -> 2285986182000
	2285956151536 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	2285956151536 -> 2285986181760
	2285986181760 [label=AccumulateGrad]
	2285986181904 -> 2285986182096
	2285986182192 -> 2285986182384
	2285956152496 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2285956152496 -> 2285986182192
	2285986182192 [label=AccumulateGrad]
	2285986182576 -> 2285986182432
	2285956152592 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2285956152592 -> 2285986182576
	2285986182576 [label=AccumulateGrad]
	2285986182528 -> 2285986182432
	2285956152688 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2285956152688 -> 2285986182528
	2285986182528 [label=AccumulateGrad]
	2285986182720 -> 2285986183056
	2285956153072 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2285956153072 -> 2285986182720
	2285986182720 [label=AccumulateGrad]
	2285986182912 -> 2285986182816
	2285956153168 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2285956153168 -> 2285986182912
	2285986182912 [label=AccumulateGrad]
	2285986183152 -> 2285986182816
	2285956153264 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2285956153264 -> 2285986183152
	2285986183152 [label=AccumulateGrad]
	2285986183440 -> 2285986183392
	2285955826032 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2285955826032 -> 2285986183440
	2285986183440 [label=AccumulateGrad]
	2285986183296 -> 2285986183632
	2285955826128 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	2285955826128 -> 2285986183296
	2285986183296 [label=AccumulateGrad]
	2285986183488 -> 2285986183632
	2285955826224 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	2285955826224 -> 2285986183488
	2285986183488 [label=AccumulateGrad]
	2285986183680 -> 2285986183920
	2285986183680 [label=CudnnBatchNormBackward0]
	2285986182960 -> 2285986183680
	2285986182960 [label=ConvolutionBackward0]
	2285986182048 -> 2285986182960
	2285986182480 -> 2285986182960
	2285956151920 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	2285956151920 -> 2285986182480
	2285986182480 [label=AccumulateGrad]
	2285986183344 -> 2285986183680
	2285956152016 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	2285956152016 -> 2285986183344
	2285986183344 [label=AccumulateGrad]
	2285986183536 -> 2285986183680
	2285956152112 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	2285956152112 -> 2285986183536
	2285986183536 [label=AccumulateGrad]
	2285986184016 -> 2285986184112
	2285955826608 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2285955826608 -> 2285986184016
	2285986184016 [label=AccumulateGrad]
	2285986184160 -> 2285986184400
	2285955826704 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2285955826704 -> 2285986184160
	2285986184160 [label=AccumulateGrad]
	2285986184496 -> 2285986184400
	2285955826800 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2285955826800 -> 2285986184496
	2285986184496 [label=AccumulateGrad]
	2285986184256 -> 2285986184640
	2285955827184 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2285955827184 -> 2285986184256
	2285986184256 [label=AccumulateGrad]
	2285986184880 -> 2285986184784
	2285955827280 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2285955827280 -> 2285986184880
	2285986184880 [label=AccumulateGrad]
	2285986184832 -> 2285986184784
	2285955827376 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2285955827376 -> 2285986184832
	2285986184832 [label=AccumulateGrad]
	2285986184928 -> 2285986170576
	2285955827760 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2285955827760 -> 2285986184928
	2285986184928 [label=AccumulateGrad]
	2285986171824 -> 2285986172352
	2285955827856 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	2285955827856 -> 2285986171824
	2285986171824 [label=AccumulateGrad]
	2285986172544 -> 2285986172352
	2285955827952 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	2285955827952 -> 2285986172544
	2285986172544 [label=AccumulateGrad]
	2285986173168 -> 2285986172016
	2285986173504 -> 2285986174464
	2285955828336 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2285955828336 -> 2285986173504
	2285986173504 [label=AccumulateGrad]
	2285986175088 -> 2285986174944
	2285955828432 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	2285955828432 -> 2285986175088
	2285986175088 [label=AccumulateGrad]
	2285986175424 -> 2285986174944
	2285955828528 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	2285955828528 -> 2285986175424
	2285986175424 [label=AccumulateGrad]
	2285986175904 -> 2285986177008
	2285955828912 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2285955828912 -> 2285986175904
	2285986175904 [label=AccumulateGrad]
	2285986176864 -> 2285986177488
	2285955829008 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	2285955829008 -> 2285986176864
	2285986176864 [label=AccumulateGrad]
	2285986177968 -> 2285986177488
	2285955829104 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	2285955829104 -> 2285986177968
	2285986177968 [label=AccumulateGrad]
	2285986178448 -> 2285986178784
	2285955829488 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2285955829488 -> 2285986178448
	2285986178448 [label=AccumulateGrad]
	2285986179408 -> 2285986179888
	2285955829584 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	2285955829584 -> 2285986179408
	2285986179408 [label=AccumulateGrad]
	2285986179264 -> 2285986179888
	2285955829680 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	2285955829680 -> 2285986179264
	2285986179264 [label=AccumulateGrad]
	2285986179744 -> 2285986180368
	2285986181808 -> 2285986182624
	2285986181808 [label=TBackward0]
	2285986180224 -> 2285986181808
	2285955830352 [label="fc.weight
 (19, 2048)" fillcolor=lightblue]
	2285955830352 -> 2285986180224
	2285986180224 [label=AccumulateGrad]
	2285986182624 -> 2285955288912
}
