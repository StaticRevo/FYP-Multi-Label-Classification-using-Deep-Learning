digraph {
	graph [size="152.25,152.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2240923493168 [label="
 (1, 19)" fillcolor=darkolivegreen1]
	2240502346128 [label=SigmoidBackward0]
	2240502345984 -> 2240502346128
	2240502345984 [label=AddmmBackward0]
	2240502345888 -> 2240502345984
	2240923073040 [label="model.fc.bias
 (19)" fillcolor=lightblue]
	2240923073040 -> 2240502345888
	2240502345888 [label=AccumulateGrad]
	2240502345936 -> 2240502345984
	2240502345936 [label=ViewBackward0]
	2240502345840 -> 2240502345936
	2240502345840 [label=MeanBackward1]
	2240502345696 -> 2240502345840
	2240502345696 [label=ReluBackward0]
	2240502337440 -> 2240502345696
	2240502337440 [label=AddBackward0]
	2240502337344 -> 2240502337440
	2240502337344 [label=CudnnBatchNormBackward0]
	2240502337152 -> 2240502337344
	2240502337152 [label=ConvolutionBackward0]
	2240502336672 -> 2240502337152
	2240502336672 [label=ReluBackward0]
	2240502336528 -> 2240502336672
	2240502336528 [label=CudnnBatchNormBackward0]
	2240502336384 -> 2240502336528
	2240502336384 [label=ConvolutionBackward0]
	2240502344352 -> 2240502336384
	2240502344352 [label=ReluBackward0]
	2240502344112 -> 2240502344352
	2240502344112 [label=CudnnBatchNormBackward0]
	2240502344016 -> 2240502344112
	2240502344016 [label=ConvolutionBackward0]
	2240502345600 -> 2240502344016
	2240502345600 [label=ReluBackward0]
	2240502343440 -> 2240502345600
	2240502343440 [label=AddBackward0]
	2240502343344 -> 2240502343440
	2240502343344 [label=CudnnBatchNormBackward0]
	2240502343104 -> 2240502343344
	2240502343104 [label=ConvolutionBackward0]
	2240502342816 -> 2240502343104
	2240502342816 [label=ReluBackward0]
	2240502342192 -> 2240502342816
	2240502342192 [label=CudnnBatchNormBackward0]
	2240502342000 -> 2240502342192
	2240502342000 [label=ConvolutionBackward0]
	2240502341952 -> 2240502342000
	2240502341952 [label=ReluBackward0]
	2240502345120 -> 2240502341952
	2240502345120 [label=CudnnBatchNormBackward0]
	2240502347616 -> 2240502345120
	2240502347616 [label=ConvolutionBackward0]
	2240502343392 -> 2240502347616
	2240502343392 [label=ReluBackward0]
	2240502344448 -> 2240502343392
	2240502344448 [label=AddBackward0]
	2240502341808 -> 2240502344448
	2240502341808 [label=CudnnBatchNormBackward0]
	2240502348096 -> 2240502341808
	2240502348096 [label=ConvolutionBackward0]
	2240502336144 -> 2240502348096
	2240502336144 [label=ReluBackward0]
	2240502336960 -> 2240502336144
	2240502336960 [label=CudnnBatchNormBackward0]
	2240502336432 -> 2240502336960
	2240502336432 [label=ConvolutionBackward0]
	2240502337200 -> 2240502336432
	2240502337200 [label=ReluBackward0]
	2240502337584 -> 2240502337200
	2240502337584 [label=CudnnBatchNormBackward0]
	2240502338976 -> 2240502337584
	2240502338976 [label=ConvolutionBackward0]
	2240502338928 -> 2240502338976
	2240502338928 [label=ReluBackward0]
	2240502339840 -> 2240502338928
	2240502339840 [label=AddBackward0]
	2240502340176 -> 2240502339840
	2240502340176 [label=CudnnBatchNormBackward0]
	2240502338352 -> 2240502340176
	2240502338352 [label=ConvolutionBackward0]
	2240923435168 -> 2240502338352
	2240923435168 [label=ReluBackward0]
	2240923435312 -> 2240923435168
	2240923435312 [label=CudnnBatchNormBackward0]
	2240923435408 -> 2240923435312
	2240923435408 [label=ConvolutionBackward0]
	2240923435600 -> 2240923435408
	2240923435600 [label=ReluBackward0]
	2240923435744 -> 2240923435600
	2240923435744 [label=CudnnBatchNormBackward0]
	2240923435840 -> 2240923435744
	2240923435840 [label=ConvolutionBackward0]
	2240502339936 -> 2240923435840
	2240502339936 [label=ReluBackward0]
	2240923436128 -> 2240502339936
	2240923436128 [label=AddBackward0]
	2240923436224 -> 2240923436128
	2240923436224 [label=CudnnBatchNormBackward0]
	2240923436368 -> 2240923436224
	2240923436368 [label=ConvolutionBackward0]
	2240923436560 -> 2240923436368
	2240923436560 [label=ReluBackward0]
	2240923436704 -> 2240923436560
	2240923436704 [label=CudnnBatchNormBackward0]
	2240923436752 -> 2240923436704
	2240923436752 [label=ConvolutionBackward0]
	2240923437040 -> 2240923436752
	2240923437040 [label=ReluBackward0]
	2240923437184 -> 2240923437040
	2240923437184 [label=CudnnBatchNormBackward0]
	2240923437232 -> 2240923437184
	2240923437232 [label=ConvolutionBackward0]
	2240923436176 -> 2240923437232
	2240923436176 [label=ReluBackward0]
	2240923437616 -> 2240923436176
	2240923437616 [label=AddBackward0]
	2240923437664 -> 2240923437616
	2240923437664 [label=CudnnBatchNormBackward0]
	2240923437904 -> 2240923437664
	2240923437904 [label=ConvolutionBackward0]
	2240923438096 -> 2240923437904
	2240923438096 [label=ReluBackward0]
	2240923438240 -> 2240923438096
	2240923438240 [label=CudnnBatchNormBackward0]
	2240923438288 -> 2240923438240
	2240923438288 [label=ConvolutionBackward0]
	2240923438576 -> 2240923438288
	2240923438576 [label=ReluBackward0]
	2240923438720 -> 2240923438576
	2240923438720 [label=CudnnBatchNormBackward0]
	2240923438768 -> 2240923438720
	2240923438768 [label=ConvolutionBackward0]
	2240923437424 -> 2240923438768
	2240923437424 [label=ReluBackward0]
	2240923439152 -> 2240923437424
	2240923439152 [label=AddBackward0]
	2240923439200 -> 2240923439152
	2240923439200 [label=CudnnBatchNormBackward0]
	2240923439440 -> 2240923439200
	2240923439440 [label=ConvolutionBackward0]
	2240923439632 -> 2240923439440
	2240923439632 [label=ReluBackward0]
	2240923439776 -> 2240923439632
	2240923439776 [label=CudnnBatchNormBackward0]
	2240923439824 -> 2240923439776
	2240923439824 [label=ConvolutionBackward0]
	2240923440112 -> 2240923439824
	2240923440112 [label=ReluBackward0]
	2240923440256 -> 2240923440112
	2240923440256 [label=CudnnBatchNormBackward0]
	2240923440304 -> 2240923440256
	2240923440304 [label=ConvolutionBackward0]
	2240923438960 -> 2240923440304
	2240923438960 [label=ReluBackward0]
	2240923440688 -> 2240923438960
	2240923440688 [label=AddBackward0]
	2240923440736 -> 2240923440688
	2240923440736 [label=CudnnBatchNormBackward0]
	2240923440976 -> 2240923440736
	2240923440976 [label=ConvolutionBackward0]
	2240923441168 -> 2240923440976
	2240923441168 [label=ReluBackward0]
	2240923441312 -> 2240923441168
	2240923441312 [label=CudnnBatchNormBackward0]
	2240923441360 -> 2240923441312
	2240923441360 [label=ConvolutionBackward0]
	2240923441648 -> 2240923441360
	2240923441648 [label=ReluBackward0]
	2240923441792 -> 2240923441648
	2240923441792 [label=CudnnBatchNormBackward0]
	2240923441840 -> 2240923441792
	2240923441840 [label=ConvolutionBackward0]
	2240923440496 -> 2240923441840
	2240923440496 [label=ReluBackward0]
	2240923442224 -> 2240923440496
	2240923442224 [label=AddBackward0]
	2240923442272 -> 2240923442224
	2240923442272 [label=CudnnBatchNormBackward0]
	2240923442512 -> 2240923442272
	2240923442512 [label=ConvolutionBackward0]
	2240923442704 -> 2240923442512
	2240923442704 [label=ReluBackward0]
	2240923442848 -> 2240923442704
	2240923442848 [label=CudnnBatchNormBackward0]
	2240923442896 -> 2240923442848
	2240923442896 [label=ConvolutionBackward0]
	2240923443184 -> 2240923442896
	2240923443184 [label=ReluBackward0]
	2240923443328 -> 2240923443184
	2240923443328 [label=CudnnBatchNormBackward0]
	2240923443376 -> 2240923443328
	2240923443376 [label=ConvolutionBackward0]
	2240923443664 -> 2240923443376
	2240923443664 [label=ReluBackward0]
	2240923443808 -> 2240923443664
	2240923443808 [label=AddBackward0]
	2240923443856 -> 2240923443808
	2240923443856 [label=CudnnBatchNormBackward0]
	2240923444096 -> 2240923443856
	2240923444096 [label=ConvolutionBackward0]
	2240923444288 -> 2240923444096
	2240923444288 [label=ReluBackward0]
	2240923444432 -> 2240923444288
	2240923444432 [label=CudnnBatchNormBackward0]
	2240923444480 -> 2240923444432
	2240923444480 [label=ConvolutionBackward0]
	2240923444768 -> 2240923444480
	2240923444768 [label=ReluBackward0]
	2240923444912 -> 2240923444768
	2240923444912 [label=CudnnBatchNormBackward0]
	2240923444960 -> 2240923444912
	2240923444960 [label=ConvolutionBackward0]
	2240923443712 -> 2240923444960
	2240923443712 [label=ReluBackward0]
	2240923445344 -> 2240923443712
	2240923445344 [label=AddBackward0]
	2240923445392 -> 2240923445344
	2240923445392 [label=CudnnBatchNormBackward0]
	2240923445632 -> 2240923445392
	2240923445632 [label=ConvolutionBackward0]
	2240923445824 -> 2240923445632
	2240923445824 [label=ReluBackward0]
	2240923445968 -> 2240923445824
	2240923445968 [label=CudnnBatchNormBackward0]
	2240923446016 -> 2240923445968
	2240923446016 [label=ConvolutionBackward0]
	2240923446304 -> 2240923446016
	2240923446304 [label=ReluBackward0]
	2240923446448 -> 2240923446304
	2240923446448 [label=CudnnBatchNormBackward0]
	2240923446496 -> 2240923446448
	2240923446496 [label=ConvolutionBackward0]
	2240923445152 -> 2240923446496
	2240923445152 [label=ReluBackward0]
	2240923446880 -> 2240923445152
	2240923446880 [label=AddBackward0]
	2240923446928 -> 2240923446880
	2240923446928 [label=CudnnBatchNormBackward0]
	2240923447168 -> 2240923446928
	2240923447168 [label=ConvolutionBackward0]
	2240923447360 -> 2240923447168
	2240923447360 [label=ReluBackward0]
	2240923447504 -> 2240923447360
	2240923447504 [label=CudnnBatchNormBackward0]
	2240923447552 -> 2240923447504
	2240923447552 [label=ConvolutionBackward0]
	2240923447840 -> 2240923447552
	2240923447840 [label=ReluBackward0]
	2240923447984 -> 2240923447840
	2240923447984 [label=CudnnBatchNormBackward0]
	2240923448032 -> 2240923447984
	2240923448032 [label=ConvolutionBackward0]
	2240923446688 -> 2240923448032
	2240923446688 [label=ReluBackward0]
	2240923448416 -> 2240923446688
	2240923448416 [label=AddBackward0]
	2240923448464 -> 2240923448416
	2240923448464 [label=CudnnBatchNormBackward0]
	2240923448704 -> 2240923448464
	2240923448704 [label=ConvolutionBackward0]
	2240923448896 -> 2240923448704
	2240923448896 [label=ReluBackward0]
	2240923449040 -> 2240923448896
	2240923449040 [label=CudnnBatchNormBackward0]
	2240923449088 -> 2240923449040
	2240923449088 [label=ConvolutionBackward0]
	2240923449376 -> 2240923449088
	2240923449376 [label=ReluBackward0]
	2240923449520 -> 2240923449376
	2240923449520 [label=CudnnBatchNormBackward0]
	2240923449568 -> 2240923449520
	2240923449568 [label=ConvolutionBackward0]
	2240923449856 -> 2240923449568
	2240923449856 [label=ReluBackward0]
	2240923450000 -> 2240923449856
	2240923450000 [label=AddBackward0]
	2240923450048 -> 2240923450000
	2240923450048 [label=CudnnBatchNormBackward0]
	2240923450288 -> 2240923450048
	2240923450288 [label=ConvolutionBackward0]
	2240923450480 -> 2240923450288
	2240923450480 [label=ReluBackward0]
	2240923450624 -> 2240923450480
	2240923450624 [label=CudnnBatchNormBackward0]
	2240923450672 -> 2240923450624
	2240923450672 [label=ConvolutionBackward0]
	2240923450960 -> 2240923450672
	2240923450960 [label=ReluBackward0]
	2240923451104 -> 2240923450960
	2240923451104 [label=CudnnBatchNormBackward0]
	2240923451152 -> 2240923451104
	2240923451152 [label=ConvolutionBackward0]
	2240923449904 -> 2240923451152
	2240923449904 [label=ReluBackward0]
	2240923582672 -> 2240923449904
	2240923582672 [label=AddBackward0]
	2240923582720 -> 2240923582672
	2240923582720 [label=CudnnBatchNormBackward0]
	2240923582960 -> 2240923582720
	2240923582960 [label=ConvolutionBackward0]
	2240923583152 -> 2240923582960
	2240923583152 [label=ReluBackward0]
	2240923583296 -> 2240923583152
	2240923583296 [label=CudnnBatchNormBackward0]
	2240923583344 -> 2240923583296
	2240923583344 [label=ConvolutionBackward0]
	2240923583632 -> 2240923583344
	2240923583632 [label=ReluBackward0]
	2240923583776 -> 2240923583632
	2240923583776 [label=CudnnBatchNormBackward0]
	2240923583824 -> 2240923583776
	2240923583824 [label=ConvolutionBackward0]
	2240923582528 -> 2240923583824
	2240923582528 [label=ReluBackward0]
	2240923584208 -> 2240923582528
	2240923584208 [label=AddBackward0]
	2240923584256 -> 2240923584208
	2240923584256 [label=CudnnBatchNormBackward0]
	2240923584496 -> 2240923584256
	2240923584496 [label=ConvolutionBackward0]
	2240923584688 -> 2240923584496
	2240923584688 [label=ReluBackward0]
	2240923584832 -> 2240923584688
	2240923584832 [label=CudnnBatchNormBackward0]
	2240923584880 -> 2240923584832
	2240923584880 [label=ConvolutionBackward0]
	2240923585168 -> 2240923584880
	2240923585168 [label=ReluBackward0]
	2240923585312 -> 2240923585168
	2240923585312 [label=CudnnBatchNormBackward0]
	2240923585360 -> 2240923585312
	2240923585360 [label=ConvolutionBackward0]
	2240923585648 -> 2240923585360
	2240923585648 [label=MaxPool2DWithIndicesBackward0]
	2240923585792 -> 2240923585648
	2240923585792 [label=ReluBackward0]
	2240923585840 -> 2240923585792
	2240923585840 [label=CudnnBatchNormBackward0]
	2240923585984 -> 2240923585840
	2240923585984 [label=ConvolutionBackward0]
	2240923586272 -> 2240923585984
	2240538133712 [label="model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2240538133712 -> 2240923586272
	2240923586272 [label=AccumulateGrad]
	2240923585936 -> 2240923585840
	2240538133808 [label="model.bn1.weight
 (64)" fillcolor=lightblue]
	2240538133808 -> 2240923585936
	2240923585936 [label=AccumulateGrad]
	2240923586080 -> 2240923585840
	2240538133904 [label="model.bn1.bias
 (64)" fillcolor=lightblue]
	2240538133904 -> 2240923586080
	2240923586080 [label=AccumulateGrad]
	2240923585600 -> 2240923585360
	2240538134864 [label="model.layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2240538134864 -> 2240923585600
	2240923585600 [label=AccumulateGrad]
	2240923585216 -> 2240923585312
	2240538134960 [label="model.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2240538134960 -> 2240923585216
	2240923585216 [label=AccumulateGrad]
	2240923585456 -> 2240923585312
	2240538135056 [label="model.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2240538135056 -> 2240923585456
	2240923585456 [label=AccumulateGrad]
	2240923585120 -> 2240923584880
	2240538135440 [label="model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2240538135440 -> 2240923585120
	2240923585120 [label=AccumulateGrad]
	2240923584736 -> 2240923584832
	2240538135536 [label="model.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2240538135536 -> 2240923584736
	2240923584736 [label=AccumulateGrad]
	2240923584976 -> 2240923584832
	2240538135632 [label="model.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2240538135632 -> 2240923584976
	2240923584976 [label=AccumulateGrad]
	2240923584640 -> 2240923584496
	2240538136016 [label="model.layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2240538136016 -> 2240923584640
	2240923584640 [label=AccumulateGrad]
	2240923584448 -> 2240923584256
	2240538136112 [label="model.layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	2240538136112 -> 2240923584448
	2240923584448 [label=AccumulateGrad]
	2240923584400 -> 2240923584256
	2240538136208 [label="model.layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	2240538136208 -> 2240923584400
	2240923584400 [label=AccumulateGrad]
	2240923584016 -> 2240923584208
	2240923584016 [label=CudnnBatchNormBackward0]
	2240923585072 -> 2240923584016
	2240923585072 [label=ConvolutionBackward0]
	2240923585648 -> 2240923585072
	2240923585504 -> 2240923585072
	2240538134288 [label="model.layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2240538134288 -> 2240923585504
	2240923585504 [label=AccumulateGrad]
	2240923584592 -> 2240923584016
	2240538134384 [label="model.layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2240538134384 -> 2240923584592
	2240923584592 [label=AccumulateGrad]
	2240923584544 -> 2240923584016
	2240538134480 [label="model.layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2240538134480 -> 2240923584544
	2240923584544 [label=AccumulateGrad]
	2240923584112 -> 2240923583824
	2240538136592 [label="model.layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2240538136592 -> 2240923584112
	2240923584112 [label=AccumulateGrad]
	2240923583680 -> 2240923583776
	2240538136688 [label="model.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2240538136688 -> 2240923583680
	2240923583680 [label=AccumulateGrad]
	2240923583920 -> 2240923583776
	2240538136784 [label="model.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2240538136784 -> 2240923583920
	2240923583920 [label=AccumulateGrad]
	2240923583584 -> 2240923583344
	2240538137168 [label="model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2240538137168 -> 2240923583584
	2240923583584 [label=AccumulateGrad]
	2240923583200 -> 2240923583296
	2240538099984 [label="model.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2240538099984 -> 2240923583200
	2240923583200 [label=AccumulateGrad]
	2240923583440 -> 2240923583296
	2240538099888 [label="model.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2240538099888 -> 2240923583440
	2240923583440 [label=AccumulateGrad]
	2240923583104 -> 2240923582960
	2240537886160 [label="model.layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2240537886160 -> 2240923583104
	2240923583104 [label=AccumulateGrad]
	2240923582912 -> 2240923582720
	2240537886064 [label="model.layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	2240537886064 -> 2240923582912
	2240923582912 [label=AccumulateGrad]
	2240923582864 -> 2240923582720
	2240537885776 [label="model.layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	2240537885776 -> 2240923582864
	2240923582864 [label=AccumulateGrad]
	2240923582528 -> 2240923582672
	2240923451344 -> 2240923451152
	2240538137456 [label="model.layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2240538137456 -> 2240923451344
	2240923451344 [label=AccumulateGrad]
	2240923451008 -> 2240923451104
	2240538137552 [label="model.layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	2240538137552 -> 2240923451008
	2240923451008 [label=AccumulateGrad]
	2240923451248 -> 2240923451104
	2240538137648 [label="model.layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	2240538137648 -> 2240923451248
	2240923451248 [label=AccumulateGrad]
	2240923450912 -> 2240923450672
	2240538138032 [label="model.layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2240538138032 -> 2240923450912
	2240923450912 [label=AccumulateGrad]
	2240923450528 -> 2240923450624
	2240538138128 [label="model.layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	2240538138128 -> 2240923450528
	2240923450528 [label=AccumulateGrad]
	2240923450768 -> 2240923450624
	2240538138224 [label="model.layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	2240538138224 -> 2240923450768
	2240923450768 [label=AccumulateGrad]
	2240923450432 -> 2240923450288
	2240538138608 [label="model.layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2240538138608 -> 2240923450432
	2240923450432 [label=AccumulateGrad]
	2240923450240 -> 2240923450048
	2240538138704 [label="model.layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	2240538138704 -> 2240923450240
	2240923450240 [label=AccumulateGrad]
	2240923450192 -> 2240923450048
	2240538138800 [label="model.layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	2240538138800 -> 2240923450192
	2240923450192 [label=AccumulateGrad]
	2240923449904 -> 2240923450000
	2240923449808 -> 2240923449568
	2240538139760 [label="model.layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2240538139760 -> 2240923449808
	2240923449808 [label=AccumulateGrad]
	2240923449424 -> 2240923449520
	2240538139856 [label="model.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2240538139856 -> 2240923449424
	2240923449424 [label=AccumulateGrad]
	2240923449664 -> 2240923449520
	2240538139952 [label="model.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2240538139952 -> 2240923449664
	2240923449664 [label=AccumulateGrad]
	2240923449328 -> 2240923449088
	2240538140336 [label="model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2240538140336 -> 2240923449328
	2240923449328 [label=AccumulateGrad]
	2240923448944 -> 2240923449040
	2240538140432 [label="model.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2240538140432 -> 2240923448944
	2240923448944 [label=AccumulateGrad]
	2240923449184 -> 2240923449040
	2240538140528 [label="model.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2240538140528 -> 2240923449184
	2240923449184 [label=AccumulateGrad]
	2240923448848 -> 2240923448704
	2240538140912 [label="model.layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2240538140912 -> 2240923448848
	2240923448848 [label=AccumulateGrad]
	2240923448656 -> 2240923448464
	2240538141008 [label="model.layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	2240538141008 -> 2240923448656
	2240923448656 [label=AccumulateGrad]
	2240923448608 -> 2240923448464
	2240538141104 [label="model.layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	2240538141104 -> 2240923448608
	2240923448608 [label=AccumulateGrad]
	2240923448224 -> 2240923448416
	2240923448224 [label=CudnnBatchNormBackward0]
	2240923449280 -> 2240923448224
	2240923449280 [label=ConvolutionBackward0]
	2240923449856 -> 2240923449280
	2240923449712 -> 2240923449280
	2240538139184 [label="model.layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2240538139184 -> 2240923449712
	2240923449712 [label=AccumulateGrad]
	2240923448800 -> 2240923448224
	2240538139280 [label="model.layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2240538139280 -> 2240923448800
	2240923448800 [label=AccumulateGrad]
	2240923448752 -> 2240923448224
	2240538139376 [label="model.layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2240538139376 -> 2240923448752
	2240923448752 [label=AccumulateGrad]
	2240923448320 -> 2240923448032
	2240538141488 [label="model.layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2240538141488 -> 2240923448320
	2240923448320 [label=AccumulateGrad]
	2240923447888 -> 2240923447984
	2240538141584 [label="model.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2240538141584 -> 2240923447888
	2240923447888 [label=AccumulateGrad]
	2240923448128 -> 2240923447984
	2240538141680 [label="model.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2240538141680 -> 2240923448128
	2240923448128 [label=AccumulateGrad]
	2240923447792 -> 2240923447552
	2240538142064 [label="model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2240538142064 -> 2240923447792
	2240923447792 [label=AccumulateGrad]
	2240923447408 -> 2240923447504
	2240538142160 [label="model.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2240538142160 -> 2240923447408
	2240923447408 [label=AccumulateGrad]
	2240923447648 -> 2240923447504
	2240538142256 [label="model.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2240538142256 -> 2240923447648
	2240923447648 [label=AccumulateGrad]
	2240923447312 -> 2240923447168
	2240538142640 [label="model.layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2240538142640 -> 2240923447312
	2240923447312 [label=AccumulateGrad]
	2240923447120 -> 2240923446928
	2240538142736 [label="model.layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	2240538142736 -> 2240923447120
	2240923447120 [label=AccumulateGrad]
	2240923447072 -> 2240923446928
	2240538142832 [label="model.layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	2240538142832 -> 2240923447072
	2240923447072 [label=AccumulateGrad]
	2240923446688 -> 2240923446880
	2240923446784 -> 2240923446496
	2240538143216 [label="model.layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2240538143216 -> 2240923446784
	2240923446784 [label=AccumulateGrad]
	2240923446352 -> 2240923446448
	2240538143312 [label="model.layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	2240538143312 -> 2240923446352
	2240923446352 [label=AccumulateGrad]
	2240923446592 -> 2240923446448
	2240538143408 [label="model.layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	2240538143408 -> 2240923446592
	2240923446592 [label=AccumulateGrad]
	2240923446256 -> 2240923446016
	2240538143792 [label="model.layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2240538143792 -> 2240923446256
	2240923446256 [label=AccumulateGrad]
	2240923445872 -> 2240923445968
	2240538143888 [label="model.layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	2240538143888 -> 2240923445872
	2240923445872 [label=AccumulateGrad]
	2240923446112 -> 2240923445968
	2240538143984 [label="model.layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	2240538143984 -> 2240923446112
	2240923446112 [label=AccumulateGrad]
	2240923445776 -> 2240923445632
	2240538144368 [label="model.layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2240538144368 -> 2240923445776
	2240923445776 [label=AccumulateGrad]
	2240923445584 -> 2240923445392
	2240538144464 [label="model.layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	2240538144464 -> 2240923445584
	2240923445584 [label=AccumulateGrad]
	2240923445536 -> 2240923445392
	2240538144560 [label="model.layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	2240538144560 -> 2240923445536
	2240923445536 [label=AccumulateGrad]
	2240923445152 -> 2240923445344
	2240923445248 -> 2240923444960
	2240538144944 [label="model.layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2240538144944 -> 2240923445248
	2240923445248 [label=AccumulateGrad]
	2240923444816 -> 2240923444912
	2240538145040 [label="model.layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	2240538145040 -> 2240923444816
	2240923444816 [label=AccumulateGrad]
	2240923445056 -> 2240923444912
	2240538145136 [label="model.layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	2240538145136 -> 2240923445056
	2240923445056 [label=AccumulateGrad]
	2240923444720 -> 2240923444480
	2240538145520 [label="model.layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2240538145520 -> 2240923444720
	2240923444720 [label=AccumulateGrad]
	2240923444336 -> 2240923444432
	2240538145616 [label="model.layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	2240538145616 -> 2240923444336
	2240923444336 [label=AccumulateGrad]
	2240923444576 -> 2240923444432
	2240538145712 [label="model.layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	2240538145712 -> 2240923444576
	2240923444576 [label=AccumulateGrad]
	2240923444240 -> 2240923444096
	2240538146096 [label="model.layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2240538146096 -> 2240923444240
	2240923444240 [label=AccumulateGrad]
	2240923444048 -> 2240923443856
	2240538146192 [label="model.layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	2240538146192 -> 2240923444048
	2240923444048 [label=AccumulateGrad]
	2240923444000 -> 2240923443856
	2240538146288 [label="model.layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	2240538146288 -> 2240923444000
	2240923444000 [label=AccumulateGrad]
	2240923443712 -> 2240923443808
	2240923443616 -> 2240923443376
	2240538147248 [label="model.layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2240538147248 -> 2240923443616
	2240923443616 [label=AccumulateGrad]
	2240923443232 -> 2240923443328
	2240538147344 [label="model.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2240538147344 -> 2240923443232
	2240923443232 [label=AccumulateGrad]
	2240923443472 -> 2240923443328
	2240538147440 [label="model.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2240538147440 -> 2240923443472
	2240923443472 [label=AccumulateGrad]
	2240923443136 -> 2240923442896
	2240538147824 [label="model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2240538147824 -> 2240923443136
	2240923443136 [label=AccumulateGrad]
	2240923442752 -> 2240923442848
	2240538147920 [label="model.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2240538147920 -> 2240923442752
	2240923442752 [label=AccumulateGrad]
	2240923442992 -> 2240923442848
	2240538148016 [label="model.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2240538148016 -> 2240923442992
	2240923442992 [label=AccumulateGrad]
	2240923442656 -> 2240923442512
	2240538148400 [label="model.layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2240538148400 -> 2240923442656
	2240923442656 [label=AccumulateGrad]
	2240923442464 -> 2240923442272
	2240538148496 [label="model.layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	2240538148496 -> 2240923442464
	2240923442464 [label=AccumulateGrad]
	2240923442416 -> 2240923442272
	2240538148592 [label="model.layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	2240538148592 -> 2240923442416
	2240923442416 [label=AccumulateGrad]
	2240923442032 -> 2240923442224
	2240923442032 [label=CudnnBatchNormBackward0]
	2240923443088 -> 2240923442032
	2240923443088 [label=ConvolutionBackward0]
	2240923443664 -> 2240923443088
	2240923443520 -> 2240923443088
	2240538146672 [label="model.layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2240538146672 -> 2240923443520
	2240923443520 [label=AccumulateGrad]
	2240923442608 -> 2240923442032
	2240538146768 [label="model.layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	2240538146768 -> 2240923442608
	2240923442608 [label=AccumulateGrad]
	2240923442560 -> 2240923442032
	2240538146864 [label="model.layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	2240538146864 -> 2240923442560
	2240923442560 [label=AccumulateGrad]
	2240923442128 -> 2240923441840
	2240923058352 [label="model.layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2240923058352 -> 2240923442128
	2240923442128 [label=AccumulateGrad]
	2240923441696 -> 2240923441792
	2240923058448 [label="model.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2240923058448 -> 2240923441696
	2240923441696 [label=AccumulateGrad]
	2240923441936 -> 2240923441792
	2240923058544 [label="model.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2240923058544 -> 2240923441936
	2240923441936 [label=AccumulateGrad]
	2240923441600 -> 2240923441360
	2240923058928 [label="model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2240923058928 -> 2240923441600
	2240923441600 [label=AccumulateGrad]
	2240923441216 -> 2240923441312
	2240923059024 [label="model.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2240923059024 -> 2240923441216
	2240923441216 [label=AccumulateGrad]
	2240923441456 -> 2240923441312
	2240923059120 [label="model.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2240923059120 -> 2240923441456
	2240923441456 [label=AccumulateGrad]
	2240923441120 -> 2240923440976
	2240923059504 [label="model.layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2240923059504 -> 2240923441120
	2240923441120 [label=AccumulateGrad]
	2240923440928 -> 2240923440736
	2240923059600 [label="model.layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	2240923059600 -> 2240923440928
	2240923440928 [label=AccumulateGrad]
	2240923440880 -> 2240923440736
	2240923059696 [label="model.layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	2240923059696 -> 2240923440880
	2240923440880 [label=AccumulateGrad]
	2240923440496 -> 2240923440688
	2240923440592 -> 2240923440304
	2240923060080 [label="model.layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2240923060080 -> 2240923440592
	2240923440592 [label=AccumulateGrad]
	2240923440160 -> 2240923440256
	2240923060176 [label="model.layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	2240923060176 -> 2240923440160
	2240923440160 [label=AccumulateGrad]
	2240923440400 -> 2240923440256
	2240923060272 [label="model.layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	2240923060272 -> 2240923440400
	2240923440400 [label=AccumulateGrad]
	2240923440064 -> 2240923439824
	2240923060656 [label="model.layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2240923060656 -> 2240923440064
	2240923440064 [label=AccumulateGrad]
	2240923439680 -> 2240923439776
	2240923060752 [label="model.layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	2240923060752 -> 2240923439680
	2240923439680 [label=AccumulateGrad]
	2240923439920 -> 2240923439776
	2240923060848 [label="model.layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	2240923060848 -> 2240923439920
	2240923439920 [label=AccumulateGrad]
	2240923439584 -> 2240923439440
	2240923061232 [label="model.layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2240923061232 -> 2240923439584
	2240923439584 [label=AccumulateGrad]
	2240923439392 -> 2240923439200
	2240923061328 [label="model.layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	2240923061328 -> 2240923439392
	2240923439392 [label=AccumulateGrad]
	2240923439344 -> 2240923439200
	2240923061424 [label="model.layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	2240923061424 -> 2240923439344
	2240923439344 [label=AccumulateGrad]
	2240923438960 -> 2240923439152
	2240923439056 -> 2240923438768
	2240923061808 [label="model.layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2240923061808 -> 2240923439056
	2240923439056 [label=AccumulateGrad]
	2240923438624 -> 2240923438720
	2240923061904 [label="model.layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	2240923061904 -> 2240923438624
	2240923438624 [label=AccumulateGrad]
	2240923438864 -> 2240923438720
	2240923062000 [label="model.layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	2240923062000 -> 2240923438864
	2240923438864 [label=AccumulateGrad]
	2240923438528 -> 2240923438288
	2240923062384 [label="model.layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2240923062384 -> 2240923438528
	2240923438528 [label=AccumulateGrad]
	2240923438144 -> 2240923438240
	2240923062480 [label="model.layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	2240923062480 -> 2240923438144
	2240923438144 [label=AccumulateGrad]
	2240923438384 -> 2240923438240
	2240923062576 [label="model.layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	2240923062576 -> 2240923438384
	2240923438384 [label=AccumulateGrad]
	2240923438048 -> 2240923437904
	2240923062960 [label="model.layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2240923062960 -> 2240923438048
	2240923438048 [label=AccumulateGrad]
	2240923437856 -> 2240923437664
	2240923063056 [label="model.layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	2240923063056 -> 2240923437856
	2240923437856 [label=AccumulateGrad]
	2240923437808 -> 2240923437664
	2240923063152 [label="model.layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	2240923063152 -> 2240923437808
	2240923437808 [label=AccumulateGrad]
	2240923437424 -> 2240923437616
	2240923437520 -> 2240923437232
	2240923063536 [label="model.layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2240923063536 -> 2240923437520
	2240923437520 [label=AccumulateGrad]
	2240923437088 -> 2240923437184
	2240923063632 [label="model.layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	2240923063632 -> 2240923437088
	2240923437088 [label=AccumulateGrad]
	2240923437328 -> 2240923437184
	2240923063728 [label="model.layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	2240923063728 -> 2240923437328
	2240923437328 [label=AccumulateGrad]
	2240923436992 -> 2240923436752
	2240923064112 [label="model.layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2240923064112 -> 2240923436992
	2240923436992 [label=AccumulateGrad]
	2240923436608 -> 2240923436704
	2240923064208 [label="model.layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	2240923064208 -> 2240923436608
	2240923436608 [label=AccumulateGrad]
	2240923436848 -> 2240923436704
	2240923064304 [label="model.layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	2240923064304 -> 2240923436848
	2240923436848 [label=AccumulateGrad]
	2240923436512 -> 2240923436368
	2240923064688 [label="model.layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2240923064688 -> 2240923436512
	2240923436512 [label=AccumulateGrad]
	2240923436320 -> 2240923436224
	2240923064784 [label="model.layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	2240923064784 -> 2240923436320
	2240923436320 [label=AccumulateGrad]
	2240923436272 -> 2240923436224
	2240923064880 [label="model.layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	2240923064880 -> 2240923436272
	2240923436272 [label=AccumulateGrad]
	2240923436176 -> 2240923436128
	2240923436032 -> 2240923435840
	2240923065264 [label="model.layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2240923065264 -> 2240923436032
	2240923436032 [label=AccumulateGrad]
	2240923435792 -> 2240923435744
	2240923065360 [label="model.layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	2240923065360 -> 2240923435792
	2240923435792 [label=AccumulateGrad]
	2240923435648 -> 2240923435744
	2240923065456 [label="model.layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	2240923065456 -> 2240923435648
	2240923435648 [label=AccumulateGrad]
	2240923435552 -> 2240923435408
	2240923065840 [label="model.layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2240923065840 -> 2240923435552
	2240923435552 [label=AccumulateGrad]
	2240923435360 -> 2240923435312
	2240923065936 [label="model.layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	2240923065936 -> 2240923435360
	2240923435360 [label=AccumulateGrad]
	2240923435216 -> 2240923435312
	2240923066032 [label="model.layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	2240923066032 -> 2240923435216
	2240923435216 [label=AccumulateGrad]
	2240923435120 -> 2240502338352
	2240923066416 [label="model.layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2240923066416 -> 2240923435120
	2240923435120 [label=AccumulateGrad]
	2240502346512 -> 2240502340176
	2240923066512 [label="model.layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	2240923066512 -> 2240502346512
	2240502346512 [label=AccumulateGrad]
	2240502339792 -> 2240502340176
	2240923066608 [label="model.layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	2240923066608 -> 2240502339792
	2240502339792 [label=AccumulateGrad]
	2240502339936 -> 2240502339840
	2240502339504 -> 2240502338976
	2240923067568 [label="model.layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2240923067568 -> 2240502339504
	2240502339504 [label=AccumulateGrad]
	2240502338448 -> 2240502337584
	2240923067664 [label="model.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2240923067664 -> 2240502338448
	2240502338448 [label=AccumulateGrad]
	2240502338400 -> 2240502337584
	2240923067760 [label="model.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2240923067760 -> 2240502338400
	2240502338400 [label=AccumulateGrad]
	2240502337392 -> 2240502336432
	2240923068144 [label="model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2240923068144 -> 2240502337392
	2240502337392 [label=AccumulateGrad]
	2240502337008 -> 2240502336960
	2240923068240 [label="model.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2240923068240 -> 2240502337008
	2240502337008 [label=AccumulateGrad]
	2240502341328 -> 2240502336960
	2240923068336 [label="model.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2240923068336 -> 2240502341328
	2240502341328 [label=AccumulateGrad]
	2240502341568 -> 2240502348096
	2240923068720 [label="model.layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2240923068720 -> 2240502341568
	2240502341568 [label=AccumulateGrad]
	2240502349296 -> 2240502341808
	2240923068816 [label="model.layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	2240923068816 -> 2240502349296
	2240502349296 [label=AccumulateGrad]
	2240502341760 -> 2240502341808
	2240923068912 [label="model.layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	2240923068912 -> 2240502341760
	2240502341760 [label=AccumulateGrad]
	2240502336000 -> 2240502344448
	2240502336000 [label=CudnnBatchNormBackward0]
	2240502337488 -> 2240502336000
	2240502337488 [label=ConvolutionBackward0]
	2240502338928 -> 2240502337488
	2240502338880 -> 2240502337488
	2240923066992 [label="model.layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	2240923066992 -> 2240502338880
	2240502338880 [label=AccumulateGrad]
	2240502341376 -> 2240502336000
	2240923067088 [label="model.layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	2240923067088 -> 2240502341376
	2240502341376 [label=AccumulateGrad]
	2240502341280 -> 2240502336000
	2240923067184 [label="model.layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	2240923067184 -> 2240502341280
	2240502341280 [label=AccumulateGrad]
	2240502344064 -> 2240502347616
	2240923069296 [label="model.layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2240923069296 -> 2240502344064
	2240502344064 [label=AccumulateGrad]
	2240502340224 -> 2240502345120
	2240923069392 [label="model.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2240923069392 -> 2240502340224
	2240502340224 [label=AccumulateGrad]
	2240502342336 -> 2240502345120
	2240923069488 [label="model.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2240923069488 -> 2240502342336
	2240502342336 [label=AccumulateGrad]
	2240502343248 -> 2240502342000
	2240923069872 [label="model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2240923069872 -> 2240502343248
	2240502343248 [label=AccumulateGrad]
	2240502342144 -> 2240502342192
	2240923069968 [label="model.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2240923069968 -> 2240502342144
	2240502342144 [label=AccumulateGrad]
	2240502342768 -> 2240502342192
	2240923070064 [label="model.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2240923070064 -> 2240502342768
	2240502342768 [label=AccumulateGrad]
	2240502342960 -> 2240502343104
	2240923070448 [label="model.layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2240923070448 -> 2240502342960
	2240502342960 [label=AccumulateGrad]
	2240502343152 -> 2240502343344
	2240923070544 [label="model.layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	2240923070544 -> 2240502343152
	2240502343152 [label=AccumulateGrad]
	2240502343200 -> 2240502343344
	2240923070640 [label="model.layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	2240923070640 -> 2240502343200
	2240502343200 [label=AccumulateGrad]
	2240502343392 -> 2240502343440
	2240502343824 -> 2240502344016
	2240923071024 [label="model.layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2240923071024 -> 2240502343824
	2240502343824 [label=AccumulateGrad]
	2240502335904 -> 2240502344112
	2240923071120 [label="model.layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	2240923071120 -> 2240502335904
	2240502335904 [label=AccumulateGrad]
	2240502344304 -> 2240502344112
	2240923071216 [label="model.layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	2240923071216 -> 2240502344304
	2240502344304 [label=AccumulateGrad]
	2240502336192 -> 2240502336384
	2240923071600 [label="model.layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2240923071600 -> 2240502336192
	2240502336192 [label=AccumulateGrad]
	2240502336480 -> 2240502336528
	2240923071696 [label="model.layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	2240923071696 -> 2240502336480
	2240502336480 [label=AccumulateGrad]
	2240502336624 -> 2240502336528
	2240923071792 [label="model.layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	2240923071792 -> 2240502336624
	2240502336624 [label=AccumulateGrad]
	2240502336720 -> 2240502337152
	2240923072176 [label="model.layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2240923072176 -> 2240502336720
	2240502336720 [label=AccumulateGrad]
	2240502337248 -> 2240502337344
	2240923072272 [label="model.layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	2240923072272 -> 2240502337248
	2240502337248 [label=AccumulateGrad]
	2240502337296 -> 2240502337344
	2240923072368 [label="model.layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	2240923072368 -> 2240502337296
	2240502337296 [label=AccumulateGrad]
	2240502345600 -> 2240502337440
	2240502346080 -> 2240502345984
	2240502346080 [label=TBackward0]
	2240502345648 -> 2240502346080
	2240923072944 [label="model.fc.weight
 (19, 2048)" fillcolor=lightblue]
	2240923072944 -> 2240502345648
	2240502345648 [label=AccumulateGrad]
	2240502346128 -> 2240923493168
}
