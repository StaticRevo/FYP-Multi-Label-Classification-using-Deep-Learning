{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eaeba4b-17d7-4561-9b1e-7fc8d91a96ba",
   "metadata": {},
   "source": [
    "# Dataset Preparation - Stage 1\r\n",
    "This Jupyter Notebook is the first Notebook from a series of Notebooks that make use of a Convolutional Neural Network to perform land classification. This notebook outlines the steps involved in preparing the EuroSAT Sentinel 2 Dataset for the training of the CNN model. The preparation process of the dataset include:\n",
    "1. The **importing** of the necessary librares including os, shutil, random and gdal\n",
    "2. **Reducing** the amount of images found within the dataset to reduce load times and process times.\n",
    "3. The **organisation** of the dataset into appropriate sub-directories including the **Train, Test and Valid** directories within the dataset directory\n",
    "4. **Conversion and Enhancement** *of JPG images are performed, resulting in more vivid images with higher contrast and improved color differentiation due to the emphasis on the RGB bands.,\n",
    "5. Files are appropriatly **shuffled and split** into training (80%), validation (10%) and test (10%) based on predifined indices.\n",
    "6.Theny the files themsleves are** move**d to the respective directories based on the split\n",
    "7. Steps 5 and 6 are repeated for custom jpg images from Malta which are used at a later stage to test the CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df66bba-b711-496d-ae89-7b2a9d06efa4",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782f8f38-0bac-4d23-80b7-ba38394fdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module for interacting with the operating system's file system\n",
    "import os\n",
    "# Import the shutil module for high-level file operations such as copying and moving files\n",
    "import shutil\n",
    "# Import the random module for generating random numbers and making random selections\n",
    "import random\n",
    "# Import the subprocess module for running external commands\n",
    "import subprocess\n",
    "# Import tqdm for displaying progress bars\n",
    "from tqdm import tqdm  \n",
    "# Import the gdal module from the osgeo package for working with geospatial data formats\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4ab93-9081-4516-9dc0-fda786c5b443",
   "metadata": {},
   "source": [
    "### Setting the Base path and Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d920193-2e21-4b0d-b383-8e3f4b888318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the datasets directory\n",
    "path = \"C:/Users/isaac/datasets/eurosat-dataset\"\n",
    "\n",
    "# Set the random seed for reproducibility, this ensures that the random operations produce the same result every time the code is run\n",
    "SEED = random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d26991-33e4-4862-8620-5b282f894110",
   "metadata": {},
   "source": [
    "### Collecting Category Names and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d8367c-666b-4282-9421-a7f433896659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store category names and file paths\n",
    "categories = []  # List to hold the names of the categories (subdirectories)\n",
    "jpg_files = []   # List to hold the paths of all .jpg files\n",
    "\n",
    "# Walk through the directory tree starting from the specified path\n",
    "# os.walk generates the file names in a directory tree by walking the tree either top-down or bottom-up\n",
    "for dirpath, dirnames, filenames in os.walk(path):\n",
    "    # Add the directory names (categories) to the categories list\n",
    "    categories.extend(dirnames)\n",
    "    # Iterate over all filenames in the current directory\n",
    "    for filename in filenames:\n",
    "        # Check if the file has a .jpg extension\n",
    "        if filename.endswith('.jpg'):\n",
    "            # Add the full path of the .jpg file to the jpg_files list\n",
    "            jpg_files.append(os.path.join(dirpath, filename))\n",
    "\n",
    "# Print the list of categories (subdirectory names)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c3e63d-c7c7-4dc2-8012-478fa8827e00",
   "metadata": {},
   "source": [
    "### Reducing the Dataset by half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf3695c-7ccb-49ec-8354-eb80d9db1a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction of images in each category by 50% completed.\n"
     ]
    }
   ],
   "source": [
    "# Reduce the number of images in each category by 50% to reduce load times and process times\n",
    "for category in categories:\n",
    "    # Construct the path to the current category\n",
    "    category_path = os.path.join(path, category)\n",
    "    \n",
    "    # Filter jpg_files to get only the files in the current category\n",
    "    category_files = [file for file in jpg_files if file.startswith(category_path)]\n",
    "\n",
    "    # If there are more than one file in the category, reduce the number by 50%\n",
    "    if len(category_files) > 1:\n",
    "        # Calculate the number of files to keep (50% of the total)\n",
    "        num_files_to_keep = len(category_files) // 2\n",
    "        \n",
    "        # Randomly select a subset of files to keep\n",
    "        files_to_keep = random.sample(category_files, num_files_to_keep)\n",
    "        \n",
    "        # Determine the files to remove (those not in the files_to_keep list)\n",
    "        files_to_remove = set(category_files) - set(files_to_keep)\n",
    "        \n",
    "        # Iterate over the files to remove and delete them\n",
    "        for file_to_remove in files_to_remove:\n",
    "            os.remove(file_to_remove)  # Delete the file\n",
    "\n",
    "# Print a completion message\n",
    "print(\"Reduction of images in each category by 50% completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e91c8-eed1-498e-b453-f1d2ff42608b",
   "metadata": {},
   "source": [
    "### Creating and Organising Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc293a2-4d7e-4792-9778-5e9bdbb49ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\n",
      "\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\AnnualCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\Forest\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\HerbaceousVegetation\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\Highway\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\Industrial\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\Pasture\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\PermanentCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\Residential\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\River\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\train\\SeaLake\n",
      "Created folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\n",
      "\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\AnnualCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\Forest\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\HerbaceousVegetation\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\Highway\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\Industrial\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\Pasture\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\PermanentCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\Residential\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\River\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\test\\SeaLake\n",
      "Created folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\n",
      "\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\AnnualCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\Forest\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\HerbaceousVegetation\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\Highway\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\Industrial\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\Pasture\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\PermanentCrop\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\Residential\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\River\n",
      "Created category folder: C:/Users/isaac/datasets/eurosat-dataset\\dataset_splits\\valid\\SeaLake\n",
      "All folders created successfully.\n"
     ]
    }
   ],
   "source": [
    "# List of split names\n",
    "split_names = ['train', 'test', 'valid']\n",
    "\n",
    "# Create new folders for train, test, and valid sets with subfolders for all categories\n",
    "for sp_name in split_names:\n",
    "    directory = os.path.join(path, 'dataset_splits', sp_name)  # Path to the split folder\n",
    "    if not os.path.exists(directory):  # Check if the split folder doesn't exist\n",
    "        os.makedirs(directory)  # Create the split folder if it doesn't exist\n",
    "        print(f\"Created folder: {directory}\")\n",
    "        print()\n",
    "    # Create category folders within each split\n",
    "    for category in categories:\n",
    "        dir_cat = os.path.join(directory, category)  # Path to the category folder within the split\n",
    "        if not os.path.exists(dir_cat):  # Check if the category folder doesn't exist\n",
    "            os.makedirs(dir_cat)  # Create the category folder if it doesn't exist\n",
    "            print(f\"Created category folder: {dir_cat}\")\n",
    "\n",
    "print(\"All folders created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d188d-7c5a-458f-9c2e-0b02ff208c01",
   "metadata": {},
   "source": [
    "### Enhancing Colors and Contrast of JPG Images Using GDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44316d1-e6e8-4805-8164-f4ec7c802040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to enhance the colors and contrast of the JPG's using GDAL \n",
    "def process_image(input_file, output_file, bands=[1, 2, 3]):\n",
    "    try:\n",
    "        # Construct the gdal_translate command\n",
    "        command = ['gdal_translate', '-of', 'JPEG']  # Set output format to JPEG\n",
    "        for band in bands:\n",
    "            # Add each specified band to the command\n",
    "            command.extend(['-b', str(band)])\n",
    "        # Add the scaling operation and specify input and output file paths\n",
    "        command.extend(['-scale', input_file, output_file])\n",
    "        \n",
    "        # Run the constructed command using subprocess\n",
    "        subprocess.run(command, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # Catch and print an error message if the command fails\n",
    "        print(f\"Error converting {input_file} to {output_file}: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Return True to indicate successful conversion\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c8178-389a-4f3f-9647-5beed46395c7",
   "metadata": {},
   "source": [
    "### Processing and Splitting Enhanced JPG Images by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d16c279c-7c94-404b-9563-9189795260e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting AnnualCrop JPGs: 100%|██████████| 1500/1500 [01:00<00:00, 24.79it/s]\n",
      "Converting Forest JPGs: 100%|██████████| 1500/1500 [00:57<00:00, 25.91it/s]\n",
      "Converting HerbaceousVegetation JPGs: 100%|██████████| 1500/1500 [00:55<00:00, 26.81it/s]\n",
      "Converting Highway JPGs: 100%|██████████| 1250/1250 [00:45<00:00, 27.18it/s]\n",
      "Converting Industrial JPGs: 100%|██████████| 1250/1250 [00:49<00:00, 25.51it/s]\n",
      "Converting Pasture JPGs: 100%|██████████| 1000/1000 [00:39<00:00, 25.48it/s]\n",
      "Converting PermanentCrop JPGs: 100%|██████████| 1250/1250 [00:49<00:00, 25.39it/s]\n",
      "Converting Residential JPGs: 100%|██████████| 1500/1500 [01:00<00:00, 24.65it/s]\n",
      "Converting River JPGs: 100%|██████████| 1250/1250 [00:50<00:00, 24.62it/s]\n",
      "Converting SeaLake JPGs: 100%|██████████| 1500/1500 [00:56<00:00, 26.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each category\n",
    "for category in categories:\n",
    "    # Define directories for input JPG files and output JPG files\n",
    "    directory = os.path.join(path, category)  # Input directory\n",
    "    directory_train = os.path.join(path, 'dataset_splits', 'train', category)  # Output JPG directory for training set\n",
    "    directory_valid = os.path.join(path, 'dataset_splits', 'test', category)  # Output JPG directory for validation set\n",
    "    directory_test = os.path.join(path, 'dataset_splits', 'valid', category)  # Output JPG directory for test set\n",
    "    \n",
    "    # Create output directories if they do not exist\n",
    "    os.makedirs(directory_train, exist_ok=True)\n",
    "    os.makedirs(directory_valid, exist_ok=True)\n",
    "    os.makedirs(directory_test, exist_ok=True)\n",
    "    \n",
    "    # List all files in the input directory\n",
    "    try:\n",
    "        cat_files = os.listdir(directory)\n",
    "    except FileNotFoundError:\n",
    "        continue  # Skip the category if the directory does not exist\n",
    "\n",
    "    # Filter out unwanted files\n",
    "    cat_files = [file for file in cat_files if file.lower().endswith(('.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Convert JPG files \n",
    "    with tqdm(total=len(cat_files), desc=f'Converting {category} JPGs') as pbar:  # Initialize tqdm progress bar\n",
    "        for file in cat_files:\n",
    "            file_no_ext = file.split('.')[0]  # Remove file extension\n",
    "            img_in = os.path.join(directory, file)  # Input file path\n",
    "            img_out = os.path.join(directory_train, file_no_ext + '.jpg')  # Output JPG file path\n",
    "                \n",
    "            # Check if the converted JPEG file already exists in the training directory\n",
    "            if not os.path.exists(img_out):\n",
    "                success = process_image(img_in, img_out, bands=[1, 2, 3])\n",
    "                if not success:\n",
    "                    print(f\"Conversion failed for {img_in}\")\n",
    "            \n",
    "            pbar.update(1)  # Update progress bar\n",
    "    \n",
    "    # Sort files into test and validation folders\n",
    "    filenames = os.listdir(directory_train)  # List JPG files in the training directory\n",
    "    filenames.sort()  # Sort filenames alphabetically\n",
    "    if '.DS_Store' in filenames:\n",
    "        filenames.remove('.DS_Store')\n",
    "        \n",
    "    random.shuffle(filenames)  # Shuffle filenames randomly\n",
    "    split_1 = int(0.8 * len(filenames))  # Split index for training-validation split\n",
    "    split_2 = int(0.9 * len(filenames))  # Split index for validation-test split\n",
    "    train_filenames = filenames[:split_1]  # Filenames for training set\n",
    "    valid_filenames = filenames[split_1:split_2]  # Filenames for validation set\n",
    "    test_filenames = filenames[split_2:]  # Filenames for test set\n",
    "        \n",
    "    for file in os.listdir(directory_train):\n",
    "        if file in valid_filenames:\n",
    "            shutil.move(os.path.join(directory_train, file), os.path.join(directory_valid, file))  # Move to validation directory\n",
    "        elif file in test_filenames:\n",
    "            shutil.move(os.path.join(directory_train, file), os.path.join(directory_test, file))  # Move to test directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca47c37b-6924-4f3f-a4ba-3866afb61232",
   "metadata": {},
   "source": [
    "### Converting Test Images to JPEG Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bf6dd70-ae47-4f2b-bdbe-b81544fcf653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting JPGs: 100%|██████████| 5/5 [00:00<00:00, 12.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define directories for input JPG files and output JPG files\n",
    "directory = 'C:/Users/isaac/datasets/test-jpg-images' # Input JPG's\n",
    "directory_converted = 'C:/Users/isaac/datasets/converted-jpg-images' # Output JPG's\n",
    "    \n",
    "# Create output directories if they do not exist\n",
    "os.makedirs(directory_converted, exist_ok=True)\n",
    "    \n",
    "# List all files in the input directory\n",
    "try:\n",
    "    cat_files = os.listdir(directory)\n",
    "except FileNotFoundError:\n",
    "    cat_files = [] \n",
    "\n",
    "# Filter out unwanted files\n",
    "cat_files = [file for file in cat_files if file.lower().endswith(('.jpg', '.jpeg'))]\n",
    "\n",
    "# Enhance JPG files and move them to the training directory\n",
    "with tqdm(total=len(cat_files), desc=f'Converting JPGs') as pbar:  # Initialize tqdm progress bar\n",
    "    for file in cat_files:\n",
    "        file_no_ext = file.split('.')[0]  # Remove file extension\n",
    "        img_in = os.path.join(directory, file)  # Input JPG file path\n",
    "        img_out = os.path.join(directory_converted, file_no_ext + '.jpg')  # Output JPG file path\n",
    "                \n",
    "        # Check if the converted JPEG file already exists in the training directory\n",
    "        if not os.path.exists(img_out):\n",
    "            success = process_image(img_in, img_out, bands=[1, 2, 3])\n",
    "        if not success:\n",
    "            print(f\"Conversion failed for {img_in}\")\n",
    "            \n",
    "        pbar.update(1)  # Update progress bar        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b4035f-4625-4bae-a90c-f1f45314a6ff",
   "metadata": {},
   "source": [
    "By employing a structured approach, I ensure that the dataset is well-organised and ready for the training, validation and the testing phases of the development of the CNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
